{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis using encoder decoder(tweetdataset)_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Smruthi3/END2/blob/main/Session6-Assignment/Sentiment_Analysis_using_encoder_decoder(tweetdataset)_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp5IzBGsPGHs"
      },
      "source": [
        "## Dataset Preview\n",
        "\n",
        "Your first step to deep learning in NLP. We will be mostly using PyTorch. Just like torchvision, PyTorch provides an official library, torchtext, for handling text-processing pipelines. \n",
        "\n",
        "We will be using previous session tweet dataset. Let's just preview the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjF33BEnUCnT",
        "outputId": "8d3956d6-58bf-4589-ce5c-30693fa5865c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1-Yz-5RRFYc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "e37838ea-52a4-4cf0-8004-fc5be1f7d5a2"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('drive/My Drive/END2/Session5-Assignment/tweets.csv')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Obama has called the GOP budget social Darwini...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In his teen years, Obama has been known to use...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IPA Congratulates President Barack Obama for L...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @Professor_Why: #WhatsRomneyHiding - his co...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @wardollarshome: Obama has approved more ta...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              tweets  labels\n",
              "0  Obama has called the GOP budget social Darwini...       1\n",
              "1  In his teen years, Obama has been known to use...       0\n",
              "2  IPA Congratulates President Barack Obama for L...       0\n",
              "3  RT @Professor_Why: #WhatsRomneyHiding - his co...       0\n",
              "4  RT @wardollarshome: Obama has approved more ta...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7JdpCW-YbAG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18319aad-a677-425d-ae96-185be7ac5d20"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1364, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqRsoF6xYdgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a020d17f-7ec3-4ab1-880c-f7fb0a7f46ca"
      },
      "source": [
        "df.labels.value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    931\n",
              "1    352\n",
              "2     81\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ6o_79ISSVb"
      },
      "source": [
        "## Defining Fields"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e63g08ijOrf7"
      },
      "source": [
        "Now we shall be defining LABEL as a LabelField, which is a subclass of Field that sets sequen tial to False (as it’s our numerical category class). TWEET is a standard Field object, where we have decided to use the spaCy tokenizer and convert all the text to lower‐ case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk8IP4SK1Lrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c317689a-16de-4783-8520-c617e451dfc2"
      },
      "source": [
        "# Import Library\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext.legacy import data \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fda9d9a1670>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6bKQax2Mf_U"
      },
      "source": [
        "Tweet = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2nfZ3bG7IAQ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX-lYIe_O7Vy"
      },
      "source": [
        "Having defined those fields, we now need to produce a list that maps them onto the list of rows that are in the CSV:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VawdWq36O6td"
      },
      "source": [
        "fields = [('tweets', Tweet),('labels',Label)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbtZ-Ph2P1xL"
      },
      "source": [
        "Armed with our declared fields, lets convert from pandas to list to torchtext. We could also use TabularDataset to apply that definition to the CSV directly but showing an alternative approach too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3OLcJ5B7rHz"
      },
      "source": [
        "example = [data.Example.fromlist([df.tweets[i],df.labels[i]], fields) for i in range(df.shape[0])] "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT-flpH-P1cd"
      },
      "source": [
        "# Creating dataset\n",
        "#twitterDataset = data.TabularDataset(path=\"tweets.csv\", format=\"CSV\", fields=fields, skip_header=True)\n",
        "\n",
        "twitterDataset = data.Dataset(example, fields)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6ZnyCPaR08F"
      },
      "source": [
        "Finally, we can split into training, testing, and validation sets by using the split() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYXyuKhRpBk"
      },
      "source": [
        "(train, valid) = twitterDataset.split(split_ratio=[0.85, 0.15], random_state=random.seed(SEED))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpmKkoIO8vEO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykvsCGQMR6UD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deaab82d-a094-45e0-8bba-9ac020cfe1c7"
      },
      "source": [
        "(len(train), len(valid))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1159, 205)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kix8P2IKSBaV"
      },
      "source": [
        "An example from the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUpEOQruR9JL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037589bb-79a7-4d67-945d-0c19e7938241"
      },
      "source": [
        "vars(train.examples[10])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': 0,\n",
              " 'tweets': ['Obama',\n",
              "  ',',\n",
              "  'Romney',\n",
              "  'agree',\n",
              "  ':',\n",
              "  'Admit',\n",
              "  'women',\n",
              "  'to',\n",
              "  'Augusta',\n",
              "  'golf',\n",
              "  'club',\n",
              "  ':',\n",
              "  'US',\n",
              "  'President',\n",
              "  'Barack',\n",
              "  'Obama',\n",
              "  'believes',\n",
              "  'women',\n",
              "  'should',\n",
              "  'be',\n",
              "  'allowe',\n",
              "  '...',\n",
              "  'http://t.co/PVKrepqI']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKdllP3FST4N"
      },
      "source": [
        "## Building Vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuvWQ-SpSmSz"
      },
      "source": [
        "At this point we would have built a one-hot encoding of each word that is present in the dataset—a rather tedious process. Thankfully, torchtext will do this for us, and will also allow a max_size parameter to be passed in to limit the vocabu‐ lary to the most common words. This is normally done to prevent the construction of a huge, memory-hungry model. We don’t want our GPUs too overwhelmed, after all. \n",
        "\n",
        "Let’s limit the vocabulary to a maximum of 5000 words in our training set:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx955u93SGeY"
      },
      "source": [
        "Tweet.build_vocab(train,max_size=5000)\n",
        "Label.build_vocab(train,max_size=5000)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvyEeEjXTGhX"
      },
      "source": [
        "By default, torchtext will add two more special tokens, <unk> for unknown words and <pad>, a padding token that will be used to pad all our text to roughly the same size to help with efficient batching on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA3tIESdcJdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82428236-12c4-4cbc-d0d8-3d96fbf17149"
      },
      "source": [
        "print('Size of input vocab : ', len(Tweet.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Tweet.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  4651\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [('Obama', 1069), (':', 783), ('#', 780), ('.', 761), (',', 598), ('\"', 550), ('the', 542), ('RT', 516), ('?', 419), ('to', 400)]\n",
            "Labels :  defaultdict(None, {0: 0, 1: 1, 2: 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwjD2-ebTeUX"
      },
      "source": [
        "**Lots of stopwords!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLWW221gTpNs"
      },
      "source": [
        "Now we need to create a data loader to feed into our training loop. Torchtext provides the BucketIterator method that will produce what it calls a Batch, which is almost, but not quite, like the data loader we used on images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQqMhMoDUDmn"
      },
      "source": [
        "But at first declare the device we are using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfo2QhGJUK4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d58658c4-3e20-4f82-98f1-6a59e7080064"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK2ORoqdTNsM"
      },
      "source": [
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.tweets),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg7gTFQO4fby"
      },
      "source": [
        "Save the vocabulary for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niE9Cc6-2bD_"
      },
      "source": [
        "import os, pickle\n",
        "with open('drive/My Drive/END2/Session6-Assignment/tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Tweet.vocab.stoi, tokens)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AbsQwqkVyAy"
      },
      "source": [
        "## Defining Our Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wt6Jlgiei4C"
      },
      "source": [
        "### Defining encoder class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0xer9hSnIef"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,input_dim,emb_dim,hid_dim,n_layers):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hid_dim=hid_dim\n",
        "    self.embedding = nn.Embedding(input_dim, emb_dim) \n",
        "    self.rnn= nn.LSTM(emb_dim, hid_dim,  num_layers=n_layers, batch_first=True)\n",
        "\n",
        "  def forward(self, text,text_lengths):\n",
        "\n",
        "      embedded =self.embedding(text)\n",
        "\n",
        "      packaged_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "\n",
        "      packed_output, (hidden, cell) = self.rnn(packaged_embedded)\n",
        "\n",
        "      print(f'Output of encoder at every step:{packed_output[0]}') ## output of each word is stroed in packaged output, it keeps appending the hidden vector after every step that is nothing but after every word\n",
        "\n",
        "      print(f'Output of encoder at last step:{hidden}') ### Hidden contains output of last time step\n",
        "    \n",
        "      return hidden,cell\n",
        "\n"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqrxoNdwenof"
      },
      "source": [
        "### Defining Decoder class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_-5XyFd4Usp"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self,out_dim,hid_dim,n_layers):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hid_dim = hid_dim\n",
        "\n",
        "    self.out_dim = out_dim\n",
        "\n",
        "    self.rnn= nn.LSTM(hid_dim,hid_dim, num_layers=n_layers)\n",
        "\n",
        "    self.fc = nn.Linear(hid_dim,out_dim)\n",
        "\n",
        "\n",
        "  def forward(self,input,hidden,cell):\n",
        "\n",
        "    output , (hidden,cell) = self.rnn(hidden,(hidden,cell))\n",
        "\n",
        "    print(f'Output of decoder at every step (Note that here it is single step):{output[0]}')\n",
        "\n",
        "    prediction = self.fc(hidden.squeeze(0))\n",
        "\n",
        "    return prediction,hidden,cell\n",
        "\n",
        "\n",
        "    \n"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNNXgmBCesAw"
      },
      "source": [
        "### Combining encoder decoder "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs321eMOB63M"
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "        print(encoder.hid_dim)\n",
        "        print(decoder.hid_dim)\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim\n",
        "        \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        \n",
        "    def forward(self, text, text_len):\n",
        "\n",
        "        #hidden, cell = self.encoder(text,text_len)\n",
        "\n",
        "        hidden, cell = self.encoder(text,text_len)\n",
        "        \n",
        "        input = hidden\n",
        "\n",
        "        output,hidden,cell = self.decoder(input,hidden,cell)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ce35h9JVkTN7",
        "outputId": "33980ec4-d44b-499d-9ff7-c1cb47be8077"
      },
      "source": [
        "INPUT_DIM = len(Tweet.vocab)\n",
        "OUTPUT_DIM = len(Label.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "NUM_LAYERS = 1\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM,NUM_LAYERS)\n",
        "dec = Decoder(OUTPUT_DIM,HID_DIM,NUM_LAYERS)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = EncoderDecoder(enc, dec, device).to(device)"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n",
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uno1tM8f8nsp",
        "outputId": "f3cf9395-d8c1-4d28-dd27-60466ced7bdc"
      },
      "source": [
        "model"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EncoderDecoder(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(4651, 256)\n",
              "    (rnn): LSTM(256, 512, batch_first=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (rnn): LSTM(512, 512)\n",
              "    (fc): Linear(in_features=512, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79EhXrtwe1Ao"
      },
      "source": [
        "### Defining loss and accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP5cTPh98Okg"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "    \n",
        "# push to cuda if available\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--u24wTqfHGp"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na7QT7ru9GF5"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        tweet, tweet_lengths = batch.tweets   \n",
        "\n",
        "  \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(tweet, tweet_lengths).squeeze()  \n",
        "\n",
        "        # output_dim = predictions.shape[-1]\n",
        "        \n",
        "        # predictions = predictions[1:].view(-1, output_dim)\n",
        "        # batch.labels = batch.labels[1:].view(-1)\n",
        "        \n",
        "        \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.labels)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        #acc = binary_accuracy(predictions, batch.labels)   \n",
        "        acc = categorical_accuracy(predictions, batch.labels)   \n",
        "\n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()  \n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzmLairPfSRs"
      },
      "source": [
        "### Evaluation Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6klmVjLo-QIH"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            tweet, tweet_lengths = batch.tweets \n",
        "            \n",
        "            #print(batch.labels.shape)\n",
        "\n",
        "            # convert to 1d tensor\n",
        "            predictions = model(tweet, tweet_lengths).squeeze()\n",
        "\n",
        "            # output_dim = predictions.shape[-1]\n",
        "        \n",
        "            # predictions = predictions[1:].view(-1, output_dim)\n",
        "            # batch.labels = batch.labels[1:].view(-1)\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.labels)\n",
        "\n",
        "            # acc = binary_accuracy(predictions, batch.labels)\n",
        "            acc = categorical_accuracy(predictions, batch.labels)   \n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R87A5IoCfVNl"
      },
      "source": [
        "### Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW4TYgnR-XdY",
        "outputId": "8ffdc777-0e96-440f-9a11-ca1b2d3ce5d6"
      },
      "source": [
        "\n",
        "N_EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'drive/My Drive/END2/Session6-Assignment/encoder_decoder_classification_saved_weights.pt')\n",
        "    \n",
        "    print(f'\\t Epoch: {epoch} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Epoch: {epoch} | Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "        [-0.1268, -0.0867,  0.0819,  ..., -0.0093, -0.1566, -0.0790],\n",
            "        [ 0.1261, -0.1523, -0.2224,  ...,  0.0828,  0.0519, -0.1369]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0202,  0.0718,  0.0827,  ..., -0.2809,  0.0009, -0.0863],\n",
            "         [ 0.0925,  0.4877, -0.1284,  ...,  0.3361, -0.1198,  0.0461],\n",
            "         [ 0.2777,  0.1316,  0.0337,  ..., -0.0521, -0.1474, -0.1820],\n",
            "         ...,\n",
            "         [ 0.1864,  0.1036, -0.0098,  ...,  0.0638, -0.1617, -0.0381],\n",
            "         [-0.1268, -0.0867,  0.0819,  ..., -0.0093, -0.1566, -0.0790],\n",
            "         [ 0.1261, -0.1523, -0.2224,  ...,  0.0828,  0.0519, -0.1369]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0198,  0.0804,  0.0372,  ..., -0.1678,  0.0232, -0.1052],\n",
            "        [ 0.3755,  0.6234, -0.1780,  ...,  0.4969,  0.0479, -0.0357],\n",
            "        [ 0.1792,  0.0935,  0.1250,  ...,  0.0687, -0.3137, -0.2698],\n",
            "        ...,\n",
            "        [ 0.0077, -0.0162,  0.0837,  ...,  0.0343, -0.2843, -0.0734],\n",
            "        [-0.0517, -0.0051, -0.0233,  ...,  0.0244,  0.0425, -0.0795],\n",
            "        [ 0.1478,  0.0078, -0.0751,  ...,  0.1211,  0.0025, -0.1252]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.1209,  0.0677, -0.0745,  ..., -0.0614, -0.0164,  0.0371],\n",
            "        [ 0.1295,  0.0248, -0.0710,  ...,  0.0424,  0.0214, -0.0267],\n",
            "        [-0.0614, -0.0056,  0.0561,  ...,  0.1045, -0.0732,  0.0823],\n",
            "        ...,\n",
            "        [ 0.1208,  0.0076,  0.0062,  ...,  0.1944, -0.1079, -0.0900],\n",
            "        [-0.0399,  0.0637,  0.0665,  ..., -0.0612, -0.0984, -0.0898],\n",
            "        [ 0.1673,  0.1795,  0.2193,  ...,  0.0040,  0.0360,  0.0275]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0034, -0.0006,  0.1175,  ...,  0.0207,  0.1416,  0.1038],\n",
            "         [ 0.0356, -0.1143, -0.0492,  ...,  0.0980, -0.0824,  0.0312],\n",
            "         [ 0.1504, -0.0035, -0.0552,  ...,  0.0677,  0.0402, -0.0938],\n",
            "         ...,\n",
            "         [-0.0022,  0.3008,  0.2461,  ...,  0.0922, -0.0481, -0.1319],\n",
            "         [ 0.0376, -0.0912, -0.1071,  ...,  0.0712, -0.1626, -0.1378],\n",
            "         [ 0.2515,  0.0991, -0.0329,  ...,  0.1241, -0.3181, -0.1398]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0641, -0.0527,  0.2650,  ...,  0.0386, -0.1498, -0.1006],\n",
            "        [-0.0991, -0.0844, -0.0188,  ...,  0.0135, -0.0509,  0.0573],\n",
            "        [ 0.1523, -0.0396,  0.1336,  ...,  0.0426, -0.2384, -0.2352],\n",
            "        ...,\n",
            "        [ 0.2008,  0.3648,  0.2732,  ...,  0.1912, -0.3131, -0.3106],\n",
            "        [ 0.0043, -0.0525,  0.0925,  ...,  0.0899, -0.3060, -0.2183],\n",
            "        [ 0.1647,  0.0559,  0.1624,  ...,  0.1281, -0.3865, -0.2296]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0601,  0.0769, -0.0157,  ..., -0.0369,  0.0101,  0.0763],\n",
            "        [-0.0601,  0.0769, -0.0157,  ..., -0.0369,  0.0101,  0.0763],\n",
            "        [-0.0601,  0.0769, -0.0157,  ..., -0.0369,  0.0101,  0.0763],\n",
            "        ...,\n",
            "        [-0.1023,  0.0183,  0.1449,  ..., -0.0412,  0.0602,  0.1618],\n",
            "        [ 0.2511,  0.1449,  0.2581,  ...,  0.2080, -0.0937, -0.1914],\n",
            "        [ 0.3078, -0.0068, -0.0370,  ...,  0.0318, -0.1097, -0.0613]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0917,  0.0994,  0.0008,  ...,  0.0029, -0.0549, -0.0985],\n",
            "         [-0.1023,  0.0183,  0.1449,  ..., -0.0412,  0.0602,  0.1618],\n",
            "         [ 0.2511,  0.1449,  0.2581,  ...,  0.2080, -0.0937, -0.1914],\n",
            "         ...,\n",
            "         [-0.1385, -0.3925,  0.0788,  ..., -0.0903, -0.1566, -0.2702],\n",
            "         [-0.1955,  0.1395,  0.0649,  ...,  0.0877, -0.3733, -0.1279],\n",
            "         [ 0.1429,  0.1518,  0.0263,  ...,  0.3354, -0.1157, -0.2177]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 3.5670e-04,  1.2885e-01,  4.5604e-02,  ...,  8.0338e-02,\n",
            "         -1.5761e-01, -1.5187e-01],\n",
            "        [-1.0973e-01,  1.7145e-02,  1.0173e-01,  ..., -7.4968e-02,\n",
            "          7.5950e-02,  1.2335e-01],\n",
            "        [ 1.9267e-01, -8.7793e-02,  5.1638e-01,  ...,  7.6519e-02,\n",
            "         -4.4970e-01, -3.5964e-01],\n",
            "        ...,\n",
            "        [ 1.3934e-01, -4.3707e-01,  2.8172e-01,  ..., -1.4903e-02,\n",
            "         -4.2905e-01, -3.7143e-01],\n",
            "        [ 1.5839e-01,  3.5840e-01,  8.7664e-02,  ...,  2.6412e-01,\n",
            "         -2.8716e-01, -4.0571e-01],\n",
            "        [ 3.0429e-01,  3.1384e-01,  1.3795e-02,  ...,  2.6387e-01,\n",
            "         -1.0497e-01, -2.4202e-01]], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0604,  0.0769, -0.0157,  ..., -0.0367,  0.0099,  0.0759],\n",
            "        [ 0.2915, -0.0373,  0.0864,  ...,  0.3072, -0.1524, -0.1359],\n",
            "        [ 0.0570,  0.1782, -0.0250,  ..., -0.0401,  0.1106,  0.0918],\n",
            "        ...,\n",
            "        [ 0.1426,  0.1991,  0.2285,  ...,  0.1499, -0.2436, -0.0457],\n",
            "        [-0.1187, -0.3434,  0.1174,  ..., -0.0720,  0.1117, -0.0263],\n",
            "        [-0.0337, -0.2406,  0.0743,  ...,  0.0526, -0.1862,  0.2201]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1187, -0.3434,  0.1174,  ..., -0.0720,  0.1117, -0.0263],\n",
            "         [-0.0337, -0.2406,  0.0743,  ...,  0.0526, -0.1862,  0.2201],\n",
            "         [ 0.1000, -0.1897,  0.1149,  ...,  0.0784, -0.2526, -0.1431],\n",
            "         ...,\n",
            "         [ 0.1844, -0.3531,  0.1963,  ..., -0.0937, -0.2220, -0.1001],\n",
            "         [ 0.1648, -0.0202,  0.2145,  ..., -0.0919, -0.3185,  0.0459],\n",
            "         [ 0.1426,  0.1991,  0.2285,  ...,  0.1499, -0.2436, -0.0457]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-1.5095e-01, -1.3014e-01, -1.3671e-02,  ..., -1.0830e-01,\n",
            "          1.5247e-01,  4.9473e-02],\n",
            "        [-1.7198e-02, -6.8758e-02, -2.5633e-03,  ..., -3.9263e-03,\n",
            "         -4.8134e-05,  1.5709e-01],\n",
            "        [ 1.1373e-01, -2.1653e-01,  2.1582e-01,  ..., -3.1400e-04,\n",
            "         -2.9702e-01, -2.3578e-01],\n",
            "        ...,\n",
            "        [-6.1224e-02, -4.3667e-01,  5.4459e-01,  ..., -1.7716e-01,\n",
            "         -6.2110e-01, -3.5022e-01],\n",
            "        [ 2.5561e-01,  7.7513e-02,  1.8591e-01,  ...,  4.4862e-02,\n",
            "         -3.4302e-01, -1.0116e-01],\n",
            "        [ 1.5635e-01,  1.8165e-01,  2.1581e-01,  ...,  1.2521e-01,\n",
            "         -4.0257e-01, -1.9878e-01]], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2223,  0.0197, -0.0019,  ...,  0.1955,  0.0520,  0.0770],\n",
            "        [ 0.2910, -0.0388,  0.0851,  ...,  0.3048, -0.1509, -0.1344],\n",
            "        [ 0.1020, -0.0193, -0.0256,  ...,  0.0625, -0.1272, -0.0490],\n",
            "        ...,\n",
            "        [ 0.1321, -0.1661, -0.0032,  ..., -0.1102,  0.0481, -0.0616],\n",
            "        [ 0.1880,  0.0848,  0.2805,  ..., -0.0659,  0.0721, -0.0413],\n",
            "        [ 0.2324, -0.0681,  0.1463,  ..., -0.0425, -0.1768, -0.1087]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1321, -0.1661, -0.0032,  ..., -0.1102,  0.0481, -0.0616],\n",
            "         [ 0.1880,  0.0848,  0.2805,  ..., -0.0659,  0.0721, -0.0413],\n",
            "         [ 0.2324, -0.0681,  0.1463,  ..., -0.0425, -0.1768, -0.1087],\n",
            "         ...,\n",
            "         [ 0.0737,  0.1316, -0.0418,  ...,  0.2108,  0.1671,  0.0622],\n",
            "         [ 0.0749, -0.0294, -0.1307,  ...,  0.0510, -0.0649, -0.0753],\n",
            "         [-0.0069, -0.1313, -0.1035,  ..., -0.1107,  0.1195, -0.1164]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0778, -0.0681,  0.0516,  ..., -0.0626, -0.0206, -0.0694],\n",
            "        [ 0.2667,  0.0400,  0.3699,  ...,  0.0091, -0.2246, -0.2136],\n",
            "        [ 0.0216, -0.1708,  0.3495,  ..., -0.0713, -0.3227, -0.1783],\n",
            "        ...,\n",
            "        [ 0.0804,  0.0817,  0.0090,  ...,  0.1091,  0.0114,  0.0030],\n",
            "        [ 0.0455, -0.0246, -0.0193,  ...,  0.0147, -0.0714, -0.0862],\n",
            "        [-0.0031, -0.0816, -0.0085,  ..., -0.0611,  0.0632,  0.0235]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1165, -0.0644, -0.1009,  ..., -0.0762,  0.0516, -0.1783],\n",
            "        [ 0.1165, -0.0644, -0.1009,  ..., -0.0762,  0.0516, -0.1783],\n",
            "        [ 0.1165, -0.0644, -0.1009,  ..., -0.0762,  0.0516, -0.1783],\n",
            "        ...,\n",
            "        [ 0.1511, -0.1932, -0.1099,  ..., -0.0974,  0.0286, -0.2518],\n",
            "        [ 0.0979,  0.3045,  0.0265,  ...,  0.0712, -0.2434,  0.0287],\n",
            "        [ 0.1511, -0.1932, -0.1099,  ..., -0.0974,  0.0286, -0.2518]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1822, -0.3720,  0.1937,  ..., -0.1036, -0.2209, -0.1014],\n",
            "         [ 0.1822, -0.3720,  0.1937,  ..., -0.1036, -0.2209, -0.1014],\n",
            "         [ 0.1822, -0.3720,  0.1937,  ..., -0.1036, -0.2209, -0.1014],\n",
            "         ...,\n",
            "         [-0.1181, -0.1091,  0.0909,  ..., -0.0234, -0.1640, -0.0847],\n",
            "         [-0.1063,  0.0231,  0.0993,  ..., -0.0562, -0.1658, -0.2178],\n",
            "         [-0.1181, -0.1091,  0.0909,  ..., -0.0234, -0.1640, -0.0847]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-6.4916e-02, -4.3939e-01,  5.5322e-01,  ..., -1.7819e-01,\n",
            "         -6.2884e-01, -3.5032e-01],\n",
            "        [-6.4916e-02, -4.3939e-01,  5.5322e-01,  ..., -1.7819e-01,\n",
            "         -6.2884e-01, -3.5032e-01],\n",
            "        [-6.4916e-02, -4.3939e-01,  5.5322e-01,  ..., -1.7819e-01,\n",
            "         -6.2884e-01, -3.5032e-01],\n",
            "        ...,\n",
            "        [-5.6158e-02, -4.7862e-02, -5.2892e-04,  ...,  3.0780e-03,\n",
            "          3.0308e-02, -9.4123e-02],\n",
            "        [-9.5150e-02, -1.7515e-01,  3.9828e-01,  ..., -1.1736e-01,\n",
            "         -4.7369e-01, -3.4311e-01],\n",
            "        [-5.6158e-02, -4.7862e-02, -5.2892e-04,  ...,  3.0780e-03,\n",
            "          3.0308e-02, -9.4123e-02]], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0607,  0.0770, -0.0155,  ..., -0.0362,  0.0089,  0.0746],\n",
            "        [ 0.2893, -0.0401,  0.0814,  ...,  0.3028, -0.1470, -0.1318],\n",
            "        [-0.0607,  0.0770, -0.0155,  ..., -0.0362,  0.0089,  0.0746],\n",
            "        ...,\n",
            "        [ 0.2120, -0.2965,  0.1552,  ...,  0.2226, -0.0986, -0.0784],\n",
            "        [ 0.1282,  0.3152, -0.0221,  ...,  0.0825, -0.2005, -0.0690],\n",
            "        [ 0.2349, -0.1996,  0.2364,  ...,  0.1002, -0.1985, -0.1464]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1282,  0.3152, -0.0221,  ...,  0.0825, -0.2005, -0.0690],\n",
            "         [ 0.2349, -0.1996,  0.2364,  ...,  0.1002, -0.1985, -0.1464],\n",
            "         [ 0.2821,  0.1173,  0.0158,  ...,  0.0355, -0.2512,  0.0269],\n",
            "         ...,\n",
            "         [-0.2813,  0.0753,  0.1131,  ...,  0.1337, -0.1826, -0.0603],\n",
            "         [-0.2813,  0.0753,  0.1131,  ...,  0.1337, -0.1826, -0.0603],\n",
            "         [-0.2194, -0.0049, -0.0103,  ..., -0.0005, -0.1349, -0.0523]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1647,  0.2182,  0.1215,  ...,  0.1427, -0.2578, -0.2439],\n",
            "        [ 0.1633, -0.1757,  0.3371,  ...,  0.1033, -0.3842, -0.2994],\n",
            "        [ 0.1965, -0.0034,  0.3023,  ..., -0.0336, -0.4881, -0.1318],\n",
            "        ...,\n",
            "        [ 0.0676,  0.3986, -0.0556,  ...,  0.2950,  0.0486, -0.2200],\n",
            "        [ 0.0676,  0.3986, -0.0556,  ...,  0.2950,  0.0486, -0.2200],\n",
            "        [-0.0325,  0.2126, -0.0997,  ...,  0.1196,  0.0729, -0.0861]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0605,  0.0770, -0.0152,  ..., -0.0361,  0.0087,  0.0741],\n",
            "        [-0.0605,  0.0770, -0.0152,  ..., -0.0361,  0.0087,  0.0741],\n",
            "        [-0.0605,  0.0770, -0.0152,  ..., -0.0361,  0.0087,  0.0741],\n",
            "        ...,\n",
            "        [ 0.4394, -0.4080,  0.0653,  ...,  0.0879, -0.0605, -0.3065],\n",
            "        [ 0.4394, -0.4080,  0.0653,  ...,  0.0879, -0.0605, -0.3065],\n",
            "        [ 0.4394, -0.4080,  0.0653,  ...,  0.0879, -0.0605, -0.3065]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.4394, -0.4080,  0.0653,  ...,  0.0879, -0.0605, -0.3065],\n",
            "         [ 0.4394, -0.4080,  0.0653,  ...,  0.0879, -0.0605, -0.3065],\n",
            "         [ 0.4394, -0.4080,  0.0653,  ...,  0.0879, -0.0605, -0.3065],\n",
            "         ...,\n",
            "         [-0.0616, -0.1577,  0.0629,  ..., -0.0201, -0.2025, -0.1146],\n",
            "         [ 0.2447,  0.1107,  0.2519,  ...,  0.1834, -0.0905, -0.1835],\n",
            "         [ 0.2533,  0.1346,  0.1393,  ...,  0.0412, -0.3458, -0.1579]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3076, -0.4864,  0.4756,  ..., -0.0800, -0.5308, -0.5669],\n",
            "        [ 0.3076, -0.4864,  0.4756,  ..., -0.0800, -0.5308, -0.5669],\n",
            "        [ 0.3076, -0.4864,  0.4756,  ..., -0.0800, -0.5308, -0.5669],\n",
            "        ...,\n",
            "        [ 0.0465, -0.3457,  0.3392,  ..., -0.0841, -0.4385, -0.3743],\n",
            "        [ 0.1488, -0.1508,  0.5303,  ...,  0.0372, -0.4597, -0.3452],\n",
            "        [ 0.2165,  0.0787,  0.2123,  ...,  0.0928, -0.4402, -0.2917]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0604,  0.0770, -0.0149,  ..., -0.0360,  0.0084,  0.0736],\n",
            "        [-0.0604,  0.0770, -0.0149,  ..., -0.0360,  0.0084,  0.0736],\n",
            "        [-0.2068, -0.0005,  0.1103,  ..., -0.1004, -0.0004, -0.0542],\n",
            "        ...,\n",
            "        [ 0.0689, -0.1347,  0.0212,  ..., -0.1887, -0.0252, -0.0748],\n",
            "        [ 0.0482,  0.1509,  0.1024,  ..., -0.0399,  0.1447,  0.1279],\n",
            "        [ 0.1180, -0.0349,  0.0608,  ...,  0.0767,  0.1425, -0.0382]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1395,  0.0528,  0.2617,  ...,  0.2519, -0.1895, -0.1567],\n",
            "         [-0.0691, -0.2022,  0.2473,  ..., -0.2383, -0.1021, -0.0673],\n",
            "         [ 0.1509, -0.0695,  0.0795,  ..., -0.1008,  0.0304, -0.1161],\n",
            "         ...,\n",
            "         [ 0.1170,  0.1835,  0.0616,  ...,  0.0888, -0.2103, -0.1284],\n",
            "         [ 0.2592, -0.1035, -0.0197,  ...,  0.3321, -0.2087, -0.1172],\n",
            "         [ 0.0631,  0.0266,  0.0393,  ..., -0.1147,  0.1088,  0.0850]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1487, -0.1003,  0.4226,  ...,  0.1005, -0.4634, -0.3188],\n",
            "        [-0.1309, -0.3794,  0.5195,  ..., -0.2170, -0.4615, -0.2987],\n",
            "        [ 0.0425, -0.1717,  0.3160,  ..., -0.1248, -0.2574, -0.1803],\n",
            "        ...,\n",
            "        [ 0.2252,  0.1854,  0.1329,  ...,  0.1486, -0.2145, -0.2255],\n",
            "        [ 0.2095, -0.0046,  0.0787,  ...,  0.1847, -0.2304, -0.1449],\n",
            "        [ 0.0352, -0.0539,  0.1785,  ..., -0.0658, -0.1048,  0.0044]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0987, -0.0197, -0.0284,  ...,  0.0622, -0.1238, -0.0479],\n",
            "        [ 0.0987, -0.0197, -0.0284,  ...,  0.0622, -0.1238, -0.0479],\n",
            "        [-0.0452, -0.2382,  0.0082,  ...,  0.1222,  0.0484, -0.1317],\n",
            "        ...,\n",
            "        [-0.1940, -0.3336,  0.1336,  ..., -0.0861, -0.3357, -0.0909],\n",
            "        [ 0.2011, -0.1329,  0.2790,  ...,  0.0459,  0.1075, -0.1783],\n",
            "        [ 0.1116,  0.2567,  0.2082,  ..., -0.0812, -0.0778, -0.3463]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3684, -0.1784, -0.0922,  ..., -0.0030, -0.0307, -0.2329],\n",
            "         [ 0.4015, -0.1995,  0.0783,  ...,  0.2979, -0.1997, -0.2151],\n",
            "         [ 0.1554, -0.0295,  0.2457,  ...,  0.1874, -0.0383, -0.1850],\n",
            "         ...,\n",
            "         [ 0.4105, -0.0410,  0.1350,  ...,  0.0681, -0.1188, -0.1669],\n",
            "         [ 0.0539,  0.0455, -0.0038,  ..., -0.1078,  0.2728,  0.1904],\n",
            "         [-0.0464, -0.2878,  0.1433,  ..., -0.0864, -0.0912, -0.0980]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2985, -0.2619,  0.2837,  ..., -0.0700, -0.4444, -0.4293],\n",
            "        [ 0.2663, -0.2331,  0.2984,  ...,  0.0797, -0.4402, -0.2887],\n",
            "        [ 0.1599, -0.2261,  0.4065,  ...,  0.0509, -0.2495, -0.2693],\n",
            "        ...,\n",
            "        [ 0.1670, -0.2436,  0.4791,  ..., -0.0369, -0.5333, -0.3648],\n",
            "        [ 0.0177, -0.0573,  0.1455,  ..., -0.1050,  0.0241,  0.0587],\n",
            "        [-0.1403, -0.2831,  0.3498,  ..., -0.1384, -0.3008, -0.1829]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0600,  0.0772, -0.0146,  ..., -0.0356,  0.0081,  0.0725],\n",
            "        [-0.0600,  0.0772, -0.0146,  ..., -0.0356,  0.0081,  0.0725],\n",
            "        [-0.0600,  0.0772, -0.0146,  ..., -0.0356,  0.0081,  0.0725],\n",
            "        ...,\n",
            "        [ 0.1282,  0.0720,  0.2450,  ...,  0.1774, -0.1316, -0.2128],\n",
            "        [ 0.0803,  0.1119,  0.3420,  ...,  0.1637,  0.0139, -0.1101],\n",
            "        [ 0.4087, -0.0383,  0.1317,  ...,  0.0720, -0.1188, -0.1669]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0598,  0.1120,  0.0994,  ..., -0.0842, -0.1248, -0.0954],\n",
            "         [ 0.3280, -0.1177,  0.0657,  ..., -0.0535, -0.0672, -0.1795],\n",
            "         [ 0.3280, -0.1177,  0.0657,  ..., -0.0535, -0.0672, -0.1795],\n",
            "         ...,\n",
            "         [ 0.1282,  0.0720,  0.2450,  ...,  0.1774, -0.1316, -0.2128],\n",
            "         [ 0.0803,  0.1119,  0.3420,  ...,  0.1637,  0.0139, -0.1101],\n",
            "         [ 0.4087, -0.0383,  0.1317,  ...,  0.0720, -0.1188, -0.1669]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0511, -0.1548,  0.3654,  ..., -0.1302, -0.4526, -0.2900],\n",
            "        [ 0.0925, -0.2102,  0.3342,  ..., -0.0728, -0.4154, -0.3164],\n",
            "        [ 0.0925, -0.2102,  0.3342,  ..., -0.0728, -0.4154, -0.3164],\n",
            "        ...,\n",
            "        [ 0.1752,  0.0129,  0.3629,  ...,  0.1320, -0.3253, -0.2621],\n",
            "        [ 0.0920, -0.0573,  0.3878,  ...,  0.0803, -0.2415, -0.2574],\n",
            "        [ 0.1690, -0.2390,  0.4745,  ..., -0.0321, -0.5305, -0.3637]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.2301,  0.1137,  0.0190,  ...,  0.0923, -0.1269,  0.1269],\n",
            "        [-0.0076,  0.1069, -0.0426,  ..., -0.0539,  0.1044, -0.1148],\n",
            "        [ 0.2865, -0.0362,  0.0721,  ...,  0.3065, -0.1381, -0.1283],\n",
            "        ...,\n",
            "        [ 0.0657,  0.4047, -0.0765,  ..., -0.0813, -0.0566, -0.1770],\n",
            "        [ 0.1613, -0.1002,  0.1449,  ..., -0.0270, -0.0390,  0.0239],\n",
            "        [-0.1675,  0.0568,  0.2561,  ..., -0.1025,  0.1847, -0.0556]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0098,  0.0569,  0.0174,  ..., -0.1414, -0.0214,  0.1588],\n",
            "         [-0.1143, -0.0796, -0.0535,  ...,  0.0371, -0.0919,  0.1211],\n",
            "         [ 0.2376, -0.0018,  0.1041,  ...,  0.1209,  0.1162,  0.1126],\n",
            "         ...,\n",
            "         [ 0.0976,  0.0423,  0.1302,  ...,  0.1684, -0.0843, -0.2403],\n",
            "         [ 0.3599, -0.2886,  0.1782,  ...,  0.0628, -0.0308, -0.1097],\n",
            "         [ 0.3400, -0.0524,  0.1713,  ..., -0.2058, -0.0826, -0.2169]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0567,  0.0164,  0.1093,  ..., -0.1028, -0.0315,  0.1152],\n",
            "        [-0.0234, -0.0073,  0.0014,  ...,  0.0208, -0.0367,  0.0417],\n",
            "        [ 0.1155, -0.0648,  0.2294,  ...,  0.0642, -0.0835, -0.0138],\n",
            "        ...,\n",
            "        [ 0.0505, -0.0433,  0.1656,  ...,  0.0783, -0.1666, -0.2073],\n",
            "        [ 0.2447, -0.3042,  0.3898,  ...,  0.0052, -0.4074, -0.3318],\n",
            "        [ 0.1337, -0.1636,  0.4048,  ..., -0.1683, -0.3836, -0.3108]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0986, -0.0181, -0.0297,  ...,  0.0621, -0.1210, -0.0473],\n",
            "        [-0.0594,  0.0775, -0.0143,  ..., -0.0352,  0.0079,  0.0714],\n",
            "        [ 0.2877, -0.0345,  0.0722,  ...,  0.3078, -0.1362, -0.1273],\n",
            "        ...,\n",
            "        [ 0.3316, -0.0224, -0.0956,  ..., -0.0410, -0.0071, -0.2455],\n",
            "        [ 0.2335,  0.1382, -0.1173,  ...,  0.0425,  0.0065, -0.2039],\n",
            "        [ 0.1799, -0.1088, -0.0489,  ..., -0.1039, -0.0719, -0.1155]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1108, -0.0661, -0.0339,  ...,  0.0903, -0.1425, -0.0154],\n",
            "         [ 0.1269,  0.0306,  0.0109,  ...,  0.1342,  0.0082,  0.0375],\n",
            "         [-0.2856,  0.3158,  0.1282,  ...,  0.0509, -0.1610, -0.0681],\n",
            "         ...,\n",
            "         [ 0.3316, -0.0224, -0.0956,  ..., -0.0410, -0.0071, -0.2455],\n",
            "         [ 0.2335,  0.1382, -0.1173,  ...,  0.0425,  0.0065, -0.2039],\n",
            "         [ 0.1799, -0.1088, -0.0489,  ..., -0.1039, -0.0719, -0.1155]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0853, -0.1018,  0.0336,  ...,  0.0125, -0.1655,  0.0080],\n",
            "        [ 0.0565, -0.0322,  0.2000,  ...,  0.0930, -0.2872, -0.1282],\n",
            "        [ 0.1140,  0.5324, -0.0208,  ...,  0.3044,  0.0295, -0.2635],\n",
            "        ...,\n",
            "        [ 0.2401, -0.0468,  0.1373,  ..., -0.0130, -0.2883, -0.3610],\n",
            "        [ 0.2525,  0.0679,  0.1880,  ..., -0.0018, -0.3508, -0.3897],\n",
            "        [ 0.1328, -0.1495,  0.1391,  ..., -0.0228, -0.2998, -0.2266]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1479,  0.0190,  0.0533,  ...,  0.1080, -0.0342,  0.0801],\n",
            "        [-0.2243, -0.0502, -0.0334,  ...,  0.1521, -0.1686, -0.0764],\n",
            "        [ 0.1026, -0.0413,  0.0935,  ..., -0.1140, -0.1203, -0.1340],\n",
            "        ...,\n",
            "        [-0.1207,  0.0037,  0.0888,  ...,  0.0407, -0.2016, -0.0974],\n",
            "        [-0.1160,  0.2155,  0.2195,  ..., -0.0774, -0.0807,  0.1271],\n",
            "        [-0.1253, -0.0108,  0.1422,  ...,  0.1842, -0.0921, -0.0814]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0069,  0.1308, -0.0322,  ...,  0.0913, -0.0775, -0.0134],\n",
            "         [ 0.1868, -0.0035, -0.0957,  ...,  0.0772,  0.0117, -0.0992],\n",
            "         [ 0.1986,  0.0796,  0.0060,  ..., -0.0947, -0.2755, -0.1107],\n",
            "         ...,\n",
            "         [-0.1207,  0.0037,  0.0888,  ...,  0.0407, -0.2016, -0.0974],\n",
            "         [-0.1160,  0.2155,  0.2195,  ..., -0.0774, -0.0807,  0.1271],\n",
            "         [-0.1253, -0.0108,  0.1422,  ...,  0.1842, -0.0921, -0.0814]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0329,  0.0241,  0.1472,  ..., -0.0007, -0.2608, -0.1125],\n",
            "        [ 0.3353,  0.1354, -0.0399,  ...,  0.1478, -0.1372, -0.2106],\n",
            "        [ 0.1507,  0.1570,  0.0984,  ...,  0.0290, -0.3489, -0.2398],\n",
            "        ...,\n",
            "        [ 0.0399,  0.1322, -0.0335,  ...,  0.1351,  0.0268, -0.1597],\n",
            "        [-0.0373,  0.1960,  0.1716,  ..., -0.0116, -0.1230,  0.0565],\n",
            "        [ 0.0909,  0.2040,  0.0109,  ...,  0.1414,  0.0383, -0.1726]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.2232, -0.0498, -0.0326,  ...,  0.1519, -0.1685, -0.0761],\n",
            "        [ 0.1874, -0.1671,  0.1219,  ...,  0.0625,  0.0955, -0.0880],\n",
            "        [-0.1668,  0.0623,  0.0094,  ...,  0.1490, -0.0708, -0.0562],\n",
            "        ...,\n",
            "        [-0.0737,  0.1674,  0.1002,  ...,  0.1634, -0.2119, -0.1557],\n",
            "        [-0.1662,  0.4654,  0.1269,  ...,  0.1547, -0.2086, -0.0116],\n",
            "        [-0.1399,  0.4975,  0.1120,  ...,  0.2480, -0.3508, -0.1268]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1662,  0.4654,  0.1269,  ...,  0.1547, -0.2086, -0.0116],\n",
            "         [-0.1399,  0.4975,  0.1120,  ...,  0.2480, -0.3508, -0.1268],\n",
            "         [ 0.0419, -0.1075,  0.1343,  ...,  0.0557, -0.0125, -0.2138],\n",
            "         ...,\n",
            "         [-0.2656,  0.1929,  0.1468,  ...,  0.1384, -0.3580, -0.0965],\n",
            "         [ 0.1139,  0.2778, -0.0282,  ...,  0.0092, -0.3074, -0.1178],\n",
            "         [-0.0737,  0.1674,  0.1002,  ...,  0.1634, -0.2119, -0.1557]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2070,  0.5841,  0.0323,  ...,  0.3786, -0.1385, -0.1756],\n",
            "        [ 0.3638,  0.7851, -0.0511,  ...,  0.5683, -0.0322, -0.4295],\n",
            "        [ 0.0493, -0.2306,  0.3694,  ...,  0.0112, -0.3674, -0.3509],\n",
            "        ...,\n",
            "        [ 0.2546,  0.5720, -0.0573,  ...,  0.4643, -0.0417, -0.3439],\n",
            "        [ 0.1772,  0.1814,  0.1727,  ...,  0.1092, -0.3748, -0.3499],\n",
            "        [ 0.1945,  0.3124,  0.0199,  ...,  0.2862, -0.0352, -0.3466]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0576,  0.0780, -0.0136,  ..., -0.0348,  0.0079,  0.0701],\n",
            "        [-0.0368,  0.1319,  0.0942,  ..., -0.1134,  0.0364,  0.0729],\n",
            "        [-0.0576,  0.0780, -0.0136,  ..., -0.0348,  0.0079,  0.0701],\n",
            "        ...,\n",
            "        [ 0.0389, -0.0174,  0.0204,  ...,  0.1157, -0.0747,  0.0518],\n",
            "        [-0.0540,  0.0916,  0.1461,  ..., -0.0628, -0.2875, -0.1592],\n",
            "        [ 0.0052,  0.4103,  0.1445,  ..., -0.0300, -0.1299, -0.1171]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0692,  0.7938,  0.0045,  ...,  0.3715, -0.0460, -0.0274],\n",
            "         [ 0.0715,  0.0336, -0.1051,  ...,  0.1182, -0.0375, -0.1738],\n",
            "         [-0.0692,  0.7938,  0.0045,  ...,  0.3715, -0.0460, -0.0274],\n",
            "         ...,\n",
            "         [-0.0803,  0.4090, -0.0298,  ...,  0.2201, -0.0253, -0.2040],\n",
            "         [ 0.0796,  0.5065,  0.0715,  ...,  0.2519, -0.1338, -0.1556],\n",
            "         [ 0.0172,  0.1219,  0.0616,  ..., -0.0567, -0.0381, -0.0908]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3000,  0.7930, -0.0430,  ...,  0.5635, -0.0850, -0.2855],\n",
            "        [ 0.1022, -0.0051,  0.1346,  ...,  0.1016, -0.2462, -0.3081],\n",
            "        [ 0.3000,  0.7930, -0.0430,  ...,  0.5635, -0.0850, -0.2855],\n",
            "        ...,\n",
            "        [ 0.1257,  0.4436, -0.0594,  ...,  0.3247,  0.0125, -0.1899],\n",
            "        [ 0.3957,  0.6477,  0.0189,  ...,  0.5036, -0.2224, -0.3627],\n",
            "        [ 0.1876, -0.0463,  0.2302,  ...,  0.0277, -0.3627, -0.2837]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0223, -0.0881, -0.0511,  ...,  0.0076, -0.0276, -0.0423],\n",
            "        [ 0.0857,  0.0009, -0.0929,  ...,  0.0629,  0.0267, -0.0258],\n",
            "        [-0.0570,  0.0782, -0.0134,  ..., -0.0346,  0.0078,  0.0697],\n",
            "        ...,\n",
            "        [ 0.1393, -0.0056, -0.0971,  ..., -0.0907, -0.0335, -0.1101],\n",
            "        [-0.1080, -0.1589,  0.0852,  ...,  0.0876, -0.1979, -0.1399],\n",
            "        [ 0.1779,  0.2317,  0.1013,  ...,  0.1084, -0.2639,  0.0013]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1080, -0.1589,  0.0852,  ...,  0.0876, -0.1979, -0.1399],\n",
            "         [ 0.1779,  0.2317,  0.1013,  ...,  0.1084, -0.2639,  0.0013],\n",
            "         [ 0.2004, -0.1195,  0.1016,  ..., -0.0693,  0.0135, -0.1048],\n",
            "         ...,\n",
            "         [ 0.0957,  0.0309,  0.1071,  ...,  0.0017, -0.2219, -0.0906],\n",
            "         [-0.0168,  0.1725,  0.0866,  ..., -0.1213,  0.0886,  0.0719],\n",
            "         [ 0.1393, -0.0056, -0.0971,  ..., -0.0907, -0.0335, -0.1101]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1151, -0.2890,  0.3043,  ...,  0.0623, -0.3542, -0.4183],\n",
            "        [ 0.4204,  0.4498,  0.1148,  ...,  0.3551, -0.3217, -0.2449],\n",
            "        [ 0.0739, -0.1759,  0.2845,  ..., -0.0693, -0.2533, -0.1925],\n",
            "        ...,\n",
            "        [ 0.0126, -0.1877,  0.3629,  ..., -0.0930, -0.4600, -0.3199],\n",
            "        [ 0.0196,  0.0100,  0.1858,  ..., -0.0929, -0.1241,  0.0390],\n",
            "        [ 0.0560,  0.0408, -0.0809,  ..., -0.0785,  0.0502,  0.0347]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0800, -0.0873,  0.0662,  ...,  0.1032, -0.0076, -0.1698],\n",
            "        [-0.0569,  0.0780, -0.0134,  ..., -0.0346,  0.0081,  0.0697],\n",
            "        [-0.0569,  0.0780, -0.0134,  ..., -0.0346,  0.0081,  0.0697],\n",
            "        ...,\n",
            "        [ 0.1848,  0.1622,  0.2273,  ...,  0.2981, -0.0765, -0.1320],\n",
            "        [-0.2190,  0.0819,  0.1756,  ...,  0.2046, -0.1625, -0.0645],\n",
            "        [ 0.3792,  0.1493,  0.0375,  ...,  0.3255, -0.2720, -0.2498]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1923, -0.0888,  0.3319,  ..., -0.0488, -0.1927, -0.2072],\n",
            "         [ 0.1075, -0.1306, -0.1079,  ..., -0.0108, -0.2106, -0.1465],\n",
            "         [ 0.3692, -0.0239,  0.0209,  ...,  0.3305, -0.2218, -0.1531],\n",
            "         ...,\n",
            "         [ 0.1848,  0.1622,  0.2273,  ...,  0.2981, -0.0765, -0.1320],\n",
            "         [-0.2190,  0.0819,  0.1756,  ...,  0.2046, -0.1625, -0.0645],\n",
            "         [ 0.3792,  0.1493,  0.0375,  ...,  0.3255, -0.2720, -0.2498]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2365, -0.1026,  0.3000,  ..., -0.0334, -0.3174, -0.3144],\n",
            "        [ 0.0496, -0.2482,  0.2058,  ..., -0.0334, -0.3747, -0.2446],\n",
            "        [ 0.2565,  0.0604,  0.0824,  ...,  0.2565, -0.3069, -0.1850],\n",
            "        ...,\n",
            "        [ 0.1935,  0.0339,  0.3678,  ...,  0.1564, -0.2939, -0.2715],\n",
            "        [-0.1098, -0.0908,  0.2521,  ...,  0.0660, -0.3042, -0.1530],\n",
            "        [ 0.3467,  0.1493,  0.2239,  ...,  0.3429, -0.4864, -0.4126]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0969,  0.1188,  0.0237,  ...,  0.1165, -0.0078,  0.0018],\n",
            "        [-0.2192, -0.0492, -0.0299,  ...,  0.1525, -0.1683, -0.0756],\n",
            "        [-0.0373,  0.1177,  0.0350,  ...,  0.1600,  0.0149,  0.1910],\n",
            "        ...,\n",
            "        [ 0.1023, -0.0385,  0.0882,  ...,  0.2570, -0.0925, -0.0968],\n",
            "        [-0.2587,  0.5702,  0.0550,  ...,  0.3288, -0.2097,  0.0338],\n",
            "        [-0.2734, -0.1448,  0.1485,  ...,  0.0498, -0.3302, -0.1752]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1153,  0.5814,  0.0906,  ...,  0.2095,  0.0036, -0.2352],\n",
            "         [ 0.0995,  0.1650,  0.2336,  ...,  0.3424, -0.1397, -0.1058],\n",
            "         [ 0.1487,  0.0088,  0.0568,  ..., -0.0869, -0.0810, -0.1746],\n",
            "         ...,\n",
            "         [-0.2587,  0.5702,  0.0550,  ...,  0.3288, -0.2097,  0.0338],\n",
            "         [-0.2734, -0.1448,  0.1485,  ...,  0.0498, -0.3302, -0.1752],\n",
            "         [ 0.0587,  0.1121,  0.2074,  ...,  0.2399, -0.1343,  0.0357]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1685,  0.6723, -0.0593,  ...,  0.4441,  0.0329, -0.2901],\n",
            "        [ 0.1884,  0.2234,  0.2186,  ...,  0.2427, -0.2369, -0.2283],\n",
            "        [ 0.1173, -0.0276,  0.1430,  ..., -0.0527, -0.2560, -0.2121],\n",
            "        ...,\n",
            "        [ 0.2977,  0.7463, -0.0641,  ...,  0.6039, -0.0529, -0.3083],\n",
            "        [-0.0248, -0.2812,  0.2809,  ...,  0.0394, -0.3931, -0.4176],\n",
            "        [ 0.1507,  0.1505,  0.2019,  ...,  0.2143, -0.2725, -0.1428]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1153,  0.1228, -0.1070,  ..., -0.0233, -0.0776, -0.0459],\n",
            "        [ 0.2905, -0.0213,  0.0690,  ...,  0.3261, -0.1279, -0.1263],\n",
            "        [-0.0568,  0.0778, -0.0134,  ..., -0.0348,  0.0087,  0.0697],\n",
            "        ...,\n",
            "        [ 0.1357,  0.0060,  0.1768,  ..., -0.0577,  0.2564,  0.0450],\n",
            "        [ 0.1060,  0.2973,  0.2064,  ..., -0.0680, -0.0996, -0.3649],\n",
            "        [ 0.0760,  0.2872, -0.0666,  ...,  0.0121, -0.0420, -0.1121]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.1977, -0.0248,  0.0319,  ..., -0.0713, -0.0419, -0.0308],\n",
            "         [ 0.1357,  0.0060,  0.1768,  ..., -0.0577,  0.2564,  0.0450],\n",
            "         [ 0.1060,  0.2973,  0.2064,  ..., -0.0680, -0.0996, -0.3649],\n",
            "         ...,\n",
            "         [ 0.2994,  0.0720,  0.0549,  ...,  0.3257, -0.2119, -0.2278],\n",
            "         [-0.1000,  0.0655,  0.0790,  ...,  0.1412, -0.1121, -0.0605],\n",
            "         [ 0.0916, -0.0582, -0.0067,  ...,  0.1271,  0.1418, -0.1611]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1710, -0.0299,  0.1729,  ...,  0.0440, -0.1828, -0.1342],\n",
            "        [ 0.2161, -0.1244,  0.3880,  ..., -0.0515, -0.2073, -0.1492],\n",
            "        [ 0.1699,  0.0332,  0.3809,  ..., -0.0039, -0.4062, -0.3700],\n",
            "        ...,\n",
            "        [ 0.2368,  0.0180,  0.2006,  ...,  0.2075, -0.3834, -0.2886],\n",
            "        [-0.0381,  0.0315,  0.0885,  ...,  0.0771, -0.1011, -0.0688],\n",
            "        [ 0.1103,  0.0240, -0.0079,  ...,  0.1145,  0.0757, -0.0654]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[ 0.0083,  0.0307,  0.0007,  ...,  0.1108,  0.1689, -0.1772],\n",
            "        [ 0.2905, -0.0213,  0.0690,  ...,  0.3261, -0.1279, -0.1263],\n",
            "        [-0.0493, -0.0688,  0.1419,  ...,  0.2903, -0.0888,  0.0218],\n",
            "        ...,\n",
            "        [-0.0585,  0.3295,  0.0549,  ...,  0.2341,  0.1622, -0.3604],\n",
            "        [ 0.1244, -0.0565,  0.1709,  ..., -0.0739, -0.3100, -0.1312],\n",
            "        [ 0.2387,  0.0695,  0.1104,  ...,  0.2058,  0.1405, -0.3054]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[-0.2440,  0.3339,  0.1290,  ...,  0.3108, -0.0297, -0.1614],\n",
            "         [ 0.2497,  0.1846,  0.1356,  ...,  0.1569,  0.1471, -0.3350],\n",
            "         [ 0.1208,  0.1544,  0.0124,  ...,  0.1149,  0.0182, -0.2355],\n",
            "         ...,\n",
            "         [ 0.0923,  0.1017,  0.0938,  ...,  0.1175,  0.0283, -0.2150],\n",
            "         [ 0.2024, -0.1563,  0.1454,  ..., -0.0724, -0.0746,  0.0038],\n",
            "         [ 0.4088,  0.1162,  0.1109,  ...,  0.2570,  0.0373, -0.3131]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1890,  0.5815,  0.0626,  ...,  0.4369, -0.0042, -0.4390],\n",
            "        [ 0.3904,  0.2614,  0.2693,  ...,  0.2856, -0.2460, -0.4480],\n",
            "        [ 0.1970,  0.1816,  0.1099,  ...,  0.1674, -0.2178, -0.3063],\n",
            "        ...,\n",
            "        [ 0.1320,  0.0757,  0.1725,  ...,  0.0945, -0.2022, -0.2188],\n",
            "        [ 0.3290, -0.1747,  0.1885,  ...,  0.0192, -0.1938, -0.0834],\n",
            "        [ 0.4140,  0.1567,  0.2827,  ...,  0.2825, -0.3003, -0.4332]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[-0.0568,  0.0778, -0.0134,  ..., -0.0348,  0.0087,  0.0697],\n",
            "        [ 0.2905, -0.0213,  0.0690,  ...,  0.3261, -0.1279, -0.1263],\n",
            "        [-0.1009,  0.0142, -0.0471,  ..., -0.0078,  0.0529,  0.0915],\n",
            "        ...,\n",
            "        [ 0.3641,  0.1777,  0.0724,  ...,  0.1435,  0.0253, -0.1764],\n",
            "        [ 0.0396,  0.2611,  0.2789,  ...,  0.0889, -0.0990, -0.2244],\n",
            "        [ 0.2076,  0.4469, -0.0223,  ...,  0.2755, -0.0083, -0.2451]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.4151, -0.0454,  0.1432,  ...,  0.1484,  0.1237, -0.3097],\n",
            "         [ 0.2519,  0.0940,  0.1666,  ...,  0.0206,  0.1374, -0.1955],\n",
            "         [ 0.1411, -0.2195,  0.1352,  ...,  0.3635, -0.3057, -0.1392],\n",
            "         ...,\n",
            "         [-0.0165, -0.1761,  0.1508,  ...,  0.0250, -0.0773, -0.1281],\n",
            "         [ 0.1464,  0.3427,  0.0613,  ...,  0.1141,  0.1032, -0.1899],\n",
            "         [ 0.2323,  0.0251,  0.0936,  ...,  0.1323,  0.1172,  0.1117]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2900, -0.2580,  0.4805,  ...,  0.0313, -0.3883, -0.4365],\n",
            "        [ 0.2443, -0.1146,  0.4490,  ..., -0.0203, -0.3324, -0.3616],\n",
            "        [ 0.2738, -0.1498,  0.3043,  ...,  0.2544, -0.4317, -0.4656],\n",
            "        ...,\n",
            "        [-0.0336, -0.2903,  0.4091,  ..., -0.0959, -0.3952, -0.3286],\n",
            "        [ 0.3170,  0.3586,  0.1475,  ...,  0.2775, -0.1751, -0.3375],\n",
            "        [ 0.1305, -0.0305,  0.1981,  ...,  0.0865, -0.0666, -0.0146]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[ 0.1028, -0.0145, -0.0295,  ...,  0.0633, -0.1193, -0.0477],\n",
            "        [ 0.0679, -0.0191,  0.0603,  ...,  0.0224, -0.0756,  0.0086],\n",
            "        [-0.0568,  0.0778, -0.0134,  ..., -0.0348,  0.0087,  0.0697],\n",
            "        ...,\n",
            "        [-0.0710,  0.2509,  0.1526,  ...,  0.0039, -0.2694, -0.1147],\n",
            "        [ 0.0840,  0.0691,  0.0215,  ...,  0.0323, -0.1362, -0.2129],\n",
            "        [ 0.0962,  0.5571, -0.1069,  ...,  0.3672, -0.1557,  0.0347]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.1338, -0.1742, -0.0724,  ...,  0.0519, -0.2215, -0.2107],\n",
            "         [-0.0265, -0.1898,  0.1495,  ...,  0.1680, -0.0680, -0.1270],\n",
            "         [-0.0382,  0.1349, -0.0079,  ..., -0.0477,  0.1818,  0.1105],\n",
            "         ...,\n",
            "         [ 0.1541,  0.1983,  0.2166,  ...,  0.0253,  0.0286,  0.0048],\n",
            "         [ 0.0009, -0.0297,  0.0907,  ..., -0.0700, -0.0052, -0.1632],\n",
            "         [-0.1113,  0.0637,  0.1294,  ...,  0.0507, -0.2314, -0.1143]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0214, -0.1354,  0.1248,  ..., -0.0217, -0.3060, -0.1639],\n",
            "        [ 0.1058, -0.2291,  0.2969,  ...,  0.0460, -0.2798, -0.3522],\n",
            "        [ 0.0860,  0.2412,  0.0137,  ...,  0.1101,  0.0415,  0.0467],\n",
            "        ...,\n",
            "        [ 0.4295,  0.1826,  0.3409,  ...,  0.2241, -0.3047, -0.2745],\n",
            "        [ 0.0369, -0.2644,  0.4543,  ..., -0.1492, -0.4227, -0.4015],\n",
            "        [ 0.0452,  0.0658,  0.2116,  ...,  0.0991, -0.2099, -0.3424]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[ 0.2905, -0.0213,  0.0690,  ...,  0.3261, -0.1279, -0.1263],\n",
            "        [-0.0568,  0.0778, -0.0134,  ..., -0.0348,  0.0087,  0.0697],\n",
            "        [ 0.0083,  0.0307,  0.0007,  ...,  0.1108,  0.1689, -0.1772],\n",
            "        ...,\n",
            "        [ 0.0127,  0.1769,  0.0089,  ...,  0.2279,  0.1903,  0.0278],\n",
            "        [ 0.3198,  0.0694,  0.1416,  ...,  0.3010,  0.1388, -0.0901],\n",
            "        [ 0.2620, -0.4383, -0.2070,  ..., -0.0261,  0.1053, -0.2323]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.5145,  0.0947,  0.2371,  ...,  0.0788, -0.1940, -0.2167],\n",
            "         [ 0.1177,  0.2522,  0.0615,  ...,  0.1401, -0.2440, -0.1623],\n",
            "         [ 0.0283,  0.1522,  0.0433,  ...,  0.2534,  0.1314, -0.1856],\n",
            "         ...,\n",
            "         [ 0.0962,  0.5571, -0.1069,  ...,  0.3672, -0.1557,  0.0347],\n",
            "         [ 0.0912, -0.0464,  0.1268,  ..., -0.0597, -0.0774, -0.0600],\n",
            "         [ 0.1037,  0.2025,  0.1342,  ...,  0.1257,  0.1288, -0.0645]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3156, -0.0864,  0.4649,  ...,  0.0585, -0.5019, -0.4518],\n",
            "        [ 0.3239,  0.3604,  0.1131,  ...,  0.2852, -0.2327, -0.3125],\n",
            "        [ 0.1614,  0.2282,  0.0054,  ...,  0.2348, -0.0459, -0.2108],\n",
            "        ...,\n",
            "        [ 0.4575,  0.7222, -0.1830,  ...,  0.6087,  0.0358, -0.1214],\n",
            "        [ 0.0757, -0.0606,  0.0456,  ..., -0.0076, -0.1066, -0.0812],\n",
            "        [ 0.0842,  0.1402,  0.2108,  ...,  0.0714, -0.1483, -0.1775]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[-0.0568,  0.0778, -0.0134,  ..., -0.0348,  0.0087,  0.0697],\n",
            "        [-0.0568,  0.0778, -0.0134,  ..., -0.0348,  0.0087,  0.0697],\n",
            "        [-0.0568,  0.0778, -0.0134,  ..., -0.0348,  0.0087,  0.0697],\n",
            "        ...,\n",
            "        [ 0.3005, -0.0712,  0.4144,  ...,  0.3541, -0.0715, -0.1450],\n",
            "        [ 0.4260, -0.3900,  0.0598,  ...,  0.1591, -0.0666, -0.3372],\n",
            "        [ 0.4260, -0.3900,  0.0598,  ...,  0.1591, -0.0666, -0.3372]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.4260, -0.3900,  0.0598,  ...,  0.1591, -0.0666, -0.3372],\n",
            "         [ 0.4260, -0.3900,  0.0598,  ...,  0.1591, -0.0666, -0.3372],\n",
            "         [ 0.3005, -0.0712,  0.4144,  ...,  0.3541, -0.0715, -0.1450],\n",
            "         ...,\n",
            "         [-0.1518,  0.5740,  0.1066,  ...,  0.3037, -0.3719, -0.1333],\n",
            "         [-0.0441,  0.0030,  0.1303,  ..., -0.0807, -0.2962, -0.0574],\n",
            "         [ 0.2554,  0.0502,  0.0564,  ...,  0.1517, -0.0267, -0.0512]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3700, -0.4796,  0.4713,  ..., -0.0087, -0.5372, -0.6121],\n",
            "        [ 0.3700, -0.4796,  0.4713,  ..., -0.0087, -0.5372, -0.6121],\n",
            "        [ 0.2254, -0.4369,  0.7347,  ...,  0.1153, -0.5197, -0.3655],\n",
            "        ...,\n",
            "        [ 0.4197,  0.8457, -0.0766,  ...,  0.6558, -0.0178, -0.4666],\n",
            "        [-0.0176, -0.1760,  0.2974,  ..., -0.0878, -0.4241, -0.2672],\n",
            "        [ 0.1350,  0.0382,  0.1682,  ...,  0.0844, -0.1958, -0.1635]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[-0.0568,  0.0778, -0.0134,  ..., -0.0348,  0.0087,  0.0697],\n",
            "        [-0.0568,  0.0778, -0.0134,  ..., -0.0348,  0.0087,  0.0697],\n",
            "        [-0.0568,  0.0778, -0.0134,  ..., -0.0348,  0.0087,  0.0697],\n",
            "        ...,\n",
            "        [ 0.4260, -0.3900,  0.0598,  ...,  0.1591, -0.0666, -0.3372],\n",
            "        [ 0.4260, -0.3900,  0.0598,  ...,  0.1591, -0.0666, -0.3372],\n",
            "        [ 0.4260, -0.3900,  0.0598,  ...,  0.1591, -0.0666, -0.3372]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.4260, -0.3900,  0.0598,  ...,  0.1591, -0.0666, -0.3372],\n",
            "         [ 0.4260, -0.3900,  0.0598,  ...,  0.1591, -0.0666, -0.3372],\n",
            "         [ 0.4260, -0.3900,  0.0598,  ...,  0.1591, -0.0666, -0.3372],\n",
            "         ...,\n",
            "         [ 0.4260, -0.3900,  0.0598,  ...,  0.1591, -0.0666, -0.3372],\n",
            "         [ 0.4260, -0.3900,  0.0598,  ...,  0.1591, -0.0666, -0.3372],\n",
            "         [ 0.4260, -0.3900,  0.0598,  ...,  0.1591, -0.0666, -0.3372]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3700, -0.4796,  0.4713,  ..., -0.0087, -0.5372, -0.6121],\n",
            "        [ 0.3700, -0.4796,  0.4713,  ..., -0.0087, -0.5372, -0.6121],\n",
            "        [ 0.3700, -0.4796,  0.4713,  ..., -0.0087, -0.5372, -0.6121],\n",
            "        ...,\n",
            "        [ 0.3700, -0.4796,  0.4713,  ..., -0.0087, -0.5372, -0.6121],\n",
            "        [ 0.3700, -0.4796,  0.4713,  ..., -0.0087, -0.5372, -0.6121],\n",
            "        [ 0.3700, -0.4796,  0.4713,  ..., -0.0087, -0.5372, -0.6121]],\n",
            "       device='cuda:0')\n",
            "\t Epoch: 5 | Train Loss: 0.251 | Train Acc: 91.22%\n",
            "\t Epoch: 5 | Val. Loss: 0.677 |  Val. Acc: 82.14% \n",
            "\n",
            "Output of encoder at every step:tensor([[ 0.1158, -0.0637, -0.1025,  ..., -0.0769,  0.0534, -0.1787],\n",
            "        [ 0.0097,  0.1458,  0.0065,  ...,  0.0766, -0.0723,  0.0151],\n",
            "        [ 0.1158, -0.0637, -0.1025,  ..., -0.0769,  0.0534, -0.1787],\n",
            "        ...,\n",
            "        [-0.2624,  0.0079,  0.0318,  ..., -0.1918, -0.0295, -0.0402],\n",
            "        [ 0.1283,  0.0188,  0.0532,  ...,  0.1829, -0.1266, -0.0438],\n",
            "        [ 0.1957, -0.3541,  0.1886,  ..., -0.0454, -0.2922, -0.1330]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1957, -0.3541,  0.1886,  ..., -0.0454, -0.2922, -0.1330],\n",
            "         [ 0.1436, -0.0412,  0.0107,  ..., -0.0515, -0.1720, -0.1236],\n",
            "         [ 0.1957, -0.3541,  0.1886,  ..., -0.0454, -0.2922, -0.1330],\n",
            "         ...,\n",
            "         [ 0.1101, -0.1293, -0.1059,  ..., -0.0041, -0.2239, -0.1578],\n",
            "         [ 0.3556, -0.0594,  0.1941,  ...,  0.2042, -0.3228, -0.0836],\n",
            "         [-0.1774,  0.6302, -0.1381,  ...,  0.2728, -0.1803, -0.0820]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0140, -0.5098,  0.5765,  ..., -0.1877, -0.6883, -0.4478],\n",
            "        [ 0.0784, -0.1319,  0.2338,  ..., -0.1045, -0.3781, -0.2220],\n",
            "        [-0.0140, -0.5098,  0.5765,  ..., -0.1877, -0.6883, -0.4478],\n",
            "        ...,\n",
            "        [ 0.0648, -0.2548,  0.2173,  ..., -0.0259, -0.3944, -0.2665],\n",
            "        [ 0.2617, -0.2175,  0.3825,  ...,  0.2107, -0.4691, -0.2680],\n",
            "        [ 0.3697,  0.7864, -0.0497,  ...,  0.6393, -0.2990, -0.3918]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0181,  0.0092, -0.0309,  ...,  0.0435, -0.0961, -0.1482],\n",
            "        [-0.0570,  0.0778, -0.0135,  ..., -0.0348,  0.0090,  0.0697],\n",
            "        [ 0.1043,  0.1103, -0.0917,  ...,  0.1132, -0.0143, -0.1876],\n",
            "        ...,\n",
            "        [ 0.0316,  0.4303,  0.1562,  ..., -0.0378, -0.1569, -0.1296],\n",
            "        [ 0.1922,  0.1972,  0.1812,  ...,  0.2770, -0.0721, -0.2021],\n",
            "        [ 0.2112, -0.1754,  0.1699,  ...,  0.1529, -0.2787, -0.2111]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1235,  0.0576, -0.0299,  ..., -0.1315, -0.3619, -0.0662],\n",
            "         [ 0.2963,  0.0034, -0.0294,  ...,  0.1272, -0.1324, -0.2244],\n",
            "         [-0.2094,  0.4048,  0.0468,  ..., -0.0250, -0.3284, -0.0784],\n",
            "         ...,\n",
            "         [ 0.0248,  0.0517, -0.0197,  ...,  0.1449, -0.1475,  0.0401],\n",
            "         [ 0.1963,  0.0012, -0.1140,  ...,  0.1742, -0.1570, -0.1671],\n",
            "         [ 0.1811, -0.1829, -0.1192,  ...,  0.0444, -0.1729, -0.0927]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0373,  0.0017,  0.1753,  ...,  0.0155, -0.4359, -0.2759],\n",
            "        [ 0.3666,  0.0034,  0.1831,  ...,  0.1570, -0.3714, -0.4207],\n",
            "        [ 0.0230,  0.3044,  0.2757,  ...,  0.0133, -0.4439, -0.3752],\n",
            "        ...,\n",
            "        [-0.0662,  0.0886, -0.0763,  ...,  0.1149, -0.0123,  0.0881],\n",
            "        [ 0.1714,  0.1730, -0.0172,  ...,  0.2190, -0.0820, -0.2335],\n",
            "        [ 0.1293, -0.2103,  0.1140,  ...,  0.0247, -0.3527, -0.2345]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2874, -0.0195,  0.0629,  ...,  0.3319, -0.1276, -0.1273],\n",
            "        [-0.0798, -0.0151, -0.1687,  ..., -0.1063, -0.0584, -0.0516],\n",
            "        [ 0.2874, -0.0195,  0.0629,  ...,  0.3319, -0.1276, -0.1273],\n",
            "        ...,\n",
            "        [-0.1067, -0.0707,  0.0236,  ...,  0.1974,  0.1734,  0.2438],\n",
            "        [-0.1169,  0.0827, -0.0318,  ...,  0.1169, -0.2620, -0.1288],\n",
            "        [ 0.3022, -0.0668,  0.0526,  ..., -0.0149, -0.0883, -0.2142]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1907,  0.0363,  0.2724,  ...,  0.1347, -0.2374, -0.1295],\n",
            "         [-0.1067, -0.0707,  0.0236,  ...,  0.1974,  0.1734,  0.2438],\n",
            "         [-0.1169,  0.0827, -0.0318,  ...,  0.1169, -0.2620, -0.1288],\n",
            "         ...,\n",
            "         [ 0.1866,  0.0909,  0.0248,  ...,  0.0019,  0.0072, -0.1233],\n",
            "         [ 0.1364, -0.2203, -0.1995,  ...,  0.3843, -0.0567, -0.2286],\n",
            "         [ 0.3401, -0.2103,  0.3752,  ...,  0.0122, -0.2671, -0.1635]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3298,  0.0486,  0.4579,  ...,  0.1773, -0.5334, -0.4212],\n",
            "        [-0.1057, -0.0128, -0.0074,  ...,  0.0739,  0.1645,  0.1940],\n",
            "        [ 0.1298,  0.0876,  0.1571,  ...,  0.1986, -0.3502, -0.2671],\n",
            "        ...,\n",
            "        [ 0.2382,  0.1578,  0.0532,  ...,  0.0601, -0.0413, -0.1679],\n",
            "        [ 0.1864, -0.0667, -0.0581,  ...,  0.2911, -0.0499, -0.2353],\n",
            "        [ 0.1419, -0.3306,  0.4454,  ..., -0.0525, -0.5150, -0.3438]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0576,  0.0775, -0.0136,  ..., -0.0348,  0.0093,  0.0694],\n",
            "        [ 0.0758,  0.0191,  0.1961,  ...,  0.0421, -0.1410, -0.0502],\n",
            "        [ 0.0534, -0.1558,  0.1119,  ...,  0.0669, -0.0449, -0.0784],\n",
            "        ...,\n",
            "        [ 0.2739, -0.0729, -0.0575,  ..., -0.0379, -0.1528, -0.1471],\n",
            "        [ 0.1793,  0.2886,  0.1964,  ...,  0.5226, -0.0444, -0.1748],\n",
            "        [ 0.0352, -0.1980, -0.0060,  ..., -0.0230, -0.2651, -0.1987]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1869, -0.1485,  0.3230,  ...,  0.1125, -0.3201, -0.1405],\n",
            "         [ 0.0650,  0.1266,  0.3362,  ...,  0.1953, -0.0153, -0.1324],\n",
            "         [ 0.1957, -0.0943, -0.0529,  ...,  0.0534, -0.0366, -0.1269],\n",
            "         ...,\n",
            "         [ 0.2739, -0.0729, -0.0575,  ..., -0.0379, -0.1528, -0.1471],\n",
            "         [ 0.1793,  0.2886,  0.1964,  ...,  0.5226, -0.0444, -0.1748],\n",
            "         [ 0.0352, -0.1980, -0.0060,  ..., -0.0230, -0.2651, -0.1987]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0674, -0.2236,  0.3339,  ...,  0.0429, -0.4524, -0.2991],\n",
            "        [ 0.1448, -0.0327,  0.3979,  ...,  0.1380, -0.2878, -0.3160],\n",
            "        [ 0.2098, -0.0469,  0.1352,  ...,  0.0624, -0.2419, -0.2534],\n",
            "        ...,\n",
            "        [ 0.2474, -0.2602,  0.2596,  ..., -0.0028, -0.5150, -0.3579],\n",
            "        [ 0.4332,  0.4875,  0.2383,  ...,  0.4962, -0.2302, -0.3840],\n",
            "        [ 0.0348, -0.2190,  0.1810,  ..., -0.0555, -0.3080, -0.2693]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0582,  0.0772, -0.0137,  ..., -0.0348,  0.0093,  0.0690],\n",
            "        [-0.0582,  0.0772, -0.0137,  ..., -0.0348,  0.0093,  0.0690],\n",
            "        [-0.0582,  0.0772, -0.0137,  ..., -0.0348,  0.0093,  0.0690],\n",
            "        ...,\n",
            "        [ 0.4191, -0.4281,  0.0531,  ...,  0.1664, -0.0754, -0.3548],\n",
            "        [ 0.4191, -0.4281,  0.0531,  ...,  0.1664, -0.0754, -0.3548],\n",
            "        [ 0.4191, -0.4281,  0.0531,  ...,  0.1664, -0.0754, -0.3548]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.4191, -0.4281,  0.0531,  ...,  0.1664, -0.0754, -0.3548],\n",
            "         [ 0.4191, -0.4281,  0.0531,  ...,  0.1664, -0.0754, -0.3548],\n",
            "         [ 0.4191, -0.4281,  0.0531,  ...,  0.1664, -0.0754, -0.3548],\n",
            "         ...,\n",
            "         [ 0.2431,  0.1374,  0.2454,  ...,  0.2196, -0.1098, -0.2073],\n",
            "         [-0.0609, -0.0991,  0.0643,  ...,  0.0750, -0.2907, -0.1540],\n",
            "         [ 0.2641, -0.3333,  0.1855,  ...,  0.2519, -0.1224, -0.1449]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3773, -0.5304,  0.4908,  ..., -0.0111, -0.5614, -0.6360],\n",
            "        [ 0.3773, -0.5304,  0.4908,  ..., -0.0111, -0.5614, -0.6360],\n",
            "        [ 0.3773, -0.5304,  0.4908,  ..., -0.0111, -0.5614, -0.6360],\n",
            "        ...,\n",
            "        [ 0.2358, -0.1518,  0.5659,  ...,  0.0875, -0.5202, -0.4237],\n",
            "        [ 0.2454, -0.2754,  0.3617,  ...,  0.1116, -0.5149, -0.5093],\n",
            "        [ 0.1726, -0.5050,  0.4953,  ...,  0.0536, -0.6002, -0.4114]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.2164, -0.0538, -0.0297,  ...,  0.1533, -0.1687, -0.0760],\n",
            "        [ 0.1008, -0.0246, -0.0335,  ...,  0.0570, -0.1156, -0.0437],\n",
            "        [-0.0429, -0.2359,  0.0109,  ...,  0.1224,  0.0455, -0.1373],\n",
            "        ...,\n",
            "        [ 0.1083,  0.2937,  0.2095,  ..., -0.0670, -0.1148, -0.3795],\n",
            "        [ 0.3518, -0.0602,  0.1734,  ..., -0.1986, -0.1086, -0.2503],\n",
            "        [ 0.2062, -0.0742,  0.1454,  ..., -0.0260, -0.2621, -0.0647]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2153,  0.1529,  0.2784,  ...,  0.4501, -0.0273, -0.1425],\n",
            "         [ 0.3265, -0.1638,  0.2256,  ..., -0.0434, -0.0566, -0.2820],\n",
            "         [ 0.1684, -0.0222,  0.2486,  ...,  0.2174, -0.0681, -0.2153],\n",
            "         ...,\n",
            "         [-0.0548, -0.2053,  0.1374,  ..., -0.0155, -0.1354, -0.1157],\n",
            "         [ 0.1785, -0.0825,  0.1489,  ...,  0.0991,  0.0634, -0.1191],\n",
            "         [ 0.3710, -0.1464,  0.3310,  ...,  0.0775, -0.3158, -0.1458]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2703,  0.0537,  0.4117,  ...,  0.2711, -0.2187, -0.2842],\n",
            "        [ 0.1778, -0.4600,  0.5058,  ..., -0.0828, -0.4501, -0.4350],\n",
            "        [ 0.2470, -0.2512,  0.4635,  ...,  0.1083, -0.3419, -0.3560],\n",
            "        ...,\n",
            "        [-0.0881, -0.1993,  0.3001,  ..., -0.0724, -0.2873, -0.2703],\n",
            "        [ 0.2114, -0.2493,  0.4148,  ...,  0.0983, -0.3071, -0.2691],\n",
            "        [ 0.1555, -0.3477,  0.4588,  ...,  0.0270, -0.5539, -0.3491]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1003, -0.0268, -0.0339,  ...,  0.0558, -0.1153, -0.0431],\n",
            "        [ 0.1834,  0.1491, -0.1052,  ...,  0.0346,  0.0369,  0.1102],\n",
            "        [-0.1470, -0.0023, -0.1668,  ..., -0.0307,  0.0176, -0.0225],\n",
            "        ...,\n",
            "        [ 0.0931,  0.5270, -0.1114,  ...,  0.3494, -0.1315,  0.0454],\n",
            "        [ 0.1806, -0.2508, -0.0298,  ..., -0.0432, -0.0274, -0.0656],\n",
            "        [ 0.1080,  0.2036,  0.0327,  ...,  0.1848, -0.1254, -0.1897]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1650, -0.4525,  0.2315,  ...,  0.0708, -0.2939, -0.1587],\n",
            "         [ 0.0455, -0.4011,  0.1886,  ..., -0.0738, -0.3782, -0.1799],\n",
            "         [ 0.3052,  0.0182,  0.0494,  ..., -0.0846, -0.1698, -0.2263],\n",
            "         ...,\n",
            "         [ 0.0931,  0.5270, -0.1114,  ...,  0.3494, -0.1315,  0.0454],\n",
            "         [ 0.1806, -0.2508, -0.0298,  ..., -0.0432, -0.0274, -0.0656],\n",
            "         [ 0.1080,  0.2036,  0.0327,  ...,  0.1848, -0.1254, -0.1897]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0188, -0.5813,  0.6227,  ..., -0.1691, -0.6868, -0.5184],\n",
            "        [ 0.2246, -0.5475,  0.5004,  ..., -0.0608, -0.6625, -0.5502],\n",
            "        [ 0.1550, -0.1530,  0.3029,  ..., -0.0208, -0.4777, -0.3787],\n",
            "        ...,\n",
            "        [ 0.4334,  0.6888, -0.1814,  ...,  0.5782,  0.0497, -0.0738],\n",
            "        [ 0.0387, -0.1431, -0.0018,  ..., -0.0776,  0.0264,  0.0059],\n",
            "        [ 0.1195,  0.1023,  0.2645,  ...,  0.1473, -0.4324, -0.4379]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0603,  0.0765, -0.0142,  ..., -0.0347,  0.0095,  0.0678],\n",
            "        [ 0.0998, -0.0290, -0.0342,  ...,  0.0547, -0.1151, -0.0425],\n",
            "        [-0.1734,  0.0585,  0.0073,  ...,  0.1491, -0.0739, -0.0572],\n",
            "        ...,\n",
            "        [-0.0777,  0.3382,  0.1698,  ...,  0.2558, -0.2936, -0.1687],\n",
            "        [-0.1567,  0.5697,  0.1039,  ...,  0.3056, -0.3751, -0.1359],\n",
            "        [-0.1567,  0.5697,  0.1039,  ...,  0.3056, -0.3751, -0.1359]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0903, -0.1761,  0.0015,  ..., -0.0410,  0.1431, -0.1724],\n",
            "         [-0.2471, -0.0561, -0.1166,  ...,  0.1954, -0.0396, -0.1348],\n",
            "         [ 0.0849,  0.3197, -0.0668,  ...,  0.0488, -0.3269, -0.0764],\n",
            "         ...,\n",
            "         [-0.0777,  0.3382,  0.1698,  ...,  0.2558, -0.2936, -0.1687],\n",
            "         [-0.1567,  0.5697,  0.1039,  ...,  0.3056, -0.3751, -0.1359],\n",
            "         [-0.1567,  0.5697,  0.1039,  ...,  0.3056, -0.3751, -0.1359]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1172, -0.2689,  0.3077,  ..., -0.0262, -0.2924, -0.3266],\n",
            "        [ 0.0302,  0.2072, -0.1816,  ...,  0.3002,  0.0646, -0.1091],\n",
            "        [ 0.1807,  0.3526, -0.0657,  ...,  0.2220, -0.1233, -0.1769],\n",
            "        ...,\n",
            "        [ 0.3584,  0.5883,  0.2244,  ...,  0.4582, -0.3075, -0.5428],\n",
            "        [ 0.4251,  0.8507, -0.0833,  ...,  0.6689, -0.0103, -0.4737],\n",
            "        [ 0.4251,  0.8507, -0.0833,  ...,  0.6689, -0.0103, -0.4737]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2768, -0.0255,  0.0562,  ...,  0.3375, -0.1323, -0.1349],\n",
            "        [ 0.2768, -0.0255,  0.0562,  ...,  0.3375, -0.1323, -0.1349],\n",
            "        [-0.0953,  0.0555,  0.0357,  ...,  0.1015, -0.0342,  0.0152],\n",
            "        ...,\n",
            "        [ 0.2705, -0.1126,  0.3133,  ...,  0.0410, -0.2995, -0.1085],\n",
            "        [ 0.1816,  0.0886,  0.2832,  ..., -0.0295,  0.0315, -0.0799],\n",
            "        [-0.0539, -0.1673, -0.1909,  ...,  0.0164, -0.1241, -0.0221]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2705, -0.1126,  0.3133,  ...,  0.0410, -0.2995, -0.1085],\n",
            "         [ 0.1816,  0.0886,  0.2832,  ..., -0.0295,  0.0315, -0.0799],\n",
            "         [-0.0539, -0.1673, -0.1909,  ...,  0.0164, -0.1241, -0.0221],\n",
            "         ...,\n",
            "         [-0.1055,  0.0870,  0.1219,  ..., -0.0181,  0.2635,  0.1061],\n",
            "         [ 0.0780, -0.0282, -0.1261,  ...,  0.0522, -0.0737, -0.0862],\n",
            "         [ 0.0801,  0.1300, -0.0392,  ...,  0.2078,  0.1658,  0.0626]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 7.5536e-02, -2.0084e-01,  3.4251e-01,  ..., -4.1855e-03,\n",
            "         -4.5850e-01, -2.3186e-01],\n",
            "        [ 3.4258e-01,  5.4501e-02,  4.1580e-01,  ...,  9.1149e-02,\n",
            "         -3.1475e-01, -3.3820e-01],\n",
            "        [ 4.7014e-02, -1.8150e-01,  3.6063e-02,  ...,  2.9111e-04,\n",
            "         -3.0379e-01, -1.7879e-01],\n",
            "        ...,\n",
            "        [-6.0414e-02,  5.6361e-02,  4.7330e-02,  ..., -6.4238e-03,\n",
            "          1.1583e-01,  4.3105e-02],\n",
            "        [ 5.5377e-02, -2.6306e-02, -7.4434e-03,  ...,  1.8515e-02,\n",
            "         -9.1242e-02, -1.0714e-01],\n",
            "        [ 8.1600e-02,  7.4528e-02,  1.5863e-02,  ...,  1.0370e-01,\n",
            "          5.9779e-03,  3.2658e-03]], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0608,  0.0760, -0.0144,  ..., -0.0348,  0.0099,  0.0672],\n",
            "        [-0.2130, -0.0545, -0.0266,  ...,  0.1526, -0.1685, -0.0768],\n",
            "        [-0.0472, -0.1210, -0.0887,  ...,  0.0714, -0.0265, -0.1126],\n",
            "        ...,\n",
            "        [ 0.3327, -0.2223,  0.2353,  ..., -0.0595, -0.1368, -0.0704],\n",
            "        [-0.0700,  0.1423,  0.2066,  ..., -0.0862,  0.1538,  0.0623],\n",
            "        [-0.0905,  0.3512,  0.1641,  ...,  0.2587, -0.2799, -0.1603]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0213,  0.1112,  0.0069,  ...,  0.0691, -0.1647, -0.0164],\n",
            "         [-0.1296,  0.4728,  0.1659,  ...,  0.1451, -0.2258, -0.0639],\n",
            "         [ 0.0960,  0.0332,  0.0552,  ...,  0.1636,  0.0215, -0.0525],\n",
            "         ...,\n",
            "         [ 0.3327, -0.2223,  0.2353,  ..., -0.0595, -0.1368, -0.0704],\n",
            "         [-0.0700,  0.1423,  0.2066,  ..., -0.0862,  0.1538,  0.0623],\n",
            "         [-0.0905,  0.3512,  0.1641,  ...,  0.2587, -0.2799, -0.1603]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2592,  0.3643, -0.0910,  ...,  0.2594, -0.0771, -0.1963],\n",
            "        [ 0.2880,  0.6160,  0.1382,  ...,  0.4134, -0.3061, -0.3077],\n",
            "        [-0.0068, -0.0883,  0.1468,  ...,  0.0008, -0.0360, -0.0472],\n",
            "        ...,\n",
            "        [ 0.1375, -0.4287,  0.5370,  ..., -0.1508, -0.6081, -0.3622],\n",
            "        [-0.0883, -0.0891,  0.4004,  ..., -0.0833, -0.1855, -0.0407],\n",
            "        [ 0.3497,  0.6125,  0.1757,  ...,  0.4676, -0.2450, -0.5220]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0611,  0.0758, -0.0146,  ..., -0.0347,  0.0100,  0.0670],\n",
            "        [-0.1724,  0.0576,  0.0070,  ...,  0.1474, -0.0731, -0.0563],\n",
            "        [ 0.2765, -0.0272,  0.0586,  ...,  0.3363, -0.1339, -0.1362],\n",
            "        ...,\n",
            "        [-0.0982, -0.0117,  0.0969,  ...,  0.0242, -0.2297, -0.1034],\n",
            "        [-0.1016,  0.0290,  0.1233,  ..., -0.0257, -0.2441, -0.2792],\n",
            "        [ 0.1143,  0.0202, -0.0486,  ..., -0.1052, -0.1286,  0.0842]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1426, -0.1657, -0.0951,  ..., -0.0272, -0.2592, -0.1955],\n",
            "         [-0.1137,  0.4183,  0.1055,  ...,  0.1460, -0.1785, -0.1253],\n",
            "         [ 0.3428, -0.1169,  0.0684,  ..., -0.0689, -0.0830, -0.1694],\n",
            "         ...,\n",
            "         [ 0.0171,  0.5755, -0.0113,  ...,  0.2040, -0.0165, -0.0437],\n",
            "         [ 0.1257,  0.0800,  0.3711,  ...,  0.1769, -0.0493, -0.1532],\n",
            "         [-0.0187,  0.0647,  0.0087,  ...,  0.1582, -0.1101, -0.0652]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0720, -0.3657,  0.3279,  ..., -0.0709, -0.5071, -0.3438],\n",
            "        [ 0.2478,  0.5035,  0.1381,  ...,  0.3818, -0.3228, -0.3454],\n",
            "        [ 0.3572, -0.2399,  0.4213,  ...,  0.0265, -0.4512, -0.4285],\n",
            "        ...,\n",
            "        [ 0.2883,  0.6249, -0.0438,  ...,  0.3694,  0.0142, -0.2232],\n",
            "        [ 0.1744, -0.1872,  0.5283,  ...,  0.0817, -0.4419, -0.3895],\n",
            "        [ 0.1703,  0.2942, -0.0625,  ...,  0.3348, -0.0257, -0.1548]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0617,  0.0756, -0.0148,  ..., -0.0345,  0.0101,  0.0666],\n",
            "        [-0.0617,  0.0756, -0.0148,  ..., -0.0345,  0.0101,  0.0666],\n",
            "        [-0.2116, -0.0528, -0.0251,  ...,  0.1529, -0.1682, -0.0771],\n",
            "        ...,\n",
            "        [ 0.1311, -0.1840,  0.0774,  ...,  0.1293, -0.1568, -0.0996],\n",
            "        [-0.2487,  0.3392, -0.0073,  ...,  0.1632, -0.1726, -0.0407],\n",
            "        [ 0.1948, -0.0711,  0.1221,  ...,  0.1188,  0.0323, -0.1129]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.2735,  0.2573,  0.1291,  ...,  0.1516, -0.3417, -0.0614],\n",
            "         [-0.2917,  0.3600,  0.0930,  ...,  0.2440, -0.1941, -0.0313],\n",
            "         [-0.1584,  0.1882, -0.0477,  ...,  0.1520, -0.0651, -0.1232],\n",
            "         ...,\n",
            "         [-0.2510,  0.3529,  0.0455,  ...,  0.2586, -0.4408, -0.1488],\n",
            "         [-0.0354, -0.1199,  0.0794,  ..., -0.2205, -0.2685, -0.1258],\n",
            "         [ 0.1579, -0.0085,  0.0648,  ..., -0.0845, -0.0947, -0.1976]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2403,  0.6151, -0.0812,  ...,  0.5036, -0.0015, -0.2537],\n",
            "        [ 0.2015,  0.6925, -0.1062,  ...,  0.5521,  0.0639, -0.2371],\n",
            "        [ 0.2493,  0.4208, -0.0130,  ...,  0.3108, -0.0751, -0.2605],\n",
            "        ...,\n",
            "        [ 0.3465,  0.7437, -0.0579,  ...,  0.6344, -0.1613, -0.5112],\n",
            "        [-0.0750, -0.3452,  0.4462,  ..., -0.2427, -0.5658, -0.3237],\n",
            "        [ 0.1439, -0.0587,  0.1955,  ..., -0.0521, -0.3125, -0.2653]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2786, -0.0290,  0.0641,  ...,  0.3344, -0.1348, -0.1374],\n",
            "        [-0.0322,  0.1283,  0.0353,  ..., -0.1003, -0.0109, -0.0421],\n",
            "        [-0.0644, -0.0292, -0.0931,  ..., -0.0673,  0.0541, -0.0513],\n",
            "        ...,\n",
            "        [-0.2173,  0.1393,  0.0695,  ...,  0.0355, -0.3087, -0.1367],\n",
            "        [-0.2173,  0.1393,  0.0695,  ...,  0.0355, -0.3087, -0.1367],\n",
            "        [-0.2173,  0.1393,  0.0695,  ...,  0.0355, -0.3087, -0.1367]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1727,  0.1081,  0.1576,  ...,  0.0655, -0.2094, -0.1779],\n",
            "         [ 0.3485, -0.1608,  0.2081,  ...,  0.0462, -0.0246, -0.2103],\n",
            "         [ 0.1066,  0.1942,  0.0720,  ...,  0.3089, -0.1370, -0.0946],\n",
            "         ...,\n",
            "         [ 0.1205,  0.0058,  0.1943,  ...,  0.1627,  0.0431, -0.1314],\n",
            "         [ 0.1171,  0.2606,  0.2351,  ..., -0.1490,  0.0122, -0.1278],\n",
            "         [-0.0648,  0.2263,  0.2011,  ...,  0.0377, -0.3788, -0.1449]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2455, -0.1034,  0.4046,  ...,  0.0570, -0.5289, -0.3441],\n",
            "        [ 0.3428, -0.4354,  0.6070,  ..., -0.0388, -0.4916, -0.4280],\n",
            "        [ 0.2692,  0.3380,  0.1106,  ...,  0.2653, -0.1785, -0.2266],\n",
            "        ...,\n",
            "        [ 0.0469, -0.1512,  0.3488,  ...,  0.0213, -0.2017, -0.2019],\n",
            "        [ 0.2395, -0.0408,  0.5182,  ..., -0.0040, -0.4729, -0.4599],\n",
            "        [ 0.2335,  0.3242,  0.3825,  ...,  0.1653, -0.4645, -0.5323]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-6.2355e-02,  7.5286e-02, -1.4887e-02,  ..., -3.4683e-02,\n",
            "          1.0268e-02,  6.6209e-02],\n",
            "        [-6.2875e-02,  3.3622e-02, -7.4333e-02,  ..., -9.1431e-05,\n",
            "         -1.8425e-01, -1.0356e-02],\n",
            "        [-6.2355e-02,  7.5286e-02, -1.4887e-02,  ..., -3.4683e-02,\n",
            "          1.0268e-02,  6.6209e-02],\n",
            "        ...,\n",
            "        [ 2.1539e-01, -1.4991e-01,  1.2905e-01,  ..., -8.8094e-02,\n",
            "         -1.4925e-02, -1.1826e-01],\n",
            "        [ 1.6915e-02, -1.3219e-01, -5.7858e-02,  ...,  9.2810e-02,\n",
            "         -7.2418e-02,  4.4824e-02],\n",
            "        [ 2.0260e-01,  1.6298e-01,  4.3078e-02,  ...,  7.2147e-02,\n",
            "         -1.5615e-01, -2.5250e-01]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0169, -0.1322, -0.0579,  ...,  0.0928, -0.0724,  0.0448],\n",
            "         [ 0.2026,  0.1630,  0.0431,  ...,  0.0721, -0.1562, -0.2525],\n",
            "         [ 0.2154, -0.1499,  0.1290,  ..., -0.0881, -0.0149, -0.1183],\n",
            "         ...,\n",
            "         [-0.0195, -0.3502,  0.1414,  ...,  0.0081, -0.2203, -0.1571],\n",
            "         [ 0.0336, -0.2742,  0.2907,  ..., -0.2517, -0.2519, -0.1085],\n",
            "         [ 0.2154, -0.1499,  0.1290,  ..., -0.0881, -0.0149, -0.1183]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.1374, -0.0891, -0.0390,  ..., -0.0057, -0.0124,  0.0889],\n",
            "        [ 0.2726,  0.1469,  0.2675,  ...,  0.1710, -0.3386, -0.3839],\n",
            "        [ 0.0794, -0.2653,  0.4006,  ..., -0.0983, -0.3647, -0.2579],\n",
            "        ...,\n",
            "        [ 0.0855, -0.4052,  0.4032,  ..., -0.0442, -0.4007, -0.4068],\n",
            "        [-0.0419, -0.5638,  0.6633,  ..., -0.2809, -0.6854, -0.4803],\n",
            "        [ 0.0794, -0.2653,  0.4006,  ..., -0.0983, -0.3647, -0.2579]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-6.2484e-02,  7.5085e-02, -1.4894e-02,  ..., -3.4896e-02,\n",
            "          1.0486e-02,  6.6336e-02],\n",
            "        [-6.2484e-02,  7.5085e-02, -1.4894e-02,  ..., -3.4896e-02,\n",
            "          1.0486e-02,  6.6336e-02],\n",
            "        [-6.2484e-02,  7.5085e-02, -1.4894e-02,  ..., -3.4896e-02,\n",
            "          1.0486e-02,  6.6336e-02],\n",
            "        ...,\n",
            "        [ 4.1791e-01, -4.2175e-01,  6.6534e-02,  ...,  1.6372e-01,\n",
            "         -7.3110e-02, -3.4475e-01],\n",
            "        [ 1.1037e-01, -3.0510e-01,  5.4467e-05,  ...,  8.3914e-02,\n",
            "         -1.3416e-01, -5.8704e-02],\n",
            "        [ 4.1791e-01, -4.2175e-01,  6.6534e-02,  ...,  1.6372e-01,\n",
            "         -7.3110e-02, -3.4475e-01]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 4.1791e-01, -4.2175e-01,  6.6534e-02,  ...,  1.6372e-01,\n",
            "          -7.3110e-02, -3.4475e-01],\n",
            "         [ 4.1791e-01, -4.2175e-01,  6.6534e-02,  ...,  1.6372e-01,\n",
            "          -7.3110e-02, -3.4475e-01],\n",
            "         [ 4.1791e-01, -4.2175e-01,  6.6534e-02,  ...,  1.6372e-01,\n",
            "          -7.3110e-02, -3.4475e-01],\n",
            "         ...,\n",
            "         [ 4.1791e-01, -4.2175e-01,  6.6534e-02,  ...,  1.6372e-01,\n",
            "          -7.3110e-02, -3.4475e-01],\n",
            "         [ 1.1037e-01, -3.0510e-01,  5.4467e-05,  ...,  8.3914e-02,\n",
            "          -1.3416e-01, -5.8704e-02],\n",
            "         [ 4.1791e-01, -4.2175e-01,  6.6534e-02,  ...,  1.6372e-01,\n",
            "          -7.3110e-02, -3.4475e-01]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3656, -0.5390,  0.5091,  ..., -0.0196, -0.5590, -0.6298],\n",
            "        [ 0.3656, -0.5390,  0.5091,  ..., -0.0196, -0.5590, -0.6298],\n",
            "        [ 0.3656, -0.5390,  0.5091,  ..., -0.0196, -0.5590, -0.6298],\n",
            "        ...,\n",
            "        [ 0.3656, -0.5390,  0.5091,  ..., -0.0196, -0.5590, -0.6298],\n",
            "        [-0.1142, -0.3081,  0.2444,  ..., -0.0330, -0.3606, -0.1091],\n",
            "        [ 0.3656, -0.5390,  0.5091,  ..., -0.0196, -0.5590, -0.6298]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0626,  0.0749, -0.0149,  ..., -0.0351,  0.0107,  0.0664],\n",
            "        [ 0.0022, -0.1146, -0.0194,  ...,  0.0465,  0.0780, -0.1118],\n",
            "        [ 0.0019,  0.1742, -0.0533,  ..., -0.0413,  0.0264, -0.0427],\n",
            "        ...,\n",
            "        [-0.2238, -0.2366,  0.1008,  ..., -0.0616, -0.2752, -0.0869],\n",
            "        [-0.0749,  0.1774,  0.0606,  ...,  0.2764,  0.0090,  0.1632],\n",
            "        [-0.1330,  0.4748,  0.0542,  ...,  0.3760, -0.3168, -0.0935]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0749,  0.1774,  0.0606,  ...,  0.2764,  0.0090,  0.1632],\n",
            "         [-0.1330,  0.4748,  0.0542,  ...,  0.3760, -0.3168, -0.0935],\n",
            "         [-0.2900, -0.0103,  0.0324,  ..., -0.0628, -0.0858, -0.1045],\n",
            "         ...,\n",
            "         [ 0.2443,  0.1133,  0.2638,  ...,  0.2386, -0.2635, -0.1080],\n",
            "         [ 0.0773,  0.3632,  0.1188,  ...,  0.5352, -0.2976, -0.1247],\n",
            "         [-0.2238, -0.2366,  0.1008,  ..., -0.0616, -0.2752, -0.0869]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0452,  0.2203, -0.0292,  ...,  0.2949,  0.0973,  0.0312],\n",
            "        [ 0.3798,  0.7637, -0.1043,  ...,  0.6367,  0.0331, -0.3403],\n",
            "        [-0.0604,  0.2173, -0.0983,  ...,  0.0740,  0.0856, -0.1153],\n",
            "        ...,\n",
            "        [ 0.2906, -0.0431,  0.4325,  ...,  0.2168, -0.4408, -0.3886],\n",
            "        [ 0.5463,  0.7495, -0.0746,  ...,  0.7494, -0.0059, -0.4753],\n",
            "        [-0.0596, -0.3294,  0.3109,  ..., -0.0801, -0.4093, -0.2783]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0629,  0.0749, -0.0149,  ..., -0.0350,  0.0106,  0.0664],\n",
            "        [ 0.0975,  0.1180,  0.0250,  ...,  0.1145, -0.0069,  0.0024],\n",
            "        [-0.1663,  0.0567,  0.0074,  ...,  0.1424, -0.0703, -0.0531],\n",
            "        ...,\n",
            "        [-0.4032,  0.0197,  0.0248,  ...,  0.1253,  0.1413,  0.3465],\n",
            "        [-0.0607, -0.1941,  0.0704,  ..., -0.0561, -0.3006, -0.1393],\n",
            "        [ 0.0533,  0.1547,  0.1824,  ...,  0.3435, -0.1076, -0.0419]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2212,  0.0426,  0.0996,  ...,  0.1837, -0.0192, -0.2108],\n",
            "         [-0.1263,  0.5664,  0.0825,  ...,  0.1948,  0.0102, -0.2198],\n",
            "         [ 0.0350,  0.1959, -0.1105,  ..., -0.0734,  0.2764,  0.1327],\n",
            "         ...,\n",
            "         [-0.0607, -0.1941,  0.0704,  ..., -0.0561, -0.3006, -0.1393],\n",
            "         [ 0.0533,  0.1547,  0.1824,  ...,  0.3435, -0.1076, -0.0419],\n",
            "         [-0.1104,  0.2326,  0.1004,  ...,  0.2109, -0.1150, -0.0465]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2408, -0.2640,  0.5197,  ...,  0.0529, -0.4863, -0.4723],\n",
            "        [ 0.1384,  0.6596, -0.0725,  ...,  0.4280,  0.0542, -0.2522],\n",
            "        [ 0.0949,  0.3058, -0.0789,  ...,  0.0808,  0.1645,  0.1123],\n",
            "        ...,\n",
            "        [-0.0405, -0.0921,  0.1344,  ..., -0.0743, -0.2450, -0.1199],\n",
            "        [ 0.1097,  0.2632,  0.0615,  ...,  0.2345, -0.0475, -0.0817],\n",
            "        [ 0.2736,  0.5879, -0.0632,  ...,  0.4360,  0.0798, -0.2771]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2124,  0.0716,  0.0726,  ..., -0.0308, -0.1087, -0.0194],\n",
            "        [ 0.0514,  0.0740,  0.1487,  ...,  0.0087,  0.1941,  0.0372],\n",
            "        [-0.0630,  0.0750, -0.0149,  ..., -0.0351,  0.0105,  0.0664],\n",
            "        ...,\n",
            "        [ 0.0541,  0.0764,  0.1941,  ...,  0.1258, -0.0816, -0.1008],\n",
            "        [ 0.0971, -0.0977, -0.0235,  ...,  0.0382, -0.1145,  0.0280],\n",
            "        [-0.0957, -0.1612,  0.0508,  ..., -0.1029, -0.3006, -0.1076]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.3131,  0.5003,  0.0498,  ...,  0.2913, -0.1432,  0.1301],\n",
            "         [-0.0387,  0.0932,  0.0091,  ..., -0.0535, -0.0854, -0.1800],\n",
            "         [ 0.1765, -0.1974,  0.1299,  ...,  0.1399, -0.2335, -0.1795],\n",
            "         ...,\n",
            "         [ 0.2828, -0.1150,  0.2067,  ..., -0.0446, -0.1254, -0.0410],\n",
            "         [ 0.0635,  0.2334,  0.0426,  ...,  0.1282, -0.2143, -0.1050],\n",
            "         [-0.0789,  0.1753,  0.0601,  ...,  0.2764,  0.0098,  0.1662]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1650,  0.6708, -0.0911,  ...,  0.5428,  0.0579, -0.1572],\n",
            "        [-0.0142,  0.1735, -0.0695,  ...,  0.0014,  0.0143, -0.0882],\n",
            "        [ 0.1711, -0.1081,  0.1734,  ...,  0.1635, -0.3122, -0.2942],\n",
            "        ...,\n",
            "        [ 0.1382, -0.2973,  0.4575,  ..., -0.1011, -0.5235, -0.3016],\n",
            "        [ 0.2630,  0.3649,  0.0277,  ...,  0.2699, -0.1181, -0.2042],\n",
            "        [ 0.0406,  0.2197, -0.0320,  ...,  0.2945,  0.1003,  0.0365]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0629,  0.0752, -0.0148,  ..., -0.0350,  0.0103,  0.0662],\n",
            "        [-0.0629,  0.0752, -0.0148,  ..., -0.0350,  0.0103,  0.0662],\n",
            "        [-0.1182,  0.0681, -0.0743,  ..., -0.0656, -0.0171,  0.0400],\n",
            "        ...,\n",
            "        [ 0.2356,  0.1556,  0.2531,  ...,  0.2197, -0.1057, -0.2008],\n",
            "        [ 0.3379, -0.0869, -0.0326,  ...,  0.0286, -0.1386, -0.0985],\n",
            "        [-0.0997,  0.0405,  0.1554,  ..., -0.0229,  0.0408,  0.1507]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0364,  0.3343,  0.0509,  ...,  0.1256, -0.2921, -0.0916],\n",
            "         [ 0.2356,  0.1556,  0.2531,  ...,  0.2197, -0.1057, -0.2008],\n",
            "         [ 0.3379, -0.0869, -0.0326,  ...,  0.0286, -0.1386, -0.0985],\n",
            "         ...,\n",
            "         [-0.0469, -0.2073,  0.0792,  ..., -0.0533, -0.3118, -0.1621],\n",
            "         [ 0.1513,  0.2706, -0.0503,  ..., -0.0287, -0.3719, -0.1178],\n",
            "         [-0.1075, -0.0772,  0.0869,  ..., -0.0369, -0.1739, -0.0757]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0151,  0.1881,  0.1275,  ...,  0.0929, -0.3365, -0.2140],\n",
            "        [ 0.2323, -0.1536,  0.5891,  ...,  0.0921, -0.5230, -0.4302],\n",
            "        [ 0.0937, -0.3468,  0.3441,  ..., -0.0691, -0.5220, -0.3336],\n",
            "        ...,\n",
            "        [-0.0277, -0.1215,  0.1784,  ..., -0.0746, -0.3008, -0.1684],\n",
            "        [ 0.1515,  0.0242,  0.2811,  ...,  0.0159, -0.5139, -0.3829],\n",
            "        [-0.0510,  0.0195, -0.0339,  ...,  0.0283,  0.0531, -0.0769]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0475,  0.0987,  0.0354,  ...,  0.1483,  0.0154,  0.1970],\n",
            "        [ 0.2305, -0.1100,  0.0559,  ..., -0.0063, -0.0547, -0.0855],\n",
            "        [-0.0633,  0.0364, -0.0752,  ...,  0.0005, -0.1837, -0.0089],\n",
            "        ...,\n",
            "        [ 0.1321, -0.0430, -0.0138,  ...,  0.2015, -0.2548, -0.0704],\n",
            "        [ 0.2983, -0.3681,  0.0925,  ..., -0.0077, -0.0357,  0.0051],\n",
            "        [-0.0730,  0.0119,  0.0865,  ...,  0.1488, -0.0119,  0.0515]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0509,  0.1155, -0.0050,  ...,  0.0710, -0.1486,  0.0057],\n",
            "         [ 0.0568, -0.1511,  0.1525,  ..., -0.2614, -0.2737, -0.0645],\n",
            "         [ 0.0433,  0.1841,  0.2046,  ...,  0.1023, -0.3762, -0.1109],\n",
            "         ...,\n",
            "         [ 0.1321, -0.0430, -0.0138,  ...,  0.2015, -0.2548, -0.0704],\n",
            "         [ 0.2983, -0.3681,  0.0925,  ..., -0.0077, -0.0357,  0.0051],\n",
            "         [-0.0730,  0.0119,  0.0865,  ...,  0.1488, -0.0119,  0.0515]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2298,  0.3763, -0.1159,  ...,  0.2614, -0.0083, -0.1201],\n",
            "        [-0.0058, -0.3570,  0.4707,  ..., -0.2213, -0.5780, -0.3169],\n",
            "        [ 0.1552, -0.1499,  0.4739,  ...,  0.0541, -0.6194, -0.4328],\n",
            "        ...,\n",
            "        [ 0.0949, -0.0864,  0.1852,  ...,  0.0520, -0.3713, -0.1734],\n",
            "        [ 0.0778, -0.3427,  0.3928,  ..., -0.1413, -0.3950, -0.2025],\n",
            "        [ 0.0819,  0.1513, -0.0236,  ...,  0.2071,  0.0850, -0.0159]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2930, -0.0261,  0.0853,  ...,  0.3366, -0.1345, -0.1385],\n",
            "        [-0.0799, -0.0772, -0.0517,  ...,  0.0115, -0.0980, -0.1196],\n",
            "        [ 0.2930, -0.0261,  0.0853,  ...,  0.3366, -0.1345, -0.1385],\n",
            "        ...,\n",
            "        [ 0.1114,  0.2768,  0.1981,  ...,  0.1537, -0.2317,  0.0885],\n",
            "        [-0.1292,  0.3044,  0.0194,  ...,  0.2196, -0.1123, -0.0483],\n",
            "        [-0.0957,  0.2335, -0.0711,  ..., -0.1466, -0.0155, -0.2020]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1015,  0.3666,  0.1809,  ...,  0.1782, -0.2439,  0.0819],\n",
            "         [ 0.0130,  0.1591,  0.0994,  ...,  0.0582, -0.1278, -0.0975],\n",
            "         [ 0.1253,  0.3308,  0.2150,  ...,  0.1658, -0.2567,  0.0534],\n",
            "         ...,\n",
            "         [ 0.1282, -0.2038,  0.1495,  ...,  0.0612, -0.1599,  0.0504],\n",
            "         [-0.0308,  0.0608,  0.1812,  ..., -0.0362,  0.0599,  0.1993],\n",
            "         [-0.2399,  0.1553,  0.0651,  ...,  0.0598, -0.2982, -0.1105]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3610,  0.5989, -0.0782,  ...,  0.5313, -0.0060,  0.0259],\n",
            "        [ 0.1693,  0.1198,  0.2707,  ...,  0.0755, -0.2711, -0.3713],\n",
            "        [ 0.3678,  0.5749, -0.0603,  ...,  0.5072, -0.0365, -0.0317],\n",
            "        ...,\n",
            "        [-0.0455, -0.1968,  0.2321,  ..., -0.0257, -0.2330, -0.0667],\n",
            "        [-0.0741,  0.0565,  0.0227,  ..., -0.0496,  0.0886,  0.1511],\n",
            "        [ 0.3108,  0.6405, -0.1310,  ...,  0.4832,  0.0325, -0.2883]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0862,  0.0768,  0.0652,  ..., -0.0705, -0.0061, -0.1426],\n",
            "        [ 0.0542, -0.1707, -0.0738,  ..., -0.0298,  0.0255, -0.0662],\n",
            "        [-0.0628,  0.0754, -0.0147,  ..., -0.0348,  0.0098,  0.0657],\n",
            "        ...,\n",
            "        [ 0.1870, -0.0372,  0.0236,  ...,  0.0609,  0.0086,  0.0141],\n",
            "        [ 0.2961, -0.1150,  0.2036,  ...,  0.0820,  0.0200, -0.2109],\n",
            "        [ 0.0461,  0.2387,  0.2498,  ...,  0.0223,  0.0121, -0.1884]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2961, -0.1150,  0.2036,  ...,  0.0820,  0.0200, -0.2109],\n",
            "         [ 0.0461,  0.2387,  0.2498,  ...,  0.0223,  0.0121, -0.1884],\n",
            "         [ 0.2110,  0.1946,  0.2430,  ...,  0.0148, -0.2749,  0.0491],\n",
            "         ...,\n",
            "         [ 0.2075, -0.3744,  0.1999,  ..., -0.0386, -0.3173, -0.1381],\n",
            "         [-0.0117,  0.0125,  0.0447,  ..., -0.0096, -0.0632, -0.1070],\n",
            "         [ 0.1870, -0.0372,  0.0236,  ...,  0.0609,  0.0086,  0.0141]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3418, -0.3342,  0.5195,  ...,  0.1123, -0.3969, -0.4065],\n",
            "        [ 0.2460,  0.2996,  0.3860,  ...,  0.1748, -0.3841, -0.3449],\n",
            "        [ 0.1818,  0.1431,  0.3595,  ...,  0.0512, -0.3613, -0.1458],\n",
            "        ...,\n",
            "        [ 0.0126, -0.5896,  0.6381,  ..., -0.2134, -0.7395, -0.4997],\n",
            "        [ 0.2048,  0.1405,  0.0616,  ...,  0.1654, -0.1395, -0.3022],\n",
            "        [ 0.1495, -0.0898,  0.1550,  ..., -0.0298, -0.1605, -0.1116]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2940, -0.0286,  0.0874,  ...,  0.3351, -0.1345, -0.1391],\n",
            "        [-0.0954,  0.0224, -0.0423,  ..., -0.0674, -0.0612,  0.1344],\n",
            "        [ 0.2940, -0.0286,  0.0874,  ...,  0.3351, -0.1345, -0.1391],\n",
            "        ...,\n",
            "        [-0.2863,  0.3277,  0.1173,  ...,  0.0310, -0.1345, -0.0400],\n",
            "        [ 0.2177,  0.6785, -0.1704,  ...,  0.1951,  0.0088, -0.2125],\n",
            "        [-0.2863,  0.3277,  0.1173,  ...,  0.0310, -0.1345, -0.0400]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.2863,  0.3277,  0.1173,  ...,  0.0310, -0.1345, -0.0400],\n",
            "         [ 0.2177,  0.6785, -0.1704,  ...,  0.1951,  0.0088, -0.2125],\n",
            "         [-0.2863,  0.3277,  0.1173,  ...,  0.0310, -0.1345, -0.0400],\n",
            "         ...,\n",
            "         [ 0.2258, -0.3878,  0.2034,  ..., -0.0447, -0.3262, -0.1451],\n",
            "         [-0.0135, -0.5427,  0.2000,  ..., -0.1372, -0.2457, -0.1463],\n",
            "         [ 0.0541,  0.1273,  0.3426,  ...,  0.1035, -0.2232, -0.0152]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0849,  0.5834, -0.0693,  ...,  0.3428,  0.0831, -0.1832],\n",
            "        [ 0.5227,  0.7596, -0.0028,  ...,  0.5315, -0.1987, -0.5047],\n",
            "        [ 0.0849,  0.5834, -0.0693,  ...,  0.3428,  0.0831, -0.1832],\n",
            "        ...,\n",
            "        [ 0.0265, -0.6089,  0.6553,  ..., -0.2227, -0.7574, -0.5170],\n",
            "        [-0.0135, -0.6535,  0.5927,  ..., -0.2412, -0.6598, -0.4792],\n",
            "        [ 0.1823, -0.1098,  0.4937,  ...,  0.0909, -0.5398, -0.3156]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0632,  0.0755, -0.0149,  ..., -0.0343,  0.0097,  0.0649],\n",
            "        [-0.0632,  0.0755, -0.0149,  ..., -0.0343,  0.0097,  0.0649],\n",
            "        [-0.0632,  0.0755, -0.0149,  ..., -0.0343,  0.0097,  0.0649],\n",
            "        ...,\n",
            "        [-0.0349,  0.1742,  0.0716,  ...,  0.1132, -0.2864, -0.1254],\n",
            "        [ 0.1348,  0.5915,  0.0639,  ...,  0.0310,  0.0124, -0.1473],\n",
            "        [-0.1353, -0.0440,  0.1659,  ..., -0.0094, -0.3455, -0.1463]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1353, -0.0440,  0.1659,  ..., -0.0094, -0.3455, -0.1463],\n",
            "         [ 0.1348,  0.5915,  0.0639,  ...,  0.0310,  0.0124, -0.1473],\n",
            "         [ 0.4290, -0.4759,  0.0795,  ...,  0.1769, -0.0809, -0.3695],\n",
            "         ...,\n",
            "         [ 0.4290, -0.4759,  0.0795,  ...,  0.1769, -0.0809, -0.3695],\n",
            "         [ 0.4290, -0.4759,  0.0795,  ...,  0.1769, -0.0809, -0.3695],\n",
            "         [ 0.4290, -0.4759,  0.0795,  ...,  0.1769, -0.0809, -0.3695]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.1400, -0.4287,  0.5488,  ..., -0.1427, -0.6628, -0.4718],\n",
            "        [ 0.4612,  0.6992, -0.0700,  ...,  0.4229,  0.0079, -0.3359],\n",
            "        [ 0.3608, -0.6275,  0.5678,  ..., -0.0435, -0.6034, -0.6626],\n",
            "        ...,\n",
            "        [ 0.3608, -0.6275,  0.5678,  ..., -0.0435, -0.6034, -0.6626],\n",
            "        [ 0.3608, -0.6275,  0.5678,  ..., -0.0435, -0.6034, -0.6626],\n",
            "        [ 0.3608, -0.6275,  0.5678,  ..., -0.0435, -0.6034, -0.6626]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0913, -0.0340, -0.0364,  ...,  0.0578, -0.1185, -0.0463],\n",
            "        [-0.0634,  0.0754, -0.0151,  ..., -0.0341,  0.0097,  0.0646],\n",
            "        [-0.2099, -0.0549, -0.0210,  ...,  0.1545, -0.1695, -0.0790],\n",
            "        ...,\n",
            "        [ 0.0889,  0.3065,  0.0791,  ...,  0.1202, -0.3235, -0.1475],\n",
            "        [ 0.0273, -0.0313,  0.0163,  ..., -0.0132, -0.1644, -0.0669],\n",
            "        [ 0.1056,  0.3515, -0.0362,  ...,  0.1253, -0.2261, -0.0831]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0273, -0.0313,  0.0163,  ..., -0.0132, -0.1644, -0.0669],\n",
            "         [ 0.1056,  0.3515, -0.0362,  ...,  0.1253, -0.2261, -0.0831],\n",
            "         [ 0.2811, -0.0621,  0.2800,  ...,  0.1002, -0.0633, -0.1935],\n",
            "         ...,\n",
            "         [ 0.0576,  0.3364,  0.0128,  ...,  0.2296, -0.0249, -0.0537],\n",
            "         [-0.2512,  0.2652, -0.0024,  ...,  0.1257, -0.1601, -0.0523],\n",
            "         [-0.2512,  0.2652, -0.0024,  ...,  0.1257, -0.1601, -0.0523]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 9.9335e-02,  6.5647e-02, -3.4361e-02,  ...,  3.1162e-02,\n",
            "          2.3180e-02, -1.5071e-02],\n",
            "        [ 2.2127e-01,  3.2287e-01,  8.2664e-02,  ...,  2.3592e-01,\n",
            "         -2.5311e-01, -2.9736e-01],\n",
            "        [ 3.0967e-01, -4.2626e-01,  6.6265e-01,  ..., -6.5598e-04,\n",
            "         -5.5046e-01, -4.6313e-01],\n",
            "        ...,\n",
            "        [ 1.5165e-01,  1.6645e-01,  2.9425e-01,  ...,  1.8659e-01,\n",
            "         -3.4596e-01, -2.8223e-01],\n",
            "        [ 1.4993e-01,  5.9688e-01, -1.2957e-01,  ...,  4.6467e-01,\n",
            "          7.7523e-02, -1.4089e-01],\n",
            "        [ 1.4993e-01,  5.9688e-01, -1.2957e-01,  ...,  4.6467e-01,\n",
            "          7.7523e-02, -1.4089e-01]], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0031,  0.3432,  0.0077,  ..., -0.0353, -0.0118, -0.1652],\n",
            "        [-0.0749, -0.0126,  0.0057,  ...,  0.1926,  0.1698,  0.1173],\n",
            "        [ 0.0920, -0.0305, -0.0369,  ...,  0.0596, -0.1173, -0.0469],\n",
            "        ...,\n",
            "        [ 0.0743,  0.3039,  0.1878,  ..., -0.0597, -0.0841, -0.3546],\n",
            "        [ 0.1440, -0.0962, -0.0144,  ...,  0.0390, -0.0198, -0.0354],\n",
            "        [ 0.3064, -0.0638,  0.2323,  ..., -0.0120, -0.1968, -0.0312]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0743,  0.3039,  0.1878,  ..., -0.0597, -0.0841, -0.3546],\n",
            "         [ 0.1440, -0.0962, -0.0144,  ...,  0.0390, -0.0198, -0.0354],\n",
            "         [ 0.3064, -0.0638,  0.2323,  ..., -0.0120, -0.1968, -0.0312],\n",
            "         ...,\n",
            "         [ 0.1483,  0.1050,  0.0979,  ...,  0.1592, -0.1675,  0.1683],\n",
            "         [ 0.1051, -0.1693, -0.0187,  ..., -0.1030,  0.0558, -0.0548],\n",
            "         [ 0.1925,  0.0393,  0.2209,  ...,  0.1477, -0.1055, -0.1818]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1717,  0.0629,  0.3615,  ...,  0.0370, -0.3758, -0.3576],\n",
            "        [ 0.0560, -0.2169,  0.2804,  ..., -0.0090, -0.3232, -0.2417],\n",
            "        [ 0.2005, -0.2610,  0.4207,  ..., -0.0007, -0.4761, -0.2334],\n",
            "        ...,\n",
            "        [ 0.0178, -0.0075,  0.2430,  ...,  0.0845, -0.3237, -0.1197],\n",
            "        [ 0.0547, -0.0436, -0.0057,  ..., -0.0517,  0.0424, -0.0316],\n",
            "        [ 0.1910, -0.1070,  0.3854,  ...,  0.0310, -0.3542, -0.2660]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.2100, -0.0564, -0.0208,  ...,  0.1543, -0.1703, -0.0797],\n",
            "        [ 0.0043, -0.2239,  0.0811,  ..., -0.0202,  0.0583,  0.0038],\n",
            "        [-0.0642,  0.0750, -0.0154,  ..., -0.0338,  0.0097,  0.0643],\n",
            "        ...,\n",
            "        [ 0.1712,  0.1642,  0.2882,  ...,  0.2876, -0.2978, -0.1878],\n",
            "        [ 0.2613,  0.0748,  0.0693,  ...,  0.0916, -0.1796, -0.1437],\n",
            "        [ 0.2566,  0.2467,  0.1889,  ...,  0.0108, -0.1618, -0.1611]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0391,  0.1187,  0.1425,  ...,  0.1740, -0.0057, -0.0254],\n",
            "         [ 0.0489, -0.1821, -0.0667,  ...,  0.0638, -0.2303, -0.3101],\n",
            "         [-0.1104,  0.3331,  0.0247,  ...,  0.2035, -0.0755,  0.1447],\n",
            "         ...,\n",
            "         [-0.1130, -0.3300,  0.1271,  ..., -0.1062,  0.1240, -0.0125],\n",
            "         [-0.1130, -0.3300,  0.1271,  ..., -0.1062,  0.1240, -0.0125],\n",
            "         [ 0.3268, -0.0603,  0.2218,  ...,  0.0707, -0.0526, -0.2235]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 3.4799e-02, -1.0905e-01,  3.0395e-01,  ...,  5.4941e-02,\n",
            "         -2.5899e-01, -1.3604e-01],\n",
            "        [ 1.5097e-01, -4.7700e-01,  3.9259e-01,  ...,  8.0491e-04,\n",
            "         -5.6629e-01, -5.3719e-01],\n",
            "        [ 6.9241e-02,  3.4936e-01, -2.0896e-02,  ...,  2.6407e-01,\n",
            "          3.1802e-04, -3.8975e-02],\n",
            "        ...,\n",
            "        [-2.0832e-01, -1.1801e-01, -3.8515e-02,  ..., -1.3789e-01,\n",
            "          1.6828e-01,  8.8750e-02],\n",
            "        [-2.0832e-01, -1.1801e-01, -3.8515e-02,  ..., -1.3789e-01,\n",
            "          1.6828e-01,  8.8750e-02],\n",
            "        [ 3.8663e-01, -3.9657e-01,  6.2310e-01,  ...,  1.1964e-01,\n",
            "         -5.1117e-01, -4.8061e-01]], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0644,  0.0748, -0.0155,  ..., -0.0338,  0.0097,  0.0642],\n",
            "        [ 0.2930, -0.0385,  0.0901,  ...,  0.3286, -0.1368, -0.1398],\n",
            "        [-0.1004,  0.0578,  0.3031,  ..., -0.1009, -0.0330, -0.1133],\n",
            "        ...,\n",
            "        [-0.0548, -0.1070,  0.0365,  ...,  0.2762, -0.2295, -0.2139],\n",
            "        [ 0.0386,  0.1593,  0.2028,  ..., -0.1186, -0.3553, -0.2180],\n",
            "        [ 0.2605,  0.1021, -0.0149,  ..., -0.2308,  0.0313, -0.2252]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1351, -0.1644, -0.1009,  ..., -0.0127, -0.2582, -0.2109],\n",
            "         [ 0.2114,  0.1701,  0.2490,  ...,  0.2870, -0.0944, -0.1688],\n",
            "         [-0.0454, -0.1536,  0.0079,  ...,  0.0877, -0.2198,  0.0639],\n",
            "         ...,\n",
            "         [-0.0548, -0.1070,  0.0365,  ...,  0.2762, -0.2295, -0.2139],\n",
            "         [ 0.0386,  0.1593,  0.2028,  ..., -0.1186, -0.3553, -0.2180],\n",
            "         [ 0.2605,  0.1021, -0.0149,  ..., -0.2308,  0.0313, -0.2252]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0918, -0.3857,  0.3393,  ..., -0.0595, -0.5164, -0.3627],\n",
            "        [ 0.2460, -0.0934,  0.5465,  ...,  0.1440, -0.4699, -0.3845],\n",
            "        [ 0.0949, -0.1511,  0.1752,  ...,  0.1038, -0.3789, -0.1385],\n",
            "        ...,\n",
            "        [ 0.3001,  0.2253,  0.0248,  ...,  0.4047, -0.1372, -0.2992],\n",
            "        [ 0.1620, -0.0249,  0.3962,  ..., -0.0719, -0.4951, -0.3311],\n",
            "        [ 0.2235, -0.1063,  0.3502,  ..., -0.1269, -0.4028, -0.3952]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0645,  0.0749, -0.0156,  ..., -0.0337,  0.0097,  0.0644],\n",
            "        [ 0.1844,  0.0959, -0.0381,  ..., -0.0151,  0.2595, -0.0227],\n",
            "        [ 0.0287,  0.0332,  0.0317,  ...,  0.1049, -0.0278,  0.1237],\n",
            "        ...,\n",
            "        [-0.1503,  0.1422,  0.2797,  ..., -0.0620,  0.1052, -0.1037],\n",
            "        [ 0.1984,  0.0115,  0.0596,  ...,  0.1393,  0.1483,  0.1220],\n",
            "        [-0.0059,  0.1307,  0.0212,  ..., -0.1126, -0.0282,  0.1704]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.4191, -0.1728,  0.3500,  ...,  0.0977, -0.3245, -0.1921],\n",
            "         [ 0.0513,  0.2015, -0.0176,  ...,  0.1692,  0.0581,  0.0629],\n",
            "         [ 0.1667, -0.2447, -0.2063,  ...,  0.0827,  0.0964, -0.0553],\n",
            "         ...,\n",
            "         [ 0.3456, -0.0727, -0.1088,  ..., -0.0215, -0.0571, -0.1033],\n",
            "         [ 0.2083, -0.0444,  0.2954,  ...,  0.1487,  0.0658, -0.2418],\n",
            "         [ 0.1850,  0.1182,  0.0438,  ...,  0.2283,  0.0648, -0.1492]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2089, -0.4728,  0.5730,  ...,  0.0247, -0.6423, -0.4484],\n",
            "        [ 0.2192,  0.3447,  0.0024,  ...,  0.3130, -0.0162, -0.1379],\n",
            "        [ 0.0811, -0.2005,  0.0987,  ...,  0.0019, -0.1837, -0.1766],\n",
            "        ...,\n",
            "        [ 0.1815, -0.1333,  0.0854,  ...,  0.0071, -0.2673, -0.2046],\n",
            "        [ 0.2938, -0.2246,  0.5043,  ...,  0.1038, -0.3730, -0.4244],\n",
            "        [ 0.3710,  0.3108, -0.0105,  ...,  0.3758, -0.0147, -0.2486]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0646,  0.0749, -0.0157,  ..., -0.0337,  0.0096,  0.0645],\n",
            "        [-0.0646,  0.0749, -0.0157,  ..., -0.0337,  0.0096,  0.0645],\n",
            "        [-0.0069,  0.0126, -0.0024,  ...,  0.0642, -0.0236,  0.1053],\n",
            "        ...,\n",
            "        [ 0.0490,  0.2509,  0.1392,  ...,  0.0027,  0.1340,  0.1144],\n",
            "        [ 0.2299,  0.0193,  0.0146,  ...,  0.1130, -0.1985, -0.1608],\n",
            "        [-0.2907,  0.5094,  0.1438,  ...,  0.0875,  0.0084, -0.1335]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1482,  0.0625,  0.2702,  ...,  0.2963, -0.2277, -0.2102],\n",
            "         [ 0.1482,  0.0625,  0.2702,  ...,  0.2963, -0.2277, -0.2102],\n",
            "         [ 0.0545,  0.2309, -0.1949,  ..., -0.0720,  0.0104, -0.2424],\n",
            "         ...,\n",
            "         [ 0.0490,  0.2509,  0.1392,  ...,  0.0027,  0.1340,  0.1144],\n",
            "         [ 0.2299,  0.0193,  0.0146,  ...,  0.1130, -0.1985, -0.1608],\n",
            "         [-0.2907,  0.5094,  0.1438,  ...,  0.0875,  0.0084, -0.1335]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2800, -0.1636,  0.5330,  ...,  0.2020, -0.5831, -0.4585],\n",
            "        [ 0.2800, -0.1636,  0.5330,  ...,  0.2020, -0.5831, -0.4585],\n",
            "        [ 0.1801,  0.2864,  0.0192,  ...,  0.0792, -0.1732, -0.3362],\n",
            "        ...,\n",
            "        [ 0.3053,  0.5007,  0.0141,  ...,  0.3274,  0.0522,  0.0252],\n",
            "        [ 0.0592, -0.3294,  0.4139,  ...,  0.0479, -0.6036, -0.3976],\n",
            "        [ 0.0427,  0.6491, -0.0626,  ...,  0.3963,  0.1147, -0.2947]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2915, -0.0409,  0.0929,  ...,  0.3245, -0.1395, -0.1372],\n",
            "        [-0.0072, -0.0932, -0.0027,  ..., -0.0592, -0.1135,  0.0690],\n",
            "        [-0.1650,  0.0513,  0.0042,  ...,  0.1370, -0.0704, -0.0508],\n",
            "        ...,\n",
            "        [ 0.1978,  0.0509,  0.0585,  ...,  0.4979, -0.1146, -0.1612],\n",
            "        [-0.2835,  0.3243,  0.1319,  ...,  0.0238, -0.1570, -0.0565],\n",
            "        [ 0.1459,  0.1959, -0.0484,  ...,  0.1295, -0.1349, -0.1506]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.2835,  0.3243,  0.1319,  ...,  0.0238, -0.1570, -0.0565],\n",
            "         [ 0.2553, -0.1455,  0.0186,  ..., -0.0971, -0.1119, -0.1626],\n",
            "         [ 0.2297,  0.2265, -0.1056,  ...,  0.1002, -0.0225, -0.2674],\n",
            "         ...,\n",
            "         [ 0.1978,  0.0509,  0.0585,  ...,  0.4979, -0.1146, -0.1612],\n",
            "         [-0.2835,  0.3243,  0.1319,  ...,  0.0238, -0.1570, -0.0565],\n",
            "         [ 0.1459,  0.1959, -0.0484,  ...,  0.1295, -0.1349, -0.1506]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1168,  0.5919, -0.0518,  ...,  0.3532,  0.0658, -0.2576],\n",
            "        [ 0.2499, -0.3606,  0.3928,  ..., -0.0138, -0.5178, -0.3936],\n",
            "        [ 0.3408,  0.1327,  0.2880,  ...,  0.0807, -0.4492, -0.5153],\n",
            "        ...,\n",
            "        [ 0.2465, -0.0285,  0.2077,  ...,  0.2296, -0.2660, -0.2368],\n",
            "        [ 0.1168,  0.5919, -0.0518,  ...,  0.3532,  0.0658, -0.2576],\n",
            "        [ 0.3747,  0.3612,  0.0564,  ...,  0.4552, -0.2130, -0.3670]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1121, -0.0586, -0.1071,  ..., -0.0682,  0.0511, -0.1864],\n",
            "        [-0.0638,  0.0753, -0.0157,  ..., -0.0336,  0.0097,  0.0647],\n",
            "        [ 0.0248,  0.0057,  0.0639,  ..., -0.0008,  0.0667,  0.0245],\n",
            "        ...,\n",
            "        [-0.1292,  0.2959, -0.0597,  ...,  0.0373, -0.0128, -0.0090],\n",
            "        [ 0.3826, -0.0660,  0.1638,  ..., -0.0625, -0.1209, -0.2146],\n",
            "        [ 0.2355, -0.1604,  0.3220,  ...,  0.0983, -0.3397, -0.1788]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2118,  0.0622, -0.2104,  ...,  0.1053, -0.3493, -0.3344],\n",
            "         [ 0.1784,  0.0807,  0.1693,  ...,  0.3280, -0.0949, -0.0903],\n",
            "         [ 0.1768,  0.2232,  0.1760,  ...,  0.2852, -0.3189, -0.1101],\n",
            "         ...,\n",
            "         [ 0.1925, -0.1082, -0.0422,  ...,  0.2053, -0.3245, -0.2532],\n",
            "         [ 0.2471,  0.0026,  0.1449,  ...,  0.2424, -0.1058, -0.2730],\n",
            "         [ 0.2410,  0.1660,  0.2115,  ...,  0.2178, -0.2434, -0.1452]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1308, -0.3259,  0.3260,  ...,  0.0047, -0.6523, -0.5105],\n",
            "        [ 0.3001, -0.0224,  0.3755,  ...,  0.1591, -0.4344, -0.3110],\n",
            "        [ 0.4297,  0.4750,  0.0740,  ...,  0.4792, -0.2661, -0.3631],\n",
            "        ...,\n",
            "        [ 0.2338, -0.3558,  0.3759,  ...,  0.2231, -0.5942, -0.5450],\n",
            "        [ 0.4653, -0.1729,  0.5334,  ...,  0.2449, -0.5659, -0.5466],\n",
            "        [ 0.3409,  0.1780,  0.3822,  ...,  0.3067, -0.4938, -0.4320]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0633,  0.0755, -0.0156,  ..., -0.0336,  0.0098,  0.0648],\n",
            "        [-0.0633,  0.0755, -0.0156,  ..., -0.0336,  0.0098,  0.0648],\n",
            "        [ 0.2919, -0.0396,  0.0948,  ...,  0.3244, -0.1398, -0.1351],\n",
            "        ...,\n",
            "        [ 0.2505, -0.2027,  0.2441,  ...,  0.2380, -0.2832, -0.1239],\n",
            "        [ 0.2241, -0.0559,  0.2126,  ..., -0.1163, -0.1735,  0.0657],\n",
            "        [-0.0708,  0.4675, -0.0128,  ...,  0.2397, -0.0435, -0.2355]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0708,  0.4675, -0.0128,  ...,  0.2397, -0.0435, -0.2355],\n",
            "         [-0.2104,  0.0277,  0.0734,  ..., -0.0686, -0.0948, -0.0262],\n",
            "         [-0.1427,  0.3823,  0.0336,  ..., -0.0229,  0.0734,  0.0012],\n",
            "         ...,\n",
            "         [ 0.1230, -0.0497,  0.2550,  ...,  0.3044, -0.1042, -0.2210],\n",
            "         [ 0.2505, -0.2027,  0.2441,  ...,  0.2380, -0.2832, -0.1239],\n",
            "         [ 0.2241, -0.0559,  0.2126,  ..., -0.1163, -0.1735,  0.0657]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1976,  0.5507, -0.0498,  ...,  0.4053, -0.0393, -0.2815],\n",
            "        [-0.1323,  0.0664,  0.0400,  ..., -0.0221, -0.0120, -0.0122],\n",
            "        [ 0.1630,  0.5105,  0.0277,  ...,  0.3061, -0.0226, -0.1596],\n",
            "        ...,\n",
            "        [ 0.2583, -0.2255,  0.4779,  ...,  0.1763, -0.4298, -0.3884],\n",
            "        [ 0.3674,  0.0134,  0.3704,  ...,  0.3664, -0.4666, -0.3896],\n",
            "        [ 0.2634, -0.3516,  0.5427,  ..., -0.1324, -0.5316, -0.2463]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0628,  0.0755, -0.0155,  ..., -0.0337,  0.0099,  0.0650],\n",
            "        [-0.0628,  0.0755, -0.0155,  ..., -0.0337,  0.0099,  0.0650],\n",
            "        [-0.0628,  0.0755, -0.0155,  ..., -0.0337,  0.0099,  0.0650],\n",
            "        ...,\n",
            "        [ 0.4368, -0.4476,  0.0962,  ...,  0.2046, -0.0807, -0.3625],\n",
            "        [ 0.4368, -0.4476,  0.0962,  ...,  0.2046, -0.0807, -0.3625],\n",
            "        [ 0.4368, -0.4476,  0.0962,  ...,  0.2046, -0.0807, -0.3625]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.4368, -0.4476,  0.0962,  ...,  0.2046, -0.0807, -0.3625],\n",
            "         [ 0.4368, -0.4476,  0.0962,  ...,  0.2046, -0.0807, -0.3625],\n",
            "         [ 0.4368, -0.4476,  0.0962,  ...,  0.2046, -0.0807, -0.3625],\n",
            "         ...,\n",
            "         [ 0.4368, -0.4476,  0.0962,  ...,  0.2046, -0.0807, -0.3625],\n",
            "         [ 0.4368, -0.4476,  0.0962,  ...,  0.2046, -0.0807, -0.3625],\n",
            "         [ 0.4368, -0.4476,  0.0962,  ...,  0.2046, -0.0807, -0.3625]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3788, -0.6143,  0.5730,  ...,  0.0020, -0.5969, -0.6557],\n",
            "        [ 0.3788, -0.6143,  0.5730,  ...,  0.0020, -0.5969, -0.6557],\n",
            "        [ 0.3788, -0.6143,  0.5730,  ...,  0.0020, -0.5969, -0.6557],\n",
            "        ...,\n",
            "        [ 0.3788, -0.6143,  0.5730,  ...,  0.0020, -0.5969, -0.6557],\n",
            "        [ 0.3788, -0.6143,  0.5730,  ...,  0.0020, -0.5969, -0.6557],\n",
            "        [ 0.3788, -0.6143,  0.5730,  ...,  0.0020, -0.5969, -0.6557]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0624,  0.0756, -0.0155,  ..., -0.0339,  0.0100,  0.0652],\n",
            "        [ 0.0944, -0.0092, -0.0406,  ...,  0.0728, -0.1119, -0.0514],\n",
            "        [-0.1627,  0.0514,  0.0042,  ...,  0.1358, -0.0696, -0.0498],\n",
            "        ...,\n",
            "        [ 0.1743,  0.2352,  0.1451,  ..., -0.1359, -0.3495, -0.2289],\n",
            "        [ 0.2188, -0.2927,  0.2242,  ...,  0.0241, -0.3140, -0.1439],\n",
            "        [ 0.2457, -0.1889,  0.2281,  ..., -0.1195, -0.1551, -0.1748]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2188, -0.2927,  0.2242,  ...,  0.0241, -0.3140, -0.1439],\n",
            "         [ 0.2350, -0.2231, -0.0518,  ...,  0.3335, -0.3779, -0.2659],\n",
            "         [ 0.1076,  0.4044,  0.0093,  ..., -0.0252, -0.2737, -0.2873],\n",
            "         ...,\n",
            "         [-0.1081,  0.1409,  0.2518,  ...,  0.0893, -0.0712, -0.0788],\n",
            "         [ 0.1460,  0.0422,  0.2474,  ...,  0.0703, -0.0650, -0.1626],\n",
            "         [-0.1772,  0.4134,  0.1540,  ...,  0.1760, -0.3468, -0.1072]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0505, -0.5870,  0.6559,  ..., -0.1991, -0.7423, -0.5150],\n",
            "        [ 0.3319, -0.2572,  0.2598,  ...,  0.3527, -0.5717, -0.4805],\n",
            "        [ 0.2692,  0.4199,  0.0011,  ...,  0.2125, -0.1758, -0.3045],\n",
            "        ...,\n",
            "        [ 0.2403,  0.4529,  0.0584,  ...,  0.3655, -0.0784, -0.2437],\n",
            "        [ 0.0874, -0.1740,  0.4843,  ..., -0.0190, -0.3575, -0.2664],\n",
            "        [ 0.2755,  0.6853,  0.0041,  ...,  0.4819, -0.0360, -0.4133]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1699,  0.0087, -0.1382,  ...,  0.0540, -0.0855, -0.1306],\n",
            "        [-0.1473, -0.0579, -0.0551,  ...,  0.0743, -0.0538,  0.0441],\n",
            "        [ 0.0943, -0.0080, -0.0410,  ...,  0.0739, -0.1118, -0.0518],\n",
            "        ...,\n",
            "        [ 0.0928,  0.0456,  0.0266,  ...,  0.0678, -0.1623, -0.1248],\n",
            "        [ 0.0800, -0.2132,  0.3414,  ...,  0.1609, -0.1496, -0.1108],\n",
            "        [ 0.1613,  0.1345,  0.1297,  ..., -0.0493, -0.2267, -0.2370]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0119,  0.1105,  0.0818,  ...,  0.4383, -0.0080, -0.0709],\n",
            "         [ 0.2835, -0.0074,  0.2519,  ...,  0.1116, -0.2790, -0.3415],\n",
            "         [ 0.3352, -0.3412, -0.1499,  ...,  0.2617, -0.0465, -0.2812],\n",
            "         ...,\n",
            "         [ 0.4003, -0.1724,  0.1248,  ..., -0.0291,  0.0421, -0.1481],\n",
            "         [-0.2859,  0.3226,  0.1299,  ...,  0.0285, -0.1506, -0.0492],\n",
            "         [ 0.1507, -0.0122,  0.1290,  ..., -0.1401, -0.1957, -0.1331]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0270,  0.1033, -0.0039,  ...,  0.2014,  0.0622, -0.0298],\n",
            "        [ 0.5003, -0.2263,  0.5470,  ...,  0.2573, -0.6617, -0.5934],\n",
            "        [ 0.3488, -0.2696,  0.2012,  ...,  0.1470, -0.3730, -0.4798],\n",
            "        ...,\n",
            "        [ 0.2201, -0.3782,  0.4175,  ..., -0.0076, -0.3592, -0.3052],\n",
            "        [ 0.1063,  0.5928, -0.0607,  ...,  0.3597,  0.0760, -0.2370],\n",
            "        [ 0.0644, -0.3181,  0.4500,  ..., -0.1626, -0.4572, -0.3763]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0610,  0.0758, -0.0152,  ..., -0.0345,  0.0106,  0.0659],\n",
            "        [ 0.0933, -0.0104, -0.0865,  ...,  0.0398,  0.0483, -0.1079],\n",
            "        [ 0.2322,  0.1495, -0.0172,  ...,  0.1177,  0.0583, -0.0493],\n",
            "        ...,\n",
            "        [-0.0720,  0.3020,  0.0904,  ...,  0.3597, -0.3674, -0.1462],\n",
            "        [ 0.0938,  0.1538,  0.2748,  ...,  0.2671, -0.1478,  0.0108],\n",
            "        [ 0.0101,  0.0902, -0.0062,  ...,  0.0029,  0.0560,  0.1575]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1571,  0.4175,  0.1162,  ...,  0.2586, -0.3412, -0.1265],\n",
            "         [ 0.2848,  0.1114,  0.2910,  ...,  0.2075, -0.0789, -0.2115],\n",
            "         [ 0.2226,  0.0127,  0.3038,  ...,  0.3868, -0.0712, -0.1382],\n",
            "         ...,\n",
            "         [ 0.0158,  0.5149,  0.2385,  ...,  0.1414, -0.0286,  0.0668],\n",
            "         [ 0.0727,  0.1784,  0.1477,  ...,  0.0186, -0.2745, -0.0023],\n",
            "         [ 0.0237, -0.2916,  0.2520,  ..., -0.0518, -0.3353, -0.1959]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3698,  0.7714, -0.0664,  ...,  0.6075,  0.0071, -0.4343],\n",
            "        [ 0.4056, -0.1620,  0.6025,  ...,  0.1831, -0.4951, -0.4747],\n",
            "        [ 0.3062, -0.2241,  0.5694,  ...,  0.2577, -0.3985, -0.3513],\n",
            "        ...,\n",
            "        [ 0.2512,  0.4890,  0.2827,  ...,  0.3622, -0.2509, -0.1643],\n",
            "        [-0.0089,  0.0311,  0.1390,  ...,  0.0345, -0.2534, -0.0640],\n",
            "        [ 0.1389, -0.6597,  0.6717,  ..., -0.1368, -0.7317, -0.6431]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1106,  0.1220, -0.1093,  ..., -0.0262, -0.0765, -0.0468],\n",
            "        [ 0.2883, -0.0415,  0.0922,  ...,  0.3200, -0.1393, -0.1307],\n",
            "        [-0.0603,  0.0760, -0.0152,  ..., -0.0347,  0.0109,  0.0663],\n",
            "        ...,\n",
            "        [ 0.1726,  0.0532,  0.2663,  ..., -0.0341,  0.2381,  0.0071],\n",
            "        [ 0.1139,  0.3386,  0.2265,  ..., -0.0552, -0.1150, -0.3939],\n",
            "        [ 0.0708,  0.3258, -0.0630,  ...,  0.0574, -0.0596, -0.1500]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.1783, -0.0147,  0.0174,  ..., -0.0650,  0.0139,  0.0104],\n",
            "         [ 0.1726,  0.0532,  0.2663,  ..., -0.0341,  0.2381,  0.0071],\n",
            "         [ 0.1139,  0.3386,  0.2265,  ..., -0.0552, -0.1150, -0.3939],\n",
            "         ...,\n",
            "         [ 0.2903,  0.0612,  0.0574,  ...,  0.3377, -0.2306, -0.2419],\n",
            "         [-0.0903,  0.0662,  0.0842,  ...,  0.1373, -0.1111, -0.0602],\n",
            "         [ 0.0929, -0.0523, -0.0092,  ...,  0.1291,  0.1473, -0.1632]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1516,  0.0303,  0.0919,  ...,  0.0669, -0.0780, -0.0657],\n",
            "        [ 0.3477, -0.0859,  0.4952,  ...,  0.0341, -0.2858, -0.2781],\n",
            "        [ 0.2177,  0.0649,  0.4377,  ...,  0.0639, -0.4463, -0.4198],\n",
            "        ...,\n",
            "        [ 0.2679,  0.0105,  0.2313,  ...,  0.2437, -0.4129, -0.3320],\n",
            "        [-0.0342,  0.0258,  0.1048,  ...,  0.0731, -0.1159, -0.0742],\n",
            "        [ 0.1115,  0.0328, -0.0171,  ...,  0.1196,  0.0843, -0.0595]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[ 0.0069,  0.0373, -0.0026,  ...,  0.1178,  0.1690, -0.1842],\n",
            "        [ 0.2883, -0.0415,  0.0922,  ...,  0.3200, -0.1393, -0.1307],\n",
            "        [-0.0460, -0.0879,  0.1453,  ...,  0.2758, -0.0840,  0.0303],\n",
            "        ...,\n",
            "        [-0.0625,  0.3894,  0.0671,  ...,  0.2608,  0.1513, -0.3874],\n",
            "        [ 0.1730, -0.0310,  0.2273,  ..., -0.0547, -0.3304, -0.1479],\n",
            "        [ 0.2516,  0.1257,  0.1309,  ...,  0.2335,  0.1270, -0.3192]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[-0.2688,  0.2984,  0.1142,  ...,  0.3179,  0.0230, -0.1365],\n",
            "         [ 0.2144,  0.2443,  0.1366,  ...,  0.1974,  0.1464, -0.3568],\n",
            "         [ 0.0957,  0.2063,  0.0015,  ...,  0.1448,  0.0088, -0.2535],\n",
            "         ...,\n",
            "         [ 0.1033,  0.1329,  0.1100,  ...,  0.1276,  0.0231, -0.2350],\n",
            "         [ 0.1946, -0.1572,  0.1473,  ..., -0.0713, -0.0601,  0.0214],\n",
            "         [ 0.4319,  0.0996,  0.1365,  ...,  0.2596,  0.0352, -0.3204]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1234,  0.5545, -0.0170,  ...,  0.4382,  0.1016, -0.3587],\n",
            "        [ 0.4267,  0.4514,  0.2486,  ...,  0.4340, -0.2391, -0.4774],\n",
            "        [ 0.2526,  0.3049,  0.0782,  ...,  0.2743, -0.2138, -0.3501],\n",
            "        ...,\n",
            "        [ 0.1690,  0.0971,  0.2296,  ...,  0.1225, -0.2497, -0.2697],\n",
            "        [ 0.3007, -0.1748,  0.1847,  ...,  0.0112, -0.1608, -0.0578],\n",
            "        [ 0.4182,  0.1062,  0.3699,  ...,  0.2955, -0.3423, -0.4564]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[-0.0603,  0.0760, -0.0152,  ..., -0.0347,  0.0109,  0.0663],\n",
            "        [ 0.2883, -0.0415,  0.0922,  ...,  0.3200, -0.1393, -0.1307],\n",
            "        [-0.0988,  0.0110, -0.0464,  ..., -0.0115,  0.0542,  0.0920],\n",
            "        ...,\n",
            "        [ 0.4216,  0.2328,  0.1057,  ...,  0.1697,  0.0008, -0.2062],\n",
            "        [ 0.0594,  0.2931,  0.3262,  ...,  0.1439, -0.1319, -0.2878],\n",
            "        [ 0.2052,  0.4701, -0.0072,  ...,  0.3052, -0.0126, -0.2793]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.4343,  0.0599,  0.1770,  ...,  0.2067,  0.0930, -0.3356],\n",
            "         [ 0.2941,  0.2293,  0.2061,  ...,  0.0573,  0.1144, -0.2356],\n",
            "         [ 0.1432, -0.2718,  0.1558,  ...,  0.3854, -0.3045, -0.1329],\n",
            "         ...,\n",
            "         [-0.0158, -0.0704,  0.1765,  ...,  0.0667, -0.0830, -0.1326],\n",
            "         [ 0.1733,  0.4431,  0.0917,  ...,  0.1465,  0.0794, -0.2241],\n",
            "         [ 0.1860,  0.0328,  0.0425,  ...,  0.1491,  0.1512,  0.1244]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3740, -0.1772,  0.5490,  ...,  0.1657, -0.4381, -0.4956],\n",
            "        [ 0.3691,  0.0232,  0.5281,  ...,  0.1101, -0.3899, -0.4721],\n",
            "        [ 0.2718, -0.2591,  0.3683,  ...,  0.2563, -0.4700, -0.4722],\n",
            "        ...,\n",
            "        [ 0.0054, -0.2512,  0.4596,  ..., -0.0746, -0.4292, -0.3925],\n",
            "        [ 0.4379,  0.5656,  0.1672,  ...,  0.4399, -0.2169, -0.4488],\n",
            "        [ 0.0978,  0.0265,  0.0469,  ...,  0.0992,  0.0559,  0.0621]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[ 0.0930, -0.0092, -0.0417,  ...,  0.0742, -0.1127, -0.0525],\n",
            "        [ 0.0657, -0.0221,  0.0628,  ...,  0.0174, -0.0761,  0.0097],\n",
            "        [-0.0603,  0.0760, -0.0152,  ..., -0.0347,  0.0109,  0.0663],\n",
            "        ...,\n",
            "        [-0.0403,  0.4008,  0.1849,  ...,  0.0243, -0.2681, -0.1234],\n",
            "        [ 0.0722,  0.0957,  0.0115,  ...,  0.0789, -0.1587, -0.2325],\n",
            "        [ 0.0949,  0.4811, -0.1089,  ...,  0.3307, -0.1238,  0.0377]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.1276, -0.1215, -0.0847,  ...,  0.0790, -0.2325, -0.2370],\n",
            "         [-0.0318, -0.2147,  0.1603,  ...,  0.1451, -0.0401, -0.1134],\n",
            "         [-0.0285,  0.1757,  0.0272,  ..., -0.0335,  0.1722,  0.0941],\n",
            "         ...,\n",
            "         [ 0.1794,  0.2907,  0.3293,  ...,  0.0766,  0.0140, -0.0408],\n",
            "         [-0.0017, -0.0304,  0.1155,  ..., -0.0650,  0.0123, -0.1603],\n",
            "         [-0.0964,  0.1296,  0.1495,  ...,  0.0959, -0.2527, -0.1281]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0100, -0.1133,  0.1300,  ...,  0.0284, -0.3365, -0.2278],\n",
            "        [ 0.0536, -0.3084,  0.3403,  ..., -0.0117, -0.2821, -0.3210],\n",
            "        [ 0.1918,  0.3830,  0.0168,  ...,  0.2145,  0.0226, -0.0104],\n",
            "        ...,\n",
            "        [ 0.5648,  0.3687,  0.4700,  ...,  0.4111, -0.3789, -0.4200],\n",
            "        [ 0.0580, -0.3294,  0.5228,  ..., -0.1644, -0.4519, -0.4193],\n",
            "        [ 0.1267,  0.1332,  0.2758,  ...,  0.1857, -0.2977, -0.4340]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[ 0.2883, -0.0415,  0.0922,  ...,  0.3200, -0.1393, -0.1307],\n",
            "        [-0.0603,  0.0760, -0.0152,  ..., -0.0347,  0.0109,  0.0663],\n",
            "        [ 0.0069,  0.0373, -0.0026,  ...,  0.1178,  0.1690, -0.1842],\n",
            "        ...,\n",
            "        [ 0.0286,  0.1997,  0.0240,  ...,  0.2327,  0.1868,  0.0116],\n",
            "        [ 0.3195,  0.1327,  0.1725,  ...,  0.3284,  0.1189, -0.1372],\n",
            "        [ 0.2975, -0.3974, -0.1936,  ...,  0.0320,  0.0842, -0.2853]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.5176,  0.1502,  0.2661,  ...,  0.1308, -0.2162, -0.2363],\n",
            "         [ 0.1032,  0.2658,  0.0632,  ...,  0.1511, -0.2511, -0.1715],\n",
            "         [ 0.0284,  0.1873,  0.0475,  ...,  0.2822,  0.1187, -0.2187],\n",
            "         ...,\n",
            "         [ 0.0949,  0.4811, -0.1089,  ...,  0.3307, -0.1238,  0.0377],\n",
            "         [ 0.0747,  0.0050,  0.1437,  ..., -0.0434, -0.0795, -0.0651],\n",
            "         [ 0.1812,  0.2218,  0.1777,  ...,  0.1251,  0.1019, -0.0905]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3709, -0.0628,  0.5329,  ...,  0.1461, -0.5501, -0.5077],\n",
            "        [ 0.3627,  0.4489,  0.1022,  ...,  0.3583, -0.2274, -0.3439],\n",
            "        [ 0.2227,  0.3177,  0.0199,  ...,  0.3103, -0.0922, -0.2927],\n",
            "        ...,\n",
            "        [ 0.4457,  0.6758, -0.1819,  ...,  0.5774,  0.0558, -0.0703],\n",
            "        [ 0.1064, -0.0013,  0.0340,  ...,  0.0418, -0.0958, -0.1089],\n",
            "        [ 0.1631,  0.0750,  0.4252,  ...,  0.0561, -0.3350, -0.3014]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[-0.0603,  0.0760, -0.0152,  ..., -0.0347,  0.0109,  0.0663],\n",
            "        [-0.0603,  0.0760, -0.0152,  ..., -0.0347,  0.0109,  0.0663],\n",
            "        [-0.0603,  0.0760, -0.0152,  ..., -0.0347,  0.0109,  0.0663],\n",
            "        ...,\n",
            "        [ 0.3305, -0.0328,  0.4908,  ...,  0.4055, -0.1016, -0.1714],\n",
            "        [ 0.4285, -0.4265,  0.0894,  ...,  0.2027, -0.0709, -0.3428],\n",
            "        [ 0.4285, -0.4265,  0.0894,  ...,  0.2027, -0.0709, -0.3428]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.4285, -0.4265,  0.0894,  ...,  0.2027, -0.0709, -0.3428],\n",
            "         [ 0.4285, -0.4265,  0.0894,  ...,  0.2027, -0.0709, -0.3428],\n",
            "         [ 0.3305, -0.0328,  0.4908,  ...,  0.4055, -0.1016, -0.1714],\n",
            "         ...,\n",
            "         [-0.1570,  0.4024,  0.1147,  ...,  0.2493, -0.3395, -0.1251],\n",
            "         [-0.0291,  0.0649,  0.1583,  ..., -0.0717, -0.3093, -0.0596],\n",
            "         [ 0.2766,  0.0725,  0.0696,  ...,  0.1549, -0.0318, -0.0525]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3674, -0.5731,  0.5468,  ...,  0.0132, -0.5697, -0.6272],\n",
            "        [ 0.3674, -0.5731,  0.5468,  ...,  0.0132, -0.5697, -0.6272],\n",
            "        [ 0.3346, -0.5428,  0.8382,  ...,  0.1777, -0.6236, -0.4597],\n",
            "        ...,\n",
            "        [ 0.3612,  0.7606, -0.0642,  ...,  0.5953,  0.0064, -0.4293],\n",
            "        [-0.0122, -0.2058,  0.3741,  ..., -0.1015, -0.4881, -0.3120],\n",
            "        [ 0.1541,  0.0537,  0.2213,  ...,  0.0931, -0.2386, -0.1960]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[-0.0603,  0.0760, -0.0152,  ..., -0.0347,  0.0109,  0.0663],\n",
            "        [-0.0603,  0.0760, -0.0152,  ..., -0.0347,  0.0109,  0.0663],\n",
            "        [-0.0603,  0.0760, -0.0152,  ..., -0.0347,  0.0109,  0.0663],\n",
            "        ...,\n",
            "        [ 0.4285, -0.4265,  0.0894,  ...,  0.2027, -0.0709, -0.3428],\n",
            "        [ 0.4285, -0.4265,  0.0894,  ...,  0.2027, -0.0709, -0.3428],\n",
            "        [ 0.4285, -0.4265,  0.0894,  ...,  0.2027, -0.0709, -0.3428]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.4285, -0.4265,  0.0894,  ...,  0.2027, -0.0709, -0.3428],\n",
            "         [ 0.4285, -0.4265,  0.0894,  ...,  0.2027, -0.0709, -0.3428],\n",
            "         [ 0.4285, -0.4265,  0.0894,  ...,  0.2027, -0.0709, -0.3428],\n",
            "         ...,\n",
            "         [ 0.4285, -0.4265,  0.0894,  ...,  0.2027, -0.0709, -0.3428],\n",
            "         [ 0.4285, -0.4265,  0.0894,  ...,  0.2027, -0.0709, -0.3428],\n",
            "         [ 0.4285, -0.4265,  0.0894,  ...,  0.2027, -0.0709, -0.3428]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3674, -0.5731,  0.5468,  ...,  0.0132, -0.5697, -0.6272],\n",
            "        [ 0.3674, -0.5731,  0.5468,  ...,  0.0132, -0.5697, -0.6272],\n",
            "        [ 0.3674, -0.5731,  0.5468,  ...,  0.0132, -0.5697, -0.6272],\n",
            "        ...,\n",
            "        [ 0.3674, -0.5731,  0.5468,  ...,  0.0132, -0.5697, -0.6272],\n",
            "        [ 0.3674, -0.5731,  0.5468,  ...,  0.0132, -0.5697, -0.6272],\n",
            "        [ 0.3674, -0.5731,  0.5468,  ...,  0.0132, -0.5697, -0.6272]],\n",
            "       device='cuda:0')\n",
            "\t Epoch: 6 | Train Loss: 0.154 | Train Acc: 94.34%\n",
            "\t Epoch: 6 | Val. Loss: 0.728 |  Val. Acc: 83.04% \n",
            "\n",
            "Output of encoder at every step:tensor([[-0.0603,  0.0760, -0.0152,  ..., -0.0347,  0.0109,  0.0663],\n",
            "        [-0.1092,  0.1463,  0.1604,  ...,  0.0153,  0.1401, -0.0720],\n",
            "        [ 0.1329, -0.0043, -0.0257,  ..., -0.0076, -0.0891, -0.1035],\n",
            "        ...,\n",
            "        [ 0.0980,  0.1017,  0.0042,  ...,  0.3037, -0.1917, -0.1373],\n",
            "        [ 0.0087,  0.0287,  0.1926,  ...,  0.0813, -0.2182, -0.0793],\n",
            "        [ 0.1183,  0.3711,  0.1916,  ...,  0.1894, -0.2930, -0.0204]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1794,  0.2907,  0.3293,  ...,  0.0766,  0.0140, -0.0408],\n",
            "         [ 0.0887, -0.3104,  0.2136,  ...,  0.3918, -0.0986, -0.3546],\n",
            "         [-0.1175, -0.0834,  0.0889,  ..., -0.0323, -0.1711, -0.0744],\n",
            "         ...,\n",
            "         [ 0.2518, -0.1096,  0.1856,  ...,  0.1266, -0.1761, -0.1100],\n",
            "         [ 0.2390,  0.1200,  0.3403,  ..., -0.0981, -0.1337, -0.1388],\n",
            "         [ 0.1730,  0.1988,  0.1724,  ...,  0.1040, -0.2095, -0.1701]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5648,  0.3687,  0.4700,  ...,  0.4111, -0.3789, -0.4200],\n",
            "        [ 0.3022, -0.2951,  0.4848,  ...,  0.3517, -0.4301, -0.5055],\n",
            "        [-0.0756,  0.0174, -0.0428,  ...,  0.0245,  0.0624, -0.0627],\n",
            "        ...,\n",
            "        [ 0.3045, -0.1803,  0.3941,  ...,  0.1364, -0.4455, -0.2825],\n",
            "        [ 0.3255, -0.2130,  0.6254,  ..., -0.0507, -0.5937, -0.4518],\n",
            "        [ 0.2810,  0.0293,  0.3855,  ...,  0.1586, -0.4998, -0.3371]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0596,  0.0762, -0.0152,  ..., -0.0350,  0.0113,  0.0668],\n",
            "        [ 0.2337, -0.1109,  0.0685,  ..., -0.0078, -0.0535, -0.0830],\n",
            "        [-0.0596,  0.0762, -0.0152,  ..., -0.0350,  0.0113,  0.0668],\n",
            "        ...,\n",
            "        [ 0.2836, -0.0267,  0.2164,  ..., -0.0108, -0.1375, -0.0566],\n",
            "        [ 0.0005,  0.0373, -0.0192,  ...,  0.1159, -0.1090,  0.0054],\n",
            "        [ 0.1597, -0.1197,  0.1584,  ...,  0.2895, -0.4175, -0.1643]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0344,  0.2273,  0.2216,  ...,  0.1323, -0.3782, -0.1176],\n",
            "         [ 0.1647, -0.1057, -0.2225,  ...,  0.0006,  0.0384, -0.2229],\n",
            "         [ 0.4098, -0.0075,  0.3036,  ...,  0.3643, -0.1445, -0.1905],\n",
            "         ...,\n",
            "         [ 0.2836, -0.0267,  0.2164,  ..., -0.0108, -0.1375, -0.0566],\n",
            "         [ 0.0005,  0.0373, -0.0192,  ...,  0.1159, -0.1090,  0.0054],\n",
            "         [ 0.1597, -0.1197,  0.1584,  ...,  0.2895, -0.4175, -0.1643]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 1.9560e-01, -1.1074e-01,  4.8998e-01,  ...,  1.0531e-01,\n",
            "         -6.2491e-01, -4.4921e-01],\n",
            "        [ 2.9804e-01, -2.8501e-01,  1.9918e-01,  ..., -2.2005e-04,\n",
            "         -4.3297e-01, -4.8398e-01],\n",
            "        [ 3.9719e-01, -1.7332e-01,  4.8418e-01,  ...,  2.4046e-01,\n",
            "         -4.8366e-01, -3.8169e-01],\n",
            "        ...,\n",
            "        [ 2.2515e-01, -2.1512e-01,  4.5062e-01,  ..., -1.6570e-02,\n",
            "         -5.2088e-01, -3.3133e-01],\n",
            "        [-9.2155e-02,  2.6921e-02, -6.3080e-02,  ...,  5.7306e-02,\n",
            "         -2.6638e-02,  5.4307e-02],\n",
            "        [ 3.1898e-01, -4.9331e-01,  5.8168e-01,  ...,  1.7894e-01,\n",
            "         -7.1646e-01, -6.1158e-01]], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0588,  0.0763, -0.0151,  ..., -0.0350,  0.0115,  0.0669],\n",
            "        [-0.0588,  0.0763, -0.0151,  ..., -0.0350,  0.0115,  0.0669],\n",
            "        [-0.0588,  0.0763, -0.0151,  ..., -0.0350,  0.0115,  0.0669],\n",
            "        ...,\n",
            "        [-0.0407,  0.2367,  0.0704,  ...,  0.1441, -0.2755, -0.1248],\n",
            "        [ 0.1079,  0.5897,  0.0470,  ...,  0.0473,  0.0243, -0.1162],\n",
            "        [-0.1453,  0.0622,  0.1771,  ...,  0.0290, -0.3317, -0.1481]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1453,  0.0622,  0.1771,  ...,  0.0290, -0.3317, -0.1481],\n",
            "         [ 0.1079,  0.5897,  0.0470,  ...,  0.0473,  0.0243, -0.1162],\n",
            "         [ 0.4236, -0.4283,  0.0812,  ...,  0.1999, -0.0670, -0.3376],\n",
            "         ...,\n",
            "         [ 0.4236, -0.4283,  0.0812,  ...,  0.1999, -0.0670, -0.3376],\n",
            "         [ 0.4236, -0.4283,  0.0812,  ...,  0.1999, -0.0670, -0.3376],\n",
            "         [ 0.4236, -0.4283,  0.0812,  ...,  0.1999, -0.0670, -0.3376]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.1082, -0.3543,  0.5430,  ..., -0.0995, -0.6352, -0.4749],\n",
            "        [ 0.4544,  0.7034, -0.1116,  ...,  0.4447,  0.0663, -0.2696],\n",
            "        [ 0.3555, -0.5678,  0.5394,  ...,  0.0057, -0.5632, -0.6167],\n",
            "        ...,\n",
            "        [ 0.3555, -0.5678,  0.5394,  ...,  0.0057, -0.5632, -0.6167],\n",
            "        [ 0.3555, -0.5678,  0.5394,  ...,  0.0057, -0.5632, -0.6167],\n",
            "        [ 0.3555, -0.5678,  0.5394,  ...,  0.0057, -0.5632, -0.6167]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0581,  0.0765, -0.0151,  ..., -0.0351,  0.0116,  0.0670],\n",
            "        [ 0.0357, -0.0552, -0.0435,  ...,  0.1177, -0.0337, -0.0038],\n",
            "        [-0.0581,  0.0765, -0.0151,  ..., -0.0351,  0.0116,  0.0670],\n",
            "        ...,\n",
            "        [ 0.1944,  0.3204,  0.2446,  ...,  0.5194, -0.0545, -0.1906],\n",
            "        [ 0.4059, -0.0136,  0.1677,  ...,  0.1515, -0.1444, -0.2087],\n",
            "        [-0.0061,  0.2203, -0.2252,  ...,  0.2127, -0.4498, -0.2256]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2965, -0.0101,  0.0557,  ...,  0.0107, -0.0836, -0.2242],\n",
            "         [ 0.1944,  0.3204,  0.2446,  ...,  0.5194, -0.0545, -0.1906],\n",
            "         [ 0.4059, -0.0136,  0.1677,  ...,  0.1515, -0.1444, -0.2087],\n",
            "         ...,\n",
            "         [ 0.3430, -0.0770, -0.1123,  ..., -0.0428, -0.0358, -0.0633],\n",
            "         [-0.1020,  0.0282,  0.2277,  ..., -0.0339, -0.3074, -0.1442],\n",
            "         [ 0.1903,  0.0654,  0.0393,  ..., -0.0181,  0.0206, -0.0994]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1733, -0.1138,  0.3412,  ...,  0.0346, -0.4408, -0.4257],\n",
            "        [ 0.4800,  0.5177,  0.3445,  ...,  0.5400, -0.3071, -0.4398],\n",
            "        [ 0.2458, -0.3086,  0.5671,  ...,  0.0643, -0.5911, -0.4608],\n",
            "        ...,\n",
            "        [ 0.1529, -0.1238,  0.0595,  ..., -0.0195, -0.2147, -0.1385],\n",
            "        [ 0.1241,  0.1352,  0.2401,  ...,  0.0573, -0.2452, -0.3866],\n",
            "        [ 0.1976,  0.1139,  0.0621,  ...,  0.0224, -0.0247, -0.1241]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.2103, -0.0561, -0.0159,  ...,  0.1560, -0.1722, -0.0789],\n",
            "        [-0.0573,  0.0764, -0.0150,  ..., -0.0353,  0.0117,  0.0670],\n",
            "        [-0.0573,  0.0764, -0.0150,  ..., -0.0353,  0.0117,  0.0670],\n",
            "        ...,\n",
            "        [ 0.2424,  0.1992,  0.1509,  ..., -0.0954, -0.1281, -0.0938],\n",
            "        [ 0.1119, -0.1578,  0.0086,  ...,  0.1097, -0.1517, -0.0440],\n",
            "        [-0.2148,  0.0896,  0.0803,  ...,  0.0220, -0.3081, -0.1518]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0024,  0.3053,  0.1167,  ...,  0.1333, -0.1962, -0.0157],\n",
            "         [-0.2148,  0.0896,  0.0803,  ...,  0.0220, -0.3081, -0.1518],\n",
            "         [-0.2148,  0.0896,  0.0803,  ...,  0.0220, -0.3081, -0.1518],\n",
            "         ...,\n",
            "         [ 0.2592, -0.3057,  0.3900,  ...,  0.0896, -0.3309, -0.2201],\n",
            "         [ 0.2117, -0.4617,  0.1910,  ..., -0.0537, -0.1040, -0.1142],\n",
            "         [ 0.1661, -0.1694,  0.2102,  ...,  0.2243, -0.0899, -0.1319]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1506,  0.3943,  0.0037,  ...,  0.2616, -0.1819, -0.1042],\n",
            "        [ 0.3133,  0.5812, -0.1148,  ...,  0.4414, -0.0156, -0.3499],\n",
            "        [ 0.3133,  0.5812, -0.1148,  ...,  0.4414, -0.0156, -0.3499],\n",
            "        ...,\n",
            "        [ 0.0851, -0.5671,  0.6151,  ..., -0.0422, -0.6701, -0.4695],\n",
            "        [ 0.1816, -0.4906,  0.5479,  ..., -0.1287, -0.5339, -0.3412],\n",
            "        [ 0.1726, -0.4806,  0.5663,  ...,  0.0389, -0.4994, -0.3215]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0565,  0.0763, -0.0149,  ..., -0.0354,  0.0118,  0.0670],\n",
            "        [ 0.2810, -0.0457,  0.0824,  ...,  0.3189, -0.1387, -0.1310],\n",
            "        [-0.1292,  0.1573, -0.0452,  ...,  0.0889, -0.0647,  0.1154],\n",
            "        ...,\n",
            "        [ 0.1203,  0.1826, -0.0524,  ...,  0.1242, -0.1244, -0.1279],\n",
            "        [ 0.2505,  0.1923, -0.0126,  ...,  0.0785, -0.0380, -0.0405],\n",
            "        [ 0.0018, -0.0794,  0.1649,  ...,  0.0045, -0.2815, -0.1880]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1142,  0.0298,  0.1544,  ...,  0.1624, -0.0518, -0.1775],\n",
            "         [-0.2833,  0.2878,  0.1234,  ..., -0.0036, -0.1455, -0.0477],\n",
            "         [ 0.3365, -0.1234,  0.1596,  ...,  0.0322,  0.0307, -0.1222],\n",
            "         ...,\n",
            "         [ 0.1203,  0.1826, -0.0524,  ...,  0.1242, -0.1244, -0.1279],\n",
            "         [ 0.2505,  0.1923, -0.0126,  ...,  0.0785, -0.0380, -0.0405],\n",
            "         [ 0.0018, -0.0794,  0.1649,  ...,  0.0045, -0.2815, -0.1880]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3439,  0.0999,  0.3010,  ...,  0.2178, -0.3335, -0.3813],\n",
            "        [ 0.0741,  0.5481, -0.0508,  ...,  0.3075,  0.0725, -0.2304],\n",
            "        [ 0.2847, -0.3229,  0.4838,  ...,  0.0145, -0.3631, -0.2994],\n",
            "        ...,\n",
            "        [ 0.3342,  0.3394,  0.0279,  ...,  0.4319, -0.1654, -0.3187],\n",
            "        [ 0.3549, -0.0140,  0.3556,  ...,  0.1014, -0.4345, -0.3290],\n",
            "        [-0.0156, -0.4438,  0.5553,  ..., -0.1271, -0.6515, -0.5019]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0558,  0.0763, -0.0148,  ..., -0.0355,  0.0118,  0.0669],\n",
            "        [ 0.0556,  0.0778,  0.1486,  ...,  0.0142,  0.1890,  0.0354],\n",
            "        [ 0.2326, -0.1110,  0.0649,  ..., -0.0064, -0.0526, -0.0838],\n",
            "        ...,\n",
            "        [ 0.1843, -0.3332,  0.1767,  ..., -0.1117, -0.2379, -0.1249],\n",
            "        [ 0.1590,  0.1708,  0.0701,  ...,  0.2150, -0.1599,  0.0257],\n",
            "        [ 0.0250,  0.1862, -0.0510,  ..., -0.0638,  0.0277,  0.0714]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 2.6637e-01, -2.2755e-02,  7.0270e-02,  ...,  8.9013e-02,\n",
            "          -5.0577e-02, -1.0420e-01],\n",
            "         [ 6.1098e-02,  2.6500e-01,  2.6762e-02,  ...,  2.7330e-04,\n",
            "          -2.0434e-01, -2.9222e-01],\n",
            "         [-2.8519e-01,  4.9993e-01,  1.3958e-01,  ...,  8.3993e-02,\n",
            "           3.4463e-03, -1.3906e-01],\n",
            "         ...,\n",
            "         [ 1.8431e-01, -3.3318e-01,  1.7672e-01,  ..., -1.1165e-01,\n",
            "          -2.3788e-01, -1.2486e-01],\n",
            "         [ 1.5902e-01,  1.7078e-01,  7.0057e-02,  ...,  2.1497e-01,\n",
            "          -1.5992e-01,  2.5689e-02],\n",
            "         [ 2.5050e-02,  1.8621e-01, -5.0953e-02,  ..., -6.3792e-02,\n",
            "           2.7669e-02,  7.1395e-02]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2296, -0.2069,  0.4062,  ...,  0.0685, -0.4590, -0.3481],\n",
            "        [ 0.2960,  0.4641, -0.0196,  ...,  0.2453, -0.2726, -0.4281],\n",
            "        [ 0.0480,  0.6415, -0.0576,  ...,  0.3959,  0.1143, -0.3209],\n",
            "        ...,\n",
            "        [ 0.0549, -0.5414,  0.6022,  ..., -0.1541, -0.6542, -0.4183],\n",
            "        [ 0.1973,  0.2587,  0.0398,  ...,  0.2584, -0.0301, -0.0957],\n",
            "        [ 0.1060,  0.1305,  0.2093,  ...,  0.0039, -0.1651, -0.0966]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1188,  0.1484, -0.0884,  ...,  0.1237, -0.0361, -0.0266],\n",
            "        [-0.0551,  0.0763, -0.0147,  ..., -0.0356,  0.0119,  0.0668],\n",
            "        [-0.0544, -0.0302, -0.0903,  ..., -0.0767,  0.0608, -0.0498],\n",
            "        ...,\n",
            "        [-0.0106,  0.1405,  0.0821,  ...,  0.0144,  0.0616, -0.0483],\n",
            "        [ 0.1105,  0.4319,  0.0346,  ...,  0.0631, -0.4531, -0.2439],\n",
            "        [ 0.1232, -0.0218,  0.0374,  ...,  0.0319, -0.1556, -0.1332]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1645, -0.1378,  0.3188,  ...,  0.0916, -0.2142, -0.3749],\n",
            "         [ 0.3661,  0.1077,  0.1426,  ...,  0.1671, -0.3473, -0.3119],\n",
            "         [ 0.2462,  0.0508,  0.0023,  ..., -0.0338,  0.1445,  0.1086],\n",
            "         ...,\n",
            "         [-0.1159, -0.2114,  0.1400,  ...,  0.0088, -0.2099, -0.0406],\n",
            "         [ 0.3990, -0.1680,  0.1248,  ..., -0.0303,  0.0442, -0.1523],\n",
            "         [-0.2827,  0.2935,  0.1236,  ..., -0.0011, -0.1519, -0.0511]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 1.9963e-01, -2.7749e-01,  5.0873e-01,  ...,  7.1391e-02,\n",
            "         -4.7675e-01, -4.5496e-01],\n",
            "        [ 4.3754e-01, -6.0385e-02,  4.9008e-01,  ...,  3.2834e-01,\n",
            "         -5.9032e-01, -5.9441e-01],\n",
            "        [ 1.9178e-01, -8.4167e-02,  2.5081e-01,  ...,  1.0436e-02,\n",
            "         -1.3561e-01,  2.3797e-04],\n",
            "        ...,\n",
            "        [ 1.2152e-01, -2.6326e-01,  3.6272e-01,  ..., -7.9775e-03,\n",
            "         -4.0886e-01, -3.4814e-01],\n",
            "        [ 2.1271e-01, -3.8503e-01,  4.2962e-01,  ..., -1.6510e-02,\n",
            "         -3.6303e-01, -3.0522e-01],\n",
            "        [ 9.0203e-02,  5.5953e-01, -4.8170e-02,  ...,  3.1961e-01,\n",
            "          6.7281e-02, -2.4947e-01]], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0545,  0.0763, -0.0146,  ..., -0.0356,  0.0118,  0.0666],\n",
            "        [-0.0545,  0.0763, -0.0146,  ..., -0.0356,  0.0118,  0.0666],\n",
            "        [ 0.0869, -0.0190, -0.0423,  ...,  0.0725, -0.1166, -0.0545],\n",
            "        ...,\n",
            "        [-0.2875,  0.1342,  0.0943,  ...,  0.1478, -0.1784, -0.0412],\n",
            "        [-0.2875,  0.1342,  0.0943,  ...,  0.1478, -0.1784, -0.0412],\n",
            "        [-0.2374,  0.1327,  0.0014,  ...,  0.0590, -0.1597, -0.0589]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2792,  0.2042,  0.0649,  ...,  0.2152, -0.1054, -0.1658],\n",
            "         [-0.2374,  0.1327,  0.0014,  ...,  0.0590, -0.1597, -0.0589],\n",
            "         [ 0.1956, -0.1486, -0.1778,  ...,  0.1089, -0.3023, -0.2049],\n",
            "         ...,\n",
            "         [ 0.1825, -0.0071,  0.0887,  ..., -0.0923, -0.0946, -0.1995],\n",
            "         [-0.2457, -0.0916,  0.1220,  ..., -0.3132, -0.0648, -0.0630],\n",
            "         [-0.2045,  0.0673,  0.0786,  ...,  0.1102, -0.4232, -0.1563]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1927,  0.0265,  0.3376,  ...,  0.0836, -0.3710, -0.3044],\n",
            "        [ 0.0775,  0.4750, -0.1265,  ...,  0.3556,  0.0844, -0.1433],\n",
            "        [-0.0040, -0.2905,  0.1182,  ...,  0.0270, -0.4796, -0.2888],\n",
            "        ...,\n",
            "        [ 0.1618, -0.0818,  0.2579,  ..., -0.0588, -0.3427, -0.2800],\n",
            "        [-0.2320, -0.0759,  0.0199,  ..., -0.2126,  0.0834,  0.0230],\n",
            "        [ 0.2766,  0.3999,  0.1758,  ...,  0.4140, -0.3968, -0.5193]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0539,  0.0762, -0.0144,  ..., -0.0356,  0.0117,  0.0663],\n",
            "        [-0.0539,  0.0762, -0.0144,  ..., -0.0356,  0.0117,  0.0663],\n",
            "        [-0.0539,  0.0762, -0.0144,  ..., -0.0356,  0.0117,  0.0663],\n",
            "        ...,\n",
            "        [ 0.4272, -0.4303,  0.0848,  ...,  0.2166, -0.0682, -0.3458],\n",
            "        [ 0.4272, -0.4303,  0.0848,  ...,  0.2166, -0.0682, -0.3458],\n",
            "        [ 0.4272, -0.4303,  0.0848,  ...,  0.2166, -0.0682, -0.3458]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.4272, -0.4303,  0.0848,  ...,  0.2166, -0.0682, -0.3458],\n",
            "         [ 0.4272, -0.4303,  0.0848,  ...,  0.2166, -0.0682, -0.3458],\n",
            "         [ 0.4272, -0.4303,  0.0848,  ...,  0.2166, -0.0682, -0.3458],\n",
            "         ...,\n",
            "         [ 0.0854,  0.5484,  0.0790,  ...,  0.2123, -0.3680, -0.1747],\n",
            "         [ 0.0653,  0.1330, -0.0186,  ...,  0.0366, -0.0645, -0.1021],\n",
            "         [ 0.2577,  0.2402,  0.2989,  ...,  0.2874, -0.1250, -0.2260]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3562, -0.5830,  0.5572,  ...,  0.0112, -0.5731, -0.6249],\n",
            "        [ 0.3562, -0.5830,  0.5572,  ...,  0.0112, -0.5731, -0.6249],\n",
            "        [ 0.3562, -0.5830,  0.5572,  ...,  0.0112, -0.5731, -0.6249],\n",
            "        ...,\n",
            "        [ 0.3003,  0.4881,  0.3013,  ...,  0.3587, -0.5963, -0.5203],\n",
            "        [-0.0012,  0.2070, -0.0294,  ...,  0.1395, -0.1073, -0.1560],\n",
            "        [ 0.3451, -0.1251,  0.6676,  ...,  0.1796, -0.5980, -0.5102]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0535,  0.0762, -0.0143,  ..., -0.0357,  0.0117,  0.0661],\n",
            "        [-0.0535,  0.0762, -0.0143,  ..., -0.0357,  0.0117,  0.0661],\n",
            "        [-0.0535,  0.0762, -0.0143,  ..., -0.0357,  0.0117,  0.0661],\n",
            "        ...,\n",
            "        [ 0.1035, -0.3082,  0.0065,  ...,  0.1195, -0.1495, -0.0884],\n",
            "        [ 0.4275, -0.4319,  0.0855,  ...,  0.2178, -0.0685, -0.3467],\n",
            "        [ 0.4275, -0.4319,  0.0855,  ...,  0.2178, -0.0685, -0.3467]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.4275, -0.4319,  0.0855,  ...,  0.2178, -0.0685, -0.3467],\n",
            "         [ 0.4275, -0.4319,  0.0855,  ...,  0.2178, -0.0685, -0.3467],\n",
            "         [ 0.4275, -0.4319,  0.0855,  ...,  0.2178, -0.0685, -0.3467],\n",
            "         ...,\n",
            "         [ 0.1035, -0.3082,  0.0065,  ...,  0.1195, -0.1495, -0.0884],\n",
            "         [ 0.4275, -0.4319,  0.0855,  ...,  0.2178, -0.0685, -0.3467],\n",
            "         [ 0.4275, -0.4319,  0.0855,  ...,  0.2178, -0.0685, -0.3467]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3554, -0.5859,  0.5598,  ...,  0.0107, -0.5744, -0.6256],\n",
            "        [ 0.3554, -0.5859,  0.5598,  ...,  0.0107, -0.5744, -0.6256],\n",
            "        [ 0.3554, -0.5859,  0.5598,  ...,  0.0107, -0.5744, -0.6256],\n",
            "        ...,\n",
            "        [-0.0853, -0.3555,  0.2921,  ..., -0.0140, -0.4161, -0.1738],\n",
            "        [ 0.3554, -0.5859,  0.5598,  ...,  0.0107, -0.5744, -0.6256],\n",
            "        [ 0.3554, -0.5859,  0.5598,  ...,  0.0107, -0.5744, -0.6256]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0530,  0.0761, -0.0142,  ..., -0.0357,  0.0116,  0.0660],\n",
            "        [ 0.0737, -0.0866,  0.0637,  ...,  0.1082, -0.0080, -0.1674],\n",
            "        [-0.0530,  0.0761, -0.0142,  ..., -0.0357,  0.0116,  0.0660],\n",
            "        ...,\n",
            "        [ 0.3137,  0.0250,  0.0836,  ..., -0.0519, -0.0437, -0.1517],\n",
            "        [ 0.3458, -0.0706,  0.3562,  ...,  0.4765, -0.1533, -0.2391],\n",
            "        [-0.0752,  0.0506,  0.1533,  ..., -0.0105, -0.2325, -0.2910]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0656, -0.0026,  0.1017,  ..., -0.0626, -0.2713, -0.3029],\n",
            "         [ 0.2569, -0.1457,  0.4240,  ..., -0.0396, -0.2107, -0.2745],\n",
            "         [ 0.3826, -0.1148,  0.2237,  ...,  0.2028, -0.3480, -0.1092],\n",
            "         ...,\n",
            "         [ 0.3137,  0.0250,  0.0836,  ..., -0.0519, -0.0437, -0.1517],\n",
            "         [ 0.3458, -0.0706,  0.3562,  ...,  0.4765, -0.1533, -0.2391],\n",
            "         [-0.0752,  0.0506,  0.1533,  ..., -0.0105, -0.2325, -0.2910]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0561, -0.2701,  0.4757,  ..., -0.0290, -0.5493, -0.4619],\n",
            "        [ 0.3175, -0.3206,  0.5193,  ..., -0.0411, -0.5016, -0.4647],\n",
            "        [ 0.2635, -0.3702,  0.5240,  ...,  0.1822, -0.5584, -0.3359],\n",
            "        ...,\n",
            "        [ 0.3503, -0.0725,  0.3998,  ...,  0.0912, -0.3836, -0.3968],\n",
            "        [ 0.4018, -0.4722,  0.7334,  ...,  0.1904, -0.6281, -0.5263],\n",
            "        [ 0.0149, -0.2874,  0.5611,  ..., -0.0851, -0.6021, -0.4692]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0526,  0.0761, -0.0141,  ..., -0.0357,  0.0115,  0.0657],\n",
            "        [-0.0526,  0.0761, -0.0141,  ..., -0.0357,  0.0115,  0.0657],\n",
            "        [-0.0526,  0.0761, -0.0141,  ..., -0.0357,  0.0115,  0.0657],\n",
            "        ...,\n",
            "        [-0.0060,  0.0301, -0.0276,  ..., -0.0477,  0.1011,  0.2151],\n",
            "        [ 0.0430,  0.2200,  0.1514,  ...,  0.3043, -0.0120, -0.0773],\n",
            "        [ 0.2157, -0.0340,  0.3028,  ...,  0.3475, -0.0687, -0.1212]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1524,  0.3496,  0.1140,  ...,  0.2146, -0.3547, -0.1345],\n",
            "         [-0.0728,  0.1779,  0.0861,  ...,  0.3026, -0.3588, -0.1434],\n",
            "         [-0.1524,  0.3496,  0.1140,  ...,  0.2146, -0.3547, -0.1345],\n",
            "         ...,\n",
            "         [-0.0060,  0.0301, -0.0276,  ..., -0.0477,  0.1011,  0.2151],\n",
            "         [ 0.0430,  0.2200,  0.1514,  ...,  0.3043, -0.0120, -0.0773],\n",
            "         [ 0.2157, -0.0340,  0.3028,  ...,  0.3475, -0.0687, -0.1212]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3596,  0.7296, -0.0306,  ...,  0.5619, -0.0384, -0.4623],\n",
            "        [ 0.3606,  0.5660,  0.0369,  ...,  0.5197, -0.1477, -0.4886],\n",
            "        [ 0.3596,  0.7296, -0.0306,  ...,  0.5619, -0.0384, -0.4623],\n",
            "        ...,\n",
            "        [-0.0697,  0.0594, -0.0530,  ..., -0.0075,  0.1267,  0.2549],\n",
            "        [ 0.1819,  0.3865,  0.0266,  ...,  0.3175,  0.0243, -0.1931],\n",
            "        [ 0.2369, -0.3315,  0.6002,  ...,  0.1694, -0.4164, -0.3269]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0522,  0.0760, -0.0140,  ..., -0.0357,  0.0114,  0.0654],\n",
            "        [-0.2100, -0.0526, -0.0144,  ...,  0.1601, -0.1741, -0.0813],\n",
            "        [ 0.2764, -0.0468,  0.0813,  ...,  0.3250, -0.1406, -0.1368],\n",
            "        ...,\n",
            "        [-0.1508, -0.0386,  0.1392,  ...,  0.1702, -0.2549, -0.2404],\n",
            "        [ 0.0923,  0.2763, -0.0598,  ...,  0.0230, -0.0634, -0.1755],\n",
            "        [ 0.3172, -0.4842,  0.0902,  ...,  0.1260, -0.1180, -0.3450]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3741, -0.0852, -0.0951,  ..., -0.0380, -0.0554, -0.0987],\n",
            "         [ 0.2451,  0.1086,  0.3512,  ...,  0.3781, -0.0501, -0.1471],\n",
            "         [ 0.2795, -0.2798,  0.1018,  ..., -0.0064,  0.0569, -0.0560],\n",
            "         ...,\n",
            "         [ 0.2675, -0.2735,  0.3605,  ...,  0.0951, -0.3291, -0.2045],\n",
            "         [ 0.3554, -0.0288,  0.1787,  ...,  0.0797, -0.1853, -0.0848],\n",
            "         [ 0.3081, -0.0537,  0.0630,  ...,  0.0141, -0.0848, -0.2370]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1750, -0.1725,  0.1371,  ..., -0.0208, -0.2989, -0.2063],\n",
            "        [ 0.2369, -0.2281,  0.6214,  ...,  0.1555, -0.4042, -0.3313],\n",
            "        [ 0.2191, -0.4101,  0.4028,  ..., -0.1019, -0.3651, -0.2548],\n",
            "        ...,\n",
            "        [ 0.0603, -0.4991,  0.5629,  ..., -0.0320, -0.6200, -0.4142],\n",
            "        [ 0.2136, -0.0313,  0.1808,  ...,  0.0345, -0.2460, -0.2182],\n",
            "        [ 0.1571, -0.2187,  0.3969,  ...,  0.0025, -0.4782, -0.4477]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0519,  0.0759, -0.0138,  ..., -0.0356,  0.0113,  0.0650],\n",
            "        [-0.1402,  0.0528,  0.1171,  ..., -0.0111, -0.0086, -0.1189],\n",
            "        [-0.0519,  0.0759, -0.0138,  ..., -0.0356,  0.0113,  0.0650],\n",
            "        ...,\n",
            "        [-0.1667,  0.1767,  0.1429,  ...,  0.0367, -0.3087, -0.0828],\n",
            "        [ 0.0213,  0.2395,  0.0305,  ..., -0.0053, -0.0866,  0.0069],\n",
            "        [-0.0936,  0.1356,  0.1375,  ...,  0.2674, -0.2309, -0.1588]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3853, -0.1174,  0.2274,  ...,  0.2046, -0.3533, -0.1142],\n",
            "         [ 0.1808,  0.1320,  0.2959,  ...,  0.2795, -0.2973, -0.1946],\n",
            "         [ 0.2584,  0.0636,  0.1762,  ...,  0.0880, -0.1103, -0.1389],\n",
            "         ...,\n",
            "         [ 0.4104, -0.1761,  0.1374,  ..., -0.0321,  0.0359, -0.1650],\n",
            "         [ 0.0195, -0.0373,  0.0439,  ...,  0.0732, -0.0254, -0.1202],\n",
            "         [ 0.0966,  0.0562,  0.1986,  ...,  0.1100, -0.2830, -0.1563]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2648, -0.3831,  0.5380,  ...,  0.1806, -0.5686, -0.3446],\n",
            "        [ 0.3601, -0.1930,  0.6476,  ...,  0.1452, -0.6618, -0.6342],\n",
            "        [ 0.3002,  0.0180,  0.3706,  ...,  0.1892, -0.3796, -0.3458],\n",
            "        ...,\n",
            "        [ 0.2136, -0.4251,  0.4740,  ..., -0.0303, -0.3984, -0.3310],\n",
            "        [ 0.0268, -0.3055,  0.4156,  ..., -0.0466, -0.4465, -0.2799],\n",
            "        [ 0.2456, -0.2451,  0.5060,  ...,  0.0772, -0.5554, -0.3744]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.1411, -0.0491,  0.0621,  ...,  0.0569, -0.0381, -0.1372],\n",
            "        [ 0.2325, -0.1107,  0.0660,  ..., -0.0045, -0.0527, -0.0865],\n",
            "        [-0.0645,  0.0399, -0.0721,  ..., -0.0020, -0.1820, -0.0095],\n",
            "        ...,\n",
            "        [-0.0030, -0.0482, -0.0327,  ...,  0.1269, -0.1316,  0.0514],\n",
            "        [ 0.2505,  0.2017,  0.0086,  ...,  0.0448, -0.3689, -0.2064],\n",
            "        [ 0.3938,  0.0322,  0.2363,  ...,  0.0217,  0.0559, -0.1361]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-3.0176e-02,  2.5790e-01, -2.4921e-04,  ..., -2.0779e-02,\n",
            "          -2.1633e-01, -1.4374e-01],\n",
            "         [ 1.9457e-02, -1.2141e-01,  1.4859e-01,  ..., -2.0819e-01,\n",
            "          -2.8136e-01, -8.5871e-02],\n",
            "         [ 2.1885e-02,  8.4818e-02, -2.1182e-02,  ..., -3.2872e-02,\n",
            "          -4.0730e-02,  5.1600e-02],\n",
            "         ...,\n",
            "         [-3.0410e-03, -4.8212e-02, -3.2651e-02,  ...,  1.2692e-01,\n",
            "          -1.3157e-01,  5.1373e-02],\n",
            "         [ 2.5053e-01,  2.0167e-01,  8.6205e-03,  ...,  4.4782e-02,\n",
            "          -3.6894e-01, -2.0635e-01],\n",
            "         [ 3.9385e-01,  3.2204e-02,  2.3625e-01,  ...,  2.1683e-02,\n",
            "           5.5944e-02, -1.3611e-01]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3233,  0.4200, -0.0236,  ...,  0.2642, -0.1589, -0.2979],\n",
            "        [ 0.0622, -0.3639,  0.4695,  ..., -0.1929, -0.5769, -0.3684],\n",
            "        [ 0.1855,  0.3447, -0.0409,  ...,  0.1509, -0.0228, -0.0206],\n",
            "        ...,\n",
            "        [-0.1582,  0.0167, -0.0852,  ...,  0.0465,  0.0189,  0.1305],\n",
            "        [ 0.4311,  0.4678,  0.1672,  ...,  0.3081, -0.5074, -0.4878],\n",
            "        [ 0.3001, -0.3531,  0.6301,  ...,  0.0016, -0.5015, -0.4274]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0509,  0.0761, -0.0135,  ..., -0.0357,  0.0115,  0.0648],\n",
            "        [ 0.2784, -0.0458,  0.0869,  ...,  0.3263, -0.1406, -0.1378],\n",
            "        [-0.0793, -0.0758, -0.0525,  ...,  0.0119, -0.1022, -0.1219],\n",
            "        ...,\n",
            "        [ 0.1038,  0.2897,  0.2367,  ...,  0.1656, -0.2534,  0.0241],\n",
            "        [ 0.0408,  0.1540,  0.1550,  ...,  0.1016, -0.1345, -0.1843],\n",
            "        [ 0.1711, -0.0586,  0.0106,  ...,  0.1609, -0.2576, -0.0832]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1711, -0.0586,  0.0106,  ...,  0.1609, -0.2576, -0.0832],\n",
            "         [ 0.1102,  0.2822,  0.2188,  ...,  0.1590, -0.2556,  0.0450],\n",
            "         [ 0.0603,  0.0898,  0.1270,  ...,  0.0095, -0.1580, -0.1249],\n",
            "         ...,\n",
            "         [ 0.2981, -0.3521,  0.1680,  ..., -0.1283, -0.0558, -0.1202],\n",
            "         [ 0.1038,  0.2897,  0.2367,  ...,  0.1656, -0.2534,  0.0241],\n",
            "         [ 0.0408,  0.1540,  0.1550,  ...,  0.1016, -0.1345, -0.1843]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1013, -0.1886,  0.3192,  ...,  0.0069, -0.4660, -0.2191],\n",
            "        [ 0.3820,  0.5521, -0.0486,  ...,  0.5153, -0.0528, -0.0713],\n",
            "        [ 0.1432, -0.2371,  0.4806,  ..., -0.0616, -0.4912, -0.4454],\n",
            "        ...,\n",
            "        [ 0.2120, -0.5213,  0.5906,  ..., -0.2255, -0.5422, -0.3795],\n",
            "        [ 0.3958,  0.5761, -0.0528,  ...,  0.5427, -0.0405, -0.0878],\n",
            "        [ 0.1007, -0.0975,  0.5289,  ...,  0.0234, -0.4882, -0.4772]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0504,  0.0763, -0.0134,  ..., -0.0358,  0.0118,  0.0648],\n",
            "        [-0.0504,  0.0763, -0.0134,  ..., -0.0358,  0.0118,  0.0648],\n",
            "        [ 0.0402,  0.1619,  0.0056,  ...,  0.0343, -0.1296, -0.0964],\n",
            "        ...,\n",
            "        [ 0.0368,  0.1932,  0.1808,  ..., -0.0740, -0.3411, -0.1986],\n",
            "        [ 0.1051,  0.0977,  0.1292,  ..., -0.0975,  0.0675,  0.0137],\n",
            "        [ 0.0925,  0.1404,  0.3002,  ...,  0.0004, -0.1765, -0.2736]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1051,  0.0977,  0.1292,  ..., -0.0975,  0.0675,  0.0137],\n",
            "         [ 0.0925,  0.1404,  0.3002,  ...,  0.0004, -0.1765, -0.2736],\n",
            "         [ 0.1123, -0.0126, -0.1239,  ..., -0.1224,  0.0089, -0.0810],\n",
            "         ...,\n",
            "         [-0.0759, -0.1448,  0.0509,  ...,  0.0201,  0.1549,  0.4068],\n",
            "         [ 0.1968,  0.0278,  0.2094,  ...,  0.2487, -0.0574, -0.2206],\n",
            "         [ 0.0368,  0.1932,  0.1808,  ..., -0.0740, -0.3411, -0.1986]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2306,  0.0257,  0.2964,  ...,  0.0467, -0.2267, -0.1890],\n",
            "        [ 0.2907,  0.0259,  0.5006,  ...,  0.1106, -0.4446, -0.4398],\n",
            "        [-0.0059,  0.0297, -0.1146,  ..., -0.1047,  0.0908,  0.0866],\n",
            "        ...,\n",
            "        [-0.2086,  0.0027, -0.0558,  ..., -0.0234,  0.1483,  0.2933],\n",
            "        [ 0.6224,  0.5713,  0.2425,  ...,  0.7116, -0.3266, -0.6548],\n",
            "        [ 0.1265, -0.1477,  0.5201,  ..., -0.1414, -0.6300, -0.5445]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0499,  0.0764, -0.0132,  ..., -0.0358,  0.0119,  0.0648],\n",
            "        [-0.0499,  0.0764, -0.0132,  ..., -0.0358,  0.0119,  0.0648],\n",
            "        [-0.0499,  0.0764, -0.0132,  ..., -0.0358,  0.0119,  0.0648],\n",
            "        ...,\n",
            "        [ 0.4388, -0.4322,  0.1063,  ...,  0.2276, -0.0707, -0.3522],\n",
            "        [ 0.4388, -0.4322,  0.1063,  ...,  0.2276, -0.0707, -0.3522],\n",
            "        [ 0.4388, -0.4322,  0.1063,  ...,  0.2276, -0.0707, -0.3522]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.4388, -0.4322,  0.1063,  ...,  0.2276, -0.0707, -0.3522],\n",
            "         [ 0.4388, -0.4322,  0.1063,  ...,  0.2276, -0.0707, -0.3522],\n",
            "         [ 0.4388, -0.4322,  0.1063,  ...,  0.2276, -0.0707, -0.3522],\n",
            "         ...,\n",
            "         [ 0.4388, -0.4322,  0.1063,  ...,  0.2276, -0.0707, -0.3522],\n",
            "         [ 0.4388, -0.4322,  0.1063,  ...,  0.2276, -0.0707, -0.3522],\n",
            "         [ 0.4388, -0.4322,  0.1063,  ...,  0.2276, -0.0707, -0.3522]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3622, -0.6036,  0.5867,  ...,  0.0144, -0.5839, -0.6347],\n",
            "        [ 0.3622, -0.6036,  0.5867,  ...,  0.0144, -0.5839, -0.6347],\n",
            "        [ 0.3622, -0.6036,  0.5867,  ...,  0.0144, -0.5839, -0.6347],\n",
            "        ...,\n",
            "        [ 0.3622, -0.6036,  0.5867,  ...,  0.0144, -0.5839, -0.6347],\n",
            "        [ 0.3622, -0.6036,  0.5867,  ...,  0.0144, -0.5839, -0.6347],\n",
            "        [ 0.3622, -0.6036,  0.5867,  ...,  0.0144, -0.5839, -0.6347]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.1001, -0.0092, -0.0659,  ..., -0.2112,  0.0855, -0.1296],\n",
            "        [-0.0495,  0.0766, -0.0131,  ..., -0.0359,  0.0120,  0.0648],\n",
            "        [ 0.0213,  0.0679,  0.0320,  ..., -0.0213, -0.0147, -0.0167],\n",
            "        ...,\n",
            "        [ 0.1543, -0.4452,  0.2484,  ...,  0.2337, -0.2689, -0.1488],\n",
            "        [ 0.2182, -0.1090,  0.3127,  ...,  0.0477, -0.1745, -0.2017],\n",
            "        [ 0.0235, -0.1241,  0.2869,  ..., -0.2257, -0.2491, -0.1242]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.3906, -0.0242,  0.0368,  ...,  0.1129,  0.1195,  0.3171],\n",
            "         [-0.0777, -0.1427,  0.0508,  ...,  0.0199,  0.1562,  0.4072],\n",
            "         [-0.1097,  0.2526,  0.0221,  ...,  0.2512, -0.0610, -0.0663],\n",
            "         ...,\n",
            "         [ 0.3068, -0.0445,  0.2455,  ..., -0.0039, -0.1429, -0.0723],\n",
            "         [-0.0138,  0.2500,  0.0818,  ...,  0.3195, -0.0697,  0.0846],\n",
            "         [ 0.3068, -0.0445,  0.2455,  ..., -0.0039, -0.1429, -0.0723]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.3395,  0.0016, -0.0639,  ...,  0.0089,  0.1574,  0.2655],\n",
            "        [-0.2133,  0.0039, -0.0563,  ..., -0.0239,  0.1486,  0.2961],\n",
            "        [ 0.0230,  0.1932,  0.0751,  ...,  0.2262, -0.1375, -0.2163],\n",
            "        ...,\n",
            "        [ 0.2211, -0.3082,  0.5177,  ..., -0.0397, -0.5656, -0.3538],\n",
            "        [ 0.2415,  0.4164, -0.0115,  ...,  0.4609,  0.0259, -0.1643],\n",
            "        [ 0.2211, -0.3082,  0.5177,  ..., -0.0397, -0.5656, -0.3538]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0492,  0.0767, -0.0130,  ..., -0.0359,  0.0121,  0.0647],\n",
            "        [ 0.0874, -0.0198, -0.0392,  ...,  0.0735, -0.1120, -0.0547],\n",
            "        [-0.0492,  0.0767, -0.0130,  ..., -0.0359,  0.0121,  0.0647],\n",
            "        ...,\n",
            "        [ 0.3837, -0.0748,  0.1789,  ..., -0.0648, -0.1118, -0.2166],\n",
            "        [-0.0865, -0.4717,  0.2147,  ..., -0.0660, -0.2857, -0.1697],\n",
            "        [-0.0705,  0.1888, -0.0778,  ..., -0.0792,  0.0005,  0.1042]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0381,  0.0806,  0.1806,  ..., -0.2253, -0.0907, -0.1843],\n",
            "         [ 0.1960, -0.2381,  0.1496,  ...,  0.1467, -0.2350, -0.1984],\n",
            "         [-0.0017, -0.0462,  0.0738,  ...,  0.1357, -0.1722, -0.0429],\n",
            "         ...,\n",
            "         [ 0.1282,  0.0931,  0.2788,  ...,  0.3000, -0.2296, -0.1781],\n",
            "         [ 0.0352, -0.0913,  0.0737,  ..., -0.1327, -0.3198, -0.1353],\n",
            "         [ 0.0117,  0.3416, -0.2048,  ..., -0.0099,  0.0348, -0.1808]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 1.3106e-01, -3.0349e-01,  6.3281e-01,  ..., -1.8075e-01,\n",
            "         -5.6160e-01, -4.5828e-01],\n",
            "        [ 2.1385e-01, -2.2771e-01,  2.8891e-01,  ...,  1.8292e-01,\n",
            "         -4.2275e-01, -3.7993e-01],\n",
            "        [-1.5117e-01,  5.2078e-03,  2.4654e-02,  ...,  3.4033e-02,\n",
            "          1.6067e-04,  8.1599e-02],\n",
            "        ...,\n",
            "        [ 2.7908e-01, -5.3492e-02,  4.9612e-01,  ...,  2.4015e-01,\n",
            "         -5.3429e-01, -4.2300e-01],\n",
            "        [ 1.7163e-02, -2.3548e-01,  3.2964e-01,  ..., -1.5418e-01,\n",
            "         -4.3305e-01, -3.4752e-01],\n",
            "        [ 1.8107e-01,  4.6193e-01, -1.0608e-01,  ...,  1.9619e-01,\n",
            "          4.8286e-02, -2.0445e-01]], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0879, -0.0196, -0.0387,  ...,  0.0731, -0.1111, -0.0541],\n",
            "        [ 0.1741, -0.0179, -0.1433,  ..., -0.0550,  0.2044, -0.0661],\n",
            "        [ 0.2057,  0.0406,  0.0791,  ...,  0.0820, -0.0574, -0.2484],\n",
            "        ...,\n",
            "        [ 0.0839,  0.1201,  0.1227,  ..., -0.0441, -0.0850,  0.1082],\n",
            "        [ 0.0843,  0.4686, -0.1102,  ...,  0.3177, -0.1132,  0.0552],\n",
            "        [ 0.0208, -0.0950,  0.2147,  ...,  0.1639, -0.2141, -0.0805]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0690,  0.0959, -0.0458,  ..., -0.0917,  0.3047,  0.3002],\n",
            "         [ 0.0873,  0.1282,  0.2050,  ..., -0.0496, -0.2679,  0.0694],\n",
            "         [-0.0551,  0.3807,  0.2356,  ..., -0.2162,  0.1909, -0.1020],\n",
            "         ...,\n",
            "         [ 0.0839,  0.1201,  0.1227,  ..., -0.0441, -0.0850,  0.1082],\n",
            "         [ 0.0843,  0.4686, -0.1102,  ...,  0.3177, -0.1132,  0.0552],\n",
            "         [ 0.0208, -0.0950,  0.2147,  ...,  0.1639, -0.2141, -0.0805]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.2053,  0.0460, -0.0836,  ..., -0.1075,  0.1894,  0.2780],\n",
            "        [ 0.4645,  0.6000,  0.0886,  ...,  0.4337, -0.0471, -0.1326],\n",
            "        [ 0.0200,  0.1840,  0.3988,  ..., -0.1313, -0.1684, -0.3128],\n",
            "        ...,\n",
            "        [ 0.2180, -0.1274,  0.4861,  ...,  0.0706, -0.4889, -0.2693],\n",
            "        [ 0.4436,  0.6652, -0.1790,  ...,  0.5758,  0.0648, -0.0512],\n",
            "        [ 0.0489, -0.0956,  0.2792,  ...,  0.0070, -0.2513, -0.2367]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.1543,  0.0610,  0.0028,  ...,  0.1403, -0.0640, -0.0489],\n",
            "        [-0.0294,  0.1163,  0.0378,  ...,  0.1693,  0.0059,  0.1899],\n",
            "        [ 0.0021,  0.0141, -0.0711,  ...,  0.0144, -0.0318, -0.0558],\n",
            "        ...,\n",
            "        [-0.0664,  0.0244,  0.1095,  ..., -0.0575, -0.2752, -0.3055],\n",
            "        [-0.0086,  0.4912,  0.1247,  ...,  0.0538,  0.0380,  0.1392],\n",
            "        [ 0.3846, -0.1039,  0.2331,  ...,  0.2111, -0.3506, -0.1057]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1359,  0.4129,  0.1148,  ...,  0.1615, -0.1668, -0.1251],\n",
            "         [ 0.2447,  0.0672,  0.0933,  ...,  0.4946, -0.1702, -0.2945],\n",
            "         [-0.0379, -0.1542,  0.0549,  ...,  0.2331, -0.2270, -0.2055],\n",
            "         ...,\n",
            "         [ 0.0113,  0.3101, -0.1218,  ...,  0.1831, -0.0729, -0.2529],\n",
            "         [ 0.4092, -0.1344,  0.3601,  ...,  0.1042, -0.3006, -0.1756],\n",
            "         [ 0.1791, -0.1736, -0.1897,  ...,  0.1338,  0.0983, -0.0456]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2590,  0.5514,  0.1139,  ...,  0.4426, -0.2786, -0.3438],\n",
            "        [ 0.4377,  0.3288,  0.0491,  ...,  0.5489, -0.2121, -0.3741],\n",
            "        [ 0.2766,  0.1365,  0.0636,  ...,  0.3323, -0.1628, -0.2912],\n",
            "        ...,\n",
            "        [ 0.2524,  0.4588, -0.1573,  ...,  0.3305, -0.0216, -0.2967],\n",
            "        [ 0.1847, -0.4376,  0.5724,  ...,  0.0277, -0.6030, -0.4054],\n",
            "        [ 0.1128, -0.1026,  0.0701,  ...,  0.0548, -0.1434, -0.1732]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0486,  0.0771, -0.0129,  ..., -0.0355,  0.0123,  0.0639],\n",
            "        [-0.0486,  0.0771, -0.0129,  ..., -0.0355,  0.0123,  0.0639],\n",
            "        [-0.0327, -0.0400,  0.0190,  ..., -0.1059, -0.2230, -0.1768],\n",
            "        ...,\n",
            "        [ 0.2406,  0.2825,  0.1065,  ...,  0.1753, -0.1969, -0.3473],\n",
            "        [-0.0410,  0.2096,  0.0203,  ...,  0.1110, -0.1906, -0.0236],\n",
            "        [ 0.4118,  0.0222,  0.3332,  ...,  0.3904, -0.1497, -0.2134]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0410,  0.2096,  0.0203,  ...,  0.1110, -0.1906, -0.0236],\n",
            "         [ 0.4118,  0.0222,  0.3332,  ...,  0.3904, -0.1497, -0.2134],\n",
            "         [-0.0359,  0.1612,  0.0859,  ...,  0.0252,  0.0007,  0.0680],\n",
            "         ...,\n",
            "         [-0.0510,  0.0805,  0.0666,  ..., -0.3416,  0.0047, -0.0908],\n",
            "         [ 0.3015,  0.1241,  0.3084,  ...,  0.2758, -0.2701, -0.1601],\n",
            "         [ 0.2406,  0.2825,  0.1065,  ...,  0.1753, -0.1969, -0.3473]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3798,  0.5975, -0.1312,  ...,  0.4456, -0.0516, -0.2786],\n",
            "        [ 0.4195, -0.1772,  0.5284,  ...,  0.2949, -0.5029, -0.4154],\n",
            "        [-0.0692,  0.0106,  0.1094,  ...,  0.0011, -0.0404,  0.0105],\n",
            "        ...,\n",
            "        [-0.0380,  0.1430, -0.0234,  ..., -0.1978,  0.0814, -0.0849],\n",
            "        [ 0.3139, -0.1660,  0.5785,  ...,  0.2425, -0.5308, -0.4684],\n",
            "        [ 0.4282,  0.3249,  0.4067,  ...,  0.3591, -0.4704, -0.5634]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0888, -0.0193, -0.0375,  ...,  0.0721, -0.1092, -0.0525],\n",
            "        [-0.2088, -0.0490, -0.0121,  ...,  0.1638, -0.1784, -0.0858],\n",
            "        [-0.0486,  0.0774, -0.0129,  ..., -0.0352,  0.0121,  0.0634],\n",
            "        ...,\n",
            "        [-0.1610, -0.3242,  0.2238,  ..., -0.0191, -0.3737, -0.1976],\n",
            "        [ 0.2385, -0.5547,  0.3058,  ...,  0.2707, -0.3306, -0.1786],\n",
            "        [ 0.2633,  0.0717,  0.1672,  ...,  0.2126, -0.0370, -0.2446]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2006,  0.1821, -0.0929,  ..., -0.1281, -0.1161, -0.0628],\n",
            "         [ 0.0301,  0.1631,  0.1810,  ...,  0.3314, -0.1183, -0.0177],\n",
            "         [ 0.1924, -0.0295,  0.1599,  ...,  0.0916, -0.1240, -0.2656],\n",
            "         ...,\n",
            "         [ 0.2385, -0.5547,  0.3058,  ...,  0.2707, -0.3306, -0.1786],\n",
            "         [ 0.2633,  0.0717,  0.1672,  ...,  0.2126, -0.0370, -0.2446],\n",
            "         [ 0.2924,  0.1218,  0.3092,  ...,  0.2054, -0.0883, -0.2206]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2424,  0.0178,  0.3079,  ..., -0.0816, -0.4944, -0.3083],\n",
            "        [ 0.0788,  0.3072,  0.0112,  ...,  0.2460, -0.0028, -0.0410],\n",
            "        [ 0.2361, -0.2541,  0.5417,  ...,  0.1218, -0.5423, -0.5616],\n",
            "        ...,\n",
            "        [ 0.2900, -0.7712,  0.7293,  ...,  0.0477, -0.7367, -0.6670],\n",
            "        [ 0.3137, -0.4148,  0.6696,  ...,  0.0382, -0.5986, -0.5684],\n",
            "        [ 0.4325, -0.2526,  0.6749,  ...,  0.1792, -0.5525, -0.5209]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.1184,  0.0277, -0.0435,  ...,  0.0300, -0.0039,  0.1781],\n",
            "        [ 0.3454, -0.0396, -0.0245,  ...,  0.0236,  0.0516, -0.0474],\n",
            "        [ 0.0877, -0.0219, -0.0386,  ...,  0.0710, -0.1099, -0.0522],\n",
            "        ...,\n",
            "        [ 0.1061,  0.1774,  0.1676,  ...,  0.5257, -0.2877, -0.1187],\n",
            "        [-0.0767,  0.5340, -0.0185,  ...,  0.0133, -0.1644,  0.0350],\n",
            "        [ 0.3222, -0.0081,  0.0814,  ...,  0.0306, -0.0865, -0.2387]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0303, -0.0352,  0.0965,  ..., -0.0060, -0.0093, -0.0395],\n",
            "         [-0.2417,  0.0976,  0.0174,  ..., -0.0217, -0.0893, -0.0625],\n",
            "         [ 0.2245,  0.0717,  0.3330,  ...,  0.0918, -0.2168, -0.2053],\n",
            "         ...,\n",
            "         [ 0.1061,  0.1774,  0.1676,  ...,  0.5257, -0.2877, -0.1187],\n",
            "         [-0.0767,  0.5340, -0.0185,  ...,  0.0133, -0.1644,  0.0350],\n",
            "         [ 0.3222, -0.0081,  0.0814,  ...,  0.0306, -0.0865, -0.2387]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0224, -0.1219,  0.1988,  ..., -0.0146, -0.2022, -0.1378],\n",
            "        [ 0.2156,  0.4177,  0.0373,  ...,  0.3171, -0.0732, -0.2912],\n",
            "        [ 0.2574, -0.3088,  0.6778,  ...,  0.1050, -0.6017, -0.4635],\n",
            "        ...,\n",
            "        [ 0.5259,  0.6404,  0.0985,  ...,  0.7166, -0.1896, -0.5241],\n",
            "        [ 0.3167,  0.6544, -0.0615,  ...,  0.2971, -0.1602, -0.1113],\n",
            "        [ 0.1821, -0.1753,  0.4115,  ...,  0.0380, -0.4763, -0.4663]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0017,  0.0778, -0.0031,  ...,  0.0031, -0.0365, -0.0315],\n",
            "        [-0.0488,  0.0779, -0.0127,  ..., -0.0345,  0.0118,  0.0624],\n",
            "        [-0.1554,  0.0614,  0.0025,  ...,  0.1426, -0.0650, -0.0501],\n",
            "        ...,\n",
            "        [ 0.1111,  0.1455,  0.2449,  ...,  0.1417, -0.0476, -0.2500],\n",
            "        [ 0.2504, -0.4433,  0.2520,  ...,  0.2562, -0.3754, -0.1417],\n",
            "        [-0.1539,  0.2109,  0.1611,  ...,  0.0019, -0.1180, -0.0913]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1595,  0.0036,  0.2152,  ...,  0.1011, -0.4294, -0.2299],\n",
            "         [ 0.2715, -0.3280,  0.2319,  ...,  0.0687, -0.3640, -0.1844],\n",
            "         [-0.0660,  0.1919,  0.1160,  ...,  0.4527, -0.2648, -0.1140],\n",
            "         ...,\n",
            "         [-0.1233,  0.3662,  0.0302,  ...,  0.2365, -0.0980,  0.1324],\n",
            "         [-0.0413, -0.2193,  0.0948,  ..., -0.0531, -0.1100, -0.1264],\n",
            "         [ 0.0412,  0.1012,  0.1573,  ...,  0.1488, -0.0034, -0.0287]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3393, -0.4643,  0.6758,  ...,  0.0765, -0.7664, -0.6645],\n",
            "        [ 0.1274, -0.6705,  0.7233,  ..., -0.1917, -0.8009, -0.5626],\n",
            "        [ 0.4191,  0.6192,  0.0086,  ...,  0.6545, -0.1573, -0.5106],\n",
            "        ...,\n",
            "        [ 0.1426,  0.4487, -0.0426,  ...,  0.3577,  0.0135, -0.0782],\n",
            "        [-0.0407, -0.3809,  0.4258,  ..., -0.1661, -0.4154, -0.3634],\n",
            "        [ 0.0191, -0.1626,  0.3710,  ...,  0.0198, -0.2929, -0.1401]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0488,  0.0781, -0.0126,  ..., -0.0343,  0.0116,  0.0618],\n",
            "        [-0.0488,  0.0781, -0.0126,  ..., -0.0343,  0.0116,  0.0618],\n",
            "        [-0.0488,  0.0781, -0.0126,  ..., -0.0343,  0.0116,  0.0618],\n",
            "        ...,\n",
            "        [ 0.2118,  0.1894, -0.0507,  ..., -0.0193, -0.0600,  0.0930],\n",
            "        [ 0.1973, -0.0031,  0.0702,  ...,  0.1846, -0.0411, -0.0585],\n",
            "        [ 0.4546,  0.0545, -0.0537,  ...,  0.1855, -0.1656, -0.2896]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2118,  0.1894, -0.0507,  ..., -0.0193, -0.0600,  0.0930],\n",
            "         [ 0.1973, -0.0031,  0.0702,  ...,  0.1846, -0.0411, -0.0585],\n",
            "         [ 0.4546,  0.0545, -0.0537,  ...,  0.1855, -0.1656, -0.2896],\n",
            "         ...,\n",
            "         [-0.0783, -0.0421, -0.1211,  ..., -0.0895,  0.0211,  0.1745],\n",
            "         [ 0.0388, -0.4064,  0.1953,  ...,  0.0715, -0.2832, -0.1267],\n",
            "         [ 0.2305, -0.2401, -0.0367,  ...,  0.3533, -0.3746, -0.2764]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0944, -0.0495,  0.2325,  ...,  0.0604, -0.3584, -0.0829],\n",
            "        [ 0.1729, -0.2414,  0.4623,  ...,  0.1293, -0.4997, -0.3554],\n",
            "        [ 0.2584,  0.0622,  0.1358,  ...,  0.2168, -0.3784, -0.3756],\n",
            "        ...,\n",
            "        [-0.1392,  0.0117, -0.1017,  ..., -0.0643,  0.1041,  0.2116],\n",
            "        [ 0.1220, -0.6380,  0.5820,  ..., -0.0741, -0.6383, -0.5042],\n",
            "        [ 0.3176, -0.3318,  0.3063,  ...,  0.3528, -0.5813, -0.4799]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0453,  0.0417,  0.0129,  ..., -0.0110, -0.0419, -0.1047],\n",
            "        [-0.0487,  0.0783, -0.0125,  ..., -0.0341,  0.0114,  0.0614],\n",
            "        [ 0.0849, -0.0285, -0.0412,  ...,  0.0685, -0.1119, -0.0514],\n",
            "        ...,\n",
            "        [-0.1219,  0.0091,  0.0857,  ...,  0.0130, -0.2037, -0.0826],\n",
            "        [-0.0593,  0.0971, -0.0333,  ...,  0.1026, -0.1458, -0.0352],\n",
            "        [ 0.3057,  0.0791,  0.3251,  ...,  0.2110, -0.0983, -0.2370]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2901, -0.0735, -0.0929,  ...,  0.0512, -0.3474, -0.1695],\n",
            "         [ 0.1437, -0.1265,  0.0526,  ...,  0.0451,  0.0993, -0.2816],\n",
            "         [-0.0744,  0.2131,  0.1282,  ...,  0.2381, -0.1715, -0.1343],\n",
            "         ...,\n",
            "         [-0.2789,  0.2360,  0.1110,  ...,  0.1399, -0.3398, -0.0352],\n",
            "         [-0.0084,  0.7519, -0.0370,  ...,  0.3736,  0.0637, -0.2092],\n",
            "         [ 0.1718, -0.5964,  0.2832,  ..., -0.0874, -0.3835, -0.2254]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2424, -0.1661,  0.2826,  ...,  0.0991, -0.4955, -0.3967],\n",
            "        [ 0.2333, -0.3469,  0.4678,  ...,  0.0768, -0.4138, -0.4463],\n",
            "        [ 0.4054,  0.6276,  0.1042,  ...,  0.5200, -0.0961, -0.5251],\n",
            "        ...,\n",
            "        [ 0.2410,  0.6106, -0.0778,  ...,  0.5496,  0.0050, -0.2136],\n",
            "        [ 0.4888,  0.8617, -0.1192,  ...,  0.6935,  0.0083, -0.5192],\n",
            "        [ 0.1232, -0.8206,  0.7789,  ..., -0.2605, -0.8190, -0.6679]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0486,  0.0784, -0.0124,  ..., -0.0339,  0.0113,  0.0611],\n",
            "        [-0.0486,  0.0784, -0.0124,  ..., -0.0339,  0.0113,  0.0611],\n",
            "        [-0.0486,  0.0784, -0.0124,  ..., -0.0339,  0.0113,  0.0611],\n",
            "        ...,\n",
            "        [ 0.2980,  0.0371,  0.3463,  ...,  0.1507, -0.0799, -0.2189],\n",
            "        [ 0.1657,  0.2703,  0.0595,  ...,  0.4006, -0.1755, -0.2810],\n",
            "        [ 0.3135, -0.0568,  0.3462,  ...,  0.2993, -0.0854, -0.2910]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1657,  0.2703,  0.0595,  ...,  0.4006, -0.1755, -0.2810],\n",
            "         [ 0.3135, -0.0568,  0.3462,  ...,  0.2993, -0.0854, -0.2910],\n",
            "         [ 0.2833,  0.1315,  0.0321,  ...,  0.0572, -0.2698,  0.0052],\n",
            "         ...,\n",
            "         [-0.2573,  0.0200,  0.0580,  ..., -0.1570, -0.1205, -0.0132],\n",
            "         [-0.2637,  0.3927,  0.0038,  ...,  0.1841, -0.1905, -0.0741],\n",
            "         [ 0.2524, -0.2977,  0.2660,  ...,  0.1401, -0.2439, -0.2053]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5361,  0.6463,  0.0655,  ...,  0.5633, -0.2726, -0.5013],\n",
            "        [ 0.5110, -0.6476,  0.8082,  ...,  0.1666, -0.7161, -0.6750],\n",
            "        [ 0.2104, -0.0581,  0.4138,  ..., -0.0108, -0.5558, -0.1851],\n",
            "        ...,\n",
            "        [-0.2331,  0.0758, -0.0243,  ..., -0.1093,  0.0456,  0.0304],\n",
            "        [ 0.2876,  0.7299, -0.1267,  ...,  0.6148,  0.0714, -0.2967],\n",
            "        [ 0.2266, -0.4203,  0.5412,  ...,  0.1275, -0.5544, -0.4537]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0765, -0.0540,  0.0554,  ...,  0.1063,  0.0177, -0.0338],\n",
            "        [-0.2249,  0.1233,  0.0181,  ...,  0.1085, -0.1477,  0.1231],\n",
            "        [ 0.0540,  0.0836,  0.1053,  ...,  0.0243,  0.0329, -0.0895],\n",
            "        ...,\n",
            "        [ 0.0588,  0.3052,  0.0158,  ...,  0.2296,  0.0471,  0.0374],\n",
            "        [-0.1366, -0.0317, -0.0455,  ...,  0.1030, -0.1293,  0.0609],\n",
            "        [-0.0319,  0.0698,  0.0159,  ...,  0.1631, -0.1134, -0.0692]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1444,  0.0023,  0.0038,  ...,  0.0170, -0.2448, -0.4740],\n",
            "         [-0.0367,  0.1296,  0.0140,  ..., -0.1238,  0.0018,  0.2170],\n",
            "         [-0.0105,  0.5563, -0.0067,  ...,  0.1937, -0.0065,  0.0265],\n",
            "         ...,\n",
            "         [ 0.2315, -0.0800,  0.2066,  ...,  0.0124, -0.2835, -0.1013],\n",
            "         [ 0.1032, -0.1246, -0.0969,  ...,  0.0422, -0.2827, -0.2472],\n",
            "         [ 0.0503,  0.2875,  0.2293,  ...,  0.1011, -0.1488, -0.2154]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3518, -0.4532,  0.5773,  ...,  0.0303, -0.6568, -0.6723],\n",
            "        [-0.1408,  0.1452, -0.0164,  ..., -0.0848,  0.0943,  0.2652],\n",
            "        [ 0.2674,  0.6213, -0.0746,  ...,  0.3784,  0.0761, -0.1414],\n",
            "        ...,\n",
            "        [ 0.2258, -0.4294,  0.5927,  ..., -0.0673, -0.6441, -0.4068],\n",
            "        [ 0.1647, -0.3584,  0.3355,  ...,  0.0285, -0.5155, -0.3992],\n",
            "        [ 0.3672,  0.5432,  0.0861,  ...,  0.3861, -0.1540, -0.3650]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0486,  0.0785, -0.0121,  ..., -0.0338,  0.0112,  0.0607],\n",
            "        [-0.0486,  0.0785, -0.0121,  ..., -0.0338,  0.0112,  0.0607],\n",
            "        [-0.0486,  0.0785, -0.0121,  ..., -0.0338,  0.0112,  0.0607],\n",
            "        ...,\n",
            "        [-0.0213, -0.0593, -0.0083,  ...,  0.3104,  0.0327, -0.2499],\n",
            "        [ 0.0997,  0.5402,  0.2045,  ..., -0.0522, -0.2105, -0.1835],\n",
            "        [ 0.1536, -0.3037,  0.2140,  ..., -0.0286, -0.2272, -0.0811]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0997,  0.5402,  0.2045,  ..., -0.0522, -0.2105, -0.1835],\n",
            "         [ 0.0997,  0.5402,  0.2045,  ..., -0.0522, -0.2105, -0.1835],\n",
            "         [-0.0854,  0.8555,  0.0333,  ...,  0.4227, -0.0882, -0.0776],\n",
            "         ...,\n",
            "         [ 0.1456, -0.2352,  0.1300,  ...,  0.0564, -0.2669, -0.4347],\n",
            "         [ 0.0933,  0.1585,  0.1200,  ..., -0.0368, -0.1260, -0.1695],\n",
            "         [ 0.1402, -0.0273,  0.2536,  ..., -0.1271, -0.1228, -0.1016]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4678,  0.6408,  0.3835,  ...,  0.3143, -0.4033, -0.6121],\n",
            "        [ 0.4678,  0.6408,  0.3835,  ...,  0.3143, -0.4033, -0.6121],\n",
            "        [ 0.4213,  0.8913, -0.0540,  ...,  0.7077, -0.1331, -0.4367],\n",
            "        ...,\n",
            "        [ 0.3235, -0.4491,  0.5395,  ...,  0.0444, -0.5838, -0.6009],\n",
            "        [ 0.2733, -0.2494,  0.5253,  ...,  0.0784, -0.5737, -0.4290],\n",
            "        [ 0.3832, -0.2700,  0.5906,  ...,  0.0730, -0.5160, -0.5186]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0780, -0.0135,  0.0125,  ...,  0.1867,  0.1666,  0.1151],\n",
            "        [-0.2099,  0.0165,  0.1238,  ..., -0.1021,  0.2019, -0.1004],\n",
            "        [ 0.0014,  0.3436,  0.0070,  ..., -0.0355, -0.0132, -0.1646],\n",
            "        ...,\n",
            "        [ 0.1622, -0.1189,  0.0197,  ...,  0.0549, -0.0216, -0.0365],\n",
            "        [ 0.3541, -0.1161,  0.3119,  ...,  0.4489, -0.2105, -0.2369],\n",
            "        [ 0.0844,  0.3261,  0.2134,  ..., -0.0529, -0.0997, -0.3821]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1622, -0.1189,  0.0197,  ...,  0.0549, -0.0216, -0.0365],\n",
            "         [ 0.3541, -0.1161,  0.3119,  ...,  0.4489, -0.2105, -0.2369],\n",
            "         [ 0.0844,  0.3261,  0.2134,  ..., -0.0529, -0.0997, -0.3821],\n",
            "         ...,\n",
            "         [ 0.0387, -0.0397,  0.0036,  ...,  0.2007, -0.1533, -0.0175],\n",
            "         [ 0.1496,  0.1377,  0.1023,  ...,  0.2011, -0.1865,  0.1602],\n",
            "         [-0.0564, -0.0261,  0.1905,  ...,  0.1479, -0.0356,  0.0300]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0646, -0.2978,  0.3627,  ..., -0.0061, -0.3658, -0.2668],\n",
            "        [ 0.3271, -0.3255,  0.5382,  ...,  0.3624, -0.5514, -0.4237],\n",
            "        [ 0.1840,  0.0357,  0.4339,  ...,  0.0580, -0.4182, -0.3849],\n",
            "        ...,\n",
            "        [-0.0158, -0.0964,  0.1533,  ...,  0.1642, -0.2900, -0.1006],\n",
            "        [ 0.0583,  0.0390,  0.2310,  ...,  0.1390, -0.3146, -0.1385],\n",
            "        [ 0.0341, -0.1668,  0.3825,  ...,  0.1083, -0.2527, -0.1489]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0505,  0.0777, -0.0127,  ..., -0.0351,  0.0124,  0.0631],\n",
            "        [ 0.1173, -0.0568, -0.1077,  ..., -0.0698,  0.0516, -0.1816],\n",
            "        [-0.0680,  0.0282, -0.0785,  ..., -0.0771,  0.1462,  0.0325],\n",
            "        ...,\n",
            "        [ 0.1252,  0.1226,  0.0205,  ...,  0.0920, -0.0628, -0.0315],\n",
            "        [-0.0092, -0.5845,  0.2171,  ..., -0.1084, -0.2717, -0.1683],\n",
            "        [-0.2708, -0.0795,  0.0379,  ..., -0.2823,  0.0321, -0.0161]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1387,  0.3758,  0.1220,  ..., -0.0697, -0.1504, -0.3235],\n",
            "         [ 0.2456, -0.3889,  0.2208,  ...,  0.0290, -0.3450, -0.1678],\n",
            "         [ 0.1071,  0.3515, -0.0272,  ...,  0.0283, -0.2285, -0.1153],\n",
            "         ...,\n",
            "         [ 0.3020, -0.0702, -0.0313,  ...,  0.3546, -0.2191, -0.0942],\n",
            "         [-0.1874,  0.1489,  0.2293,  ...,  0.2545, -0.2064, -0.1677],\n",
            "         [ 0.1797,  0.2221,  0.2558,  ...,  0.3160, -0.0982, -0.1357]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3384,  0.4161,  0.2814,  ...,  0.1859, -0.3792, -0.4849],\n",
            "        [ 0.0766, -0.6644,  0.7158,  ..., -0.1902, -0.7863, -0.5200],\n",
            "        [ 0.4468,  0.5843,  0.0218,  ...,  0.4618, -0.3132, -0.4203],\n",
            "        ...,\n",
            "        [ 0.1715,  0.0811, -0.0297,  ...,  0.2375, -0.1595, -0.0524],\n",
            "        [-0.0097, -0.1940,  0.4853,  ...,  0.1223, -0.5049, -0.3852],\n",
            "        [ 0.2681,  0.0704,  0.4679,  ...,  0.2375, -0.3742, -0.3492]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0514,  0.0773, -0.0130,  ..., -0.0357,  0.0129,  0.0640],\n",
            "        [-0.0514,  0.0773, -0.0130,  ..., -0.0357,  0.0129,  0.0640],\n",
            "        [-0.0514,  0.0773, -0.0130,  ..., -0.0357,  0.0129,  0.0640],\n",
            "        ...,\n",
            "        [-0.0149, -0.0513,  0.1013,  ...,  0.0937, -0.2715, -0.1534],\n",
            "        [-0.1110,  0.0497,  0.1204,  ..., -0.0148,  0.0633,  0.1691],\n",
            "        [ 0.2897, -0.3407,  0.2308,  ...,  0.3019, -0.1163, -0.1632]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2618,  0.1632,  0.3012,  ...,  0.2319, -0.1181, -0.2061],\n",
            "         [-0.0149, -0.0513,  0.1013,  ...,  0.0937, -0.2715, -0.1534],\n",
            "         [-0.1110,  0.0497,  0.1204,  ..., -0.0148,  0.0633,  0.1691],\n",
            "         ...,\n",
            "         [-0.0840, -0.5132,  0.1394,  ..., -0.0585, -0.2100, -0.3612],\n",
            "         [ 0.2312, -0.6270,  0.3004,  ...,  0.2599, -0.3273, -0.1740],\n",
            "         [ 0.1749,  0.2106, -0.0589,  ..., -0.0246, -0.4041, -0.1387]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2547, -0.3084,  0.7036,  ...,  0.0779, -0.6078, -0.4660],\n",
            "        [ 0.2781, -0.3887,  0.4967,  ...,  0.1292, -0.5732, -0.5308],\n",
            "        [-0.1329,  0.0436,  0.0451,  ..., -0.0635,  0.1100,  0.1639],\n",
            "        ...,\n",
            "        [ 0.2595, -0.7151,  0.5487,  ...,  0.1063, -0.6248, -0.5446],\n",
            "        [ 0.2374, -0.8062,  0.7403,  ..., -0.0077, -0.7464, -0.6467],\n",
            "        [ 0.1819, -0.2507,  0.4521,  ..., -0.0208, -0.6561, -0.4495]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2854, -0.0412,  0.1176,  ...,  0.3356, -0.1417, -0.1411],\n",
            "        [ 0.0780, -0.0358, -0.0483,  ...,  0.0683, -0.1188, -0.0520],\n",
            "        [ 0.0780, -0.0358, -0.0483,  ...,  0.0683, -0.1188, -0.0520],\n",
            "        ...,\n",
            "        [ 0.2777, -0.1771,  0.3413,  ...,  0.0958, -0.3040, -0.1647],\n",
            "        [ 0.3760, -0.0877,  0.1616,  ...,  0.3436, -0.2960, -0.2349],\n",
            "        [ 0.1547, -0.0757,  0.1551,  ...,  0.0142, -0.1826, -0.1254]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2777, -0.1771,  0.3413,  ...,  0.0958, -0.3040, -0.1647],\n",
            "         [ 0.3760, -0.0877,  0.1616,  ...,  0.3436, -0.2960, -0.2349],\n",
            "         [ 0.1547, -0.0757,  0.1551,  ...,  0.0142, -0.1826, -0.1254],\n",
            "         ...,\n",
            "         [ 0.0728, -0.0269, -0.1233,  ...,  0.0521, -0.0736, -0.0915],\n",
            "         [-0.1056,  0.0888,  0.1329,  ..., -0.0160,  0.2662,  0.1041],\n",
            "         [-0.0025, -0.1344, -0.0817,  ..., -0.1118,  0.1189, -0.1260]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 4.9354e-02, -3.6643e-01,  4.9173e-01,  ..., -6.3152e-03,\n",
            "         -5.3084e-01, -3.0453e-01],\n",
            "        [ 2.1603e-01, -2.2160e-01,  4.1005e-01,  ...,  1.9246e-01,\n",
            "         -5.5193e-01, -3.8980e-01],\n",
            "        [-3.4903e-04, -2.2740e-01,  4.0885e-01,  ..., -5.7734e-02,\n",
            "         -3.4494e-01, -2.0340e-01],\n",
            "        ...,\n",
            "        [ 5.3925e-02, -3.0911e-02,  4.6844e-03,  ...,  1.8124e-02,\n",
            "         -1.0172e-01, -1.1630e-01],\n",
            "        [-5.6637e-02,  5.7029e-02,  5.5451e-02,  ..., -3.2052e-03,\n",
            "          1.1198e-01,  3.7110e-02],\n",
            "        [-1.3828e-02, -9.9148e-02,  2.4474e-02,  ..., -7.5591e-02,\n",
            "          4.8291e-02,  2.5186e-02]], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.2037, -0.0332,  0.0986,  ..., -0.0947, -0.1901,  0.0502],\n",
            "        [-0.0529,  0.0766, -0.0133,  ..., -0.0365,  0.0138,  0.0655],\n",
            "        [-0.2104, -0.0502, -0.0145,  ...,  0.1685, -0.1789, -0.0865],\n",
            "        ...,\n",
            "        [-0.0967,  0.3815,  0.1312,  ..., -0.1028, -0.1750, -0.0172],\n",
            "        [ 0.1347, -0.1390, -0.1764,  ..., -0.0657,  0.1437, -0.0501],\n",
            "        [-0.1408, -0.2979,  0.1096,  ..., -0.0902,  0.1431, -0.0042]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 1.3468e-01, -1.3903e-01, -1.7642e-01,  ..., -6.5730e-02,\n",
            "           1.4368e-01, -5.0097e-02],\n",
            "         [-1.4085e-01, -2.9786e-01,  1.0956e-01,  ..., -9.0151e-02,\n",
            "           1.4306e-01, -4.1891e-03],\n",
            "         [ 1.7556e-01,  2.3299e-02,  1.1777e-02,  ..., -4.0928e-02,\n",
            "           4.0108e-03, -1.0058e-01],\n",
            "         ...,\n",
            "         [ 1.9664e-01,  2.3830e-01,  1.6886e-01,  ..., -1.6897e-01,\n",
            "          -1.4122e-01, -8.9244e-02],\n",
            "         [ 2.1850e-01, -3.5493e-01,  2.0590e-01,  ..., -2.2911e-04,\n",
            "          -3.1592e-01, -1.4507e-01],\n",
            "         [-9.6692e-02,  3.8146e-01,  1.3122e-01,  ..., -1.0275e-01,\n",
            "          -1.7504e-01, -1.7215e-02]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2367,  0.0302, -0.0533,  ...,  0.0930, -0.0135, -0.1828],\n",
            "        [-0.3109, -0.0796, -0.0700,  ..., -0.1562,  0.1782,  0.1515],\n",
            "        [ 0.0341, -0.2108,  0.4184,  ..., -0.1106, -0.3949, -0.2686],\n",
            "        ...,\n",
            "        [ 0.2178,  0.0133,  0.5239,  ..., -0.1707, -0.5042, -0.3071],\n",
            "        [ 0.0403, -0.6280,  0.6924,  ..., -0.1920, -0.7564, -0.4848],\n",
            "        [ 0.3545,  0.6712,  0.0321,  ...,  0.3338, -0.1157, -0.2660]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1076,  0.1212, -0.1101,  ..., -0.0303, -0.0736, -0.0450],\n",
            "        [ 0.2843, -0.0401,  0.1162,  ...,  0.3377, -0.1425, -0.1418],\n",
            "        [-0.0535,  0.0762, -0.0134,  ..., -0.0368,  0.0142,  0.0661],\n",
            "        ...,\n",
            "        [ 0.1748,  0.0293,  0.2734,  ..., -0.0499,  0.2370,  0.0151],\n",
            "        [ 0.1109,  0.3651,  0.2320,  ..., -0.0531, -0.1189, -0.3927],\n",
            "        [ 0.0748,  0.2569, -0.0724,  ...,  0.0065, -0.0430, -0.1263]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.1704, -0.0106,  0.0228,  ..., -0.0655,  0.0168,  0.0231],\n",
            "         [ 0.1748,  0.0293,  0.2734,  ..., -0.0499,  0.2370,  0.0151],\n",
            "         [ 0.1109,  0.3651,  0.2320,  ..., -0.0531, -0.1189, -0.3927],\n",
            "         ...,\n",
            "         [ 0.2812,  0.0168,  0.0638,  ...,  0.3353, -0.2286, -0.2398],\n",
            "         [-0.0900,  0.0595,  0.0833,  ...,  0.1371, -0.1129, -0.0620],\n",
            "         [ 0.0766, -0.0477, -0.0163,  ...,  0.1295,  0.1535, -0.1583]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1413,  0.0354,  0.0888,  ...,  0.0683, -0.0641, -0.0551],\n",
            "        [ 0.2958, -0.2378,  0.5635,  ..., -0.0397, -0.3273, -0.2790],\n",
            "        [ 0.2058,  0.0576,  0.4721,  ...,  0.0707, -0.4512, -0.4102],\n",
            "        ...,\n",
            "        [ 0.2204, -0.0858,  0.2797,  ...,  0.1900, -0.4282, -0.3107],\n",
            "        [-0.0389,  0.0072,  0.1184,  ...,  0.0635, -0.1266, -0.0770],\n",
            "        [ 0.0997,  0.0390, -0.0299,  ...,  0.1197,  0.0971, -0.0446]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[ 0.0029,  0.0384, -0.0061,  ...,  0.1191,  0.1699, -0.1844],\n",
            "        [ 0.2843, -0.0401,  0.1162,  ...,  0.3377, -0.1425, -0.1418],\n",
            "        [-0.0482, -0.0847,  0.1454,  ...,  0.2771, -0.0838,  0.0305],\n",
            "        ...,\n",
            "        [-0.1014,  0.4652,  0.0621,  ...,  0.2928,  0.1387, -0.4124],\n",
            "        [ 0.1789, -0.1027,  0.2137,  ..., -0.0930, -0.3269, -0.1464],\n",
            "        [ 0.2395,  0.1169,  0.1258,  ...,  0.2272,  0.1251, -0.3136]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[-0.2822,  0.3592,  0.0955,  ...,  0.3593,  0.0233, -0.1354],\n",
            "         [ 0.1927,  0.2574,  0.1276,  ...,  0.2028,  0.1442, -0.3609],\n",
            "         [ 0.0604,  0.1317, -0.0130,  ...,  0.1249,  0.0215, -0.2405],\n",
            "         ...,\n",
            "         [ 0.1029,  0.0798,  0.1079,  ...,  0.0967,  0.0255, -0.2224],\n",
            "         [ 0.1960, -0.1400,  0.1710,  ..., -0.0368, -0.0758, -0.0130],\n",
            "         [ 0.4211,  0.0983,  0.1350,  ...,  0.2734,  0.0276, -0.3274]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1875,  0.6479, -0.0601,  ...,  0.5509,  0.1215, -0.3978],\n",
            "        [ 0.4107,  0.4656,  0.2677,  ...,  0.4515, -0.2442, -0.4664],\n",
            "        [ 0.1814,  0.1702,  0.1086,  ...,  0.1935, -0.2133, -0.3039],\n",
            "        ...,\n",
            "        [ 0.1203, -0.0362,  0.2971,  ...,  0.0538, -0.2818, -0.2476],\n",
            "        [ 0.3500, -0.1587,  0.2221,  ...,  0.0785, -0.2067, -0.1267],\n",
            "        [ 0.3998,  0.0742,  0.4053,  ...,  0.3131, -0.3579, -0.4531]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[-0.0535,  0.0762, -0.0134,  ..., -0.0368,  0.0142,  0.0661],\n",
            "        [ 0.2843, -0.0401,  0.1162,  ...,  0.3377, -0.1425, -0.1418],\n",
            "        [-0.0976,  0.0071, -0.0449,  ..., -0.0133,  0.0514,  0.0939],\n",
            "        ...,\n",
            "        [ 0.4363,  0.2035,  0.1094,  ...,  0.1661, -0.0025, -0.2095],\n",
            "        [ 0.0369,  0.3459,  0.3215,  ...,  0.1618, -0.1234, -0.2726],\n",
            "        [ 0.0888,  0.6181, -0.0273,  ...,  0.4211, -0.0126, -0.2495]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.4295,  0.0009,  0.1648,  ...,  0.1917,  0.0920, -0.3334],\n",
            "         [ 0.2233,  0.1952,  0.1727,  ...,  0.0403,  0.1420, -0.2127],\n",
            "         [ 0.1258, -0.2584,  0.1486,  ...,  0.4147, -0.3182, -0.1327],\n",
            "         ...,\n",
            "         [-0.0037, -0.1061,  0.1668,  ...,  0.0567, -0.0957, -0.1362],\n",
            "         [ 0.2045,  0.4421,  0.0992,  ...,  0.1270,  0.0728, -0.2408],\n",
            "         [ 0.1963,  0.0731,  0.0564,  ...,  0.1653,  0.1369,  0.1139]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3112, -0.3396,  0.5916,  ...,  0.1052, -0.4518, -0.4574],\n",
            "        [ 0.2774, -0.0713,  0.5182,  ...,  0.0542, -0.3526, -0.4109],\n",
            "        [ 0.3047, -0.2199,  0.3776,  ...,  0.3349, -0.4756, -0.4916],\n",
            "        ...,\n",
            "        [ 0.0080, -0.3716,  0.5375,  ..., -0.1070, -0.4995, -0.4282],\n",
            "        [ 0.4352,  0.4902,  0.3117,  ...,  0.3966, -0.2989, -0.4954],\n",
            "        [ 0.1362,  0.0613,  0.0638,  ...,  0.1353,  0.0322,  0.0318]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[ 0.0765, -0.0372, -0.0503,  ...,  0.0677, -0.1197, -0.0516],\n",
            "        [ 0.0645, -0.0247,  0.0604,  ...,  0.0187, -0.0765,  0.0083],\n",
            "        [-0.0535,  0.0762, -0.0134,  ..., -0.0368,  0.0142,  0.0661],\n",
            "        ...,\n",
            "        [-0.0621,  0.3195,  0.1637,  ..., -0.0205, -0.2630, -0.1152],\n",
            "        [ 0.0285,  0.0117, -0.0174,  ...,  0.0253, -0.1277, -0.2097],\n",
            "        [ 0.0778,  0.5053, -0.1016,  ...,  0.3453, -0.1357,  0.0469]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.1267, -0.2681, -0.0983,  ...,  0.0429, -0.2185, -0.2283],\n",
            "         [-0.0562, -0.1900,  0.1405,  ...,  0.1605, -0.0370, -0.1077],\n",
            "         [-0.0475,  0.1465,  0.0230,  ..., -0.0549,  0.2014,  0.1266],\n",
            "         ...,\n",
            "         [ 0.1647,  0.1826,  0.3521,  ...,  0.0236,  0.0557, -0.0026],\n",
            "         [-0.0081,  0.0049,  0.1095,  ..., -0.0579,  0.0011, -0.1578],\n",
            "         [-0.1024,  0.1331,  0.1339,  ...,  0.0676, -0.2352, -0.1187]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0644, -0.2630,  0.2295,  ..., -0.0696, -0.3926, -0.1966],\n",
            "        [ 0.0593, -0.2659,  0.3093,  ...,  0.0206, -0.2412, -0.3159],\n",
            "        [ 0.0813,  0.2700,  0.0269,  ...,  0.1186,  0.0501,  0.0684],\n",
            "        ...,\n",
            "        [ 0.4176, -0.0894,  0.5647,  ...,  0.1807, -0.3999, -0.3589],\n",
            "        [ 0.0727, -0.3432,  0.5503,  ..., -0.1525, -0.4669, -0.4210],\n",
            "        [ 0.0955,  0.1081,  0.2838,  ...,  0.1553, -0.2797, -0.4249]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[ 0.2843, -0.0401,  0.1162,  ...,  0.3377, -0.1425, -0.1418],\n",
            "        [-0.0535,  0.0762, -0.0134,  ..., -0.0368,  0.0142,  0.0661],\n",
            "        [ 0.0029,  0.0384, -0.0061,  ...,  0.1191,  0.1699, -0.1844],\n",
            "        ...,\n",
            "        [ 0.0176,  0.2430,  0.0297,  ...,  0.2549,  0.1796,  0.0020],\n",
            "        [ 0.3049,  0.0412,  0.1573,  ...,  0.3122,  0.1192, -0.1265],\n",
            "        [ 0.2722, -0.5533, -0.2158,  ..., -0.0115,  0.0859, -0.2673]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.5127,  0.0666,  0.2512,  ...,  0.1054, -0.2111, -0.2297],\n",
            "         [ 0.0743,  0.2741,  0.0558,  ...,  0.1460, -0.2533, -0.1438],\n",
            "         [ 0.0228,  0.2613,  0.0523,  ...,  0.3258,  0.0869, -0.2739],\n",
            "         ...,\n",
            "         [ 0.0778,  0.5053, -0.1016,  ...,  0.3453, -0.1357,  0.0469],\n",
            "         [ 0.0375,  0.0601,  0.1547,  ..., -0.0051, -0.0882, -0.0769],\n",
            "         [ 0.1645,  0.2321,  0.1759,  ...,  0.1406,  0.1025, -0.0895]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2963, -0.2377,  0.5777,  ...,  0.0800, -0.5662, -0.4685],\n",
            "        [ 0.3667,  0.4901,  0.0604,  ...,  0.3862, -0.1846, -0.3283],\n",
            "        [ 0.3125,  0.4797,  0.0482,  ...,  0.4389, -0.1745, -0.4160],\n",
            "        ...,\n",
            "        [ 0.5005,  0.7252, -0.1834,  ...,  0.6500,  0.0667, -0.0989],\n",
            "        [ 0.1618,  0.1224, -0.0053,  ...,  0.1625, -0.0594, -0.1513],\n",
            "        [ 0.1579,  0.0643,  0.4372,  ...,  0.0795, -0.3281, -0.2933]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[-0.0535,  0.0762, -0.0134,  ..., -0.0368,  0.0142,  0.0661],\n",
            "        [-0.0535,  0.0762, -0.0134,  ..., -0.0368,  0.0142,  0.0661],\n",
            "        [-0.0535,  0.0762, -0.0134,  ..., -0.0368,  0.0142,  0.0661],\n",
            "        ...,\n",
            "        [ 0.3026, -0.0565,  0.4660,  ...,  0.4184, -0.0934, -0.1212],\n",
            "        [ 0.4291, -0.5292,  0.1304,  ...,  0.2245, -0.0827, -0.3654],\n",
            "        [ 0.4291, -0.5292,  0.1304,  ...,  0.2245, -0.0827, -0.3654]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.4291, -0.5292,  0.1304,  ...,  0.2245, -0.0827, -0.3654],\n",
            "         [ 0.4291, -0.5292,  0.1304,  ...,  0.2245, -0.0827, -0.3654],\n",
            "         [ 0.3026, -0.0565,  0.4660,  ...,  0.4184, -0.0934, -0.1212],\n",
            "         ...,\n",
            "         [-0.1918,  0.5543,  0.0926,  ...,  0.3131, -0.3281, -0.1041],\n",
            "         [-0.0373,  0.0786,  0.1400,  ..., -0.0795, -0.3011, -0.0536],\n",
            "         [ 0.2770,  0.0581,  0.0661,  ...,  0.1629, -0.0434, -0.0817]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3511, -0.6982,  0.6333,  ..., -0.0061, -0.6135, -0.6409],\n",
            "        [ 0.3511, -0.6982,  0.6333,  ..., -0.0061, -0.6135, -0.6409],\n",
            "        [ 0.2612, -0.5679,  0.8267,  ...,  0.1707, -0.5772, -0.3915],\n",
            "        ...,\n",
            "        [ 0.4216,  0.8485, -0.0897,  ...,  0.7178,  0.0386, -0.4442],\n",
            "        [-0.0306, -0.2212,  0.3843,  ..., -0.1110, -0.4816, -0.3062],\n",
            "        [ 0.1474,  0.0014,  0.2789,  ...,  0.0850, -0.2876, -0.2319]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[-0.0535,  0.0762, -0.0134,  ..., -0.0368,  0.0142,  0.0661],\n",
            "        [-0.0535,  0.0762, -0.0134,  ..., -0.0368,  0.0142,  0.0661],\n",
            "        [-0.0535,  0.0762, -0.0134,  ..., -0.0368,  0.0142,  0.0661],\n",
            "        ...,\n",
            "        [ 0.4291, -0.5292,  0.1304,  ...,  0.2245, -0.0827, -0.3654],\n",
            "        [ 0.4291, -0.5292,  0.1304,  ...,  0.2245, -0.0827, -0.3654],\n",
            "        [ 0.4291, -0.5292,  0.1304,  ...,  0.2245, -0.0827, -0.3654]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.4291, -0.5292,  0.1304,  ...,  0.2245, -0.0827, -0.3654],\n",
            "         [ 0.4291, -0.5292,  0.1304,  ...,  0.2245, -0.0827, -0.3654],\n",
            "         [ 0.4291, -0.5292,  0.1304,  ...,  0.2245, -0.0827, -0.3654],\n",
            "         ...,\n",
            "         [ 0.4291, -0.5292,  0.1304,  ...,  0.2245, -0.0827, -0.3654],\n",
            "         [ 0.4291, -0.5292,  0.1304,  ...,  0.2245, -0.0827, -0.3654],\n",
            "         [ 0.4291, -0.5292,  0.1304,  ...,  0.2245, -0.0827, -0.3654]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3511, -0.6982,  0.6333,  ..., -0.0061, -0.6135, -0.6409],\n",
            "        [ 0.3511, -0.6982,  0.6333,  ..., -0.0061, -0.6135, -0.6409],\n",
            "        [ 0.3511, -0.6982,  0.6333,  ..., -0.0061, -0.6135, -0.6409],\n",
            "        ...,\n",
            "        [ 0.3511, -0.6982,  0.6333,  ..., -0.0061, -0.6135, -0.6409],\n",
            "        [ 0.3511, -0.6982,  0.6333,  ..., -0.0061, -0.6135, -0.6409],\n",
            "        [ 0.3511, -0.6982,  0.6333,  ..., -0.0061, -0.6135, -0.6409]],\n",
            "       device='cuda:0')\n",
            "\t Epoch: 7 | Train Loss: 0.083 | Train Acc: 98.31%\n",
            "\t Epoch: 7 | Val. Loss: 0.888 |  Val. Acc: 83.48% \n",
            "\n",
            "Output of encoder at every step:tensor([[-0.0535,  0.0762, -0.0134,  ..., -0.0368,  0.0142,  0.0661],\n",
            "        [-0.0535,  0.0762, -0.0134,  ..., -0.0368,  0.0142,  0.0661],\n",
            "        [-0.0535,  0.0762, -0.0134,  ..., -0.0368,  0.0142,  0.0661],\n",
            "        ...,\n",
            "        [ 0.2174, -0.3039,  0.3831,  ...,  0.0897, -0.3319, -0.2089],\n",
            "        [ 0.1733, -0.0936,  0.0794,  ...,  0.1953, -0.1365, -0.1390],\n",
            "        [ 0.1478, -0.1107,  0.1261,  ..., -0.0736, -0.2796, -0.0096]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1116,  0.0095,  0.1857,  ...,  0.0897, -0.1839, -0.0984],\n",
            "         [-0.1735,  0.2087,  0.1396,  ...,  0.0243, -0.2982, -0.0718],\n",
            "         [ 0.1198,  0.2016,  0.2789,  ..., -0.0194, -0.1945, -0.2158],\n",
            "         ...,\n",
            "         [ 0.1514, -0.0056,  0.0319,  ...,  0.1665, -0.0155,  0.0026],\n",
            "         [ 0.0873,  0.0982,  0.1477,  ...,  0.1742, -0.0468, -0.1725],\n",
            "         [ 0.1434,  0.2141,  0.1004,  ...,  0.0964, -0.2568, -0.2417]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3056,  0.1060,  0.3820,  ...,  0.2317, -0.4564, -0.3866],\n",
            "        [ 0.0563,  0.4314,  0.0406,  ...,  0.1846, -0.0350, -0.2764],\n",
            "        [ 0.2168, -0.1151,  0.5406,  ...,  0.0404, -0.5481, -0.3909],\n",
            "        ...,\n",
            "        [ 0.1110, -0.1788,  0.3690,  ...,  0.1121, -0.4176, -0.2532],\n",
            "        [ 0.3583,  0.2436,  0.2492,  ...,  0.2904, -0.2857, -0.3815],\n",
            "        [ 0.2745, -0.0308,  0.4560,  ...,  0.1907, -0.5077, -0.4107]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0008,  0.0767, -0.0018,  ...,  0.0028, -0.0376, -0.0302],\n",
            "        [-0.1418, -0.0600,  0.0617,  ...,  0.0524, -0.0379, -0.1372],\n",
            "        [ 0.0006,  0.0772, -0.1247,  ..., -0.0884,  0.0004,  0.0429],\n",
            "        ...,\n",
            "        [ 0.1430,  0.0984,  0.2588,  ..., -0.0377, -0.1358, -0.0468],\n",
            "        [ 0.0446,  0.4328,  0.0028,  ...,  0.3006, -0.1842, -0.1280],\n",
            "        [-0.0927,  0.0817,  0.2460,  ...,  0.2465, -0.2949, -0.0738]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0379,  0.0928,  0.1697,  ...,  0.0751, -0.3698, -0.1856],\n",
            "         [-0.1820,  0.3413,  0.1410,  ...,  0.0351, -0.1198, -0.0891],\n",
            "         [ 0.2655, -0.0163, -0.0501,  ...,  0.1990, -0.1379, -0.1740],\n",
            "         ...,\n",
            "         [ 0.3748, -0.0991,  0.2340,  ...,  0.2076, -0.3397, -0.0896],\n",
            "         [ 0.1273,  0.3672,  0.2691,  ...,  0.3784, -0.2863, -0.1839],\n",
            "         [ 0.3229,  0.2730,  0.2114,  ...,  0.0329, -0.1782, -0.1965]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2841, -0.2102,  0.5725,  ...,  0.1294, -0.6609, -0.6011],\n",
            "        [ 0.3409,  0.6655, -0.0939,  ...,  0.4817, -0.0194, -0.3423],\n",
            "        [ 0.1484, -0.2816,  0.3332,  ...,  0.0387, -0.4649, -0.3262],\n",
            "        ...,\n",
            "        [ 0.2592, -0.3576,  0.5218,  ...,  0.2054, -0.5346, -0.3064],\n",
            "        [ 0.4885,  0.5090,  0.5382,  ...,  0.5266, -0.5615, -0.6512],\n",
            "        [ 0.3721,  0.3396,  0.4448,  ...,  0.2417, -0.4460, -0.4754]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.2101, -0.0504, -0.0145,  ...,  0.1692, -0.1791, -0.0867],\n",
            "        [ 0.0418, -0.0679, -0.0549,  ..., -0.0869, -0.0844, -0.0100],\n",
            "        [ 0.0739,  0.1060,  0.0168,  ...,  0.0025, -0.0313, -0.0803],\n",
            "        ...,\n",
            "        [-0.2479,  0.1594,  0.0689,  ...,  0.0665, -0.3084, -0.1271],\n",
            "        [ 0.1794,  0.2118,  0.2231,  ..., -0.0709, -0.2045, -0.1253],\n",
            "        [-0.2479,  0.1594,  0.0689,  ...,  0.0665, -0.3084, -0.1271]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0465,  0.3036,  0.0693,  ...,  0.1390, -0.1894,  0.0334],\n",
            "         [ 0.0841, -0.1443, -0.0731,  ...,  0.0873, -0.2092, -0.1891],\n",
            "         [ 0.0254,  0.1035,  0.0356,  ...,  0.0721,  0.1263,  0.0162],\n",
            "         ...,\n",
            "         [ 0.0139,  0.0520, -0.2114,  ...,  0.0172,  0.1661,  0.3272],\n",
            "         [ 0.3573,  0.2244,  0.1391,  ...,  0.2220, -0.3833, -0.3373],\n",
            "         [ 0.0738, -0.2492,  0.3331,  ...,  0.1349, -0.1288, -0.0977]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0991,  0.4087, -0.0691,  ...,  0.2903, -0.0488,  0.0138],\n",
            "        [ 0.1371, -0.2955,  0.3622,  ...,  0.1381, -0.5345, -0.4141],\n",
            "        [ 0.0100,  0.1104, -0.0751,  ...,  0.0652,  0.1390,  0.1193],\n",
            "        ...,\n",
            "        [-0.0772,  0.0312, -0.1095,  ..., -0.0395,  0.1536,  0.2665],\n",
            "        [ 0.4820,  0.1517,  0.5012,  ...,  0.4978, -0.5943, -0.6162],\n",
            "        [ 0.2525, -0.4369,  0.4635,  ...,  0.1132, -0.3690, -0.3223]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0545,  0.0754, -0.0137,  ..., -0.0373,  0.0150,  0.0672],\n",
            "        [-0.0545,  0.0754, -0.0137,  ..., -0.0373,  0.0150,  0.0672],\n",
            "        [-0.2100, -0.0506, -0.0144,  ...,  0.1693, -0.1792, -0.0869],\n",
            "        ...,\n",
            "        [-0.0796, -0.0572,  0.0708,  ..., -0.2110, -0.2363, -0.1020],\n",
            "        [ 0.2333,  0.0342,  0.1223,  ...,  0.2024, -0.0211, -0.1986],\n",
            "        [ 0.2211,  0.1568,  0.3648,  ...,  0.4129, -0.0689, -0.1266]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1432, -0.0186,  0.2224,  ...,  0.2552, -0.2281, -0.2824],\n",
            "         [-0.4340, -0.0148,  0.0249,  ...,  0.1246,  0.1558,  0.3646],\n",
            "         [-0.2788,  0.3515,  0.0446,  ...,  0.2985, -0.4434, -0.1350],\n",
            "         ...,\n",
            "         [ 0.2333,  0.0342,  0.1223,  ...,  0.2024, -0.0211, -0.1986],\n",
            "         [ 0.2211,  0.1568,  0.3648,  ...,  0.4129, -0.0689, -0.1266],\n",
            "         [-0.1702,  0.5165,  0.0583,  ...,  0.4243, -0.3376, -0.1100]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2742, -0.3401,  0.5209,  ...,  0.2213, -0.5924, -0.4760],\n",
            "        [-0.4318,  0.0090, -0.0756,  ...,  0.0027,  0.1593,  0.3277],\n",
            "        [ 0.3681,  0.7789, -0.0958,  ...,  0.7157, -0.0730, -0.5303],\n",
            "        ...,\n",
            "        [ 0.2460, -0.3872,  0.5990,  ...,  0.0376, -0.5249, -0.4830],\n",
            "        [ 0.2530, -0.1565,  0.6203,  ...,  0.2699, -0.3834, -0.3568],\n",
            "        [ 0.4498,  0.8232, -0.1058,  ...,  0.7498,  0.0459, -0.4657]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0737, -0.0385, -0.0533,  ...,  0.0673, -0.1201, -0.0507],\n",
            "        [-0.0548,  0.0752, -0.0137,  ..., -0.0374,  0.0152,  0.0674],\n",
            "        [-0.0548,  0.0752, -0.0137,  ..., -0.0374,  0.0152,  0.0674],\n",
            "        ...,\n",
            "        [ 0.4060, -0.0339,  0.3429,  ...,  0.3684, -0.1470, -0.1929],\n",
            "        [ 0.3163, -0.1427,  0.2326,  ..., -0.0237, -0.1356, -0.0555],\n",
            "        [-0.0229, -0.2353, -0.1534,  ..., -0.0947, -0.0208,  0.1167]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.2710,  0.1162,  0.0276,  ...,  0.1653, -0.1707, -0.0632],\n",
            "         [ 0.3163, -0.1427,  0.2326,  ..., -0.0237, -0.1356, -0.0555],\n",
            "         [ 0.0257,  0.2977,  0.1974,  ...,  0.1232, -0.3595, -0.1051],\n",
            "         ...,\n",
            "         [ 0.4060, -0.0339,  0.3429,  ...,  0.3684, -0.1470, -0.1929],\n",
            "         [ 0.3163, -0.1427,  0.2326,  ..., -0.0237, -0.1356, -0.0555],\n",
            "         [-0.0229, -0.2353, -0.1534,  ..., -0.0947, -0.0208,  0.1167]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0584,  0.4742, -0.0872,  ...,  0.4003,  0.0837, -0.1441],\n",
            "        [ 0.1600, -0.4272,  0.5586,  ..., -0.0876, -0.5816, -0.3125],\n",
            "        [ 0.1791, -0.0628,  0.4906,  ...,  0.1081, -0.5941, -0.4326],\n",
            "        ...,\n",
            "        [ 0.3685, -0.2842,  0.5581,  ...,  0.2101, -0.5087, -0.3798],\n",
            "        [ 0.1600, -0.4272,  0.5586,  ..., -0.0876, -0.5816, -0.3125],\n",
            "        [-0.1505, -0.0864, -0.0930,  ..., -0.1591,  0.0625,  0.1501]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2834, -0.0417,  0.1171,  ...,  0.3393, -0.1445, -0.1441],\n",
            "        [-0.1568,  0.0613,  0.0009,  ...,  0.1471, -0.0659, -0.0511],\n",
            "        [-0.0007, -0.0926,  0.0045,  ..., -0.0646, -0.1119,  0.0682],\n",
            "        ...,\n",
            "        [-0.1609,  0.3031,  0.0251,  ...,  0.1626, -0.1202, -0.1909],\n",
            "        [ 0.3252, -0.1034,  0.3212,  ...,  0.0817, -0.2946, -0.1354],\n",
            "        [ 0.0728,  0.1516, -0.0655,  ..., -0.0060, -0.1640, -0.3777]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-2.8127e-01,  4.5698e-01, -4.9661e-02,  ...,  1.8223e-01,\n",
            "          -1.0900e-01, -1.5983e-01],\n",
            "         [-1.4888e-01, -2.9908e-01,  1.0616e-01,  ..., -8.8382e-02,\n",
            "           1.5431e-01,  3.8772e-04],\n",
            "         [ 1.1618e-01, -1.2241e-01,  4.0090e-01,  ...,  1.5032e-01,\n",
            "          -1.2281e-01, -9.9528e-02],\n",
            "         ...,\n",
            "         [ 4.5241e-02, -8.0616e-02, -1.1529e-01,  ...,  4.0257e-02,\n",
            "          -2.2251e-01, -1.4824e-01],\n",
            "         [ 1.0679e-01,  4.8749e-02,  1.6555e-01,  ...,  1.6211e-01,\n",
            "          -8.7677e-02, -2.6871e-01],\n",
            "         [ 3.3776e-01, -1.8249e-01, -7.6245e-02,  ...,  9.3675e-02,\n",
            "          -4.8104e-02, -2.6001e-01]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1058,  0.5576, -0.1139,  ...,  0.4186, -0.0582, -0.2598],\n",
            "        [-0.3385, -0.0745, -0.0729,  ..., -0.1599,  0.1774,  0.1693],\n",
            "        [ 0.1376, -0.1959,  0.4317,  ...,  0.0602, -0.2915, -0.2026],\n",
            "        ...,\n",
            "        [ 0.1048, -0.1813,  0.1709,  ...,  0.0573, -0.3405, -0.2761],\n",
            "        [ 0.0634, -0.0825,  0.2514,  ...,  0.0813, -0.2278, -0.2632],\n",
            "        [ 0.3674, -0.3406,  0.3854,  ...,  0.0014, -0.4980, -0.5040]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0301,  0.0414,  0.0737,  ...,  0.1523,  0.0118, -0.1378],\n",
            "        [ 0.2834, -0.0425,  0.1175,  ...,  0.3394, -0.1448, -0.1448],\n",
            "        [-0.0552,  0.0748, -0.0138,  ..., -0.0375,  0.0155,  0.0674],\n",
            "        ...,\n",
            "        [ 0.1669, -0.2153,  0.3341,  ...,  0.0772, -0.3129, -0.1425],\n",
            "        [ 0.3075, -0.1927,  0.0551,  ..., -0.0066, -0.0793, -0.1924],\n",
            "        [ 0.0734, -0.2035,  0.0267,  ..., -0.0202, -0.2823, -0.2161]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0569,  0.0775,  0.0592,  ..., -0.1015,  0.2743,  0.2182],\n",
            "         [ 0.2034,  0.0601,  0.3197,  ...,  0.1232, -0.2305, -0.1244],\n",
            "         [ 0.3075, -0.1927,  0.0551,  ..., -0.0066, -0.0793, -0.1924],\n",
            "         ...,\n",
            "         [ 0.1669, -0.2153,  0.3341,  ...,  0.0772, -0.3129, -0.1425],\n",
            "         [ 0.3075, -0.1927,  0.0551,  ..., -0.0066, -0.0793, -0.1924],\n",
            "         [ 0.0734, -0.2035,  0.0267,  ..., -0.0202, -0.2823, -0.2161]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0338, -0.0656,  0.2105,  ..., -0.1068,  0.0160,  0.0606],\n",
            "        [ 0.3170, -0.0797,  0.5971,  ...,  0.1681, -0.5778, -0.4219],\n",
            "        [ 0.0961, -0.3795,  0.4424,  ..., -0.0542, -0.4895, -0.3823],\n",
            "        ...,\n",
            "        [ 0.0117, -0.3892,  0.4438,  ..., -0.0251, -0.5026, -0.3113],\n",
            "        [ 0.0961, -0.3795,  0.4424,  ..., -0.0542, -0.4895, -0.3823],\n",
            "        [ 0.0650, -0.3069,  0.3038,  ..., -0.0612, -0.3966, -0.3282]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0553,  0.0746, -0.0139,  ..., -0.0375,  0.0156,  0.0674],\n",
            "        [-0.0553,  0.0746, -0.0139,  ..., -0.0375,  0.0156,  0.0674],\n",
            "        [-0.0553,  0.0746, -0.0139,  ..., -0.0375,  0.0156,  0.0674],\n",
            "        ...,\n",
            "        [ 0.4181, -0.5488,  0.1179,  ...,  0.2123, -0.0820, -0.3604],\n",
            "        [ 0.4181, -0.5488,  0.1179,  ...,  0.2123, -0.0820, -0.3604],\n",
            "        [ 0.4181, -0.5488,  0.1179,  ...,  0.2123, -0.0820, -0.3604]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.4181, -0.5488,  0.1179,  ...,  0.2123, -0.0820, -0.3604],\n",
            "         [ 0.4181, -0.5488,  0.1179,  ...,  0.2123, -0.0820, -0.3604],\n",
            "         [ 0.4181, -0.5488,  0.1179,  ...,  0.2123, -0.0820, -0.3604],\n",
            "         ...,\n",
            "         [ 0.2479,  0.1172,  0.2776,  ...,  0.1761, -0.1025, -0.1715],\n",
            "         [-0.1189,  0.0550,  0.1030,  ..., -0.0051,  0.0727,  0.1805],\n",
            "         [ 0.2541,  0.1151,  0.1393,  ...,  0.0710, -0.3695, -0.1905]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3307, -0.7061,  0.6272,  ..., -0.0202, -0.6090, -0.6225],\n",
            "        [ 0.3307, -0.7061,  0.6272,  ..., -0.0202, -0.6090, -0.6225],\n",
            "        [ 0.3307, -0.7061,  0.6272,  ..., -0.0202, -0.6090, -0.6225],\n",
            "        ...,\n",
            "        [ 0.1610, -0.3188,  0.6666,  ...,  0.0194, -0.5557, -0.3887],\n",
            "        [-0.1525,  0.0520,  0.0098,  ..., -0.0594,  0.1254,  0.1873],\n",
            "        [ 0.2666, -0.0661,  0.3558,  ...,  0.1504, -0.5323, -0.3813]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0963,  0.0603,  0.3133,  ..., -0.1030, -0.0352, -0.1118],\n",
            "        [-0.0555,  0.0745, -0.0140,  ..., -0.0375,  0.0157,  0.0673],\n",
            "        [-0.0555,  0.0745, -0.0140,  ..., -0.0375,  0.0157,  0.0673],\n",
            "        ...,\n",
            "        [ 0.0855,  0.0489,  0.2371,  ...,  0.2791, -0.2117, -0.1130],\n",
            "        [-0.1420, -0.1639,  0.0089,  ...,  0.1863, -0.1127,  0.0511],\n",
            "        [ 0.2084, -0.3211,  0.1435,  ...,  0.1150, -0.2670, -0.1964]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1281,  0.0807, -0.0155,  ..., -0.0925, -0.0888,  0.0158],\n",
            "         [ 0.2475, -0.2252,  0.0501,  ...,  0.0065, -0.0081, -0.0388],\n",
            "         [ 0.1646, -0.1885, -0.0671,  ...,  0.1808, -0.3092, -0.2326],\n",
            "         ...,\n",
            "         [-0.0641,  0.1707,  0.0023,  ...,  0.0878, -0.1588,  0.0013],\n",
            "         [ 0.0242, -0.0331,  0.0338,  ..., -0.1066,  0.0931,  0.0876],\n",
            "         [ 0.1804,  0.0929, -0.0198,  ...,  0.4770, -0.2278, -0.0750]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0056, -0.0391,  0.2094,  ..., -0.0333, -0.2839, -0.1400],\n",
            "        [ 0.0473, -0.3311,  0.4397,  ..., -0.0818, -0.4043, -0.1541],\n",
            "        [ 0.1395, -0.4623,  0.4176,  ...,  0.1469, -0.5885, -0.4715],\n",
            "        ...,\n",
            "        [ 0.3106,  0.5108, -0.1429,  ...,  0.3757, -0.0009, -0.1757],\n",
            "        [-0.0217, -0.1509,  0.2903,  ..., -0.1425, -0.1841, -0.0554],\n",
            "        [ 0.3543,  0.3953, -0.0892,  ...,  0.5196, -0.0118, -0.1110]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0557,  0.0743, -0.0140,  ..., -0.0374,  0.0158,  0.0672],\n",
            "        [-0.0557,  0.0743, -0.0140,  ..., -0.0374,  0.0158,  0.0672],\n",
            "        [-0.0557,  0.0743, -0.0140,  ..., -0.0374,  0.0158,  0.0672],\n",
            "        ...,\n",
            "        [-0.0549,  0.2726,  0.0396,  ...,  0.1447, -0.2529, -0.1136],\n",
            "        [ 0.1110,  0.6379,  0.0854,  ...,  0.0366,  0.0197, -0.1472],\n",
            "        [-0.1708,  0.1598,  0.1376,  ...,  0.0327, -0.2982, -0.1258]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1708,  0.1598,  0.1376,  ...,  0.0327, -0.2982, -0.1258],\n",
            "         [ 0.1110,  0.6379,  0.0854,  ...,  0.0366,  0.0197, -0.1472],\n",
            "         [ 0.4208, -0.5644,  0.1223,  ...,  0.2098, -0.0841, -0.3658],\n",
            "         ...,\n",
            "         [ 0.4208, -0.5644,  0.1223,  ...,  0.2098, -0.0841, -0.3658],\n",
            "         [ 0.4208, -0.5644,  0.1223,  ...,  0.2098, -0.0841, -0.3658],\n",
            "         [ 0.4208, -0.5644,  0.1223,  ...,  0.2098, -0.0841, -0.3658]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.1351, -0.2422,  0.4887,  ..., -0.0670, -0.5363, -0.4282],\n",
            "        [ 0.5080,  0.7567, -0.1056,  ...,  0.4950,  0.0428, -0.3835],\n",
            "        [ 0.3243, -0.7213,  0.6399,  ..., -0.0310, -0.6181, -0.6252],\n",
            "        ...,\n",
            "        [ 0.3243, -0.7213,  0.6399,  ..., -0.0310, -0.6181, -0.6252],\n",
            "        [ 0.3243, -0.7213,  0.6399,  ..., -0.0310, -0.6181, -0.6252],\n",
            "        [ 0.3243, -0.7213,  0.6399,  ..., -0.0310, -0.6181, -0.6252]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0944,  0.0575,  0.0491,  ...,  0.0953, -0.0364,  0.0155],\n",
            "        [ 0.2225,  0.0277,  0.0006,  ...,  0.1850,  0.0528,  0.0909],\n",
            "        [ 0.0720, -0.0373, -0.0542,  ...,  0.0676, -0.1208, -0.0506],\n",
            "        ...,\n",
            "        [-0.0472, -0.1818, -0.2005,  ..., -0.0098, -0.1153, -0.0068],\n",
            "        [ 0.0892, -0.1906, -0.0196,  ..., -0.1309,  0.0656, -0.0260],\n",
            "        [ 0.1477, -0.0896,  0.1530,  ..., -0.0124, -0.1811, -0.1187]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0472, -0.1818, -0.2005,  ..., -0.0098, -0.1153, -0.0068],\n",
            "         [ 0.0892, -0.1906, -0.0196,  ..., -0.1309,  0.0656, -0.0260],\n",
            "         [ 0.1477, -0.0896,  0.1530,  ..., -0.0124, -0.1811, -0.1187],\n",
            "         ...,\n",
            "         [ 0.0780, -0.0273, -0.1209,  ...,  0.0514, -0.0759, -0.0939],\n",
            "         [-0.1025,  0.0881,  0.1446,  ..., -0.0147,  0.2652,  0.1006],\n",
            "         [-0.0016, -0.1344, -0.0782,  ..., -0.1113,  0.1152, -0.1285]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0306, -0.2020,  0.0636,  ..., -0.0239, -0.3004, -0.1410],\n",
            "        [-0.0035, -0.0579, -0.0344,  ..., -0.0930,  0.0979,  0.0435],\n",
            "        [-0.0121, -0.2393,  0.4176,  ..., -0.0701, -0.3464, -0.1904],\n",
            "        ...,\n",
            "        [ 0.0556, -0.0384,  0.0161,  ...,  0.0160, -0.1139, -0.1234],\n",
            "        [-0.0507,  0.0533,  0.0696,  ..., -0.0020,  0.1026,  0.0292],\n",
            "        [-0.0119, -0.1042,  0.0360,  ..., -0.0768,  0.0375,  0.0199]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 1.9177e-02,  1.8447e-01, -4.0447e-02,  ..., -3.2937e-02,\n",
            "          2.3615e-02, -4.0646e-02],\n",
            "        [-5.5902e-02,  7.3964e-02, -1.3990e-02,  ..., -3.7309e-02,\n",
            "          1.6044e-02,  6.7004e-02],\n",
            "        [-6.0974e-02,  3.7621e-02, -6.5565e-02,  ..., -1.0340e-02,\n",
            "         -1.7832e-01, -4.4134e-03],\n",
            "        ...,\n",
            "        [ 2.7396e-01, -4.2841e-01,  6.8442e-02,  ..., -2.4136e-04,\n",
            "         -2.9142e-02,  1.2907e-02],\n",
            "        [-2.1591e-01,  3.0640e-01,  1.6576e-01,  ..., -3.0507e-02,\n",
            "         -5.9743e-02,  2.0760e-01],\n",
            "        [ 5.3943e-02,  1.9183e-02, -1.5308e-01,  ...,  2.2038e-01,\n",
            "         -1.9322e-01, -1.6701e-01]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 1.2182e-01, -1.5111e-01, -8.9289e-02,  ...,  6.2012e-03,\n",
            "           4.9512e-02,  1.1778e-01],\n",
            "         [ 4.7582e-02,  1.8540e-01,  2.0019e-01,  ...,  1.0622e-01,\n",
            "          -1.2581e-01, -6.8266e-02],\n",
            "         [ 4.6959e-02,  2.6186e-01,  2.0327e-01,  ...,  1.0320e-01,\n",
            "          -3.5974e-01, -1.0718e-01],\n",
            "         ...,\n",
            "         [ 2.7396e-01, -4.2841e-01,  6.8442e-02,  ..., -2.4136e-04,\n",
            "          -2.9142e-02,  1.2907e-02],\n",
            "         [-2.1591e-01,  3.0640e-01,  1.6576e-01,  ..., -3.0507e-02,\n",
            "          -5.9743e-02,  2.0760e-01],\n",
            "         [ 5.3943e-02,  1.9183e-02, -1.5308e-01,  ...,  2.2038e-01,\n",
            "          -1.9322e-01, -1.6701e-01]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0354, -0.0503, -0.0707,  ..., -0.0220,  0.0989,  0.1301],\n",
            "        [ 0.1504, -0.1580,  0.5277,  ...,  0.1047, -0.4701, -0.3374],\n",
            "        [ 0.1513, -0.1963,  0.5400,  ...,  0.0383, -0.6333, -0.4276],\n",
            "        ...,\n",
            "        [ 0.0521, -0.3837,  0.4039,  ..., -0.1323, -0.3830, -0.1698],\n",
            "        [-0.0838,  0.4565, -0.0461,  ...,  0.2028,  0.0689,  0.2772],\n",
            "        [ 0.1836,  0.3131, -0.1068,  ...,  0.3677,  0.0159, -0.2297]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0559,  0.0739, -0.0139,  ..., -0.0372,  0.0162,  0.0668],\n",
            "        [-0.2101, -0.0518, -0.0135,  ...,  0.1720, -0.1800, -0.0890],\n",
            "        [-0.0559,  0.0739, -0.0139,  ..., -0.0372,  0.0162,  0.0668],\n",
            "        ...,\n",
            "        [ 0.4331, -0.0283, -0.0876,  ...,  0.1481, -0.1629, -0.2676],\n",
            "        [-0.1489, -0.1641,  0.1245,  ...,  0.0204, -0.1847, -0.0211],\n",
            "        [ 0.2312, -0.1682,  0.1246,  ..., -0.1158, -0.1756, -0.0702]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.4331, -0.0283, -0.0876,  ...,  0.1481, -0.1629, -0.2676],\n",
            "         [-0.1489, -0.1641,  0.1245,  ...,  0.0204, -0.1847, -0.0211],\n",
            "         [ 0.2312, -0.1682,  0.1246,  ..., -0.1158, -0.1756, -0.0702],\n",
            "         ...,\n",
            "         [-0.0796,  0.1911,  0.3695,  ...,  0.3302, -0.4005, -0.3671],\n",
            "         [ 0.3156, -0.4353,  0.3672,  ...,  0.0025, -0.2925, -0.1493],\n",
            "         [ 0.2154,  0.1351,  0.1344,  ...,  0.5275, -0.1811, -0.2068]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1863, -0.0536,  0.1423,  ...,  0.1471, -0.3748, -0.3248],\n",
            "        [ 0.1043, -0.1507,  0.2738,  ...,  0.0420, -0.2972, -0.3151],\n",
            "        [ 0.1034, -0.3460,  0.4443,  ..., -0.1556, -0.4122, -0.2320],\n",
            "        ...,\n",
            "        [ 0.2036,  0.1355,  0.4761,  ...,  0.3990, -0.5389, -0.4689],\n",
            "        [ 0.1054, -0.6428,  0.6294,  ..., -0.0954, -0.6314, -0.3921],\n",
            "        [ 0.4521,  0.4519, -0.0036,  ...,  0.6071, -0.1474, -0.3121]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0723, -0.0353, -0.0529,  ...,  0.0685, -0.1221, -0.0517],\n",
            "        [ 0.2390, -0.1108,  0.0772,  ..., -0.0107, -0.0520, -0.0780],\n",
            "        [-0.0560,  0.0738, -0.0138,  ..., -0.0371,  0.0163,  0.0665],\n",
            "        ...,\n",
            "        [ 0.3870,  0.0138, -0.1516,  ..., -0.1237, -0.2409, -0.1078],\n",
            "        [-0.1153, -0.1093,  0.0401,  ...,  0.0383,  0.1563,  0.4432],\n",
            "        [ 0.0927, -0.0107, -0.1291,  ..., -0.1097,  0.0127, -0.0702]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1157,  0.0187, -0.0666,  ...,  0.3450,  0.0746, -0.2108],\n",
            "         [ 0.1098, -0.3852,  0.1491,  ..., -0.1505, -0.2399, -0.1254],\n",
            "         [-0.1049,  0.8688,  0.0273,  ...,  0.4323, -0.0766, -0.0443],\n",
            "         ...,\n",
            "         [ 0.0660,  0.2388,  0.2020,  ..., -0.2211,  0.0280, -0.0356],\n",
            "         [-0.1115,  0.4426,  0.0043,  ...,  0.0427, -0.2318, -0.1555],\n",
            "         [ 0.1444, -0.2158, -0.0873,  ..., -0.0566, -0.0985, -0.1951]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1083,  0.2189, -0.1308,  ...,  0.3543,  0.1252, -0.1426],\n",
            "        [ 0.0483, -0.5481,  0.5401,  ..., -0.2045, -0.5650, -0.3577],\n",
            "        [ 0.4391,  0.9030, -0.0907,  ...,  0.7379, -0.0594, -0.4183],\n",
            "        ...,\n",
            "        [ 0.0490, -0.0519,  0.5138,  ..., -0.0928, -0.3506, -0.2033],\n",
            "        [ 0.4204,  0.6542, -0.1319,  ...,  0.5115, -0.0567, -0.3524],\n",
            "        [ 0.0530, -0.3904,  0.3578,  ..., -0.1433, -0.4670, -0.2852]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1195, -0.0549, -0.1087,  ..., -0.0704,  0.0511, -0.1796],\n",
            "        [ 0.0198, -0.1506, -0.0677,  ..., -0.0447, -0.2331, -0.0616],\n",
            "        [ 0.1195, -0.0549, -0.1087,  ..., -0.0704,  0.0511, -0.1796],\n",
            "        ...,\n",
            "        [ 0.1365,  0.3209,  0.1122,  ..., -0.1155, -0.1313, -0.2874],\n",
            "        [ 0.2284, -0.4208,  0.1988,  ..., -0.0552, -0.3034, -0.1345],\n",
            "        [ 0.0011, -0.2427,  0.2069,  ...,  0.0594, -0.2148, -0.0537]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2284, -0.4208,  0.1988,  ..., -0.0552, -0.3034, -0.1345],\n",
            "         [-0.0080, -0.1400,  0.1680,  ...,  0.0084, -0.0865, -0.0364],\n",
            "         [ 0.2284, -0.4208,  0.1988,  ..., -0.0552, -0.3034, -0.1345],\n",
            "         ...,\n",
            "         [ 0.1223, -0.1307, -0.1035,  ...,  0.0110, -0.2561, -0.2022],\n",
            "         [ 0.1037,  0.1924, -0.0897,  ...,  0.2504, -0.2504,  0.1310],\n",
            "         [-0.0568, -0.0446,  0.1014,  ..., -0.0771, -0.2728, -0.2995]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0249, -0.6279,  0.7137,  ..., -0.1862, -0.7626, -0.4394],\n",
            "        [ 0.1859,  0.0506,  0.0940,  ...,  0.1181, -0.1269, -0.1651],\n",
            "        [ 0.0249, -0.6279,  0.7137,  ..., -0.1862, -0.7626, -0.4394],\n",
            "        ...,\n",
            "        [ 0.1114, -0.3807,  0.3443,  ..., -0.0237, -0.4997, -0.3454],\n",
            "        [ 0.3590,  0.4357, -0.0676,  ...,  0.4487, -0.0919, -0.1270],\n",
            "        [ 0.0479, -0.3723,  0.5376,  ..., -0.0580, -0.5768, -0.4281]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0562,  0.0738, -0.0136,  ..., -0.0370,  0.0164,  0.0661],\n",
            "        [-0.0562,  0.0738, -0.0136,  ..., -0.0370,  0.0164,  0.0661],\n",
            "        [-0.0562,  0.0738, -0.0136,  ..., -0.0370,  0.0164,  0.0661],\n",
            "        ...,\n",
            "        [ 0.4267, -0.6116,  0.1286,  ...,  0.2258, -0.0901, -0.3939],\n",
            "        [ 0.4267, -0.6116,  0.1286,  ...,  0.2258, -0.0901, -0.3939],\n",
            "        [ 0.4267, -0.6116,  0.1286,  ...,  0.2258, -0.0901, -0.3939]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.4267, -0.6116,  0.1286,  ...,  0.2258, -0.0901, -0.3939],\n",
            "         [ 0.0779, -0.3133, -0.0221,  ...,  0.1094, -0.1501, -0.0647],\n",
            "         [ 0.4267, -0.6116,  0.1286,  ...,  0.2258, -0.0901, -0.3939],\n",
            "         ...,\n",
            "         [ 0.4267, -0.6116,  0.1286,  ...,  0.2258, -0.0901, -0.3939],\n",
            "         [ 0.4267, -0.6116,  0.1286,  ...,  0.2258, -0.0901, -0.3939],\n",
            "         [ 0.4267, -0.6116,  0.1286,  ...,  0.2258, -0.0901, -0.3939]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3076, -0.7643,  0.6765,  ..., -0.0539, -0.6501, -0.6400],\n",
            "        [-0.1060, -0.3754,  0.2983,  ..., -0.0236, -0.4083, -0.1373],\n",
            "        [ 0.3076, -0.7643,  0.6765,  ..., -0.0539, -0.6501, -0.6400],\n",
            "        ...,\n",
            "        [ 0.3076, -0.7643,  0.6765,  ..., -0.0539, -0.6501, -0.6400],\n",
            "        [ 0.3076, -0.7643,  0.6765,  ..., -0.0539, -0.6501, -0.6400],\n",
            "        [ 0.3076, -0.7643,  0.6765,  ..., -0.0539, -0.6501, -0.6400]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0563,  0.0738, -0.0135,  ..., -0.0369,  0.0164,  0.0659],\n",
            "        [-0.0563,  0.0738, -0.0135,  ..., -0.0369,  0.0164,  0.0659],\n",
            "        [-0.0563,  0.0738, -0.0135,  ..., -0.0369,  0.0164,  0.0659],\n",
            "        ...,\n",
            "        [ 0.0496,  0.2049,  0.0346,  ...,  0.0884, -0.2813, -0.0969],\n",
            "        [-0.0091, -0.1204,  0.0941,  ...,  0.0532, -0.2590, -0.1414],\n",
            "        [ 0.3764, -0.2659, -0.0691,  ...,  0.0087, -0.1461, -0.1209]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0461, -0.1033, -0.0347,  ..., -0.0335, -0.0285, -0.0512],\n",
            "         [ 0.0496,  0.2049,  0.0346,  ...,  0.0884, -0.2813, -0.0969],\n",
            "         [-0.0091, -0.1204,  0.0941,  ...,  0.0532, -0.2590, -0.1414],\n",
            "         ...,\n",
            "         [ 0.2898, -0.4378,  0.2034,  ...,  0.0680, -0.2265, -0.2014],\n",
            "         [-0.2590,  0.3412,  0.0713,  ...,  0.3073, -0.4712, -0.1752],\n",
            "         [ 0.0976, -0.1656,  0.3434,  ...,  0.1991, -0.0110, -0.1490]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.1609, -0.0042, -0.0384,  ..., -0.0430, -0.0064,  0.0176],\n",
            "        [-0.0391, -0.1174,  0.3270,  ..., -0.0132, -0.4950, -0.2439],\n",
            "        [ 0.1986, -0.5223,  0.5329,  ..., -0.0033, -0.5963, -0.4844],\n",
            "        ...,\n",
            "        [ 0.1314, -0.5967,  0.6505,  ..., -0.0293, -0.6424, -0.4238],\n",
            "        [ 0.4150,  0.7910, -0.0111,  ...,  0.7338, -0.2747, -0.6137],\n",
            "        [ 0.0066, -0.4337,  0.6071,  ..., -0.0093, -0.3987, -0.2870]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0562,  0.0738, -0.0134,  ..., -0.0369,  0.0165,  0.0657],\n",
            "        [-0.0562,  0.0738, -0.0134,  ..., -0.0369,  0.0165,  0.0657],\n",
            "        [-0.0056,  0.0515,  0.0731,  ...,  0.1709, -0.0480, -0.1310],\n",
            "        ...,\n",
            "        [ 0.3019,  0.1569,  0.2123,  ...,  0.3045, -0.0593,  0.0131],\n",
            "        [ 0.1580,  0.1809,  0.0425,  ...,  0.3348, -0.1458, -0.2415],\n",
            "        [-0.2517,  0.3169,  0.0738,  ...,  0.2942, -0.4705, -0.1772]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1580,  0.1809,  0.0425,  ...,  0.3348, -0.1458, -0.2415],\n",
            "         [-0.2517,  0.3169,  0.0738,  ...,  0.2942, -0.4705, -0.1772],\n",
            "         [ 0.1582, -0.2700, -0.0621,  ...,  0.1311, -0.1356, -0.0765],\n",
            "         ...,\n",
            "         [-0.2665,  0.4026,  0.0185,  ...,  0.1942, -0.1839, -0.0611],\n",
            "         [ 0.0730,  0.3580,  0.0197,  ...,  0.1914, -0.0264, -0.0728],\n",
            "         [ 0.2868,  0.1903,  0.0558,  ...,  0.1969, -0.0979, -0.1744]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4467,  0.4527,  0.0816,  ...,  0.4122, -0.2281, -0.4075],\n",
            "        [ 0.4112,  0.7732,  0.0226,  ...,  0.7193, -0.3124, -0.6124],\n",
            "        [-0.0818, -0.3524,  0.2531,  ..., -0.0232, -0.4148, -0.1351],\n",
            "        ...,\n",
            "        [ 0.2513,  0.7363, -0.1263,  ...,  0.6427,  0.0769, -0.2310],\n",
            "        [ 0.1415,  0.0275,  0.4216,  ...,  0.1196, -0.4198, -0.3048],\n",
            "        [ 0.1773, -0.0678,  0.4006,  ...,  0.0446, -0.4073, -0.3136]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.1046, -0.0584, -0.0549,  ..., -0.1059, -0.1884, -0.0676],\n",
            "        [ 0.0734, -0.0326, -0.0509,  ...,  0.0685, -0.1219, -0.0516],\n",
            "        [-0.0562,  0.0738, -0.0132,  ..., -0.0368,  0.0165,  0.0656],\n",
            "        ...,\n",
            "        [-0.1118,  0.0058,  0.0963,  ..., -0.0164, -0.1887, -0.0765],\n",
            "        [ 0.3762, -0.1107,  0.2395,  ...,  0.2228, -0.3483, -0.1107],\n",
            "        [ 0.2754, -0.1705,  0.4365,  ..., -0.0201, -0.2284, -0.3293]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0813,  0.4662,  0.1523,  ...,  0.0581, -0.0376,  0.0874],\n",
            "         [ 0.3539, -0.1923,  0.0414,  ...,  0.2784, -0.2656, -0.2644],\n",
            "         [ 0.1579, -0.1681, -0.1028,  ...,  0.0006, -0.2747, -0.2396],\n",
            "         ...,\n",
            "         [-0.1118,  0.0058,  0.0963,  ..., -0.0164, -0.1887, -0.0765],\n",
            "         [ 0.3762, -0.1107,  0.2395,  ...,  0.2228, -0.3483, -0.1107],\n",
            "         [ 0.2754, -0.1705,  0.4365,  ..., -0.0201, -0.2284, -0.3293]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4132,  0.5786,  0.2607,  ...,  0.4351, -0.2651, -0.2441],\n",
            "        [ 0.1284, -0.4174,  0.4827,  ...,  0.0633, -0.6024, -0.3950],\n",
            "        [ 0.1092, -0.4634,  0.4112,  ..., -0.0617, -0.5661, -0.3723],\n",
            "        ...,\n",
            "        [-0.0439,  0.1380, -0.0584,  ...,  0.0971,  0.0675, -0.1020],\n",
            "        [ 0.2549, -0.4016,  0.5562,  ...,  0.2110, -0.5583, -0.3223],\n",
            "        [ 0.3348, -0.4626,  0.6113,  ..., -0.0009, -0.5747, -0.5070]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.1583,  0.2135, -0.0152,  ..., -0.0265, -0.0172,  0.0159],\n",
            "        [-0.0555,  0.0741, -0.0131,  ..., -0.0369,  0.0166,  0.0660],\n",
            "        [ 0.0063,  0.1384,  0.0247,  ..., -0.1100, -0.0226, -0.1198],\n",
            "        ...,\n",
            "        [ 0.3158, -0.2249,  0.0487,  ...,  0.0224, -0.0893, -0.2305],\n",
            "        [ 0.0975,  0.3010,  0.1802,  ...,  0.5585, -0.3015, -0.1269],\n",
            "        [-0.2331,  0.0735,  0.0201,  ..., -0.0201, -0.1093, -0.0829]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1320, -0.0733, -0.0653,  ...,  0.0693, -0.0085, -0.2978],\n",
            "         [ 0.3158, -0.2249,  0.0487,  ...,  0.0224, -0.0893, -0.2305],\n",
            "         [ 0.0975,  0.3010,  0.1802,  ...,  0.5585, -0.3015, -0.1269],\n",
            "         ...,\n",
            "         [ 0.1642, -0.2175, -0.0292,  ...,  0.0486, -0.0213, -0.0450],\n",
            "         [-0.1207,  0.3262, -0.0748,  ...,  0.3644,  0.0253, -0.0417],\n",
            "         [ 0.2846, -0.1840,  0.2985,  ...,  0.1453, -0.2900, -0.1454]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1912, -0.2879,  0.3761,  ...,  0.0328, -0.4600, -0.4983],\n",
            "        [ 0.1154, -0.4517,  0.4800,  ..., -0.0526, -0.5326, -0.4221],\n",
            "        [ 0.5932,  0.7450,  0.0822,  ...,  0.7953, -0.2002, -0.5914],\n",
            "        ...,\n",
            "        [ 0.0488, -0.4173,  0.3941,  ..., -0.0541, -0.4051, -0.2669],\n",
            "        [ 0.1704,  0.5385, -0.1463,  ...,  0.4800,  0.0768, -0.1477],\n",
            "        [ 0.1536, -0.3342,  0.3632,  ...,  0.0904, -0.4735, -0.3417]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2896, -0.0488,  0.1387,  ...,  0.3448, -0.1459, -0.1488],\n",
            "        [-0.0951,  0.0690,  0.0017,  ...,  0.0420, -0.0561, -0.0210],\n",
            "        [ 0.2896, -0.0488,  0.1387,  ...,  0.3448, -0.1459, -0.1488],\n",
            "        ...,\n",
            "        [-0.0148, -0.2035, -0.0427,  ..., -0.0901, -0.0147, -0.2208],\n",
            "        [-0.1151,  0.0866,  0.2233,  ...,  0.0245, -0.3443, -0.1620],\n",
            "        [ 0.1475, -0.2172, -0.1513,  ...,  0.4079, -0.0921, -0.3225]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0148, -0.2035, -0.0427,  ..., -0.0901, -0.0147, -0.2208],\n",
            "         [-0.1151,  0.0866,  0.2233,  ...,  0.0245, -0.3443, -0.1620],\n",
            "         [ 0.1475, -0.2172, -0.1513,  ...,  0.4079, -0.0921, -0.3225],\n",
            "         ...,\n",
            "         [ 0.0467, -0.0424,  0.0023,  ...,  0.1970, -0.1705, -0.0235],\n",
            "         [ 0.2178,  0.0114,  0.2761,  ...,  0.1162, -0.1225, -0.1914],\n",
            "         [ 0.2718, -0.1786,  0.3349,  ...,  0.0759, -0.3039, -0.1632]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0193, -0.3246,  0.2446,  ..., -0.0935, -0.2499, -0.2763],\n",
            "        [ 0.2488,  0.2708,  0.2768,  ...,  0.2012, -0.3120, -0.4957],\n",
            "        [ 0.3012, -0.0453, -0.0171,  ...,  0.4073, -0.1313, -0.3957],\n",
            "        ...,\n",
            "        [-0.0047, -0.1292,  0.1899,  ...,  0.1600, -0.3299, -0.1253],\n",
            "        [ 0.1949, -0.2902,  0.5562,  ..., -0.0141, -0.4792, -0.3133],\n",
            "        [ 0.0388, -0.3786,  0.4978,  ..., -0.0236, -0.5259, -0.2917]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0895, -0.0156, -0.0919,  ...,  0.0392,  0.0499, -0.1054],\n",
            "        [-0.0544,  0.0744, -0.0128,  ..., -0.0371,  0.0168,  0.0666],\n",
            "        [ 0.0752, -0.0281, -0.0488,  ...,  0.0688, -0.1197, -0.0522],\n",
            "        ...,\n",
            "        [ 0.0506,  0.4432, -0.0784,  ...,  0.1455, -0.4448, -0.1075],\n",
            "        [ 0.2952, -0.1207,  0.1467,  ..., -0.1709, -0.3215, -0.1860],\n",
            "        [ 0.3160, -0.2895,  0.0081,  ...,  0.0156, -0.2143, -0.2277]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2884, -0.0280,  0.2836,  ...,  0.1341, -0.0757, -0.1967],\n",
            "         [-0.1740,  0.5385,  0.1149,  ...,  0.3057, -0.3742, -0.1380],\n",
            "         [-0.2392,  0.0223, -0.0393,  ...,  0.2291, -0.0906, -0.2277],\n",
            "         ...,\n",
            "         [-0.2788,  0.3938,  0.1375,  ...,  0.2254, -0.3914, -0.0749],\n",
            "         [ 0.2404, -0.1911, -0.2742,  ...,  0.0593, -0.3196, -0.3063],\n",
            "         [ 0.1310, -0.2158,  0.0895,  ..., -0.0280, -0.1815, -0.0278]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 2.6925e-01, -4.7658e-01,  7.0356e-01,  ..., -8.2792e-03,\n",
            "         -5.6928e-01, -4.3819e-01],\n",
            "        [ 4.7260e-01,  8.6510e-01, -9.2891e-02,  ...,  7.3681e-01,\n",
            "          3.8461e-03, -5.5428e-01],\n",
            "        [ 1.9800e-01,  3.8736e-01, -1.7345e-01,  ...,  4.7126e-01,\n",
            "          8.0941e-03, -3.3883e-01],\n",
            "        ...,\n",
            "        [ 3.5191e-01,  7.6162e-01, -9.1791e-02,  ...,  6.9325e-01,\n",
            "         -2.5754e-03, -4.2621e-01],\n",
            "        [ 3.1772e-02, -4.7807e-01,  3.7918e-01,  ..., -9.0291e-02,\n",
            "         -6.8202e-01, -3.9674e-01],\n",
            "        [-1.9817e-04, -4.2799e-01,  4.7784e-01,  ..., -1.3062e-01,\n",
            "         -5.8017e-01, -1.9982e-01]], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0241,  0.0215,  0.0523,  ...,  0.0502, -0.0757, -0.1521],\n",
            "        [-0.1369,  0.0882,  0.1057,  ...,  0.0178,  0.0616,  0.2232],\n",
            "        [ 0.2029,  0.1489, -0.0498,  ...,  0.0824,  0.0582, -0.0787],\n",
            "        ...,\n",
            "        [ 0.0915,  0.5321,  0.2348,  ...,  0.2163, -0.3213, -0.0088],\n",
            "        [ 0.1775, -0.1773, -0.0557,  ...,  0.0976,  0.0168, -0.1702],\n",
            "        [ 0.0093, -0.2536,  0.1614,  ...,  0.0127, -0.1825, -0.0395]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2710, -0.1723,  0.2759,  ...,  0.0397, -0.2827, -0.1194],\n",
            "         [ 0.3269, -0.3367,  0.2491,  ..., -0.1339, -0.0280, -0.0863],\n",
            "         [ 0.2402,  0.0349,  0.1339,  ..., -0.0853, -0.0754, -0.0991],\n",
            "         ...,\n",
            "         [ 0.4261, -0.2430,  0.6182,  ...,  0.2569, -0.0906,  0.0523],\n",
            "         [ 0.2253, -0.1074,  0.2446,  ..., -0.1276, -0.1170, -0.1603],\n",
            "         [ 0.1680, -0.2900,  0.1499,  ...,  0.0267, -0.1405,  0.0306]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0523, -0.3142,  0.3988,  ..., -0.0652, -0.4550, -0.1964],\n",
            "        [ 0.2208, -0.5191,  0.5926,  ..., -0.1428, -0.4701, -0.2749],\n",
            "        [ 0.2147, -0.2659,  0.5228,  ..., -0.1344, -0.4575, -0.3378],\n",
            "        ...,\n",
            "        [ 0.1886, -0.6406,  0.8117,  ...,  0.0643, -0.5753, -0.2695],\n",
            "        [ 0.1727, -0.4557,  0.6631,  ..., -0.1563, -0.6262, -0.3754],\n",
            "        [-0.0578, -0.3289,  0.4063,  ..., -0.0784, -0.3684, -0.1013]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.2043,  0.0011,  0.1017,  ..., -0.1007, -0.0009, -0.0544],\n",
            "        [ 0.1141,  0.1626, -0.0939,  ...,  0.1332, -0.0423, -0.0288],\n",
            "        [ 0.1026, -0.1161, -0.0794,  ...,  0.1156,  0.0166,  0.0115],\n",
            "        ...,\n",
            "        [ 0.3215, -0.2055,  0.2381,  ...,  0.0287,  0.0312, -0.2046],\n",
            "        [-0.0715,  0.3188,  0.1154,  ...,  0.0624, -0.1559, -0.1052],\n",
            "        [ 0.1754, -0.0213,  0.1254,  ..., -0.1067, -0.0625, -0.0578]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0715,  0.3188,  0.1154,  ...,  0.0624, -0.1559, -0.1052],\n",
            "         [ 0.1754, -0.0213,  0.1254,  ..., -0.1067, -0.0625, -0.0578],\n",
            "         [-0.2735, -0.0357,  0.0542,  ..., -0.2393,  0.0209, -0.0117],\n",
            "         ...,\n",
            "         [ 0.2218, -0.4454,  0.1795,  ..., -0.0504, -0.3079, -0.1455],\n",
            "         [ 0.1155, -0.2164, -0.1384,  ..., -0.0030,  0.0046, -0.2982],\n",
            "         [ 0.3215, -0.2055,  0.2381,  ...,  0.0287,  0.0312, -0.2046]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3581,  0.6054,  0.1187,  ...,  0.3801, -0.0962, -0.4575],\n",
            "        [ 0.1582, -0.3671,  0.5441,  ..., -0.1065, -0.4850, -0.2974],\n",
            "        [-0.5005,  0.0273, -0.0861,  ..., -0.2066,  0.1441,  0.2221],\n",
            "        ...,\n",
            "        [ 0.0340, -0.6232,  0.7143,  ..., -0.1670, -0.7721, -0.4190],\n",
            "        [ 0.1516, -0.3320,  0.2650,  ..., -0.0235, -0.3909, -0.4389],\n",
            "        [ 0.1810, -0.4923,  0.6943,  ..., -0.1006, -0.4793, -0.3354]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0537,  0.0743, -0.0132,  ..., -0.0383,  0.0166,  0.0679],\n",
            "        [-0.0537,  0.0743, -0.0132,  ..., -0.0383,  0.0166,  0.0679],\n",
            "        [ 0.2940, -0.0518,  0.1449,  ...,  0.3335, -0.1463, -0.1403],\n",
            "        ...,\n",
            "        [ 0.1658, -0.0237,  0.1580,  ...,  0.2771, -0.0632, -0.0480],\n",
            "        [ 0.0703,  0.1014,  0.0415,  ..., -0.0811,  0.0602,  0.0105],\n",
            "        [ 0.1971, -0.0703,  0.3031,  ...,  0.0660, -0.1924, -0.0129]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 1.9919e-02, -5.2270e-01,  1.7629e-01,  ..., -1.6682e-01,\n",
            "          -2.7774e-01, -1.6754e-01],\n",
            "         [-2.7849e-01,  3.7909e-01,  1.2737e-01,  ...,  2.0904e-01,\n",
            "          -3.8437e-01, -4.3060e-02],\n",
            "         [-1.3603e-01,  1.7255e-01, -9.8509e-02,  ..., -7.1033e-02,\n",
            "           4.2891e-04,  1.2077e-01],\n",
            "         ...,\n",
            "         [-3.5970e-03,  3.0121e-01, -2.2939e-01,  ...,  2.7864e-02,\n",
            "           2.5481e-02, -2.2069e-01],\n",
            "         [ 7.9719e-02, -4.1041e-01,  2.1029e-01,  ...,  8.3689e-02,\n",
            "          -2.6400e-01, -1.5484e-01],\n",
            "         [ 2.3663e-01, -1.3210e-01,  1.3862e-01,  ...,  1.8243e-01,\n",
            "          -8.5486e-02, -2.2646e-01]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-1.9961e-02, -7.1301e-01,  7.0463e-01,  ..., -2.4456e-01,\n",
            "         -7.3346e-01, -5.0538e-01],\n",
            "        [ 3.2199e-01,  7.3889e-01, -8.7219e-02,  ...,  6.7989e-01,\n",
            "         -6.1718e-04, -3.4225e-01],\n",
            "        [-2.3593e-01,  1.1756e-01, -1.2054e-01,  ..., -7.8223e-02,\n",
            "          9.7725e-02,  3.0033e-01],\n",
            "        ...,\n",
            "        [ 2.2439e-01,  4.8710e-01, -1.1160e-01,  ...,  2.6374e-01,\n",
            "          3.3903e-02, -2.7922e-01],\n",
            "        [ 1.0088e-01, -6.5501e-01,  5.8392e-01,  ..., -1.0848e-01,\n",
            "         -7.0986e-01, -3.9621e-01],\n",
            "        [ 3.1536e-01, -4.9947e-01,  5.9418e-01,  ...,  5.3843e-02,\n",
            "         -5.6990e-01, -4.3658e-01]], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0536,  0.0743, -0.0134,  ..., -0.0386,  0.0165,  0.0682],\n",
            "        [ 0.2945, -0.0526,  0.1458,  ...,  0.3304, -0.1464, -0.1379],\n",
            "        [ 0.2166,  0.0460,  0.0790,  ...,  0.0700, -0.0509, -0.2318],\n",
            "        ...,\n",
            "        [ 0.0918,  0.1155,  0.1460,  ..., -0.1000, -0.1520, -0.3246],\n",
            "        [ 0.0175,  0.0702,  0.0009,  ..., -0.0811,  0.1048,  0.0938],\n",
            "        [ 0.2913, -0.2255,  0.3328,  ..., -0.0152, -0.2946, -0.1429]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 1.7508e-02,  7.0169e-02,  9.0000e-04,  ..., -8.1136e-02,\n",
            "           1.0476e-01,  9.3816e-02],\n",
            "         [ 2.9132e-01, -2.2551e-01,  3.3282e-01,  ..., -1.5174e-02,\n",
            "          -2.9463e-01, -1.4293e-01],\n",
            "         [-3.4415e-02,  3.0241e-01,  2.2237e-01,  ..., -2.4736e-01,\n",
            "           1.9820e-01, -9.0008e-02],\n",
            "         ...,\n",
            "         [ 9.6507e-03, -3.2714e-01,  1.0370e-01,  ...,  5.8581e-02,\n",
            "          -5.9344e-02, -3.7758e-01],\n",
            "         [ 1.3454e-01, -1.9973e-01, -4.7276e-02,  ..., -4.1595e-02,\n",
            "          -2.3556e-04,  5.1445e-02],\n",
            "         [ 9.1844e-02,  1.1553e-01,  1.4597e-01,  ..., -1.0004e-01,\n",
            "          -1.5205e-01, -3.2459e-01]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0523,  0.0929,  0.0340,  ...,  0.0440,  0.0347,  0.0551],\n",
            "        [ 0.0185, -0.5008,  0.6120,  ..., -0.1063, -0.6139, -0.3483],\n",
            "        [-0.0294, -0.0235,  0.4771,  ..., -0.1893, -0.2076, -0.2626],\n",
            "        ...,\n",
            "        [ 0.2135, -0.4454,  0.4880,  ...,  0.0636, -0.4653, -0.4820],\n",
            "        [-0.0667, -0.0531, -0.0796,  ..., -0.0871,  0.1072,  0.1619],\n",
            "        [ 0.1467, -0.1506,  0.4424,  ..., -0.0239, -0.4713, -0.3698]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0679,  0.1288,  0.0197,  ...,  0.0404,  0.0713,  0.0171],\n",
            "        [-0.0532,  0.0743, -0.0135,  ..., -0.0389,  0.0164,  0.0685],\n",
            "        [ 0.0816, -0.0118, -0.0415,  ...,  0.0684, -0.1072, -0.0517],\n",
            "        ...,\n",
            "        [ 0.2215,  0.1141,  0.3459,  ...,  0.3855, -0.0352, -0.1206],\n",
            "        [ 0.1695, -0.0404,  0.1255,  ..., -0.0129, -0.2361, -0.0643],\n",
            "        [-0.1886, -0.0427,  0.0995,  ...,  0.1798, -0.2319, -0.2144]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2106, -0.3731,  0.2314,  ...,  0.0623,  0.0021, -0.0740],\n",
            "         [ 0.1122,  0.3512,  0.2093,  ..., -0.0555, -0.1035, -0.3732],\n",
            "         [ 0.2948, -0.1520,  0.2300,  ..., -0.0493, -0.0309, -0.2602],\n",
            "         ...,\n",
            "         [ 0.3696, -0.0081,  0.1286,  ...,  0.1543, -0.1186, -0.1810],\n",
            "         [ 0.2750, -0.0531, -0.0978,  ..., -0.0732, -0.1281, -0.1242],\n",
            "         [ 0.1299,  0.2252,  0.1299,  ...,  0.1613, -0.1254,  0.0012]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1185, -0.3781,  0.4171,  ...,  0.0318, -0.2881, -0.2141],\n",
            "        [ 0.1811,  0.0214,  0.4680,  ...,  0.0452, -0.4357, -0.3732],\n",
            "        [ 0.1149, -0.5164,  0.5943,  ..., -0.1263, -0.4618, -0.3904],\n",
            "        ...,\n",
            "        [ 0.1865, -0.2878,  0.5276,  ...,  0.0638, -0.5280, -0.3687],\n",
            "        [ 0.1975, -0.3286,  0.3053,  ..., -0.0442, -0.4987, -0.2923],\n",
            "        [ 0.2229, -0.0208,  0.3073,  ...,  0.1306, -0.2868, -0.1692]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0534,  0.0742, -0.0136,  ..., -0.0389,  0.0162,  0.0685],\n",
            "        [-0.0534,  0.0742, -0.0136,  ..., -0.0389,  0.0162,  0.0685],\n",
            "        [-0.0534,  0.0742, -0.0136,  ..., -0.0389,  0.0162,  0.0685],\n",
            "        ...,\n",
            "        [ 0.4093, -0.5294,  0.1010,  ...,  0.2609, -0.0724, -0.3632],\n",
            "        [ 0.4093, -0.5294,  0.1010,  ...,  0.2609, -0.0724, -0.3632],\n",
            "        [ 0.4093, -0.5294,  0.1010,  ...,  0.2609, -0.0724, -0.3632]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.4093, -0.5294,  0.1010,  ...,  0.2609, -0.0724, -0.3632],\n",
            "         [ 0.4093, -0.5294,  0.1010,  ...,  0.2609, -0.0724, -0.3632],\n",
            "         [ 0.4093, -0.5294,  0.1010,  ...,  0.2609, -0.0724, -0.3632],\n",
            "         ...,\n",
            "         [ 0.4093, -0.5294,  0.1010,  ...,  0.2609, -0.0724, -0.3632],\n",
            "         [ 0.4093, -0.5294,  0.1010,  ...,  0.2609, -0.0724, -0.3632],\n",
            "         [ 0.4093, -0.5294,  0.1010,  ...,  0.2609, -0.0724, -0.3632]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3122, -0.6850,  0.6047,  ...,  0.0067, -0.5905, -0.5902],\n",
            "        [ 0.3122, -0.6850,  0.6047,  ...,  0.0067, -0.5905, -0.5902],\n",
            "        [ 0.3122, -0.6850,  0.6047,  ...,  0.0067, -0.5905, -0.5902],\n",
            "        ...,\n",
            "        [ 0.3122, -0.6850,  0.6047,  ...,  0.0067, -0.5905, -0.5902],\n",
            "        [ 0.3122, -0.6850,  0.6047,  ...,  0.0067, -0.5905, -0.5902],\n",
            "        [ 0.3122, -0.6850,  0.6047,  ...,  0.0067, -0.5905, -0.5902]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0535,  0.0741, -0.0138,  ..., -0.0389,  0.0161,  0.0685],\n",
            "        [ 0.2971, -0.0568,  0.1517,  ...,  0.3222, -0.1467, -0.1337],\n",
            "        [-0.0535,  0.0741, -0.0138,  ..., -0.0389,  0.0161,  0.0685],\n",
            "        ...,\n",
            "        [-0.2968,  0.5994,  0.0930,  ...,  0.3403, -0.2991, -0.0423],\n",
            "        [-0.2968,  0.5994,  0.0930,  ...,  0.3403, -0.2991, -0.0423],\n",
            "        [ 0.0546, -0.1148, -0.2016,  ...,  0.0548, -0.2379, -0.0517]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1327,  0.1644, -0.1853,  ..., -0.1753,  0.1414,  0.2968],\n",
            "         [-0.2487, -0.0147,  0.0497,  ..., -0.1800, -0.1125,  0.0024],\n",
            "         [ 0.1430, -0.0047,  0.1244,  ...,  0.1534, -0.2748, -0.0984],\n",
            "         ...,\n",
            "         [-0.1633, -0.3286,  0.1647,  ..., -0.0738, -0.3014, -0.1537],\n",
            "         [-0.4295, -0.0238,  0.0305,  ...,  0.1212,  0.1464,  0.3830],\n",
            "         [ 0.1053, -0.2816,  0.1478,  ..., -0.1312, -0.2364, -0.1383]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.1922,  0.1333, -0.1406,  ..., -0.0970,  0.1350,  0.3111],\n",
            "        [-0.3106,  0.0292, -0.0359,  ..., -0.1629,  0.0663,  0.0967],\n",
            "        [ 0.1390, -0.1074,  0.3857,  ...,  0.1035, -0.4055, -0.3327],\n",
            "        ...,\n",
            "        [-0.1263, -0.5949,  0.5946,  ..., -0.1922, -0.6420, -0.4034],\n",
            "        [-0.4781,  0.0041, -0.0761,  ..., -0.0191,  0.1655,  0.3760],\n",
            "        [ 0.0970, -0.5222,  0.5418,  ..., -0.1917, -0.5656, -0.3790]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.1501,  0.0629,  0.0010,  ...,  0.1467, -0.0692, -0.0528],\n",
            "        [-0.2097, -0.0637, -0.0098,  ...,  0.1715, -0.1773, -0.0918],\n",
            "        [-0.0538,  0.0740, -0.0140,  ..., -0.0389,  0.0161,  0.0685],\n",
            "        ...,\n",
            "        [-0.0733, -0.2136,  0.0615,  ..., -0.0912, -0.0655, -0.0956],\n",
            "        [ 0.0041, -0.1536, -0.0910,  ...,  0.0607, -0.1571, -0.2580],\n",
            "        [-0.0733, -0.2136,  0.0615,  ..., -0.0912, -0.0655, -0.0956]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1627,  0.1974,  0.1438,  ...,  0.0092, -0.3298, -0.0732],\n",
            "         [ 0.0102,  0.0931,  0.1198,  ...,  0.1166,  0.0272,  0.0257],\n",
            "         [-0.2038,  0.3220,  0.1145,  ...,  0.3119, -0.2308, -0.1197],\n",
            "         ...,\n",
            "         [ 0.1087,  0.2110,  0.1472,  ...,  0.0175,  0.0360,  0.0745],\n",
            "         [ 0.2844,  0.0054,  0.2077,  ...,  0.0767,  0.0622, -0.0676],\n",
            "         [ 0.0434, -0.2553,  0.2443,  ...,  0.1450, -0.2473, -0.1079]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1057,  0.4485,  0.0664,  ...,  0.2053, -0.0762, -0.3428],\n",
            "        [-0.0438, -0.0930,  0.2324,  ..., -0.0111, -0.1333,  0.0036],\n",
            "        [ 0.3132,  0.6248, -0.0855,  ...,  0.6367,  0.0379, -0.3633],\n",
            "        ...,\n",
            "        [ 0.4695,  0.5439,  0.0307,  ...,  0.3917,  0.0055, -0.0969],\n",
            "        [ 0.3364, -0.1586,  0.4885,  ...,  0.2086, -0.3095, -0.3068],\n",
            "        [-0.0043, -0.3699,  0.4888,  ..., -0.0771, -0.4729, -0.3552]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0537,  0.0739, -0.0141,  ..., -0.0389,  0.0161,  0.0685],\n",
            "        [ 0.0450, -0.1536,  0.1181,  ...,  0.0636, -0.0516, -0.0837],\n",
            "        [-0.0798, -0.0918, -0.0341,  ..., -0.0705, -0.0884, -0.0116],\n",
            "        ...,\n",
            "        [-0.1997,  0.1014,  0.1765,  ...,  0.1828, -0.1549, -0.0870],\n",
            "        [ 0.3442, -0.0578,  0.3772,  ...,  0.4698, -0.1363, -0.1923],\n",
            "        [ 0.0921, -0.0869, -0.1126,  ...,  0.0311, -0.2337, -0.1939]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3656, -0.0679,  0.2401,  ...,  0.2238, -0.3400, -0.0850],\n",
            "         [-0.0922,  0.0249,  0.0976,  ..., -0.0386, -0.1840, -0.2485],\n",
            "         [ 0.0599,  0.0855, -0.1330,  ..., -0.0836, -0.0186,  0.1120],\n",
            "         ...,\n",
            "         [ 0.1517, -0.2191, -0.2122,  ...,  0.1973,  0.0875, -0.0746],\n",
            "         [-0.0637,  0.1377, -0.0089,  ..., -0.0999, -0.0145,  0.2140],\n",
            "         [ 0.1045,  0.4098, -0.1729,  ...,  0.1887, -0.2846, -0.0025]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2697, -0.3145,  0.5011,  ...,  0.2530, -0.5125, -0.2921],\n",
            "        [-0.0122, -0.3076,  0.5255,  ..., -0.0986, -0.5541, -0.3570],\n",
            "        [ 0.0389, -0.0974,  0.1901,  ..., -0.0299, -0.2528, -0.0395],\n",
            "        ...,\n",
            "        [ 0.1317, -0.1399,  0.0838,  ...,  0.0858, -0.1673, -0.2261],\n",
            "        [-0.1804,  0.1891, -0.0644,  ..., -0.0638,  0.1099,  0.3011],\n",
            "        [ 0.2518,  0.5051, -0.1583,  ...,  0.4022,  0.0046,  0.0122]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0538,  0.0738, -0.0143,  ..., -0.0389,  0.0160,  0.0685],\n",
            "        [ 0.1771, -0.0107, -0.1430,  ..., -0.0540,  0.2068, -0.0653],\n",
            "        [-0.0538,  0.0738, -0.0143,  ..., -0.0389,  0.0160,  0.0685],\n",
            "        ...,\n",
            "        [ 0.1154,  0.2662, -0.0374,  ...,  0.0031, -0.3040, -0.1170],\n",
            "        [ 0.2440,  0.0224,  0.0480,  ...,  0.0282, -0.0529, -0.0117],\n",
            "        [-0.0605,  0.0435,  0.0656,  ..., -0.3456,  0.0259, -0.0833]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2998, -0.0562,  0.2698,  ..., -0.2078, -0.0621, -0.0404],\n",
            "         [-0.0021,  0.0821,  0.1804,  ..., -0.0738, -0.2302,  0.1522],\n",
            "         [ 0.0394,  0.5606, -0.0989,  ...,  0.3650, -0.1641,  0.0751],\n",
            "         ...,\n",
            "         [ 0.1154,  0.2662, -0.0374,  ...,  0.0031, -0.3040, -0.1170],\n",
            "         [ 0.2440,  0.0224,  0.0480,  ...,  0.0282, -0.0529, -0.0117],\n",
            "         [-0.0605,  0.0435,  0.0656,  ..., -0.3456,  0.0259, -0.0833]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1415, -0.1809,  0.4239,  ..., -0.1790, -0.2922, -0.1526],\n",
            "        [ 0.3683,  0.5403, -0.0192,  ...,  0.3966,  0.0568,  0.1235],\n",
            "        [ 0.5674,  0.7939, -0.1833,  ...,  0.7411,  0.0714, -0.1472],\n",
            "        ...,\n",
            "        [ 0.1808,  0.0315,  0.2946,  ...,  0.0842, -0.4540, -0.3681],\n",
            "        [ 0.2258,  0.0113,  0.1597,  ...,  0.0616, -0.1535, -0.0734],\n",
            "        [-0.1233,  0.0861, -0.0319,  ..., -0.2506,  0.1101, -0.0211]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0540,  0.0739, -0.0145,  ..., -0.0389,  0.0159,  0.0682],\n",
            "        [-0.0540,  0.0739, -0.0145,  ..., -0.0389,  0.0159,  0.0682],\n",
            "        [-0.0540,  0.0739, -0.0145,  ..., -0.0389,  0.0159,  0.0682],\n",
            "        ...,\n",
            "        [-0.0094,  0.2917,  0.2091,  ...,  0.0718, -0.1514, -0.1317],\n",
            "        [-0.1676,  0.4439,  0.0972,  ...,  0.2017, -0.3435, -0.0877],\n",
            "        [-0.1375,  0.4037,  0.0643,  ...,  0.3397, -0.3610, -0.1063]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0524, -0.2400,  0.1047,  ...,  0.1456, -0.3722, -0.1264],\n",
            "         [ 0.0524, -0.2400,  0.1047,  ...,  0.1456, -0.3722, -0.1264],\n",
            "         [-0.1375,  0.4037,  0.0643,  ...,  0.3397, -0.3610, -0.1063],\n",
            "         ...,\n",
            "         [-0.0094,  0.2917,  0.2091,  ...,  0.0718, -0.1514, -0.1317],\n",
            "         [-0.1676,  0.4439,  0.0972,  ...,  0.2017, -0.3435, -0.0877],\n",
            "         [-0.1375,  0.4037,  0.0643,  ...,  0.3397, -0.3610, -0.1063]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0824, -0.5684,  0.5508,  ..., -0.0489, -0.6477, -0.4473],\n",
            "        [ 0.0824, -0.5684,  0.5508,  ..., -0.0489, -0.6477, -0.4473],\n",
            "        [ 0.4596,  0.7829, -0.1181,  ...,  0.7157,  0.0242, -0.5116],\n",
            "        ...,\n",
            "        [ 0.0503,  0.3065,  0.0569,  ...,  0.1482, -0.1560, -0.1994],\n",
            "        [ 0.4034,  0.8021, -0.0995,  ...,  0.6550,  0.0275, -0.4609],\n",
            "        [ 0.4596,  0.7829, -0.1181,  ...,  0.7157,  0.0242, -0.5116]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0541,  0.0739, -0.0146,  ..., -0.0387,  0.0158,  0.0681],\n",
            "        [ 0.0461, -0.1532,  0.1189,  ...,  0.0635, -0.0519, -0.0834],\n",
            "        [-0.0541,  0.0739, -0.0146,  ..., -0.0387,  0.0158,  0.0681],\n",
            "        ...,\n",
            "        [ 0.3014,  0.2183, -0.0375,  ...,  0.0935, -0.0764, -0.3612],\n",
            "        [-0.2696,  0.5199,  0.1332,  ...,  0.0821, -0.0105, -0.1442],\n",
            "        [ 0.1538,  0.4333,  0.2300,  ...,  0.2980, -0.1903,  0.0994]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1118, -0.0796,  0.0567,  ..., -0.0889, -0.2995, -0.0962],\n",
            "         [ 0.1124,  0.1445,  0.1458,  ...,  0.1390, -0.1927, -0.0286],\n",
            "         [-0.0166, -0.1767,  0.2225,  ..., -0.2480, -0.1603, -0.0812],\n",
            "         ...,\n",
            "         [ 0.3014,  0.2183, -0.0375,  ...,  0.0935, -0.0764, -0.3612],\n",
            "         [-0.2696,  0.5199,  0.1332,  ...,  0.0821, -0.0105, -0.1442],\n",
            "         [ 0.1538,  0.4333,  0.2300,  ...,  0.2980, -0.1903,  0.0994]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.1572, -0.1504,  0.2057,  ..., -0.1489, -0.3177, -0.1142],\n",
            "        [ 0.0022,  0.1721,  0.0907,  ...,  0.1321, -0.0819, -0.0262],\n",
            "        [-0.0450, -0.5118,  0.6569,  ..., -0.2400, -0.6055, -0.3551],\n",
            "        ...,\n",
            "        [ 0.3275,  0.0256,  0.2898,  ...,  0.1947, -0.4108, -0.5271],\n",
            "        [ 0.1233,  0.7079, -0.0805,  ...,  0.4925,  0.1224, -0.4312],\n",
            "        [ 0.4078,  0.5577,  0.3065,  ...,  0.5021, -0.2285, -0.2109]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0105,  0.0276,  0.0540,  ..., -0.0663, -0.0992,  0.0342],\n",
            "        [-0.0545,  0.0740, -0.0148,  ..., -0.0385,  0.0158,  0.0679],\n",
            "        [ 0.0707, -0.1213,  0.0708,  ...,  0.0608, -0.1190, -0.0785],\n",
            "        ...,\n",
            "        [-0.2769,  0.4069,  0.1214,  ...,  0.0449, -0.2112, -0.0504],\n",
            "        [-0.0050, -0.0902,  0.1232,  ..., -0.0086, -0.2607, -0.1737],\n",
            "        [-0.2769,  0.4069,  0.1214,  ...,  0.0449, -0.2112, -0.0504]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1828, -0.1014,  0.1120,  ..., -0.1541, -0.2100, -0.1325],\n",
            "         [ 0.4091, -0.1486,  0.0990,  ..., -0.0410,  0.0560, -0.1218],\n",
            "         [ 0.1840,  0.2840,  0.1891,  ...,  0.2183, -0.0453, -0.1721],\n",
            "         ...,\n",
            "         [-0.2769,  0.4069,  0.1214,  ...,  0.0449, -0.2112, -0.0504],\n",
            "         [-0.0050, -0.0902,  0.1232,  ..., -0.0086, -0.2607, -0.1737],\n",
            "         [-0.2769,  0.4069,  0.1214,  ...,  0.0449, -0.2112, -0.0504]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0703, -0.4480,  0.5683,  ..., -0.1749, -0.5787, -0.3674],\n",
            "        [ 0.1803, -0.3832,  0.4367,  ..., -0.0408, -0.3411, -0.2482],\n",
            "        [ 0.2500, -0.0313,  0.5298,  ...,  0.1807, -0.4076, -0.3761],\n",
            "        ...,\n",
            "        [ 0.2474,  0.7308, -0.0889,  ...,  0.5182,  0.0620, -0.3959],\n",
            "        [-0.0200, -0.4783,  0.5727,  ..., -0.1361, -0.6445, -0.4320],\n",
            "        [ 0.2474,  0.7308, -0.0889,  ...,  0.5182,  0.0620, -0.3959]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-2.0879e-01, -7.0863e-02, -7.4553e-03,  ...,  1.6979e-01,\n",
            "         -1.7503e-01, -9.3305e-02],\n",
            "        [-5.5059e-02,  7.4102e-02, -1.4957e-02,  ..., -3.8126e-02,\n",
            "          1.5881e-02,  6.7641e-02],\n",
            "        [-1.5305e-01,  6.2791e-02, -4.8979e-05,  ...,  1.4802e-01,\n",
            "         -6.9738e-02, -5.3540e-02],\n",
            "        ...,\n",
            "        [-2.8115e-02, -1.2073e-01, -6.6946e-02,  ...,  1.1477e-01,\n",
            "         -7.6476e-02,  4.7701e-02],\n",
            "        [ 1.1896e-01,  4.2001e-01,  2.5807e-01,  ...,  1.7657e-01,\n",
            "         -2.9653e-01,  6.8609e-03],\n",
            "        [ 1.5428e-02, -2.8451e-01,  2.2169e-01,  ...,  6.7845e-02,\n",
            "         -2.4225e-01, -1.0427e-01]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0154, -0.2845,  0.2217,  ...,  0.0678, -0.2423, -0.1043],\n",
            "         [ 0.3649, -0.2925,  0.3782,  ...,  0.0958, -0.2954, -0.1497],\n",
            "         [ 0.0923,  0.1886,  0.3244,  ..., -0.0139, -0.1647, -0.2530],\n",
            "         ...,\n",
            "         [ 0.0874,  0.0941,  0.0646,  ..., -0.0792,  0.0451, -0.0118],\n",
            "         [-0.0281, -0.1207, -0.0669,  ...,  0.1148, -0.0765,  0.0477],\n",
            "         [ 0.1190,  0.4200,  0.2581,  ...,  0.1766, -0.2965,  0.0069]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0859, -0.4656,  0.4556,  ..., -0.0611, -0.5715, -0.3204],\n",
            "        [ 0.1226, -0.5129,  0.5829,  ..., -0.0287, -0.5727, -0.3673],\n",
            "        [ 0.2702,  0.0539,  0.5177,  ...,  0.1156, -0.4184, -0.4055],\n",
            "        ...,\n",
            "        [ 0.2419,  0.0144,  0.2768,  ...,  0.0830, -0.2369, -0.2179],\n",
            "        [-0.2273, -0.0596, -0.0949,  ..., -0.0125,  0.0478,  0.1538],\n",
            "        [ 0.5905,  0.7654, -0.0978,  ...,  0.7030, -0.0560, -0.2751]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0042, -0.1238, -0.0196,  ...,  0.0406,  0.0762, -0.1053],\n",
            "        [-0.0571, -0.0412, -0.0895,  ..., -0.0811,  0.0589, -0.0499],\n",
            "        [ 0.0226,  0.1173,  0.0644,  ..., -0.1238,  0.0106, -0.1074],\n",
            "        ...,\n",
            "        [-0.0925,  0.8323,  0.0119,  ...,  0.3709, -0.0483, -0.0092],\n",
            "        [-0.2792,  0.2238,  0.1120,  ...,  0.1363, -0.3543, -0.0204],\n",
            "        [-0.2689,  0.4269, -0.0176,  ..., -0.0341,  0.0529,  0.2163]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.2792,  0.2238,  0.1120,  ...,  0.1363, -0.3543, -0.0204],\n",
            "         [-0.2689,  0.4269, -0.0176,  ..., -0.0341,  0.0529,  0.2163],\n",
            "         [ 0.1649,  0.0139,  0.1522,  ..., -0.0164, -0.0722, -0.1016],\n",
            "         ...,\n",
            "         [ 0.2164, -0.0222,  0.2103,  ...,  0.1919, -0.0246, -0.1748],\n",
            "         [ 0.1292,  0.0321,  0.1066,  ..., -0.0137, -0.2259, -0.1008],\n",
            "         [-0.0925,  0.8323,  0.0119,  ...,  0.3709, -0.0483, -0.0092]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2088,  0.6119, -0.0860,  ...,  0.5826,  0.0078, -0.1996],\n",
            "        [ 0.1244,  0.5280, -0.0439,  ...,  0.2236, -0.0603, -0.0235],\n",
            "        [ 0.2180, -0.2955,  0.4901,  ...,  0.0526, -0.4360, -0.3500],\n",
            "        ...,\n",
            "        [ 0.5820,  0.3964,  0.3361,  ...,  0.6343, -0.3399, -0.5918],\n",
            "        [ 0.0436, -0.3979,  0.5579,  ..., -0.1542, -0.6040, -0.3698],\n",
            "        [ 0.4059,  0.8703, -0.0901,  ...,  0.6905, -0.0501, -0.3622]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1112,  0.1229, -0.1101,  ..., -0.0336, -0.0718, -0.0423],\n",
            "        [ 0.2919, -0.0671,  0.1526,  ...,  0.3199, -0.1464, -0.1338],\n",
            "        [-0.0562,  0.0742, -0.0154,  ..., -0.0375,  0.0160,  0.0672],\n",
            "        ...,\n",
            "        [ 0.1601, -0.0183,  0.1712,  ..., -0.0417,  0.2138, -0.0379],\n",
            "        [ 0.1237,  0.3361,  0.2044,  ..., -0.0601, -0.1012, -0.3710],\n",
            "        [ 0.0762,  0.2291, -0.0858,  ..., -0.0179, -0.0305, -0.1094]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.1932, -0.0394,  0.0252,  ..., -0.0707, -0.0224,  0.0046],\n",
            "         [ 0.1601, -0.0183,  0.1712,  ..., -0.0417,  0.2138, -0.0379],\n",
            "         [ 0.1237,  0.3361,  0.2044,  ..., -0.0601, -0.1012, -0.3710],\n",
            "         ...,\n",
            "         [ 0.2917, -0.0007,  0.0974,  ...,  0.3193, -0.2340, -0.2435],\n",
            "         [-0.0777,  0.0526,  0.0955,  ...,  0.1236, -0.1120, -0.0609],\n",
            "         [ 0.0682, -0.0426, -0.0214,  ...,  0.1392,  0.1502, -0.1686]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1652, -0.0294,  0.1737,  ...,  0.0640, -0.1565, -0.1209],\n",
            "        [ 0.2627, -0.3164,  0.5466,  ..., -0.0469, -0.3511, -0.2883],\n",
            "        [ 0.1708, -0.0279,  0.4872,  ...,  0.0219, -0.4491, -0.3645],\n",
            "        ...,\n",
            "        [ 0.2130, -0.1575,  0.3477,  ...,  0.1661, -0.4617, -0.3162],\n",
            "        [-0.0321, -0.0247,  0.1682,  ...,  0.0470, -0.1676, -0.0911],\n",
            "        [ 0.1127,  0.0500, -0.0317,  ...,  0.1372,  0.0886, -0.0655]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[-0.0044,  0.0440, -0.0119,  ...,  0.1252,  0.1695, -0.1856],\n",
            "        [ 0.2919, -0.0671,  0.1526,  ...,  0.3199, -0.1464, -0.1338],\n",
            "        [-0.0476, -0.0974,  0.1524,  ...,  0.2714, -0.0774,  0.0347],\n",
            "        ...,\n",
            "        [-0.0237,  0.3414,  0.0315,  ...,  0.2293,  0.1528, -0.3589],\n",
            "        [ 0.1577, -0.0792,  0.1734,  ..., -0.0851, -0.2971, -0.1393],\n",
            "        [ 0.2570,  0.1104,  0.1058,  ...,  0.2086,  0.1167, -0.3032]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[-0.2831,  0.3639,  0.0905,  ...,  0.3697,  0.0079, -0.1515],\n",
            "         [ 0.2326,  0.1994,  0.1129,  ...,  0.1590,  0.1481, -0.3339],\n",
            "         [ 0.0973,  0.1169, -0.0195,  ...,  0.1175,  0.0149, -0.2593],\n",
            "         ...,\n",
            "         [ 0.0823,  0.0426,  0.0746,  ...,  0.0685,  0.0434, -0.1819],\n",
            "         [ 0.2168, -0.1642,  0.1945,  ..., -0.1007, -0.0657,  0.0014],\n",
            "         [ 0.4368,  0.0428,  0.1286,  ...,  0.2420,  0.0322, -0.3069]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2368,  0.6896, -0.0678,  ...,  0.6126,  0.1132, -0.4757],\n",
            "        [ 0.3629,  0.3106,  0.3179,  ...,  0.3613, -0.2620, -0.4111],\n",
            "        [ 0.1936,  0.1145,  0.1793,  ...,  0.1808, -0.2782, -0.3341],\n",
            "        ...,\n",
            "        [ 0.0656, -0.0543,  0.2232,  ...,  0.0164, -0.2097, -0.1551],\n",
            "        [ 0.2994, -0.2685,  0.3148,  ..., -0.0265, -0.2581, -0.1070],\n",
            "        [ 0.3483, -0.0865,  0.4570,  ...,  0.2268, -0.3809, -0.4085]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[-0.0562,  0.0742, -0.0154,  ..., -0.0375,  0.0160,  0.0672],\n",
            "        [ 0.2919, -0.0671,  0.1526,  ...,  0.3199, -0.1464, -0.1338],\n",
            "        [-0.0959, -0.0057, -0.0475,  ..., -0.0164,  0.0498,  0.0918],\n",
            "        ...,\n",
            "        [ 0.4547,  0.1691,  0.0748,  ...,  0.1380,  0.0086, -0.1994],\n",
            "        [ 0.0414,  0.2774,  0.3019,  ...,  0.1105, -0.0815, -0.2292],\n",
            "        [ 0.0983,  0.5657, -0.0544,  ...,  0.3961, -0.0116, -0.2328]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.4335, -0.0308,  0.1230,  ...,  0.1671,  0.0988, -0.3088],\n",
            "         [ 0.2558,  0.0553,  0.1116,  ...,  0.0169,  0.1431, -0.2200],\n",
            "         [ 0.1642, -0.3292,  0.1683,  ...,  0.3709, -0.3178, -0.1385],\n",
            "         ...,\n",
            "         [ 0.0855, -0.1869,  0.1515,  ...,  0.0085, -0.1015, -0.1481],\n",
            "         [ 0.2160,  0.3503,  0.0537,  ...,  0.1030,  0.0750, -0.2365],\n",
            "         [ 0.2106,  0.0693,  0.0844,  ...,  0.1664,  0.1168,  0.0975]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2567, -0.3883,  0.5778,  ...,  0.0628, -0.4407, -0.3958],\n",
            "        [ 0.2101, -0.2677,  0.5260,  ..., -0.0364, -0.3711, -0.3645],\n",
            "        [ 0.2369, -0.5196,  0.5531,  ...,  0.1813, -0.6094, -0.4845],\n",
            "        ...,\n",
            "        [ 0.0339, -0.5321,  0.6481,  ..., -0.1655, -0.6171, -0.4271],\n",
            "        [ 0.3862,  0.3397,  0.3188,  ...,  0.3221, -0.3100, -0.4562],\n",
            "        [ 0.1792,  0.0251,  0.1752,  ...,  0.1438, -0.0574, -0.0502]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[ 0.0773, -0.0253, -0.0447,  ...,  0.0680, -0.1145, -0.0572],\n",
            "        [ 0.0694, -0.0298,  0.0649,  ...,  0.0143, -0.0743,  0.0079],\n",
            "        [-0.0562,  0.0742, -0.0154,  ..., -0.0375,  0.0160,  0.0672],\n",
            "        ...,\n",
            "        [-0.0230,  0.2155,  0.1401,  ..., -0.0675, -0.2500, -0.1201],\n",
            "        [ 0.0377,  0.0435, -0.0047,  ...,  0.0248, -0.1322, -0.2150],\n",
            "        [ 0.0665,  0.5176, -0.1004,  ...,  0.3439, -0.1585,  0.0470]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.1654, -0.2528, -0.0980,  ...,  0.0432, -0.2079, -0.2535],\n",
            "         [-0.0287, -0.1795,  0.1365,  ...,  0.1444, -0.0462, -0.1176],\n",
            "         [-0.0522,  0.1424, -0.0532,  ..., -0.0327,  0.1743,  0.0740],\n",
            "         ...,\n",
            "         [ 0.1629,  0.0428,  0.3079,  ..., -0.0112,  0.0585, -0.0204],\n",
            "         [ 0.0261, -0.1172,  0.0989,  ..., -0.0933, -0.0076, -0.1554],\n",
            "         [-0.0358,  0.0722,  0.1318,  ...,  0.0381, -0.2475, -0.1360]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0266, -0.3087,  0.3050,  ..., -0.0700, -0.4616, -0.2598],\n",
            "        [ 0.0755, -0.3629,  0.4215,  ..., -0.0217, -0.3546, -0.3602],\n",
            "        [ 0.1733,  0.3332, -0.0073,  ...,  0.2111,  0.0135, -0.0514],\n",
            "        ...,\n",
            "        [ 0.2849, -0.3432,  0.5985,  ..., -0.0167, -0.4262, -0.3027],\n",
            "        [ 0.0302, -0.4853,  0.6258,  ..., -0.1759, -0.5459, -0.3658],\n",
            "        [ 0.1185, -0.2196,  0.4603,  ...,  0.0329, -0.5047, -0.4567]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[ 0.2919, -0.0671,  0.1526,  ...,  0.3199, -0.1464, -0.1338],\n",
            "        [-0.0562,  0.0742, -0.0154,  ..., -0.0375,  0.0160,  0.0672],\n",
            "        [-0.0044,  0.0440, -0.0119,  ...,  0.1252,  0.1695, -0.1856],\n",
            "        ...,\n",
            "        [ 0.0656,  0.1973,  0.0378,  ...,  0.2100,  0.1753, -0.0203],\n",
            "        [ 0.3016,  0.0012,  0.1012,  ...,  0.2754,  0.1162, -0.1103],\n",
            "        [ 0.2822, -0.5820, -0.2398,  ...,  0.0182,  0.0822, -0.3069]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.5597,  0.0698,  0.2577,  ...,  0.0740, -0.2019, -0.2239],\n",
            "         [ 0.0787,  0.2662,  0.0458,  ...,  0.1185, -0.2354, -0.1272],\n",
            "         [ 0.0979,  0.1608,  0.0255,  ...,  0.2794,  0.0905, -0.2621],\n",
            "         ...,\n",
            "         [ 0.0665,  0.5176, -0.1004,  ...,  0.3439, -0.1585,  0.0470],\n",
            "         [ 0.0966,  0.0109,  0.1682,  ..., -0.0318, -0.1042, -0.1066],\n",
            "         [ 0.1509,  0.1941,  0.1285,  ...,  0.1166,  0.1220, -0.0786]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2741, -0.3513,  0.6427,  ...,  0.0259, -0.6078, -0.4508],\n",
            "        [ 0.3532,  0.4602,  0.0404,  ...,  0.3548, -0.1675, -0.2986],\n",
            "        [ 0.2664,  0.2641,  0.1562,  ...,  0.3162, -0.2515, -0.3794],\n",
            "        ...,\n",
            "        [ 0.5557,  0.7651, -0.1955,  ...,  0.7041,  0.0611, -0.1723],\n",
            "        [ 0.1920, -0.0512,  0.1613,  ...,  0.0764, -0.2624, -0.2435],\n",
            "        [ 0.1191,  0.0099,  0.3724,  ...,  0.0492, -0.2647, -0.2297]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[-0.0562,  0.0742, -0.0154,  ..., -0.0375,  0.0160,  0.0672],\n",
            "        [-0.0562,  0.0742, -0.0154,  ..., -0.0375,  0.0160,  0.0672],\n",
            "        [-0.0562,  0.0742, -0.0154,  ..., -0.0375,  0.0160,  0.0672],\n",
            "        ...,\n",
            "        [ 0.3019, -0.0744,  0.4631,  ...,  0.3721, -0.0830, -0.1261],\n",
            "        [ 0.4245, -0.5840,  0.1177,  ...,  0.2329, -0.0700, -0.3687],\n",
            "        [ 0.4245, -0.5840,  0.1177,  ...,  0.2329, -0.0700, -0.3687]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.4245, -0.5840,  0.1177,  ...,  0.2329, -0.0700, -0.3687],\n",
            "         [ 0.4245, -0.5840,  0.1177,  ...,  0.2329, -0.0700, -0.3687],\n",
            "         [ 0.3019, -0.0744,  0.4631,  ...,  0.3721, -0.0830, -0.1261],\n",
            "         ...,\n",
            "         [-0.1613,  0.3702,  0.0966,  ...,  0.1605, -0.3159, -0.0932],\n",
            "         [-0.0085,  0.0388,  0.1352,  ..., -0.0848, -0.2940, -0.0732],\n",
            "         [ 0.3729,  0.0439,  0.0592,  ...,  0.1277, -0.0439, -0.1030]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2680, -0.7233,  0.6539,  ..., -0.0577, -0.6214, -0.5840],\n",
            "        [ 0.2680, -0.7233,  0.6539,  ..., -0.0577, -0.6214, -0.5840],\n",
            "        [ 0.2158, -0.5920,  0.8379,  ...,  0.1028, -0.5892, -0.3594],\n",
            "        ...,\n",
            "        [ 0.3274,  0.7374, -0.0857,  ...,  0.5658,  0.0252, -0.4299],\n",
            "        [-0.0052, -0.3404,  0.4897,  ..., -0.1510, -0.5692, -0.3380],\n",
            "        [ 0.1572, -0.1021,  0.3827,  ...,  0.0271, -0.3774, -0.2583]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[-0.0562,  0.0742, -0.0154,  ..., -0.0375,  0.0160,  0.0672],\n",
            "        [-0.0562,  0.0742, -0.0154,  ..., -0.0375,  0.0160,  0.0672],\n",
            "        [-0.0562,  0.0742, -0.0154,  ..., -0.0375,  0.0160,  0.0672],\n",
            "        ...,\n",
            "        [ 0.4245, -0.5840,  0.1177,  ...,  0.2329, -0.0700, -0.3687],\n",
            "        [ 0.4245, -0.5840,  0.1177,  ...,  0.2329, -0.0700, -0.3687],\n",
            "        [ 0.4245, -0.5840,  0.1177,  ...,  0.2329, -0.0700, -0.3687]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.4245, -0.5840,  0.1177,  ...,  0.2329, -0.0700, -0.3687],\n",
            "         [ 0.4245, -0.5840,  0.1177,  ...,  0.2329, -0.0700, -0.3687],\n",
            "         [ 0.4245, -0.5840,  0.1177,  ...,  0.2329, -0.0700, -0.3687],\n",
            "         ...,\n",
            "         [ 0.4245, -0.5840,  0.1177,  ...,  0.2329, -0.0700, -0.3687],\n",
            "         [ 0.4245, -0.5840,  0.1177,  ...,  0.2329, -0.0700, -0.3687],\n",
            "         [ 0.4245, -0.5840,  0.1177,  ...,  0.2329, -0.0700, -0.3687]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2680, -0.7233,  0.6539,  ..., -0.0577, -0.6214, -0.5840],\n",
            "        [ 0.2680, -0.7233,  0.6539,  ..., -0.0577, -0.6214, -0.5840],\n",
            "        [ 0.2680, -0.7233,  0.6539,  ..., -0.0577, -0.6214, -0.5840],\n",
            "        ...,\n",
            "        [ 0.2680, -0.7233,  0.6539,  ..., -0.0577, -0.6214, -0.5840],\n",
            "        [ 0.2680, -0.7233,  0.6539,  ..., -0.0577, -0.6214, -0.5840],\n",
            "        [ 0.2680, -0.7233,  0.6539,  ..., -0.0577, -0.6214, -0.5840]],\n",
            "       device='cuda:0')\n",
            "\t Epoch: 8 | Train Loss: 0.068 | Train Acc: 98.31%\n",
            "\t Epoch: 8 | Val. Loss: 0.970 |  Val. Acc: 84.38% \n",
            "\n",
            "Output of encoder at every step:tensor([[-0.0562,  0.0742, -0.0154,  ..., -0.0375,  0.0160,  0.0672],\n",
            "        [-0.0562,  0.0742, -0.0154,  ..., -0.0375,  0.0160,  0.0672],\n",
            "        [-0.0562,  0.0742, -0.0154,  ..., -0.0375,  0.0160,  0.0672],\n",
            "        ...,\n",
            "        [ 0.2491,  0.1140,  0.1232,  ...,  0.0530, -0.3480, -0.1780],\n",
            "        [ 0.0165, -0.0791,  0.0787,  ...,  0.0182, -0.2316, -0.1304],\n",
            "        [ 0.0314,  0.0304, -0.0280,  ...,  0.0049, -0.0350, -0.0571]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2690,  0.1837,  0.2743,  ...,  0.1980, -0.1031, -0.1850],\n",
            "         [ 0.2491,  0.1140,  0.1232,  ...,  0.0530, -0.3480, -0.1780],\n",
            "         [ 0.0165, -0.0791,  0.0787,  ...,  0.0182, -0.2316, -0.1304],\n",
            "         ...,\n",
            "         [ 0.0404, -0.1205,  0.0452,  ..., -0.0238, -0.3359, -0.2668],\n",
            "         [ 0.1777,  0.2416, -0.0715,  ..., -0.0316, -0.3876, -0.1264],\n",
            "         [ 0.2860, -0.2647,  0.2312,  ...,  0.1051, -0.2269, -0.1956]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2251, -0.3068,  0.6938,  ...,  0.0491, -0.5864, -0.4117],\n",
            "        [ 0.2401, -0.0621,  0.3377,  ...,  0.1166, -0.5069, -0.3445],\n",
            "        [ 0.1729, -0.4918,  0.5267,  ..., -0.0517, -0.5811, -0.4463],\n",
            "        ...,\n",
            "        [ 0.0800, -0.2520,  0.3761,  ..., -0.0446, -0.5213, -0.3543],\n",
            "        [ 0.1810, -0.2422,  0.4433,  ..., -0.0265, -0.6438, -0.4065],\n",
            "        [ 0.2090, -0.4827,  0.6002,  ...,  0.0610, -0.5939, -0.4248]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0566,  0.0742, -0.0156,  ..., -0.0372,  0.0160,  0.0670],\n",
            "        [-0.1618,  0.1093, -0.0656,  ...,  0.0016, -0.1519, -0.1560],\n",
            "        [-0.1561,  0.0624, -0.0012,  ...,  0.1495, -0.0692, -0.0540],\n",
            "        ...,\n",
            "        [ 0.2567,  0.1195,  0.0154,  ...,  0.0426, -0.2500,  0.0615],\n",
            "        [ 0.4175, -0.2768,  0.3710,  ...,  0.0652, -0.2628, -0.1667],\n",
            "        [-0.0222, -0.4713,  0.0921,  ..., -0.0870, -0.1668, -0.3114]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.4175, -0.2768,  0.3710,  ...,  0.0652, -0.2628, -0.1667],\n",
            "         [-0.0222, -0.4713,  0.0921,  ..., -0.0870, -0.1668, -0.3114],\n",
            "         [ 0.3043, -0.3343,  0.1778,  ...,  0.2148, -0.0944, -0.1322],\n",
            "         ...,\n",
            "         [ 0.0950,  0.0875,  0.0446,  ..., -0.0835,  0.0432, -0.0169],\n",
            "         [-0.3017,  0.4651,  0.0898,  ...,  0.2785, -0.2710, -0.0605],\n",
            "         [ 0.2709, -0.0088,  0.1520,  ...,  0.1372,  0.0019, -0.1490]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0754, -0.5620,  0.6997,  ..., -0.0909, -0.6800, -0.3652],\n",
            "        [ 0.1913, -0.6788,  0.5381,  ..., -0.0134, -0.6007, -0.4489],\n",
            "        [ 0.1322, -0.5585,  0.5962,  ...,  0.0010, -0.6151, -0.3284],\n",
            "        ...,\n",
            "        [ 0.2553, -0.0034,  0.2900,  ...,  0.0723, -0.2606, -0.2323],\n",
            "        [ 0.3254,  0.8227, -0.1303,  ...,  0.7306,  0.0662, -0.4932],\n",
            "        [ 0.1935, -0.1590,  0.3215,  ...,  0.0892, -0.2216, -0.3117]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2102,  0.0716,  0.0667,  ..., -0.0277, -0.1051, -0.0215],\n",
            "        [ 0.2394, -0.1149,  0.0941,  ..., -0.0018, -0.0545, -0.0882],\n",
            "        [-0.0570,  0.0742, -0.0157,  ..., -0.0369,  0.0160,  0.0669],\n",
            "        ...,\n",
            "        [ 0.2519, -0.1400,  0.1327,  ...,  0.1643, -0.0812, -0.2208],\n",
            "        [-0.1015, -0.1800,  0.0664,  ...,  0.0224,  0.1503,  0.4268],\n",
            "        [ 0.0843, -0.0952,  0.0753,  ..., -0.1692, -0.2919, -0.1329]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.2799,  0.5485,  0.0454,  ...,  0.3314, -0.2029, -0.0672],\n",
            "         [-0.2710,  0.5097,  0.1342,  ...,  0.0653, -0.0154, -0.1525],\n",
            "         [ 0.2259, -0.1109,  0.2862,  ...,  0.0220, -0.1439, -0.1682],\n",
            "         ...,\n",
            "         [ 0.2519, -0.1400,  0.1327,  ...,  0.1643, -0.0812, -0.2208],\n",
            "         [-0.1015, -0.1800,  0.0664,  ...,  0.0224,  0.1503,  0.4268],\n",
            "         [ 0.0843, -0.0952,  0.0753,  ..., -0.1692, -0.2919, -0.1329]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3439,  0.7900, -0.0466,  ...,  0.6687, -0.1354, -0.4527],\n",
            "        [ 0.0950,  0.6860, -0.0491,  ...,  0.4427,  0.1221, -0.4557],\n",
            "        [ 0.1400, -0.3531,  0.5647,  ...,  0.0219, -0.5129, -0.3574],\n",
            "        ...,\n",
            "        [ 0.3011, -0.5169,  0.6044,  ...,  0.0374, -0.5771, -0.4226],\n",
            "        [-0.3172, -0.0023, -0.0612,  ..., -0.0386,  0.1628,  0.3798],\n",
            "        [ 0.0101, -0.3601,  0.4799,  ..., -0.1875, -0.5700, -0.3499]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0573,  0.0743, -0.0159,  ..., -0.0368,  0.0160,  0.0667],\n",
            "        [-0.0573,  0.0743, -0.0159,  ..., -0.0368,  0.0160,  0.0667],\n",
            "        [-0.0939,  0.0613,  0.3164,  ..., -0.1023, -0.0328, -0.1115],\n",
            "        ...,\n",
            "        [-0.0960,  0.0646,  0.0943,  ...,  0.0110, -0.2174, -0.1000],\n",
            "        [ 0.1030,  0.1692, -0.0963,  ...,  0.2336, -0.2548,  0.1269],\n",
            "        [ 0.1449, -0.1346, -0.1100,  ...,  0.0070, -0.2422, -0.2447]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.4126, -0.1082,  0.2598,  ...,  0.2000, -0.3385, -0.1154],\n",
            "         [ 0.4126, -0.1082,  0.2598,  ...,  0.2000, -0.3385, -0.1154],\n",
            "         [-0.0425, -0.1797, -0.0021,  ...,  0.0401, -0.2166,  0.0564],\n",
            "         ...,\n",
            "         [ 0.1792, -0.3019, -0.1985,  ...,  0.1716,  0.0838, -0.0910],\n",
            "         [ 0.0875, -0.3248,  0.2632,  ...,  0.1015, -0.2377, -0.1244],\n",
            "         [-0.1292, -0.3030,  0.1197,  ..., -0.1027,  0.1426, -0.0023]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2491, -0.4412,  0.6127,  ...,  0.1793, -0.5883, -0.3271],\n",
            "        [ 0.2491, -0.4412,  0.6127,  ...,  0.1793, -0.5883, -0.3271],\n",
            "        [ 0.0825, -0.2456,  0.2555,  ...,  0.0534, -0.4275, -0.1443],\n",
            "        ...,\n",
            "        [ 0.1151, -0.3066,  0.1916,  ...,  0.0125, -0.2671, -0.2599],\n",
            "        [ 0.0058, -0.5143,  0.6483,  ..., -0.1286, -0.6237, -0.4049],\n",
            "        [-0.3663, -0.0930, -0.0664,  ..., -0.1908,  0.2014,  0.1936]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1160,  0.0644,  0.0015,  ..., -0.0422,  0.1007,  0.0804],\n",
            "        [-0.0576,  0.0744, -0.0161,  ..., -0.0367,  0.0160,  0.0665],\n",
            "        [-0.0576,  0.0744, -0.0161,  ..., -0.0367,  0.0160,  0.0665],\n",
            "        ...,\n",
            "        [ 0.1997, -0.2596, -0.1178,  ...,  0.1452, -0.2706, -0.2220],\n",
            "        [ 0.3345,  0.2237, -0.0239,  ...,  0.0970, -0.0785, -0.3835],\n",
            "        [ 0.4036, -0.1193,  0.1352,  ..., -0.1413, -0.0779, -0.1561]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1013, -0.4087,  0.2059,  ...,  0.0668, -0.2560, -0.1519],\n",
            "         [-0.0955, -0.2004,  0.0679,  ...,  0.0170,  0.1510,  0.4219],\n",
            "         [ 0.3312, -0.1282,  0.3713,  ...,  0.0772, -0.2408, -0.1391],\n",
            "         ...,\n",
            "         [-0.0156, -0.3151,  0.1957,  ..., -0.0960, -0.0606, -0.0965],\n",
            "         [ 0.4257, -0.0949,  0.3481,  ...,  0.3379, -0.1433, -0.2084],\n",
            "         [ 0.3507, -0.1513,  0.2115,  ..., -0.0361, -0.1166, -0.0652]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0853, -0.6439,  0.5945,  ..., -0.1074, -0.7133, -0.3704],\n",
            "        [-0.3056, -0.0133, -0.0593,  ..., -0.0458,  0.1658,  0.3727],\n",
            "        [ 0.1703, -0.4934,  0.6396,  ...,  0.0385, -0.6216, -0.3591],\n",
            "        ...,\n",
            "        [-0.0584, -0.5431,  0.6281,  ..., -0.2154, -0.5161, -0.3426],\n",
            "        [ 0.3090, -0.4035,  0.6194,  ...,  0.1303, -0.5487, -0.3600],\n",
            "        [ 0.1420, -0.4547,  0.5900,  ..., -0.1029, -0.5969, -0.2845]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1443, -0.0297, -0.0114,  ..., -0.1321,  0.1026, -0.1183],\n",
            "        [-0.0579,  0.0744, -0.0164,  ..., -0.0366,  0.0162,  0.0663],\n",
            "        [ 0.0752, -0.1733,  0.0989,  ..., -0.1958,  0.1047,  0.2852],\n",
            "        ...,\n",
            "        [ 0.3912, -0.1832,  0.1311,  ...,  0.3722, -0.2045, -0.2482],\n",
            "        [-0.1994, -0.2933,  0.1078,  ..., -0.0616, -0.3416, -0.0964],\n",
            "        [ 0.0953,  0.2285, -0.0829,  ..., -0.0248, -0.0397, -0.1385]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1439,  0.3404,  0.0498,  ..., -0.0877, -0.0528, -0.0238],\n",
            "         [ 0.3514, -0.1373,  0.3643,  ...,  0.1194, -0.2817, -0.1612],\n",
            "         [ 0.3908, -0.0429,  0.1402,  ...,  0.1084, -0.1079, -0.1853],\n",
            "         ...,\n",
            "         [ 0.4096, -0.1863,  0.3217,  ..., -0.0020, -0.2587, -0.1233],\n",
            "         [ 0.3341, -0.1735,  0.0450,  ...,  0.0054, -0.0617, -0.2154],\n",
            "         [ 0.0699, -0.3890,  0.1265,  ...,  0.0255, -0.1264, -0.1318]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1938,  0.5648,  0.0169,  ...,  0.2204, -0.0267, -0.2526],\n",
            "        [ 0.1318, -0.4435,  0.6012,  ...,  0.0023, -0.6015, -0.3649],\n",
            "        [ 0.1629, -0.3880,  0.6004,  ..., -0.0102, -0.5775, -0.3664],\n",
            "        ...,\n",
            "        [ 0.0849, -0.4440,  0.5884,  ..., -0.0744, -0.5792, -0.2799],\n",
            "        [ 0.1323, -0.3860,  0.4546,  ..., -0.0581, -0.4909, -0.3883],\n",
            "        [-0.0040, -0.5647,  0.5519,  ..., -0.1599, -0.5312, -0.4044]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0310,  0.0438,  0.0638,  ...,  0.1497,  0.0132, -0.1383],\n",
            "        [ 0.2893, -0.0696,  0.1506,  ...,  0.3187, -0.1448, -0.1325],\n",
            "        [-0.0880, -0.0237, -0.1557,  ..., -0.1065, -0.0613, -0.0564],\n",
            "        ...,\n",
            "        [ 0.2865, -0.0927, -0.0258,  ..., -0.0087, -0.1126, -0.1411],\n",
            "        [ 0.0667, -0.0426,  0.1287,  ..., -0.0371, -0.0233, -0.0470],\n",
            "        [ 0.3340, -0.1679,  0.0448,  ...,  0.0064, -0.0612, -0.2152]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0737,  0.0412,  0.0108,  ..., -0.0863,  0.2283,  0.1535],\n",
            "         [ 0.1518, -0.0087,  0.1829,  ..., -0.0244, -0.0748, -0.0948],\n",
            "         [-0.1248, -0.0693,  0.0305,  ...,  0.1992,  0.1834,  0.2780],\n",
            "         ...,\n",
            "         [ 0.2865, -0.0927, -0.0258,  ..., -0.0087, -0.1126, -0.1411],\n",
            "         [ 0.0667, -0.0426,  0.1287,  ..., -0.0371, -0.0233, -0.0470],\n",
            "         [ 0.3340, -0.1679,  0.0448,  ...,  0.0064, -0.0612, -0.2152]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0875, -0.1662,  0.2992,  ..., -0.0976, -0.1226, -0.0636],\n",
            "        [ 0.0904, -0.1640,  0.2986,  ..., -0.0174, -0.2773, -0.1637],\n",
            "        [-0.2014, -0.0051, -0.0393,  ...,  0.0530,  0.1967,  0.2925],\n",
            "        ...,\n",
            "        [ 0.2869, -0.2421,  0.3015,  ...,  0.1136, -0.4572, -0.3327],\n",
            "        [ 0.0461, -0.2090,  0.3147,  ..., -0.0410, -0.3010, -0.1811],\n",
            "        [ 0.1352, -0.3791,  0.4512,  ..., -0.0545, -0.4880, -0.3879]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0612,  0.0870,  0.1269,  ...,  0.0203,  0.0355, -0.0885],\n",
            "        [-0.2076, -0.0761, -0.0053,  ...,  0.1685, -0.1723, -0.0935],\n",
            "        [ 0.1904,  0.0920, -0.0265,  ..., -0.0253,  0.2609, -0.0272],\n",
            "        ...,\n",
            "        [ 0.1500, -0.1005,  0.4042,  ...,  0.1365, -0.1208, -0.1224],\n",
            "        [ 0.2824, -0.2574,  0.0854,  ..., -0.0669, -0.0344, -0.1547],\n",
            "        [-0.1810,  0.0474,  0.1552,  ..., -0.0544,  0.2623,  0.0086]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0344,  0.5378, -0.0190,  ...,  0.2506, -0.0101,  0.0319],\n",
            "         [ 0.2642, -0.2740,  0.0869,  ...,  0.1950, -0.1761, -0.1653],\n",
            "         [-0.0113,  0.2382, -0.0502,  ...,  0.1927,  0.0795,  0.1225],\n",
            "         ...,\n",
            "         [ 0.3144, -0.5686,  0.0529,  ...,  0.1087, -0.0933, -0.3161],\n",
            "         [ 0.3665, -0.0382, -0.0860,  ..., -0.0162, -0.0673, -0.1328],\n",
            "         [ 0.0589,  0.2616,  0.2148,  ...,  0.0534, -0.1321, -0.1752]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 2.6344e-01,  6.2009e-01, -8.3912e-02,  ...,  4.1313e-01,\n",
            "          8.8541e-02, -1.4806e-01],\n",
            "        [ 2.5845e-01, -2.3304e-01,  3.7543e-01,  ...,  1.4359e-01,\n",
            "         -4.7093e-01, -3.0116e-01],\n",
            "        [ 2.0986e-01,  4.3486e-01, -1.1110e-01,  ...,  3.8197e-01,\n",
            "          1.0752e-01, -3.3882e-02],\n",
            "        ...,\n",
            "        [ 2.5745e-01, -7.2637e-01,  5.7331e-01,  ..., -4.6807e-05,\n",
            "         -5.9578e-01, -5.4276e-01],\n",
            "        [ 1.8662e-01, -1.8395e-01,  1.8218e-01,  ...,  8.2002e-03,\n",
            "         -3.2457e-01, -2.4356e-01],\n",
            "        [ 3.4857e-01,  4.9869e-01,  6.4191e-02,  ...,  3.3487e-01,\n",
            "         -1.2154e-01, -3.1217e-01]], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0252, -0.1069, -0.0405,  ...,  0.0949,  0.0900, -0.0921],\n",
            "        [ 0.2905, -0.0690,  0.1523,  ...,  0.3178, -0.1433, -0.1316],\n",
            "        [ 0.2905, -0.0690,  0.1523,  ...,  0.3178, -0.1433, -0.1316],\n",
            "        ...,\n",
            "        [-0.0438, -0.0424,  0.1878,  ...,  0.1065, -0.0146,  0.0366],\n",
            "        [ 0.2980, -0.1247,  0.3186,  ...,  0.0215, -0.2820, -0.1212],\n",
            "        [ 0.2115,  0.0388,  0.2622,  ...,  0.0968, -0.1039, -0.1592]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0438, -0.0424,  0.1878,  ...,  0.1065, -0.0146,  0.0366],\n",
            "         [ 0.2980, -0.1247,  0.3186,  ...,  0.0215, -0.2820, -0.1212],\n",
            "         [ 0.2115,  0.0388,  0.2622,  ...,  0.0968, -0.1039, -0.1592],\n",
            "         ...,\n",
            "         [ 0.0024, -0.1384, -0.0723,  ..., -0.1075,  0.1106, -0.1350],\n",
            "         [ 0.0807, -0.0262, -0.1213,  ...,  0.0502, -0.0771, -0.1051],\n",
            "         [ 0.0871,  0.1297, -0.0309,  ...,  0.2255,  0.1751,  0.0575]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0089, -0.2156,  0.4192,  ...,  0.0452, -0.2620, -0.1177],\n",
            "        [ 0.0965, -0.2975,  0.4411,  ..., -0.0160, -0.5033, -0.2473],\n",
            "        [ 0.1840, -0.2069,  0.4912,  ..., -0.0143, -0.4055, -0.2639],\n",
            "        ...,\n",
            "        [-0.0080, -0.1139,  0.0556,  ..., -0.0783,  0.0179,  0.0120],\n",
            "        [ 0.0625, -0.0442,  0.0329,  ...,  0.0176, -0.1360, -0.1421],\n",
            "        [ 0.1024,  0.0552,  0.0546,  ...,  0.1155, -0.0334, -0.0318]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0586,  0.0745, -0.0172,  ..., -0.0363,  0.0166,  0.0658],\n",
            "        [-0.0586,  0.0745, -0.0172,  ..., -0.0363,  0.0166,  0.0658],\n",
            "        [-0.0586,  0.0745, -0.0172,  ..., -0.0363,  0.0166,  0.0658],\n",
            "        ...,\n",
            "        [-0.1123, -0.2390,  0.0868,  ..., -0.0202, -0.2477, -0.1263],\n",
            "        [ 0.3118, -0.0865,  0.1493,  ..., -0.1630, -0.2995, -0.1771],\n",
            "        [-0.1584,  0.3285,  0.0981,  ...,  0.1428, -0.2941, -0.0940]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1584,  0.3285,  0.0981,  ...,  0.1428, -0.2941, -0.0940],\n",
            "         [-0.0978,  0.3766,  0.1406,  ...,  0.2241, -0.2181, -0.1415],\n",
            "         [-0.1332, -0.0252,  0.0834,  ...,  0.0013, -0.1763, -0.0782],\n",
            "         ...,\n",
            "         [ 0.0799,  0.2258, -0.0925,  ...,  0.0867, -0.2357, -0.0289],\n",
            "         [-0.2771,  0.0974,  0.1178,  ...,  0.0955, -0.3316, -0.0485],\n",
            "         [ 0.0862,  0.0398,  0.1365,  ...,  0.4176, -0.2447, -0.1111]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2709,  0.6892, -0.0732,  ...,  0.5064,  0.0236, -0.4131],\n",
            "        [ 0.3518,  0.6183,  0.2021,  ...,  0.4715, -0.2441, -0.5282],\n",
            "        [-0.0666,  0.1165, -0.0652,  ...,  0.0906,  0.0757, -0.0898],\n",
            "        ...,\n",
            "        [ 0.3487,  0.4377, -0.0630,  ...,  0.3303, -0.1487, -0.1551],\n",
            "        [ 0.1584,  0.5123, -0.0920,  ...,  0.4855,  0.0144, -0.2427],\n",
            "        [ 0.5068,  0.4534,  0.0462,  ...,  0.6365, -0.1183, -0.5089]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2918, -0.0676,  0.1539,  ...,  0.3182, -0.1419, -0.1310],\n",
            "        [ 0.2918, -0.0676,  0.1539,  ...,  0.3182, -0.1419, -0.1310],\n",
            "        [-0.1189,  0.0829, -0.0659,  ..., -0.0660, -0.0200,  0.0474],\n",
            "        ...,\n",
            "        [ 0.1325,  0.1400,  0.0514,  ...,  0.5664, -0.1225, -0.1170],\n",
            "        [ 0.1684,  0.0321,  0.0152,  ...,  0.1875, -0.0111, -0.0149],\n",
            "        [ 0.3642, -0.1302,  0.1694,  ...,  0.0175,  0.0367, -0.0984]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.2714,  0.3306,  0.1288,  ..., -0.0020, -0.1861, -0.0668],\n",
            "         [-0.2714,  0.3306,  0.1288,  ..., -0.0020, -0.1861, -0.0668],\n",
            "         [ 0.1909,  0.1784,  0.0953,  ...,  0.0458, -0.2331, -0.2144],\n",
            "         ...,\n",
            "         [ 0.1325,  0.1400,  0.0514,  ...,  0.5664, -0.1225, -0.1170],\n",
            "         [ 0.1684,  0.0321,  0.0152,  ...,  0.1875, -0.0111, -0.0149],\n",
            "         [ 0.3642, -0.1302,  0.1694,  ...,  0.0175,  0.0367, -0.0984]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1850,  0.6366, -0.0231,  ...,  0.3985,  0.0064, -0.4132],\n",
            "        [ 0.1850,  0.6366, -0.0231,  ...,  0.3985,  0.0064, -0.4132],\n",
            "        [ 0.2317, -0.1540,  0.5020,  ...,  0.0776, -0.5191, -0.3523],\n",
            "        ...,\n",
            "        [ 0.2893,  0.3012, -0.0441,  ...,  0.4073, -0.0457, -0.1537],\n",
            "        [ 0.1485, -0.1584,  0.3627,  ...,  0.1365, -0.4117, -0.2613],\n",
            "        [ 0.2495, -0.3924,  0.5572,  ..., -0.0209, -0.3851, -0.2697]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.2070, -0.0126,  0.0067,  ...,  0.0996, -0.0441, -0.0414],\n",
            "        [ 0.0175,  0.0377, -0.1027,  ..., -0.1985,  0.0177,  0.0714],\n",
            "        [-0.0587,  0.0745, -0.0174,  ..., -0.0361,  0.0168,  0.0658],\n",
            "        ...,\n",
            "        [ 0.0826,  0.2252,  0.1194,  ...,  0.1488, -0.3794, -0.1383],\n",
            "        [-0.1152, -0.1989,  0.1439,  ...,  0.1282, -0.2910, -0.1621],\n",
            "        [ 0.4185, -0.0854,  0.2667,  ...,  0.2034, -0.3355, -0.1161]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.2045,  0.2620,  0.0518,  ...,  0.2616,  0.0342,  0.0825],\n",
            "         [-0.0600, -0.2460,  0.0662,  ..., -0.1097, -0.0508, -0.1002],\n",
            "         [-0.1267,  0.3645,  0.0186,  ...,  0.2378, -0.1154,  0.1266],\n",
            "         ...,\n",
            "         [ 0.3069, -0.1157,  0.2084,  ...,  0.0519,  0.0672, -0.1107],\n",
            "         [-0.1235, -0.2981,  0.1229,  ..., -0.1076,  0.1431, -0.0032],\n",
            "         [ 0.1305,  0.2519,  0.2195,  ...,  0.0808, -0.1659,  0.0458]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0357,  0.2415,  0.0121,  ...,  0.2512,  0.0445, -0.0453],\n",
            "        [-0.0957, -0.3545,  0.4392,  ..., -0.1741, -0.3847, -0.2591],\n",
            "        [ 0.1801,  0.4878, -0.0637,  ...,  0.4014,  0.0017, -0.1276],\n",
            "        ...,\n",
            "        [ 0.2451, -0.3630,  0.5526,  ...,  0.0466, -0.3431, -0.2716],\n",
            "        [-0.3747, -0.0971, -0.0632,  ..., -0.1988,  0.2115,  0.2010],\n",
            "        [ 0.1754,  0.2046,  0.3874,  ...,  0.1352, -0.3832, -0.1955]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0722,  0.0863, -0.1330,  ..., -0.1169,  0.1379,  0.0716],\n",
            "        [-0.0588,  0.0747, -0.0175,  ..., -0.0360,  0.0169,  0.0656],\n",
            "        [-0.0588,  0.0747, -0.0175,  ..., -0.0360,  0.0169,  0.0656],\n",
            "        ...,\n",
            "        [ 0.1678,  0.2405,  0.0723,  ...,  0.1227, -0.0128,  0.0342],\n",
            "        [ 0.0968, -0.1898,  0.3203,  ...,  0.1668, -0.1428, -0.1264],\n",
            "        [ 0.2053, -0.0837,  0.3326,  ...,  0.0886, -0.2140, -0.3765]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2330, -0.0494,  0.1038,  ...,  0.1635, -0.1354, -0.1461],\n",
            "         [ 0.3577,  0.1902,  0.1105,  ...,  0.1687, -0.3197, -0.3067],\n",
            "         [-0.1113,  0.0498,  0.1640,  ..., -0.0794, -0.2898, -0.0866],\n",
            "         ...,\n",
            "         [-0.2746,  0.3350,  0.1259,  ...,  0.0038, -0.1805, -0.0629],\n",
            "         [ 0.5353,  0.0136, -0.0678,  ...,  0.1203, -0.1335, -0.2766],\n",
            "         [-0.2746,  0.3350,  0.1259,  ...,  0.0038, -0.1805, -0.0629]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2107, -0.2188,  0.4407,  ...,  0.1495, -0.4352, -0.2790],\n",
            "        [ 0.3958,  0.0293,  0.4890,  ...,  0.3916, -0.5640, -0.5238],\n",
            "        [-0.0099,  0.0213,  0.3347,  ..., -0.0884, -0.3178, -0.3482],\n",
            "        ...,\n",
            "        [ 0.1818,  0.6486, -0.0421,  ...,  0.4134,  0.0288, -0.4026],\n",
            "        [ 0.2310, -0.1510,  0.2908,  ...,  0.1016, -0.4649, -0.3741],\n",
            "        [ 0.1818,  0.6486, -0.0421,  ...,  0.4134,  0.0288, -0.4026]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0597, -0.0421, -0.0914,  ..., -0.0784,  0.0612, -0.0521],\n",
            "        [ 0.0833,  0.0177,  0.1992,  ...,  0.0349, -0.1316, -0.0484],\n",
            "        [-0.0587,  0.0748, -0.0176,  ..., -0.0361,  0.0172,  0.0656],\n",
            "        ...,\n",
            "        [ 0.1045,  0.1501,  0.3800,  ...,  0.1711, -0.0077, -0.1205],\n",
            "        [ 0.4157,  0.0016,  0.1764,  ...,  0.1439, -0.1276, -0.2087],\n",
            "        [ 0.0643,  0.1483,  0.0983,  ..., -0.0568, -0.1401, -0.1187]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1437,  0.2556,  0.1405,  ...,  0.1640, -0.1340, -0.0250],\n",
            "         [ 0.1045,  0.1501,  0.3800,  ...,  0.1711, -0.0077, -0.1205],\n",
            "         [ 0.4157,  0.0016,  0.1764,  ...,  0.1439, -0.1276, -0.2087],\n",
            "         ...,\n",
            "         [-0.0256, -0.1872, -0.0465,  ..., -0.1031,  0.0031, -0.2001],\n",
            "         [-0.1230,  0.2801, -0.0854,  ...,  0.3224,  0.0403, -0.0211],\n",
            "         [ 0.1333, -0.0726, -0.0530,  ...,  0.0502,  0.0059, -0.0134]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2670, -0.0028,  0.3460,  ...,  0.1671, -0.3298, -0.2108],\n",
            "        [ 0.1403, -0.1253,  0.5306,  ...,  0.0996, -0.3413, -0.3037],\n",
            "        [ 0.2071, -0.3952,  0.6330,  ...,  0.0466, -0.6018, -0.4095],\n",
            "        ...,\n",
            "        [-0.0018, -0.2520,  0.1724,  ..., -0.0911, -0.1542, -0.2043],\n",
            "        [ 0.1028,  0.4540, -0.1440,  ...,  0.4165,  0.0826, -0.0978],\n",
            "        [ 0.0528, -0.2095,  0.2474,  ...,  0.0010, -0.2634, -0.1947]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0657, -0.1377, -0.0836,  ...,  0.0263, -0.0397,  0.0741],\n",
            "        [ 0.0373,  0.1314, -0.0267,  ...,  0.0779,  0.0589, -0.0755],\n",
            "        [ 0.0746, -0.0389, -0.0501,  ...,  0.0670, -0.1139, -0.0562],\n",
            "        ...,\n",
            "        [ 0.0667,  0.0655,  0.1517,  ...,  0.3964, -0.0178, -0.0894],\n",
            "        [-0.4388, -0.0475,  0.0241,  ...,  0.1246,  0.1576,  0.3822],\n",
            "        [ 0.6537,  0.1739,  0.0946,  ..., -0.0486, -0.2461, -0.3370]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1456,  0.0195,  0.0803,  ...,  0.0124, -0.1396, -0.1383],\n",
            "         [ 0.2475,  0.2984,  0.3701,  ...,  0.4352, -0.0739, -0.1531],\n",
            "         [ 0.1979,  0.2789, -0.0647,  ..., -0.0141, -0.4028, -0.1308],\n",
            "         ...,\n",
            "         [-0.4388, -0.0475,  0.0241,  ...,  0.1246,  0.1576,  0.3822],\n",
            "         [ 0.6537,  0.1739,  0.0946,  ..., -0.0486, -0.2461, -0.3370],\n",
            "         [ 0.1133, -0.1442,  0.1083,  ...,  0.1978, -0.3571, -0.1347]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3124, -0.0050,  0.4436,  ...,  0.2032, -0.5433, -0.3938],\n",
            "        [ 0.4430,  0.0588,  0.6653,  ...,  0.4030, -0.4401, -0.4352],\n",
            "        [ 0.2338, -0.2202,  0.4625,  ...,  0.0274, -0.6623, -0.4278],\n",
            "        ...,\n",
            "        [-0.5138, -0.0071, -0.0775,  ..., -0.0387,  0.1792,  0.3971],\n",
            "        [ 0.2539, -0.3765,  0.6248,  ..., -0.0442, -0.6735, -0.4428],\n",
            "        [ 0.1752, -0.5454,  0.5756,  ...,  0.0394, -0.6702, -0.4768]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0587,  0.0750, -0.0178,  ..., -0.0362,  0.0176,  0.0656],\n",
            "        [-0.0015,  0.0125, -0.0766,  ..., -0.0010, -0.0296, -0.0508],\n",
            "        [ 0.0746, -0.0391, -0.0501,  ...,  0.0670, -0.1138, -0.0564],\n",
            "        ...,\n",
            "        [ 0.2578,  0.0481,  0.1630,  ...,  0.4998, -0.1667, -0.3127],\n",
            "        [ 0.2996,  0.1658,  0.0424,  ..., -0.0331, -0.0506, -0.1568],\n",
            "        [ 0.1101, -0.0737, -0.1056,  ...,  0.0399, -0.2369, -0.2326]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1101, -0.0737, -0.1056,  ...,  0.0399, -0.2369, -0.2326],\n",
            "         [-0.1124, -0.1918,  0.0263,  ...,  0.1726, -0.1828, -0.1127],\n",
            "         [ 0.3555,  0.0322,  0.4052,  ...,  0.5004, -0.1306, -0.2111],\n",
            "         ...,\n",
            "         [ 0.2578,  0.0481,  0.1630,  ...,  0.4998, -0.1667, -0.3127],\n",
            "         [ 0.2996,  0.1658,  0.0424,  ..., -0.0331, -0.0506, -0.1568],\n",
            "         [ 0.1101, -0.0737, -0.1056,  ...,  0.0399, -0.2369, -0.2326]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1616, -0.2821,  0.2969,  ...,  0.0491, -0.4649, -0.3514],\n",
            "        [ 0.1430,  0.0559, -0.0009,  ...,  0.1943, -0.0430, -0.1245],\n",
            "        [ 0.4100, -0.4465,  0.7777,  ...,  0.2644, -0.6015, -0.4846],\n",
            "        ...,\n",
            "        [ 0.4633,  0.3181,  0.1084,  ...,  0.5678, -0.2552, -0.4094],\n",
            "        [ 0.4370,  0.2517,  0.2917,  ...,  0.2787, -0.3523, -0.4278],\n",
            "        [ 0.1616, -0.2821,  0.2969,  ...,  0.0491, -0.4649, -0.3514]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1424,  0.0948, -0.1481,  ..., -0.0510, -0.0022, -0.0710],\n",
            "        [ 0.1135,  0.2814,  0.0052,  ...,  0.1966,  0.0219, -0.0589],\n",
            "        [-0.0588,  0.0751, -0.0179,  ..., -0.0362,  0.0177,  0.0654],\n",
            "        ...,\n",
            "        [ 0.2642,  0.1151,  0.1010,  ...,  0.0459, -0.2635, -0.2328],\n",
            "        [ 0.1322, -0.2241, -0.0453,  ..., -0.0471,  0.0039,  0.0756],\n",
            "        [-0.0982,  0.2694,  0.0604,  ...,  0.2227, -0.0262, -0.0099]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1322, -0.2241, -0.0453,  ..., -0.0471,  0.0039,  0.0756],\n",
            "         [-0.0982,  0.2694,  0.0604,  ...,  0.2227, -0.0262, -0.0099],\n",
            "         [-0.0352,  0.5130,  0.1129,  ..., -0.0226, -0.0919, -0.1043],\n",
            "         ...,\n",
            "         [ 0.4023, -0.1711,  0.0929,  ...,  0.1772, -0.0152, -0.1893],\n",
            "         [ 0.2156,  0.1321,  0.1293,  ...,  0.0709,  0.0396, -0.0344],\n",
            "         [ 0.2642,  0.1151,  0.1010,  ...,  0.0459, -0.2635, -0.2328]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0943, -0.0684, -0.0714,  ..., -0.0971,  0.1143,  0.1833],\n",
            "        [ 0.0479,  0.2559,  0.0324,  ...,  0.2876,  0.0242, -0.1383],\n",
            "        [ 0.4900,  0.7709, -0.1111,  ...,  0.4799,  0.0932, -0.4406],\n",
            "        ...,\n",
            "        [ 0.3137, -0.3602,  0.4334,  ...,  0.1154, -0.4294, -0.4050],\n",
            "        [ 0.2909, -0.0843,  0.4999,  ..., -0.0223, -0.3730, -0.2954],\n",
            "        [ 0.2557, -0.0468,  0.4139,  ...,  0.0724, -0.4452, -0.3743]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0589,  0.0752, -0.0179,  ..., -0.0362,  0.0177,  0.0651],\n",
            "        [-0.0589,  0.0752, -0.0179,  ..., -0.0362,  0.0177,  0.0651],\n",
            "        [-0.0589,  0.0752, -0.0179,  ..., -0.0362,  0.0177,  0.0651],\n",
            "        ...,\n",
            "        [ 0.4466, -0.4873,  0.1661,  ...,  0.2962, -0.0657, -0.3769],\n",
            "        [ 0.4466, -0.4873,  0.1661,  ...,  0.2962, -0.0657, -0.3769],\n",
            "        [ 0.4466, -0.4873,  0.1661,  ...,  0.2962, -0.0657, -0.3769]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.4466, -0.4873,  0.1661,  ...,  0.2962, -0.0657, -0.3769],\n",
            "         [ 0.4466, -0.4873,  0.1661,  ...,  0.2962, -0.0657, -0.3769],\n",
            "         [ 0.4466, -0.4873,  0.1661,  ...,  0.2962, -0.0657, -0.3769],\n",
            "         ...,\n",
            "         [ 0.4466, -0.4873,  0.1661,  ...,  0.2962, -0.0657, -0.3769],\n",
            "         [ 0.4466, -0.4873,  0.1661,  ...,  0.2962, -0.0657, -0.3769],\n",
            "         [ 0.4466, -0.4873,  0.1661,  ...,  0.2962, -0.0657, -0.3769]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3214, -0.7017,  0.6700,  ...,  0.0369, -0.6083, -0.6067],\n",
            "        [ 0.3214, -0.7017,  0.6700,  ...,  0.0369, -0.6083, -0.6067],\n",
            "        [ 0.3214, -0.7017,  0.6700,  ...,  0.0369, -0.6083, -0.6067],\n",
            "        ...,\n",
            "        [ 0.3214, -0.7017,  0.6700,  ...,  0.0369, -0.6083, -0.6067],\n",
            "        [ 0.3214, -0.7017,  0.6700,  ...,  0.0369, -0.6083, -0.6067],\n",
            "        [ 0.3214, -0.7017,  0.6700,  ...,  0.0369, -0.6083, -0.6067]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.3031, -0.0471,  0.1719,  ...,  0.3365, -0.1301, -0.1361],\n",
            "        [ 0.3031, -0.0471,  0.1719,  ...,  0.3365, -0.1301, -0.1361],\n",
            "        [-0.0590,  0.0753, -0.0180,  ..., -0.0362,  0.0178,  0.0650],\n",
            "        ...,\n",
            "        [ 0.3456, -0.0747, -0.0690,  ...,  0.0242, -0.0142, -0.2889],\n",
            "        [-0.2879,  0.3806,  0.1077,  ...,  0.0341, -0.1737, -0.0531],\n",
            "        [ 0.4391, -0.1227,  0.1185,  ..., -0.0284,  0.0383, -0.1389]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3456, -0.0747, -0.0690,  ...,  0.0242, -0.0142, -0.2889],\n",
            "         [-0.2879,  0.3806,  0.1077,  ...,  0.0341, -0.1737, -0.0531],\n",
            "         [ 0.4391, -0.1227,  0.1185,  ..., -0.0284,  0.0383, -0.1389],\n",
            "         ...,\n",
            "         [-0.0283, -0.1714,  0.1306,  ...,  0.1205, -0.2429, -0.1038],\n",
            "         [ 0.2741, -0.2368,  0.1767,  ...,  0.0420, -0.2958, -0.1469],\n",
            "         [ 0.2741, -0.2368,  0.1767,  ...,  0.0420, -0.2958, -0.1469]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2476, -0.2499,  0.3163,  ..., -0.0362, -0.4155, -0.4283],\n",
            "        [ 0.2217,  0.7163, -0.0910,  ...,  0.5050,  0.0821, -0.3861],\n",
            "        [ 0.2320, -0.3856,  0.4686,  ...,  0.0052, -0.3731, -0.2963],\n",
            "        ...,\n",
            "        [ 0.2276, -0.1958,  0.4014,  ...,  0.1859, -0.4823, -0.4605],\n",
            "        [ 0.1158, -0.6194,  0.7033,  ..., -0.1425, -0.7620, -0.4355],\n",
            "        [ 0.1158, -0.6194,  0.7033,  ..., -0.1425, -0.7620, -0.4355]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0590,  0.0754, -0.0180,  ..., -0.0362,  0.0176,  0.0648],\n",
            "        [-0.0590,  0.0754, -0.0180,  ..., -0.0362,  0.0176,  0.0648],\n",
            "        [-0.0590,  0.0754, -0.0180,  ..., -0.0362,  0.0176,  0.0648],\n",
            "        ...,\n",
            "        [ 0.4480, -0.4854,  0.1667,  ...,  0.3018, -0.0659, -0.3804],\n",
            "        [ 0.4480, -0.4854,  0.1667,  ...,  0.3018, -0.0659, -0.3804],\n",
            "        [ 0.4480, -0.4854,  0.1667,  ...,  0.3018, -0.0659, -0.3804]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.4480, -0.4854,  0.1667,  ...,  0.3018, -0.0659, -0.3804],\n",
            "         [ 0.4480, -0.4854,  0.1667,  ...,  0.3018, -0.0659, -0.3804],\n",
            "         [ 0.4480, -0.4854,  0.1667,  ...,  0.3018, -0.0659, -0.3804],\n",
            "         ...,\n",
            "         [ 0.4480, -0.4854,  0.1667,  ...,  0.3018, -0.0659, -0.3804],\n",
            "         [ 0.4480, -0.4854,  0.1667,  ...,  0.3018, -0.0659, -0.3804],\n",
            "         [ 0.4480, -0.4854,  0.1667,  ...,  0.3018, -0.0659, -0.3804]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3213, -0.7036,  0.6726,  ...,  0.0429, -0.6099, -0.6084],\n",
            "        [ 0.3213, -0.7036,  0.6726,  ...,  0.0429, -0.6099, -0.6084],\n",
            "        [ 0.3213, -0.7036,  0.6726,  ...,  0.0429, -0.6099, -0.6084],\n",
            "        ...,\n",
            "        [ 0.3213, -0.7036,  0.6726,  ...,  0.0429, -0.6099, -0.6084],\n",
            "        [ 0.3213, -0.7036,  0.6726,  ...,  0.0429, -0.6099, -0.6084],\n",
            "        [ 0.3213, -0.7036,  0.6726,  ...,  0.0429, -0.6099, -0.6084]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0071,  0.0710,  0.0244,  ...,  0.0431,  0.1065,  0.0155],\n",
            "        [-0.0589,  0.0755, -0.0179,  ..., -0.0363,  0.0174,  0.0647],\n",
            "        [ 0.2024, -0.0490,  0.0145,  ..., -0.0018,  0.0476,  0.0644],\n",
            "        ...,\n",
            "        [ 0.2587, -0.3024,  0.1690,  ...,  0.0157, -0.2872, -0.1439],\n",
            "        [ 0.1067,  0.3138,  0.0110,  ..., -0.0809, -0.2041, -0.2470],\n",
            "        [-0.1349, -0.2643,  0.1075,  ..., -0.0906,  0.1593,  0.0065]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1067,  0.3138,  0.0110,  ..., -0.0809, -0.2041, -0.2470],\n",
            "         [-0.1349, -0.2643,  0.1075,  ..., -0.0906,  0.1593,  0.0065],\n",
            "         [ 0.0301,  0.1588,  0.1622,  ...,  0.3807, -0.2275, -0.0975],\n",
            "         ...,\n",
            "         [ 0.2587, -0.3024,  0.1690,  ...,  0.0157, -0.2872, -0.1439],\n",
            "         [ 0.2587, -0.3024,  0.1690,  ...,  0.0157, -0.2872, -0.1439],\n",
            "         [ 0.2587, -0.3024,  0.1690,  ...,  0.0157, -0.2872, -0.1439]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3076,  0.3641,  0.2770,  ...,  0.2326, -0.3858, -0.3672],\n",
            "        [-0.4267, -0.0698, -0.0788,  ..., -0.2048,  0.2025,  0.2399],\n",
            "        [ 0.4287,  0.5530, -0.0117,  ...,  0.5962, -0.0461, -0.4291],\n",
            "        ...,\n",
            "        [ 0.0936, -0.6230,  0.6972,  ..., -0.1442, -0.7549, -0.4147],\n",
            "        [ 0.0936, -0.6230,  0.6972,  ..., -0.1442, -0.7549, -0.4147],\n",
            "        [ 0.0936, -0.6230,  0.6972,  ..., -0.1442, -0.7549, -0.4147]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0754, -0.0394, -0.0494,  ...,  0.0662, -0.1126, -0.0559],\n",
            "        [-0.0152, -0.1874, -0.0425,  ..., -0.0613, -0.1013, -0.0090],\n",
            "        [-0.0940,  0.0696, -0.0090,  ...,  0.0404, -0.0533, -0.0178],\n",
            "        ...,\n",
            "        [ 0.3403, -0.0556,  0.2689,  ..., -0.0264, -0.1735, -0.0327],\n",
            "        [ 0.3740, -0.1817,  0.3844,  ..., -0.0033, -0.2511, -0.1625],\n",
            "        [-0.1203,  0.1679,  0.1932,  ...,  0.0073, -0.2961, -0.1394]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3403, -0.0556,  0.2689,  ..., -0.0264, -0.1735, -0.0327],\n",
            "         [ 0.3740, -0.1817,  0.3844,  ..., -0.0033, -0.2511, -0.1625],\n",
            "         [-0.1203,  0.1679,  0.1932,  ...,  0.0073, -0.2961, -0.1394],\n",
            "         ...,\n",
            "         [-0.0554, -0.1123, -0.1913,  ...,  0.0445, -0.1247, -0.0394],\n",
            "         [ 0.2645, -0.1101,  0.3405,  ...,  0.1080, -0.2894, -0.1609],\n",
            "         [ 0.4264, -0.0799,  0.2398,  ...,  0.3358, -0.2689, -0.2671]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1794, -0.3385,  0.4995,  ..., -0.0139, -0.4883, -0.2061],\n",
            "        [ 0.1692, -0.4120,  0.5600,  ..., -0.0335, -0.5518, -0.3276],\n",
            "        [ 0.2512,  0.4542,  0.0980,  ...,  0.2390, -0.1150, -0.4556],\n",
            "        ...,\n",
            "        [ 0.0856, -0.1533,  0.0460,  ...,  0.0637, -0.2937, -0.1988],\n",
            "        [ 0.0934, -0.3054,  0.4596,  ...,  0.0398, -0.4919, -0.2932],\n",
            "        [ 0.2169, -0.3529,  0.5473,  ...,  0.1621, -0.6088, -0.4103]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0593,  0.0756, -0.0179,  ..., -0.0362,  0.0169,  0.0642],\n",
            "        [ 0.3036, -0.0514,  0.1696,  ...,  0.3339, -0.1282, -0.1373],\n",
            "        [ 0.1075,  0.1546, -0.0974,  ...,  0.1237,  0.0701, -0.0247],\n",
            "        ...,\n",
            "        [ 0.3186, -0.3058,  0.0684,  ...,  0.0218, -0.0431, -0.0901],\n",
            "        [-0.1540,  0.1302,  0.0507,  ...,  0.2800, -0.2752, -0.0937],\n",
            "        [ 0.1514,  0.2131,  0.2985,  ...,  0.0592, -0.0473,  0.1573]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1558, -0.0665,  0.1486,  ..., -0.0062,  0.1370,  0.0889],\n",
            "         [ 0.0480, -0.1710, -0.1568,  ..., -0.0860, -0.0548,  0.0570],\n",
            "         [-0.2094,  0.1110,  0.1135,  ...,  0.0444,  0.0067, -0.0005],\n",
            "         ...,\n",
            "         [ 0.3186, -0.3058,  0.0684,  ...,  0.0218, -0.0431, -0.0901],\n",
            "         [-0.1540,  0.1302,  0.0507,  ...,  0.2800, -0.2752, -0.0937],\n",
            "         [ 0.1514,  0.2131,  0.2985,  ...,  0.0592, -0.0473,  0.1573]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0193, -0.2692,  0.3626,  ..., -0.0787, -0.1948, -0.0421],\n",
            "        [-0.0608, -0.0938, -0.0406,  ..., -0.1537, -0.0703,  0.0430],\n",
            "        [-0.2850,  0.1110,  0.0294,  ...,  0.0011,  0.1066,  0.0425],\n",
            "        ...,\n",
            "        [ 0.1480, -0.4030,  0.4541,  ..., -0.0927, -0.4485, -0.3036],\n",
            "        [ 0.2399,  0.5547, -0.0999,  ...,  0.5490,  0.0647, -0.3571],\n",
            "        [ 0.1691, -0.1014,  0.5381,  ...,  0.0535, -0.4332, -0.1351]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0757, -0.0389, -0.0490,  ...,  0.0652, -0.1107, -0.0543],\n",
            "        [-0.0595,  0.0756, -0.0179,  ..., -0.0357,  0.0166,  0.0635],\n",
            "        [-0.0491,  0.0379, -0.0841,  ..., -0.0170,  0.0168,  0.0154],\n",
            "        ...,\n",
            "        [ 0.2653,  0.2139,  0.3871,  ...,  0.5602, -0.1121, -0.1777],\n",
            "        [ 0.4007, -0.0259,  0.1345,  ..., -0.1211, -0.0794, -0.1658],\n",
            "        [-0.0102,  0.2348,  0.1768,  ...,  0.0052, -0.0588, -0.0920]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2610, -0.2759,  0.1321,  ...,  0.1239, -0.2335, -0.2182],\n",
            "         [-0.2957,  0.1397,  0.0962,  ...,  0.1280, -0.3143, -0.0191],\n",
            "         [ 0.2867,  0.1043,  0.2712,  ...,  0.1240, -0.0598, -0.1724],\n",
            "         ...,\n",
            "         [ 0.1742,  0.2233,  0.0632,  ...,  0.2516, -0.2126, -0.0670],\n",
            "         [ 0.0020,  0.1922, -0.2151,  ...,  0.0057,  0.0450, -0.1843],\n",
            "         [ 0.2259, -0.0879,  0.1470,  ..., -0.1072,  0.0043, -0.1394]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2098, -0.4383,  0.4810,  ...,  0.1211, -0.5474, -0.3985],\n",
            "        [ 0.0985,  0.5296, -0.0812,  ...,  0.5458,  0.0236, -0.0868],\n",
            "        [ 0.3377, -0.3158,  0.6603,  ...,  0.0533, -0.5059, -0.4207],\n",
            "        ...,\n",
            "        [ 0.3223,  0.4195,  0.0230,  ...,  0.3983, -0.0916, -0.2350],\n",
            "        [ 0.1099,  0.3383, -0.1057,  ...,  0.1275,  0.0794, -0.1587],\n",
            "        [ 0.1199, -0.3936,  0.6049,  ..., -0.1324, -0.4944, -0.2846]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.1191,  0.0831, -0.0650,  ..., -0.0676, -0.0220,  0.0474],\n",
            "        [ 0.1147, -0.0533, -0.1204,  ..., -0.0614,  0.0492, -0.1846],\n",
            "        [ 0.0030,  0.1158,  0.0079,  ...,  0.0336, -0.0762,  0.0150],\n",
            "        ...,\n",
            "        [ 0.1348,  0.2946,  0.0900,  ..., -0.1195, -0.1218, -0.2553],\n",
            "        [ 0.0264, -0.1541,  0.2585,  ...,  0.0427, -0.2664,  0.0157],\n",
            "        [ 0.2583, -0.3572,  0.1612,  ..., -0.0223, -0.2790, -0.1431]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0429, -0.1526,  0.1460,  ...,  0.0182,  0.1049, -0.0607],\n",
            "         [ 0.2583, -0.3572,  0.1612,  ..., -0.0223, -0.2790, -0.1431],\n",
            "         [ 0.1727,  0.0106, -0.0045,  ..., -0.0159, -0.1784, -0.1486],\n",
            "         ...,\n",
            "         [-0.2129,  0.5147, -0.0648,  ...,  0.0262,  0.1001,  0.0698],\n",
            "         [ 0.3274, -0.0836,  0.0220,  ...,  0.3647, -0.2126, -0.1068],\n",
            "         [ 0.2094,  0.1080,  0.2765,  ...,  0.2321, -0.1174, -0.1753]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0489,  0.0317,  0.0201,  ...,  0.0670,  0.1007, -0.0090],\n",
            "        [ 0.0762, -0.6233,  0.6988,  ..., -0.1466, -0.7543, -0.3961],\n",
            "        [ 0.1321, -0.1442,  0.3002,  ..., -0.0477, -0.4305, -0.2688],\n",
            "        ...,\n",
            "        [ 0.1897,  0.6488, -0.1522,  ...,  0.3482,  0.1307,  0.0497],\n",
            "        [ 0.1984,  0.0569,  0.0150,  ...,  0.2316, -0.2078, -0.0928],\n",
            "        [ 0.3197, -0.2929,  0.6512,  ...,  0.1586, -0.5337, -0.3951]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.1211,  0.0437, -0.1089,  ...,  0.0604, -0.0431,  0.1303],\n",
            "        [ 0.0519, -0.0977,  0.1100,  ..., -0.0918,  0.0848, -0.0969],\n",
            "        [-0.0598,  0.0754, -0.0177,  ..., -0.0351,  0.0160,  0.0625],\n",
            "        ...,\n",
            "        [-0.2084,  0.1409,  0.0717,  ...,  0.0363, -0.3123, -0.1791],\n",
            "        [ 0.0019, -0.2059,  0.1825,  ..., -0.0894, -0.0528, -0.0825],\n",
            "        [ 0.3658,  0.1386, -0.1462,  ..., -0.0272,  0.0062, -0.1566]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0018, -0.0250,  0.0417,  ...,  0.1902, -0.0589, -0.1925],\n",
            "         [-0.0211, -0.0886,  0.0747,  ...,  0.0214,  0.2385, -0.1063],\n",
            "         [-0.0753,  0.3075,  0.1424,  ...,  0.2085, -0.1328, -0.3134],\n",
            "         ...,\n",
            "         [ 0.2705,  0.0366, -0.0200,  ..., -0.0545,  0.1265,  0.0596],\n",
            "         [-0.1484,  0.0457,  0.1457,  ..., -0.1399, -0.1413, -0.1462],\n",
            "         [ 0.0957, -0.0922,  0.2164,  ..., -0.0613, -0.0727, -0.2441]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1908, -0.1300,  0.3628,  ...,  0.1798, -0.4236, -0.4074],\n",
            "        [ 0.0170,  0.0898, -0.0796,  ...,  0.2096,  0.1777,  0.0931],\n",
            "        [ 0.1758,  0.1867,  0.4412,  ...,  0.2717, -0.4347, -0.4151],\n",
            "        ...,\n",
            "        [ 0.2144, -0.1693,  0.3295,  ..., -0.0096, -0.2299, -0.1026],\n",
            "        [-0.0122, -0.3978,  0.5692,  ..., -0.1869, -0.5624, -0.4405],\n",
            "        [ 0.1477, -0.1258,  0.3427,  ..., -0.0665, -0.3046, -0.2575]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0599,  0.0754, -0.0176,  ..., -0.0349,  0.0158,  0.0620],\n",
            "        [-0.0599,  0.0754, -0.0176,  ..., -0.0349,  0.0158,  0.0620],\n",
            "        [-0.0599,  0.0754, -0.0176,  ..., -0.0349,  0.0158,  0.0620],\n",
            "        ...,\n",
            "        [-0.0200,  0.2517,  0.0051,  ...,  0.0901, -0.2449, -0.1133],\n",
            "        [ 0.1532,  0.5487,  0.0690,  ...,  0.0051,  0.0173, -0.1905],\n",
            "        [-0.1213,  0.1099,  0.1142,  ..., -0.0341, -0.2822, -0.1307]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1213,  0.1099,  0.1142,  ..., -0.0341, -0.2822, -0.1307],\n",
            "         [ 0.1532,  0.5487,  0.0690,  ...,  0.0051,  0.0173, -0.1905],\n",
            "         [ 0.4476, -0.5427,  0.1611,  ...,  0.2697, -0.0679, -0.3859],\n",
            "         ...,\n",
            "         [ 0.4476, -0.5427,  0.1611,  ...,  0.2697, -0.0679, -0.3859],\n",
            "         [ 0.4476, -0.5427,  0.1611,  ...,  0.2697, -0.0679, -0.3859],\n",
            "         [ 0.3774,  0.0482, -0.0186,  ...,  0.1795, -0.0905, -0.1998]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0551, -0.3836,  0.5679,  ..., -0.1176, -0.6380, -0.4083],\n",
            "        [ 0.5397,  0.7207, -0.0517,  ...,  0.4747, -0.0370, -0.4752],\n",
            "        [ 0.2780, -0.7350,  0.6915,  ..., -0.0231, -0.6274, -0.5975],\n",
            "        ...,\n",
            "        [ 0.2780, -0.7350,  0.6915,  ..., -0.0231, -0.6274, -0.5975],\n",
            "        [ 0.2780, -0.7350,  0.6915,  ..., -0.0231, -0.6274, -0.5975],\n",
            "        [ 0.2249, -0.1881,  0.3708,  ...,  0.0655, -0.4873, -0.4152]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0600,  0.0753, -0.0175,  ..., -0.0347,  0.0157,  0.0616],\n",
            "        [-0.0600,  0.0753, -0.0175,  ..., -0.0347,  0.0157,  0.0616],\n",
            "        [-0.0796, -0.0282,  0.1169,  ...,  0.0734, -0.0215, -0.0784],\n",
            "        ...,\n",
            "        [ 0.1945,  0.2360, -0.0056,  ..., -0.0665, -0.1775, -0.1465],\n",
            "        [ 0.2206, -0.0875,  0.1510,  ..., -0.0773,  0.0204, -0.1022],\n",
            "        [ 0.0812,  0.1548,  0.1278,  ..., -0.1336,  0.0617,  0.0056]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3541, -0.0196,  0.2393,  ..., -0.0809, -0.0607, -0.2107],\n",
            "         [ 0.2206, -0.0875,  0.1510,  ..., -0.0773,  0.0204, -0.1022],\n",
            "         [ 0.1227, -0.2137,  0.1144,  ..., -0.0747, -0.1528,  0.0086],\n",
            "         ...,\n",
            "         [-0.0564, -0.2609,  0.1780,  ..., -0.0612, -0.0402, -0.0892],\n",
            "         [-0.0845,  0.1188,  0.0897,  ...,  0.2422, -0.0810,  0.0087],\n",
            "         [ 0.1287, -0.1782, -0.0763,  ..., -0.0183,  0.0521,  0.1342]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1301, -0.2692,  0.5229,  ..., -0.1277, -0.4368, -0.2790],\n",
            "        [ 0.0935, -0.2518,  0.4158,  ..., -0.0670, -0.3036, -0.1970],\n",
            "        [ 0.1679, -0.4655,  0.5120,  ..., -0.1032, -0.5171, -0.2224],\n",
            "        ...,\n",
            "        [-0.0434, -0.4908,  0.5329,  ..., -0.1847, -0.4075, -0.3213],\n",
            "        [ 0.2942,  0.4589, -0.0732,  ...,  0.5025,  0.0556, -0.2093],\n",
            "        [ 0.0088, -0.0764, -0.0551,  ..., -0.0542,  0.1018,  0.1517]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0600,  0.0753, -0.0174,  ..., -0.0344,  0.0155,  0.0612],\n",
            "        [-0.0600,  0.0753, -0.0174,  ..., -0.0344,  0.0155,  0.0612],\n",
            "        [-0.0600,  0.0753, -0.0174,  ..., -0.0344,  0.0155,  0.0612],\n",
            "        ...,\n",
            "        [ 0.4491, -0.5583,  0.1616,  ...,  0.2607, -0.0689, -0.3892],\n",
            "        [ 0.4491, -0.5583,  0.1616,  ...,  0.2607, -0.0689, -0.3892],\n",
            "        [ 0.4491, -0.5583,  0.1616,  ...,  0.2607, -0.0689, -0.3892]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.4491, -0.5583,  0.1616,  ...,  0.2607, -0.0689, -0.3892],\n",
            "         [ 0.4491, -0.5583,  0.1616,  ...,  0.2607, -0.0689, -0.3892],\n",
            "         [ 0.4491, -0.5583,  0.1616,  ...,  0.2607, -0.0689, -0.3892],\n",
            "         ...,\n",
            "         [ 0.0635,  0.3878,  0.0456,  ...,  0.1212, -0.2801, -0.1164],\n",
            "         [-0.1018,  0.0220,  0.1092,  ..., -0.0414,  0.0600,  0.1626],\n",
            "         [ 0.3764, -0.1170, -0.0730,  ...,  0.0314, -0.1156, -0.1197]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2662, -0.7428,  0.6990,  ..., -0.0386, -0.6339, -0.5967],\n",
            "        [ 0.2662, -0.7428,  0.6990,  ..., -0.0386, -0.6339, -0.5967],\n",
            "        [ 0.2662, -0.7428,  0.6990,  ..., -0.0386, -0.6339, -0.5967],\n",
            "        ...,\n",
            "        [ 0.0788,  0.1657,  0.2397,  ...,  0.1070, -0.4469, -0.2888],\n",
            "        [-0.1374,  0.0146,  0.0637,  ..., -0.0860,  0.0994,  0.1582],\n",
            "        [ 0.1282, -0.4610,  0.4184,  ..., -0.0607, -0.5759, -0.3191]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0600,  0.0753, -0.0173,  ..., -0.0342,  0.0154,  0.0608],\n",
            "        [-0.0004,  0.0982, -0.1310,  ...,  0.0360, -0.0022,  0.0247],\n",
            "        [-0.0561, -0.0410, -0.0904,  ..., -0.0793,  0.0647, -0.0492],\n",
            "        ...,\n",
            "        [ 0.1827, -0.1964, -0.0841,  ...,  0.0160,  0.0444, -0.0954],\n",
            "        [ 0.4165,  0.0082,  0.2244,  ..., -0.0100,  0.0665, -0.0971],\n",
            "        [ 0.0976,  0.0885,  0.0580,  ..., -0.0852, -0.0622, -0.1032]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0819,  0.1326,  0.1875,  ...,  0.0717, -0.1010, -0.0824],\n",
            "         [ 0.1853, -0.2048,  0.0398,  ...,  0.1126, -0.1569, -0.1548],\n",
            "         [ 0.1317, -0.0436,  0.1485,  ..., -0.1586, -0.0605, -0.0872],\n",
            "         ...,\n",
            "         [ 0.1827, -0.1964, -0.0841,  ...,  0.0160,  0.0444, -0.0954],\n",
            "         [ 0.4165,  0.0082,  0.2244,  ..., -0.0100,  0.0665, -0.0971],\n",
            "         [ 0.0976,  0.0885,  0.0580,  ..., -0.0852, -0.0622, -0.1032]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1414, -0.2558,  0.5701,  ...,  0.0561, -0.4888, -0.3243],\n",
            "        [ 0.1276, -0.2051,  0.2128,  ...,  0.1050, -0.3195, -0.2563],\n",
            "        [ 0.2751, -0.2977,  0.5182,  ..., -0.0282, -0.4393, -0.4028],\n",
            "        ...,\n",
            "        [ 0.2214, -0.2053,  0.1018,  ..., -0.0582, -0.1856, -0.1951],\n",
            "        [ 0.2470, -0.4144,  0.6581,  ..., -0.0356, -0.4876, -0.3327],\n",
            "        [ 0.1576, -0.3022,  0.4550,  ..., -0.0227, -0.4836, -0.2725]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2912, -0.0606,  0.1527,  ...,  0.3347, -0.1348, -0.1464],\n",
            "        [-0.0201, -0.0220, -0.0637,  ..., -0.0031, -0.0201, -0.1644],\n",
            "        [-0.1181,  0.0823, -0.0635,  ..., -0.0677, -0.0239,  0.0457],\n",
            "        ...,\n",
            "        [-0.0551, -0.0979,  0.2415,  ..., -0.0362, -0.1618, -0.1437],\n",
            "        [ 0.0593,  0.1186,  0.1027,  ..., -0.0099, -0.1020, -0.1074],\n",
            "        [ 0.1750, -0.0311, -0.1515,  ...,  0.1724, -0.1409, -0.1691]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1750, -0.0311, -0.1515,  ...,  0.1724, -0.1409, -0.1691],\n",
            "         [ 0.2371, -0.0477,  0.3267,  ...,  0.5229, -0.1306, -0.1694],\n",
            "         [ 0.1324, -0.0572,  0.1569,  ...,  0.0116,  0.0603, -0.0392],\n",
            "         ...,\n",
            "         [ 0.1359,  0.0139, -0.0085,  ...,  0.2304, -0.1435, -0.1349],\n",
            "         [-0.0551, -0.0979,  0.2415,  ..., -0.0362, -0.1618, -0.1437],\n",
            "         [ 0.0593,  0.1186,  0.1027,  ..., -0.0099, -0.1020, -0.1074]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1952,  0.1912, -0.0348,  ...,  0.2405, -0.0700, -0.2626],\n",
            "        [ 0.3438, -0.3671,  0.6292,  ...,  0.3089, -0.5185, -0.4120],\n",
            "        [ 0.2175, -0.3674,  0.5801,  ...,  0.0642, -0.4182, -0.3239],\n",
            "        ...,\n",
            "        [ 0.1576, -0.1948,  0.3645,  ...,  0.0794, -0.4224, -0.3212],\n",
            "        [ 0.0290, -0.4577,  0.6507,  ..., -0.0828, -0.5980, -0.3184],\n",
            "        [ 0.1287, -0.2405,  0.4799,  ..., -0.0735, -0.4432, -0.4005]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2898, -0.0620,  0.1501,  ...,  0.3340, -0.1352, -0.1465],\n",
            "        [ 0.2898, -0.0620,  0.1501,  ...,  0.3340, -0.1352, -0.1465],\n",
            "        [ 0.2898, -0.0620,  0.1501,  ...,  0.3340, -0.1352, -0.1465],\n",
            "        ...,\n",
            "        [-0.1474,  0.3849,  0.0042,  ..., -0.0281,  0.1110, -0.0062],\n",
            "        [-0.0076, -0.1727, -0.0698,  ...,  0.0935, -0.0730,  0.0371],\n",
            "        [ 0.2230, -0.1540, -0.0241,  ...,  0.0688,  0.0272, -0.1464]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1055,  0.2967,  0.2834,  ...,  0.1565, -0.2277,  0.0342],\n",
            "         [ 0.1073,  0.2840,  0.2519,  ...,  0.1467, -0.2295,  0.0653],\n",
            "         [ 0.0997,  0.4088,  0.2464,  ...,  0.1805, -0.2513,  0.0305],\n",
            "         ...,\n",
            "         [ 0.1804,  0.1368,  0.3496,  ..., -0.1060,  0.0147, -0.0015],\n",
            "         [ 0.0635,  0.2453,  0.3205,  ...,  0.0956, -0.0909, -0.2585],\n",
            "         [ 0.2200,  0.0219,  0.2003,  ...,  0.2263, -0.0252, -0.1986]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4868,  0.6308, -0.0656,  ...,  0.6179, -0.0228, -0.1316],\n",
            "        [ 0.4554,  0.5935, -0.0717,  ...,  0.5784, -0.0102, -0.0596],\n",
            "        [ 0.5739,  0.7438, -0.0948,  ...,  0.7018, -0.0259, -0.2172],\n",
            "        ...,\n",
            "        [ 0.1406, -0.3494,  0.6880,  ..., -0.1344, -0.5030, -0.2572],\n",
            "        [ 0.2602,  0.0929,  0.5865,  ...,  0.1915, -0.5159, -0.4619],\n",
            "        [ 0.6098,  0.5497,  0.3106,  ...,  0.7129, -0.3508, -0.6199]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0177,  0.0923,  0.0599,  ..., -0.0174,  0.0037,  0.0461],\n",
            "        [-0.0603,  0.0753, -0.0171,  ..., -0.0338,  0.0150,  0.0600],\n",
            "        [ 0.1266,  0.0022, -0.0355,  ...,  0.2218, -0.0066,  0.0324],\n",
            "        ...,\n",
            "        [ 0.0122,  0.0677,  0.3072,  ...,  0.1763, -0.3429, -0.3099],\n",
            "        [ 0.2839, -0.0184, -0.0625,  ...,  0.1687, -0.1128, -0.2014],\n",
            "        [ 0.2690, -0.4030,  0.1538,  ..., -0.0796, -0.2605, -0.1426]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3954,  0.0153,  0.2840,  ..., -0.2054,  0.0801, -0.0770],\n",
            "         [ 0.2634,  0.0351,  0.2799,  ..., -0.0866, -0.1228, -0.0521],\n",
            "         [ 0.1785,  0.0038,  0.1195,  ..., -0.1932, -0.2481, -0.1433],\n",
            "         ...,\n",
            "         [ 0.2976,  0.3236,  0.2688,  ..., -0.1814, -0.2603, -0.4318],\n",
            "         [-0.2478, -0.0882,  0.0769,  ..., -0.3115, -0.0308, -0.0086],\n",
            "         [-0.1678,  0.2077,  0.1254,  ...,  0.2882, -0.2201, -0.1545]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1415, -0.3722,  0.6393,  ..., -0.1296, -0.4669, -0.2437],\n",
            "        [ 0.1488, -0.3293,  0.6108,  ..., -0.1221, -0.5212, -0.1923],\n",
            "        [ 0.1130, -0.1685,  0.3209,  ..., -0.1533, -0.3233, -0.1727],\n",
            "        ...,\n",
            "        [ 0.3615, -0.0408,  0.6476,  ...,  0.0313, -0.5833, -0.5031],\n",
            "        [-0.3684,  0.0265, -0.0598,  ..., -0.2336,  0.1318,  0.2085],\n",
            "        [ 0.3221,  0.5223, -0.0024,  ...,  0.5737, -0.1015, -0.4566]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0602,  0.0752, -0.0171,  ..., -0.0337,  0.0149,  0.0599],\n",
            "        [-0.0831,  0.1209,  0.0699,  ..., -0.1098,  0.1255, -0.0382],\n",
            "        [-0.0602,  0.0752, -0.0171,  ..., -0.0337,  0.0149,  0.0599],\n",
            "        ...,\n",
            "        [-0.2601,  0.2587,  0.0029,  ...,  0.1427, -0.1415, -0.0661],\n",
            "        [ 0.0973,  0.0871, -0.0029,  ..., -0.1065, -0.1046, -0.0521],\n",
            "        [ 0.2405, -0.2614,  0.1793,  ...,  0.0960, -0.1588, -0.1533]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.2601,  0.2587,  0.0029,  ...,  0.1427, -0.1415, -0.0661],\n",
            "         [ 0.0193,  0.0674,  0.0067,  ..., -0.0109, -0.1837, -0.0056],\n",
            "         [ 0.1382, -0.1838,  0.0515,  ...,  0.1682, -0.2093, -0.1422],\n",
            "         ...,\n",
            "         [ 0.0483,  0.2153,  0.1488,  ...,  0.1146, -0.3875, -0.1688],\n",
            "         [ 0.2649, -0.0869,  0.1215,  ...,  0.1621, -0.0206, -0.2246],\n",
            "         [-0.4393, -0.0210,  0.0310,  ...,  0.1479,  0.1508,  0.3602]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1527,  0.6220, -0.1242,  ...,  0.5750,  0.0902, -0.1579],\n",
            "        [-0.0292, -0.2915,  0.4390,  ..., -0.1245, -0.5381, -0.1867],\n",
            "        [ 0.2510,  0.0343,  0.0163,  ...,  0.2758, -0.1834, -0.2573],\n",
            "        ...,\n",
            "        [ 0.3298,  0.5317, -0.0409,  ...,  0.4297, -0.1756, -0.3162],\n",
            "        [ 0.1869, -0.5851,  0.6935,  ..., -0.0692, -0.6069, -0.4624],\n",
            "        [-0.5432,  0.0045, -0.0776,  ..., -0.0310,  0.1788,  0.4138]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0603,  0.0749, -0.0170,  ..., -0.0338,  0.0148,  0.0599],\n",
            "        [-0.0603,  0.0749, -0.0170,  ..., -0.0338,  0.0148,  0.0599],\n",
            "        [-0.0603,  0.0749, -0.0170,  ..., -0.0338,  0.0148,  0.0599],\n",
            "        ...,\n",
            "        [ 0.1414,  0.2733,  0.0847,  ...,  0.1577, -0.1669, -0.1254],\n",
            "        [-0.1679,  0.4187, -0.0787,  ...,  0.0611,  0.0631, -0.0544],\n",
            "        [ 0.0193, -0.1709,  0.0018,  ...,  0.1052, -0.1445, -0.0917]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2598,  0.0607,  0.0415,  ..., -0.2209,  0.2227, -0.0042],\n",
            "         [-0.0138, -0.1688, -0.0745,  ...,  0.0950, -0.0695,  0.0420],\n",
            "         [ 0.2022,  0.0733, -0.0560,  ...,  0.0662, -0.1549, -0.0653],\n",
            "         ...,\n",
            "         [ 0.1414,  0.2733,  0.0847,  ...,  0.1577, -0.1669, -0.1254],\n",
            "         [-0.1679,  0.4187, -0.0787,  ...,  0.0611,  0.0631, -0.0544],\n",
            "         [ 0.0193, -0.1709,  0.0018,  ...,  0.1052, -0.1445, -0.0917]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1096, -0.2048,  0.4087,  ..., -0.1695, -0.2517, -0.1927],\n",
            "        [-0.2291, -0.0921, -0.0776,  ..., -0.0314,  0.0411,  0.1534],\n",
            "        [-0.0022, -0.1893,  0.2355,  ..., -0.0038, -0.4263, -0.1407],\n",
            "        ...,\n",
            "        [ 0.0964,  0.0440,  0.3458,  ...,  0.0946, -0.3623, -0.2732],\n",
            "        [ 0.1792,  0.4881, -0.1537,  ...,  0.3596,  0.0920, -0.0363],\n",
            "        [-0.0763, -0.2539,  0.1800,  ...,  0.0429, -0.3072, -0.1416]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0466, -0.0127, -0.0417,  ...,  0.0979, -0.0079,  0.0048],\n",
            "        [-0.0604,  0.0747, -0.0171,  ..., -0.0339,  0.0147,  0.0600],\n",
            "        [ 0.0766, -0.0230, -0.0539,  ...,  0.0695, -0.0951, -0.0482],\n",
            "        ...,\n",
            "        [ 0.2979, -0.0283,  0.0787,  ..., -0.0095, -0.0607, -0.0611],\n",
            "        [-0.0152,  0.2196,  0.1005,  ...,  0.0676, -0.1961,  0.0062],\n",
            "        [ 0.1055,  0.1843,  0.4310,  ..., -0.1176, -0.0189,  0.0100]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0152,  0.2196,  0.1005,  ...,  0.0676, -0.1961,  0.0062],\n",
            "         [ 0.1055,  0.1843,  0.4310,  ..., -0.1176, -0.0189,  0.0100],\n",
            "         [ 0.2032, -0.4939,  0.2502,  ...,  0.0430, -0.2196, -0.1469],\n",
            "         ...,\n",
            "         [ 0.0111, -0.3326,  0.0671,  ...,  0.0328, -0.0520, -0.3873],\n",
            "         [ 0.1077,  0.1028,  0.0839,  ..., -0.0847,  0.0595, -0.0370],\n",
            "         [ 0.2979, -0.0283,  0.0787,  ..., -0.0095, -0.0607, -0.0611]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0085,  0.2134,  0.0466,  ...,  0.0714, -0.2090, -0.0746],\n",
            "        [ 0.1716, -0.1678,  0.5952,  ..., -0.0426, -0.4420, -0.2457],\n",
            "        [ 0.0376, -0.6570,  0.7482,  ..., -0.1556, -0.7178, -0.4541],\n",
            "        ...,\n",
            "        [ 0.2104, -0.4539,  0.4802,  ...,  0.0568, -0.4704, -0.4537],\n",
            "        [ 0.2883,  0.0268,  0.3160,  ...,  0.1103, -0.2587, -0.2599],\n",
            "        [ 0.2199, -0.1847,  0.3299,  ..., -0.0053, -0.3079, -0.1479]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.1338,  0.0038,  0.0458,  ...,  0.0656, -0.0678, -0.0065],\n",
            "        [-0.0605,  0.0745, -0.0170,  ..., -0.0339,  0.0146,  0.0600],\n",
            "        [ 0.2855, -0.0688,  0.1409,  ...,  0.3285, -0.1387, -0.1463],\n",
            "        ...,\n",
            "        [-0.0439,  0.1206,  0.0258,  ...,  0.1154, -0.1649, -0.0811],\n",
            "        [ 0.2904, -0.1877, -0.1321,  ..., -0.1375, -0.2155, -0.1174],\n",
            "        [-0.1894,  0.4373,  0.0855,  ...,  0.2367, -0.3001, -0.1057]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2793, -0.2438,  0.0150,  ..., -0.0253, -0.2647, -0.0777],\n",
            "         [-0.1413,  0.3441,  0.0602,  ...,  0.3512, -0.3079, -0.1241],\n",
            "         [ 0.2334, -0.1223, -0.0029,  ...,  0.0295, -0.1922, -0.1984],\n",
            "         ...,\n",
            "         [-0.0439,  0.1206,  0.0258,  ...,  0.1154, -0.1649, -0.0811],\n",
            "         [ 0.2904, -0.1877, -0.1321,  ..., -0.1375, -0.2155, -0.1174],\n",
            "         [-0.1894,  0.4373,  0.0855,  ...,  0.2367, -0.3001, -0.1057]]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1312, -0.3987,  0.4332,  ..., -0.0225, -0.5293, -0.2474],\n",
            "        [ 0.4628,  0.7519, -0.1001,  ...,  0.7087,  0.0251, -0.5518],\n",
            "        [ 0.1594, -0.2470,  0.2811,  ...,  0.0439, -0.4329, -0.3336],\n",
            "        ...,\n",
            "        [ 0.3507,  0.4372, -0.1196,  ...,  0.3880, -0.0322, -0.2201],\n",
            "        [ 0.0459, -0.2636,  0.2509,  ..., -0.0917, -0.3961, -0.1969],\n",
            "        [ 0.4307,  0.8071, -0.0921,  ...,  0.6885,  0.0385, -0.5112]],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1080,  0.1191, -0.1119,  ..., -0.0344, -0.0703, -0.0451],\n",
            "        [ 0.2850, -0.0701,  0.1396,  ...,  0.3276, -0.1394, -0.1464],\n",
            "        [-0.0606,  0.0743, -0.0170,  ..., -0.0340,  0.0145,  0.0600],\n",
            "        ...,\n",
            "        [ 0.1885, -0.0220,  0.2009,  ..., -0.0542,  0.2219, -0.0316],\n",
            "        [ 0.1297,  0.3347,  0.2037,  ..., -0.0612, -0.1149, -0.3935],\n",
            "        [ 0.0590,  0.2269, -0.0883,  ..., -0.0040, -0.0281, -0.1058]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 1.6514e-01, -9.6198e-03,  1.9680e-02,  ..., -5.8148e-02,\n",
            "          -4.2022e-04,  2.1354e-02],\n",
            "         [ 1.8849e-01, -2.2016e-02,  2.0087e-01,  ..., -5.4162e-02,\n",
            "           2.2188e-01, -3.1602e-02],\n",
            "         [ 1.2970e-01,  3.3471e-01,  2.0372e-01,  ..., -6.1177e-02,\n",
            "          -1.1489e-01, -3.9350e-01],\n",
            "         ...,\n",
            "         [ 2.7550e-01, -3.1469e-04,  5.6089e-02,  ...,  3.2751e-01,\n",
            "          -2.1632e-01, -2.3864e-01],\n",
            "         [-7.1490e-02,  5.6811e-02,  1.0509e-01,  ...,  1.2315e-01,\n",
            "          -1.0360e-01, -6.1775e-02],\n",
            "         [ 5.8615e-02, -3.8618e-02, -2.6039e-02,  ...,  1.3779e-01,\n",
            "           1.5637e-01, -1.6360e-01]]], device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1876,  0.0671,  0.0926,  ...,  0.1242, -0.0782, -0.1004],\n",
            "        [ 0.2489, -0.3668,  0.5931,  ..., -0.0736, -0.3626, -0.2759],\n",
            "        [ 0.1660, -0.0649,  0.5185,  ...,  0.0345, -0.4756, -0.3708],\n",
            "        ...,\n",
            "        [ 0.2011, -0.1109,  0.2755,  ...,  0.1645, -0.4039, -0.2768],\n",
            "        [-0.0342, -0.0310,  0.1837,  ...,  0.0404, -0.1691, -0.0880],\n",
            "        [ 0.1097,  0.0596, -0.0429,  ...,  0.1414,  0.0999, -0.0546]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[-0.0116,  0.0413, -0.0167,  ...,  0.1247,  0.1702, -0.1868],\n",
            "        [ 0.2850, -0.0701,  0.1396,  ...,  0.3276, -0.1394, -0.1464],\n",
            "        [-0.0509, -0.1000,  0.1569,  ...,  0.2708, -0.0815,  0.0355],\n",
            "        ...,\n",
            "        [-0.0178,  0.3283,  0.0298,  ...,  0.2271,  0.1422, -0.3666],\n",
            "        [ 0.1570, -0.0672,  0.1571,  ..., -0.1125, -0.2592, -0.1307],\n",
            "        [ 0.2431,  0.0987,  0.0977,  ...,  0.2038,  0.1131, -0.3084]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[-0.3091,  0.4079,  0.0739,  ...,  0.4155,  0.0514, -0.1462],\n",
            "         [ 0.2240,  0.1683,  0.1061,  ...,  0.1538,  0.1440, -0.3375],\n",
            "         [ 0.0591,  0.1240, -0.0449,  ...,  0.1233,  0.0359, -0.2494],\n",
            "         ...,\n",
            "         [ 0.0627,  0.0078,  0.0579,  ...,  0.0569,  0.0508, -0.1752],\n",
            "         [ 0.2143, -0.1658,  0.2010,  ..., -0.1119, -0.0687, -0.0077],\n",
            "         [ 0.4309,  0.0124,  0.1153,  ...,  0.2294,  0.0351, -0.3136]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2772,  0.7317, -0.0880,  ...,  0.6996,  0.1383, -0.4918],\n",
            "        [ 0.3329,  0.2622,  0.3394,  ...,  0.3498, -0.2750, -0.3959],\n",
            "        [ 0.1900,  0.2046,  0.0706,  ...,  0.2197, -0.1921, -0.2964],\n",
            "        ...,\n",
            "        [ 0.0480, -0.0694,  0.1919,  ...,  0.0077, -0.1798, -0.1312],\n",
            "        [ 0.3001, -0.3013,  0.3513,  ..., -0.0306, -0.2879, -0.1302],\n",
            "        [ 0.3106, -0.1529,  0.4748,  ...,  0.1955, -0.3905, -0.3895]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[-0.0606,  0.0743, -0.0170,  ..., -0.0340,  0.0145,  0.0600],\n",
            "        [ 0.2850, -0.0701,  0.1396,  ...,  0.3276, -0.1394, -0.1464],\n",
            "        [-0.0946, -0.0069, -0.0475,  ..., -0.0173,  0.0540,  0.0924],\n",
            "        ...,\n",
            "        [ 0.4619,  0.1441,  0.0711,  ...,  0.1322,  0.0124, -0.1967],\n",
            "        [ 0.0563,  0.2381,  0.3200,  ...,  0.0894, -0.0852, -0.2413],\n",
            "        [ 0.1482,  0.5262, -0.0172,  ...,  0.3963, -0.0151, -0.2847]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.4449, -0.1074,  0.1188,  ...,  0.1389,  0.0937, -0.3084],\n",
            "         [ 0.2797,  0.0462,  0.1099,  ...,  0.0128,  0.1487, -0.2236],\n",
            "         [ 0.1562, -0.2888,  0.1495,  ...,  0.3898, -0.2899, -0.1371],\n",
            "         ...,\n",
            "         [ 0.0417, -0.1020,  0.1251,  ...,  0.0194, -0.0487, -0.1366],\n",
            "         [ 0.2817,  0.3577,  0.0709,  ...,  0.0942,  0.0729, -0.2414],\n",
            "         [ 0.1829,  0.1464,  0.0707,  ...,  0.2080,  0.1317,  0.1104]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2096, -0.4912,  0.6149,  ...,  0.0174, -0.4703, -0.3736],\n",
            "        [ 0.2031, -0.2913,  0.5408,  ..., -0.0367, -0.3701, -0.3537],\n",
            "        [ 0.2636, -0.4221,  0.5008,  ...,  0.2561, -0.5570, -0.4789],\n",
            "        ...,\n",
            "        [ 0.0248, -0.4249,  0.5688,  ..., -0.1393, -0.5112, -0.3972],\n",
            "        [ 0.4012,  0.2997,  0.3985,  ...,  0.3103, -0.3422, -0.4698],\n",
            "        [ 0.2158,  0.1799,  0.0270,  ...,  0.2434,  0.0434, -0.0112]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[ 0.0768, -0.0169, -0.0550,  ...,  0.0724, -0.0922, -0.0484],\n",
            "        [ 0.0755, -0.0290,  0.0687,  ...,  0.0118, -0.0740,  0.0078],\n",
            "        [-0.0606,  0.0743, -0.0170,  ..., -0.0340,  0.0145,  0.0600],\n",
            "        ...,\n",
            "        [-0.0302,  0.1792,  0.1242,  ..., -0.0978, -0.2034, -0.1085],\n",
            "        [ 0.0154,  0.0323, -0.0309,  ...,  0.0219, -0.1039, -0.2095],\n",
            "        [ 0.0705,  0.5630, -0.0870,  ...,  0.3658, -0.1750,  0.0214]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.1282, -0.1829, -0.1122,  ...,  0.0545, -0.1798, -0.2348],\n",
            "         [-0.0502, -0.1625,  0.1211,  ...,  0.1457, -0.0141, -0.1075],\n",
            "         [-0.0475,  0.1393, -0.0470,  ..., -0.0377,  0.2015,  0.0845],\n",
            "         ...,\n",
            "         [ 0.1526,  0.0578,  0.2895,  ..., -0.0140,  0.1137,  0.0033],\n",
            "         [ 0.0462, -0.1232,  0.0927,  ..., -0.1133,  0.0153, -0.1513],\n",
            "         [-0.0378,  0.0649,  0.1205,  ...,  0.0163, -0.2122, -0.1261]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0614, -0.1890,  0.1525,  ..., -0.0536, -0.3088, -0.1507],\n",
            "        [ 0.0811, -0.2643,  0.3297,  ...,  0.0122, -0.2533, -0.3288],\n",
            "        [ 0.1824,  0.3332, -0.0224,  ...,  0.2097,  0.0503, -0.0223],\n",
            "        ...,\n",
            "        [ 0.2657, -0.2614,  0.5236,  ..., -0.0036, -0.3210, -0.2389],\n",
            "        [ 0.0323, -0.4911,  0.6277,  ..., -0.1643, -0.5323, -0.3435],\n",
            "        [ 0.0989, -0.1776,  0.4135,  ...,  0.0240, -0.4329, -0.4265]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[ 0.2850, -0.0701,  0.1396,  ...,  0.3276, -0.1394, -0.1464],\n",
            "        [-0.0606,  0.0743, -0.0170,  ..., -0.0340,  0.0145,  0.0600],\n",
            "        [-0.0116,  0.0413, -0.0167,  ...,  0.1247,  0.1702, -0.1868],\n",
            "        ...,\n",
            "        [ 0.0626,  0.2122,  0.0480,  ...,  0.2183,  0.1781, -0.0226],\n",
            "        [ 0.2849, -0.0148,  0.0869,  ...,  0.2858,  0.1165, -0.1066],\n",
            "        [ 0.2853, -0.5861, -0.2330,  ...,  0.0094,  0.0887, -0.3041]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.5722, -0.0029,  0.2569,  ...,  0.0414, -0.1763, -0.2245],\n",
            "         [ 0.0829,  0.2711,  0.0511,  ...,  0.1236, -0.2454, -0.1489],\n",
            "         [ 0.1206,  0.1567,  0.0274,  ...,  0.2839,  0.0643, -0.2899],\n",
            "         ...,\n",
            "         [ 0.0705,  0.5630, -0.0870,  ...,  0.3658, -0.1750,  0.0214],\n",
            "         [ 0.0619,  0.0610,  0.1479,  ..., -0.0166, -0.0891, -0.0865],\n",
            "         [ 0.1696,  0.1363,  0.1307,  ...,  0.0858,  0.1265, -0.0779]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2329, -0.4280,  0.6651,  ..., -0.0155, -0.6077, -0.4235],\n",
            "        [ 0.3922,  0.5010,  0.0637,  ...,  0.3991, -0.2037, -0.3491],\n",
            "        [ 0.2814,  0.2556,  0.2350,  ...,  0.3450, -0.3203, -0.4122],\n",
            "        ...,\n",
            "        [ 0.6135,  0.8191, -0.2048,  ...,  0.7668,  0.0411, -0.3020],\n",
            "        [ 0.1721,  0.0825,  0.0153,  ...,  0.1272, -0.0948, -0.1720],\n",
            "        [ 0.0961, -0.1199,  0.4337,  ...,  0.0035, -0.2976, -0.2184]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[-0.0606,  0.0743, -0.0170,  ..., -0.0340,  0.0145,  0.0600],\n",
            "        [-0.0606,  0.0743, -0.0170,  ..., -0.0340,  0.0145,  0.0600],\n",
            "        [-0.0606,  0.0743, -0.0170,  ..., -0.0340,  0.0145,  0.0600],\n",
            "        ...,\n",
            "        [ 0.3129, -0.2176,  0.4963,  ...,  0.2726, -0.0893, -0.1339],\n",
            "        [ 0.4406, -0.5724,  0.1526,  ...,  0.2383, -0.0673, -0.3790],\n",
            "        [ 0.4406, -0.5724,  0.1526,  ...,  0.2383, -0.0673, -0.3790]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.4406, -0.5724,  0.1526,  ...,  0.2383, -0.0673, -0.3790],\n",
            "         [ 0.4406, -0.5724,  0.1526,  ...,  0.2383, -0.0673, -0.3790],\n",
            "         [ 0.3129, -0.2176,  0.4963,  ...,  0.2726, -0.0893, -0.1339],\n",
            "         ...,\n",
            "         [-0.1915,  0.4540,  0.0859,  ...,  0.2440, -0.2981, -0.1041],\n",
            "         [ 0.0026,  0.0368,  0.1279,  ..., -0.1175, -0.2561, -0.0661],\n",
            "         [ 0.3531,  0.0326,  0.0528,  ...,  0.1365, -0.0518, -0.1171]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2416, -0.7387,  0.6927,  ..., -0.0580, -0.6269, -0.5770],\n",
            "        [ 0.2416, -0.7387,  0.6927,  ..., -0.0580, -0.6269, -0.5770],\n",
            "        [ 0.1431, -0.6744,  0.8800,  ..., -0.0037, -0.6505, -0.3502],\n",
            "        ...,\n",
            "        [ 0.4365,  0.8150, -0.0931,  ...,  0.6996,  0.0407, -0.5143],\n",
            "        [-0.0179, -0.3173,  0.4601,  ..., -0.1578, -0.5226, -0.3084],\n",
            "        [ 0.1542, -0.1042,  0.3669,  ...,  0.0414, -0.3711, -0.2559]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at every step:tensor([[-0.0606,  0.0743, -0.0170,  ..., -0.0340,  0.0145,  0.0600],\n",
            "        [-0.0606,  0.0743, -0.0170,  ..., -0.0340,  0.0145,  0.0600],\n",
            "        [-0.0606,  0.0743, -0.0170,  ..., -0.0340,  0.0145,  0.0600],\n",
            "        ...,\n",
            "        [ 0.4406, -0.5724,  0.1526,  ...,  0.2383, -0.0673, -0.3790],\n",
            "        [ 0.4406, -0.5724,  0.1526,  ...,  0.2383, -0.0673, -0.3790],\n",
            "        [ 0.4406, -0.5724,  0.1526,  ...,  0.2383, -0.0673, -0.3790]],\n",
            "       device='cuda:0')\n",
            "Output of encoder at last step:tensor([[[ 0.4406, -0.5724,  0.1526,  ...,  0.2383, -0.0673, -0.3790],\n",
            "         [ 0.4406, -0.5724,  0.1526,  ...,  0.2383, -0.0673, -0.3790],\n",
            "         [ 0.4406, -0.5724,  0.1526,  ...,  0.2383, -0.0673, -0.3790],\n",
            "         ...,\n",
            "         [ 0.4406, -0.5724,  0.1526,  ...,  0.2383, -0.0673, -0.3790],\n",
            "         [ 0.4406, -0.5724,  0.1526,  ...,  0.2383, -0.0673, -0.3790],\n",
            "         [ 0.4406, -0.5724,  0.1526,  ...,  0.2383, -0.0673, -0.3790]]],\n",
            "       device='cuda:0')\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2416, -0.7387,  0.6927,  ..., -0.0580, -0.6269, -0.5770],\n",
            "        [ 0.2416, -0.7387,  0.6927,  ..., -0.0580, -0.6269, -0.5770],\n",
            "        [ 0.2416, -0.7387,  0.6927,  ..., -0.0580, -0.6269, -0.5770],\n",
            "        ...,\n",
            "        [ 0.2416, -0.7387,  0.6927,  ..., -0.0580, -0.6269, -0.5770],\n",
            "        [ 0.2416, -0.7387,  0.6927,  ..., -0.0580, -0.6269, -0.5770],\n",
            "        [ 0.2416, -0.7387,  0.6927,  ..., -0.0580, -0.6269, -0.5770]],\n",
            "       device='cuda:0')\n",
            "\t Epoch: 9 | Train Loss: 0.054 | Train Acc: 98.56%\n",
            "\t Epoch: 9 | Val. Loss: 0.951 |  Val. Acc: 83.04% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73XPku_1feEc"
      },
      "source": [
        "### Validation of the model by passing the tweets and observing it's outcome along with printing the output from encoder and decoder time steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A3bf-t4-erR"
      },
      "source": [
        "path = 'drive/My Drive/END2/Session6-Assignment/encoder_decoder_classification_saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('drive/My Drive/END2/Session6-Assignment/tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_tweet(tweet):\n",
        "    \n",
        "    categories = {0: \"Negative\", 1:\"Positive\", 2:\"Neutral\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR8rcLfhu3ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9edab97d-f2ef-411c-bfb4-97dff3e0d678"
      },
      "source": [
        "twt=\"Today is a beautiful day\"\n",
        "print(f'Tweet : {twt}')\n",
        "print(f'Predicted Sentiment : {classify_tweet(twt)} \\n')"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tweet : Today is a beautiful day\n",
            "Output of encoder at every step:tensor([[-0.1027, -0.0503,  0.0479,  ..., -0.0233,  0.0349,  0.0769],\n",
            "        [-0.0739,  0.1454,  0.0878,  ...,  0.1310,  0.0336,  0.2236],\n",
            "        [-0.0323,  0.1598,  0.1058,  ...,  0.0845, -0.1329, -0.0104],\n",
            "        [ 0.0232,  0.1074,  0.0423,  ...,  0.1420,  0.0861, -0.2030],\n",
            "        [ 0.2048,  0.2209,  0.1606,  ...,  0.2254,  0.1387, -0.0564]],\n",
            "       device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[ 2.0482e-01,  2.2091e-01,  1.6060e-01,  6.5629e-02,  8.1761e-02,\n",
            "           2.6118e-01, -1.2571e-01, -1.0286e-02,  1.7628e-01,  1.1670e-01,\n",
            "          -1.2344e-01,  2.9172e-02, -2.5349e-01, -8.9846e-02, -1.8479e-01,\n",
            "           1.5307e-01, -3.1001e-01,  2.5397e-02,  1.8019e-02, -4.4491e-02,\n",
            "          -4.1621e-02,  1.1113e-01,  2.8468e-02,  2.6997e-02,  9.7495e-02,\n",
            "           9.1819e-02, -2.5758e-02,  8.1477e-02, -1.6929e-01,  6.3044e-02,\n",
            "          -5.9090e-02, -1.6788e-01,  2.1268e-02,  1.1165e-01, -3.3092e-02,\n",
            "          -9.5504e-02, -1.4864e-01, -8.7875e-02, -6.8033e-02, -7.5282e-02,\n",
            "           6.5804e-02,  1.1031e-02,  6.2971e-02, -7.8091e-02, -1.5917e-02,\n",
            "          -1.2435e-02, -1.6166e-01,  5.6909e-02,  5.5061e-02,  4.1140e-03,\n",
            "          -7.6593e-02,  1.2914e-01,  3.8886e-02,  7.3666e-02,  1.9025e-02,\n",
            "          -2.2518e-01,  3.2073e-02, -8.0276e-02, -2.8408e-02, -8.3092e-02,\n",
            "          -1.0074e-01, -3.3525e-02,  8.4335e-02, -3.3211e-02,  3.6989e-03,\n",
            "          -4.0628e-02, -2.7347e-01,  7.5368e-02,  5.0809e-02,  1.0467e-02,\n",
            "           1.1052e-01, -1.5553e-02,  4.5365e-03, -3.8674e-02,  1.9486e-02,\n",
            "           8.1228e-02,  6.0726e-02, -5.8778e-02, -9.6463e-02, -1.2986e-01,\n",
            "           9.6550e-03, -9.8741e-04,  6.6111e-02,  1.1697e-01, -1.4643e-01,\n",
            "           2.7306e-02, -2.4444e-01,  2.5987e-02,  1.5333e-01, -3.0928e-02,\n",
            "           4.9150e-02,  1.0890e-01,  2.2442e-02, -5.3508e-02,  7.8863e-02,\n",
            "           1.4931e-01,  9.3846e-03,  2.5959e-03, -4.8095e-02,  5.5691e-02,\n",
            "          -1.3835e-01, -5.4584e-02, -1.7220e-01,  1.0211e-02, -1.5596e-01,\n",
            "          -1.2796e-02, -1.1754e-01,  1.1435e-01,  1.5901e-01, -2.3222e-02,\n",
            "          -1.1723e-02, -1.1430e-01, -2.0333e-01, -1.9126e-02,  1.6294e-01,\n",
            "           3.7799e-02, -7.3957e-03, -8.6718e-02, -5.4245e-02,  2.4983e-02,\n",
            "          -1.0702e-02, -6.0210e-02,  4.3086e-02,  1.1756e-01, -6.9513e-02,\n",
            "          -6.9049e-02,  1.0701e-01, -8.8552e-02, -6.5666e-02,  5.9365e-02,\n",
            "           9.4927e-02, -1.3810e-01, -3.6191e-02,  1.2479e-01, -7.4187e-02,\n",
            "           2.0458e-01,  7.1203e-02, -3.4228e-02,  3.6814e-02,  7.5373e-02,\n",
            "          -1.8356e-01,  1.3840e-01,  9.0796e-02,  1.6706e-01, -2.4651e-02,\n",
            "          -3.5141e-02, -4.9763e-03,  1.4794e-01, -1.1506e-01,  1.9348e-02,\n",
            "           1.5726e-02,  5.5319e-02, -9.5496e-03, -2.0554e-02,  1.0324e-02,\n",
            "           7.4747e-02,  3.8787e-02,  2.0019e-01,  2.1397e-01, -1.6004e-01,\n",
            "          -7.9633e-02,  6.6575e-02,  4.7450e-02, -4.6214e-02,  1.7710e-02,\n",
            "          -7.4724e-02,  3.1909e-03,  1.4940e-01,  1.7052e-01, -5.8112e-02,\n",
            "          -7.5736e-02,  6.9099e-02, -5.5347e-02,  6.8781e-02, -6.9866e-02,\n",
            "          -1.8225e-02,  4.5868e-02, -7.0815e-02,  1.4855e-01,  1.3457e-02,\n",
            "          -1.2616e-01,  7.7319e-02, -2.0042e-02, -1.1617e-01,  4.6285e-02,\n",
            "          -8.1176e-02, -1.3171e-01,  1.0996e-01,  7.7884e-02,  5.6395e-02,\n",
            "          -2.3466e-01,  4.4056e-05,  6.1234e-02, -9.3989e-02,  1.9691e-03,\n",
            "          -5.3900e-02,  8.3929e-02, -1.1296e-03,  1.2147e-01,  1.3027e-01,\n",
            "           1.5097e-02,  1.2658e-01, -4.7099e-02,  1.8362e-02,  3.8468e-02,\n",
            "          -4.3595e-02,  1.1014e-01, -2.0454e-01,  8.6865e-02, -7.2008e-02,\n",
            "          -1.0347e-01, -6.8359e-02, -9.9922e-02, -1.8012e-01, -2.0045e-02,\n",
            "          -8.3775e-02,  1.5127e-01, -2.9907e-02,  3.6000e-02,  2.3568e-01,\n",
            "           2.5309e-01, -4.3486e-02,  4.4019e-02, -1.0515e-01, -2.9790e-03,\n",
            "           8.0206e-03,  6.2866e-02,  1.1351e-01,  5.0861e-02, -2.0956e-01,\n",
            "           1.0714e-01, -9.5731e-02,  3.1667e-02, -1.8708e-01, -1.8691e-02,\n",
            "           2.2195e-01,  8.7446e-02, -8.5015e-02, -7.6505e-02, -1.1282e-01,\n",
            "           1.3931e-01, -3.3208e-02,  1.5868e-01,  3.1106e-02,  2.4291e-02,\n",
            "          -1.2685e-01,  3.0462e-02, -5.3056e-02,  1.8792e-01,  1.1253e-01,\n",
            "          -1.7744e-01, -1.3043e-01, -8.8580e-02,  2.7368e-03, -1.1593e-01,\n",
            "           2.5921e-02, -2.2268e-02,  1.2693e-01, -1.9898e-03,  2.3187e-01,\n",
            "          -2.2559e-01,  1.2194e-01, -1.2068e-01,  1.6500e-01, -9.1496e-02,\n",
            "           1.2379e-01,  2.0414e-01,  1.6479e-01,  5.9029e-03,  3.5341e-02,\n",
            "           1.4713e-01,  2.3167e-02,  8.0266e-03, -1.7180e-01,  2.9913e-02,\n",
            "          -4.3091e-02, -6.6109e-02,  3.3216e-02,  1.4916e-01,  5.7090e-02,\n",
            "           6.7999e-02,  1.9676e-01, -2.3960e-02, -1.4729e-01,  4.8881e-02,\n",
            "          -2.0928e-01, -2.8475e-02, -1.9281e-02,  2.1532e-01, -3.2495e-02,\n",
            "           1.4373e-01, -1.3349e-01,  1.3198e-01,  4.7057e-03, -1.3041e-01,\n",
            "           8.2083e-02,  5.6943e-02, -1.5918e-01, -1.6861e-01, -1.4045e-02,\n",
            "           5.5219e-02,  1.6380e-01, -9.1223e-02, -5.4401e-02,  5.6066e-03,\n",
            "          -1.5055e-01, -1.2537e-01, -1.0575e-01, -1.7974e-01, -2.7873e-02,\n",
            "          -3.8219e-02,  1.6097e-01,  3.3650e-02,  1.0748e-01,  1.5264e-01,\n",
            "          -5.8129e-02,  7.5103e-02,  3.5635e-02,  1.8037e-01, -2.4198e-01,\n",
            "          -5.1806e-02, -6.7221e-02, -7.2042e-02,  1.9945e-01, -1.0428e-01,\n",
            "           1.1237e-01,  4.6784e-02, -9.9828e-02,  2.7648e-02,  1.0451e-01,\n",
            "          -2.1412e-01,  1.4116e-01, -2.9739e-02, -3.3292e-02, -2.1141e-02,\n",
            "          -2.1047e-02, -2.9374e-02,  1.9025e-02,  1.0026e-01, -8.9636e-04,\n",
            "           1.5310e-02, -6.1660e-02, -2.9720e-02,  4.6223e-03,  3.3403e-02,\n",
            "          -2.0460e-01, -6.2818e-03, -9.9478e-02, -1.7948e-03, -9.9232e-02,\n",
            "          -8.7146e-02,  2.5983e-01, -1.3330e-02, -7.7534e-02, -2.5740e-02,\n",
            "          -8.9343e-02,  1.2531e-01,  1.2639e-01, -1.6534e-03,  1.8194e-01,\n",
            "           1.5783e-02, -1.5962e-02, -9.5264e-02,  5.8127e-02, -1.9392e-01,\n",
            "           1.4375e-01,  1.5741e-02, -1.8307e-02, -1.0946e-01, -2.1594e-02,\n",
            "          -6.8547e-03, -9.9624e-02,  1.3136e-01,  8.9113e-02,  1.6514e-01,\n",
            "           7.8994e-02, -1.2163e-01, -1.6618e-01,  1.1121e-01,  3.7641e-01,\n",
            "          -4.1033e-02, -1.5094e-01, -1.2206e-01, -9.1188e-02,  1.3008e-01,\n",
            "          -1.3803e-01,  1.4316e-01,  1.7357e-01,  8.1028e-02, -6.1260e-02,\n",
            "          -1.9898e-01, -1.0106e-01,  5.0545e-02, -1.8146e-02,  1.7795e-01,\n",
            "           4.1410e-02, -1.4554e-01, -3.1439e-02,  8.6111e-02,  9.8059e-02,\n",
            "          -9.4528e-02,  6.6178e-03, -6.7729e-02, -4.0382e-02,  5.7794e-02,\n",
            "           8.0320e-02,  4.7121e-02,  2.6789e-02,  6.2006e-02, -8.4410e-03,\n",
            "          -1.3337e-01, -7.9162e-02, -1.7436e-01, -1.1245e-02,  4.2859e-02,\n",
            "          -7.1076e-02,  2.3013e-02,  9.0459e-02,  1.1575e-01,  1.2432e-01,\n",
            "           2.6895e-02,  8.2880e-04, -3.5325e-02, -7.0303e-02,  1.1538e-01,\n",
            "           2.0279e-01, -2.3050e-02,  2.2587e-02,  1.0864e-02,  1.1833e-02,\n",
            "           1.5269e-01,  2.8182e-02, -1.2638e-01,  6.9589e-02,  1.6392e-01,\n",
            "           1.1925e-01, -7.0158e-02,  8.7654e-02, -5.3762e-02, -9.8745e-02,\n",
            "           4.0150e-02, -1.7780e-01,  1.3899e-01,  5.9675e-02,  1.5413e-01,\n",
            "           3.2224e-02,  7.3061e-02, -3.7390e-02,  9.5943e-02, -7.1032e-02,\n",
            "           1.3949e-01, -1.4048e-01,  1.1700e-01, -3.0638e-02, -2.4776e-02,\n",
            "           5.9494e-02, -1.0163e-01, -1.8088e-01, -2.0288e-01, -2.9513e-02,\n",
            "          -5.7911e-02, -1.3499e-02, -1.9118e-01,  1.0329e-01,  1.6986e-02,\n",
            "          -6.8410e-02,  3.0290e-01, -1.1725e-01, -1.0689e-01, -1.3659e-01,\n",
            "          -2.3744e-02,  9.2893e-02,  4.9919e-02,  1.0589e-01,  1.0559e-01,\n",
            "          -3.5274e-02,  8.1015e-02,  2.3058e-01,  1.8922e-01, -1.2371e-01,\n",
            "           1.4019e-02, -5.7348e-03,  5.1613e-02, -9.9199e-03, -8.3397e-02,\n",
            "           4.4012e-02, -7.1120e-02, -9.3700e-02, -7.0136e-02, -1.1139e-02,\n",
            "           2.1132e-01, -9.9969e-02,  9.6170e-03,  6.5619e-03,  1.3222e-04,\n",
            "           5.3982e-02,  2.1203e-01, -2.6833e-02,  1.3178e-01, -1.0258e-01,\n",
            "           1.5944e-01, -3.7072e-03, -7.6014e-02,  2.7214e-02, -3.6096e-02,\n",
            "          -6.6414e-02,  8.5308e-02, -6.4416e-03,  2.2101e-01,  2.2536e-01,\n",
            "           1.3865e-01, -5.6445e-02]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 1.2419e-01,  1.2216e-01,  1.6920e-01,  5.5178e-02,  9.7267e-02,\n",
            "          1.7238e-01, -9.3237e-02, -6.7335e-02,  8.8249e-02,  9.4885e-02,\n",
            "          5.4678e-02,  1.9432e-02, -9.8278e-02, -3.2199e-02, -7.2163e-02,\n",
            "          9.7472e-02, -6.0517e-02,  3.5717e-04, -2.4469e-02, -3.3861e-02,\n",
            "         -6.1658e-02,  1.3066e-01,  9.4238e-02, -4.8747e-02,  1.2813e-01,\n",
            "          8.3793e-02,  3.3960e-02,  6.0199e-02, -7.9003e-02,  3.8432e-02,\n",
            "         -8.2524e-02, -9.6876e-02,  2.7116e-03,  1.1649e-01,  1.7744e-02,\n",
            "         -1.0065e-01, -3.6089e-02, -1.8458e-02, -6.4004e-03,  2.4646e-02,\n",
            "          5.7333e-02, -2.5765e-03,  6.7178e-03, -5.1762e-02,  5.4939e-02,\n",
            "          2.7590e-02, -1.0257e-01, -2.3097e-03,  2.1654e-02,  2.9960e-02,\n",
            "         -6.5473e-02,  8.5008e-02,  8.4950e-02,  1.1618e-01, -3.0283e-02,\n",
            "         -9.4676e-02,  5.1043e-02,  2.2611e-02, -4.3148e-02, -8.7598e-02,\n",
            "         -1.1793e-01, -6.4893e-02,  4.3852e-02,  4.6203e-02,  5.8514e-02,\n",
            "          1.6695e-02, -1.0857e-01,  3.8637e-02,  1.8479e-02,  4.6296e-02,\n",
            "         -2.3313e-02,  4.9177e-02,  1.0611e-02, -8.2928e-02, -4.3658e-02,\n",
            "          6.5003e-02,  2.5632e-02, -8.0684e-02, -3.0189e-02, -4.0056e-02,\n",
            "         -3.4972e-02, -4.8786e-02,  8.1820e-02,  2.5258e-02, -7.1629e-02,\n",
            "          5.4818e-02, -1.0648e-01, -1.8664e-02,  4.1500e-02, -7.2975e-03,\n",
            "          3.4204e-02,  7.7839e-02,  2.9464e-02, -1.6038e-02,  7.5412e-02,\n",
            "          3.3668e-02, -2.9694e-02, -2.3105e-02, -4.3948e-02,  3.7347e-02,\n",
            "         -6.2149e-02, -1.1854e-02, -7.2153e-02, -1.8722e-02, -7.0078e-02,\n",
            "         -1.4620e-02, -1.6252e-01,  2.2425e-02,  1.2227e-01,  1.6956e-03,\n",
            "         -4.1810e-02, -1.3848e-01, -9.1543e-02,  6.5864e-02,  9.4172e-02,\n",
            "          1.9678e-02,  5.2545e-03, -1.7701e-02, -5.1166e-02, -2.5443e-04,\n",
            "         -4.6842e-02, -5.2548e-02,  6.1146e-02,  1.0735e-01, -1.4790e-02,\n",
            "         -3.5114e-02,  4.9503e-02,  3.8544e-03, -3.4177e-02,  9.7329e-02,\n",
            "          1.1364e-01, -7.3105e-02, -6.3275e-02,  1.2686e-01,  2.4489e-03,\n",
            "          1.3660e-01,  5.1015e-02,  1.7766e-03, -2.1704e-02, -1.3927e-02,\n",
            "         -9.9491e-02,  9.0831e-02,  1.0862e-01,  5.1107e-02, -6.2723e-02,\n",
            "         -1.9474e-02,  2.3049e-02,  8.7930e-02, -9.7971e-02, -1.6063e-02,\n",
            "         -3.1589e-02,  8.1200e-02,  8.7114e-04, -5.5430e-02, -5.0247e-02,\n",
            "          3.1121e-02,  1.2233e-02,  1.0533e-01,  1.0830e-01, -5.5810e-02,\n",
            "         -1.0372e-02,  5.4224e-02,  3.3419e-02, -4.5058e-02,  1.9507e-03,\n",
            "          1.6483e-02, -6.8097e-02,  3.8216e-02,  1.4434e-01, -2.3277e-03,\n",
            "         -4.2633e-02,  2.2295e-02, -1.1056e-01,  1.7751e-02, -8.0454e-02,\n",
            "          1.1065e-02,  1.6805e-02,  9.7482e-03,  1.4780e-01, -8.1758e-03,\n",
            "         -5.8314e-02,  4.3683e-02,  4.6102e-03, -8.4710e-02, -3.8675e-02,\n",
            "          2.2200e-02, -9.0039e-02,  2.7250e-02,  1.9696e-02, -1.3101e-02,\n",
            "         -1.4430e-01,  9.2509e-03,  6.6389e-02, -1.2529e-01, -3.5566e-02,\n",
            "         -8.7115e-03,  2.4606e-02, -2.3145e-02,  7.7008e-02,  1.7892e-02,\n",
            "          1.8890e-03,  7.7625e-02, -1.8508e-02,  1.5411e-02,  3.3613e-02,\n",
            "         -6.2726e-02,  1.8438e-01, -8.2879e-02, -1.7004e-02, -4.0883e-02,\n",
            "          3.4203e-02, -2.3149e-02, -5.8237e-02, -3.4048e-02, -2.2497e-02,\n",
            "         -4.4120e-02,  1.0449e-01,  2.3568e-02,  4.6234e-02,  1.7895e-01,\n",
            "          8.8710e-02, -1.4742e-02,  3.6190e-02, -7.6887e-02,  6.9677e-03,\n",
            "          3.2264e-02,  5.4880e-03,  6.7759e-02,  3.8696e-02, -1.8379e-01,\n",
            "          6.5125e-02, -1.2216e-01, -2.6604e-02, -8.9036e-02,  3.8229e-02,\n",
            "          1.1840e-01,  7.6758e-02, -7.5276e-02, -1.8613e-02, -8.0633e-02,\n",
            "         -1.7844e-02, -2.6686e-02,  8.8903e-02,  1.9122e-02,  2.7432e-02,\n",
            "         -4.6252e-02, -1.0284e-01, -7.5696e-02,  1.6140e-01,  3.7567e-02,\n",
            "         -7.7577e-02, -1.1205e-01, -2.8132e-02, -2.8826e-02, -5.5979e-02,\n",
            "         -7.6905e-02, -7.2677e-02,  8.5078e-02,  1.1897e-02,  1.0630e-01,\n",
            "         -1.3050e-01,  1.0918e-01, -4.6673e-02,  1.1824e-01, -7.2504e-02,\n",
            "          6.6591e-02,  8.7975e-02,  6.2418e-02, -4.5179e-03, -9.9852e-05,\n",
            "          1.6896e-01, -2.8573e-02,  4.9696e-02, -3.7890e-02,  5.4473e-02,\n",
            "         -3.7995e-02, -4.1679e-02,  8.9349e-02,  9.2493e-02,  3.0312e-02,\n",
            "          9.0096e-02,  4.6964e-02, -7.0473e-02, -1.2594e-01,  3.7445e-02,\n",
            "         -7.0472e-02,  2.3826e-02, -5.8606e-02,  8.1716e-02, -2.8137e-02,\n",
            "          1.1481e-01, -1.6622e-01,  8.8274e-02,  1.9924e-02, -4.7707e-03,\n",
            "          4.6021e-02,  1.3138e-02, -1.1871e-01, -1.2755e-01,  3.5452e-02,\n",
            "          6.2956e-02,  7.2361e-02, -5.7285e-02, -2.3006e-02, -2.1332e-02,\n",
            "         -5.5568e-02, -1.2960e-01, -5.6452e-02, -1.0169e-01, -3.1154e-02,\n",
            "         -1.8466e-02,  4.7506e-02, -3.0719e-02,  8.8743e-02,  6.9613e-02,\n",
            "         -2.4081e-02,  8.0658e-02,  1.3960e-02,  1.1677e-01, -1.7509e-01,\n",
            "          1.0022e-02, -1.5734e-02, -4.9002e-02,  1.0940e-01, -8.3723e-02,\n",
            "          7.0324e-02,  9.1407e-02, -3.0060e-02,  4.6367e-02,  4.2002e-02,\n",
            "         -1.4759e-01,  7.0293e-02, -1.6336e-02,  3.1818e-02, -2.9468e-02,\n",
            "         -4.0940e-02, -7.7700e-02,  8.7870e-02,  1.2580e-02,  3.4739e-02,\n",
            "          1.8501e-02, -9.0887e-02, -4.0947e-02,  8.5944e-02,  3.0913e-02,\n",
            "         -7.0716e-02,  2.6161e-02, -2.7102e-02, -5.8630e-03, -1.3867e-01,\n",
            "         -6.6856e-02,  1.9280e-01, -7.1780e-02, -6.4167e-02, -7.9871e-02,\n",
            "         -1.0269e-02,  1.2337e-01, -1.7086e-02, -2.5047e-02,  9.8806e-02,\n",
            "          5.2479e-02, -5.8920e-03, -1.3512e-01,  5.7162e-02, -1.2058e-01,\n",
            "          1.5139e-02,  3.4574e-02,  4.6397e-02, -2.0722e-03,  2.3872e-03,\n",
            "         -3.5852e-02,  4.2991e-03,  7.9230e-02,  6.5666e-02,  5.7807e-02,\n",
            "          3.6200e-02, -4.2188e-02, -1.3480e-02,  1.5934e-01,  2.1352e-01,\n",
            "         -5.1833e-02, -1.0204e-01, -1.2056e-01, -4.1574e-02,  9.7979e-02,\n",
            "         -1.6334e-02,  1.1493e-01,  4.5640e-02,  1.0427e-01, -6.7130e-02,\n",
            "         -1.8092e-01, -2.0653e-02,  3.6394e-02, -3.5221e-02,  8.1177e-02,\n",
            "         -2.3915e-02, -1.4369e-01, -5.8258e-02, -1.0054e-03,  9.8221e-02,\n",
            "         -2.9245e-02,  2.3367e-02, -3.2640e-02, -1.9758e-03,  6.8781e-02,\n",
            "          3.8995e-02, -3.5214e-02,  2.7816e-02, -4.4412e-02,  2.1534e-02,\n",
            "         -1.1563e-01, -1.9064e-02, -7.5408e-02, -5.5932e-02,  1.9236e-02,\n",
            "         -5.6127e-02, -2.7672e-02,  4.2641e-02,  1.0255e-01,  6.9374e-02,\n",
            "          5.6562e-02,  1.9437e-02, -2.5115e-02,  3.3378e-02,  7.6247e-02,\n",
            "          1.6784e-01,  2.2420e-02,  5.5131e-02, -2.5911e-02,  5.7677e-02,\n",
            "          1.0228e-01, -2.5088e-02, -1.3269e-01, -1.5338e-02,  3.2312e-02,\n",
            "          1.6480e-01, -8.0684e-02,  8.7694e-02, -1.0120e-02, -1.2533e-01,\n",
            "          3.1339e-02, -1.1494e-01,  8.9537e-02,  2.5497e-02,  1.3167e-01,\n",
            "          1.0033e-02,  2.4860e-02, -3.6681e-02,  6.5663e-02, -6.8396e-02,\n",
            "          1.0571e-01, -5.4632e-02, -1.3509e-02, -3.1489e-02, -2.3470e-02,\n",
            "          7.2320e-02, -8.9499e-02, -1.0632e-01, -1.7038e-01,  2.1537e-02,\n",
            "         -1.9167e-02, -2.3274e-02, -8.7728e-02,  1.2080e-01, -7.8992e-02,\n",
            "         -7.5356e-02,  1.7410e-01, -1.9103e-02, -3.8365e-02, -4.3131e-02,\n",
            "         -1.0355e-02,  4.4311e-02,  3.2689e-02,  7.3647e-02,  4.6105e-02,\n",
            "         -7.7940e-02,  1.2324e-01,  1.6691e-01,  1.3738e-01, -7.9957e-02,\n",
            "          2.1938e-02, -3.9523e-02,  1.1185e-01, -2.1692e-02,  2.6316e-02,\n",
            "          1.5026e-02, -8.7621e-02, -1.4777e-01, -5.8733e-02, -3.2766e-02,\n",
            "          1.8513e-01, -3.4719e-02,  3.1088e-02,  4.0829e-02, -2.9003e-02,\n",
            "          8.9969e-02,  5.8812e-02, -2.7913e-02,  9.5795e-02, -9.8252e-02,\n",
            "          1.1901e-01, -6.4240e-02, -3.7685e-02,  1.1349e-02, -3.5173e-02,\n",
            "         -4.0824e-02,  3.7190e-02,  1.4259e-02,  9.7557e-02,  1.1797e-01,\n",
            "          1.6505e-02, -6.6416e-02]], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Predicted Sentiment : Negative \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9tYsw1wu_lt",
        "outputId": "2722fa7b-e539-4716-c645-58382fed1a98"
      },
      "source": [
        "twt=\"This is my first encoder decoder model\"\n",
        "print(f'Tweet : {twt}')\n",
        "print(f'Predicted Sentiment : {classify_tweet(twt)} \\n')"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tweet : This is my first encoder decoder model\n",
            "Output of encoder at every step:tensor([[ 1.4525e-01,  6.4722e-05, -4.5118e-04,  ..., -2.3553e-02,\n",
            "         -9.0755e-02, -9.9952e-02],\n",
            "        [ 6.5447e-03,  1.6383e-01,  9.3974e-02,  ...,  1.4722e-01,\n",
            "         -5.0717e-02,  1.2002e-01],\n",
            "        [-1.4163e-02,  8.2040e-02, -3.9873e-02,  ...,  1.1530e-01,\n",
            "          8.7571e-02, -3.1883e-02],\n",
            "        ...,\n",
            "        [-4.4577e-02,  1.2651e-01,  6.3556e-02,  ...,  1.0086e-01,\n",
            "          1.6790e-01, -1.0740e-01],\n",
            "        [-2.3125e-02,  9.3015e-02,  3.5015e-02,  ...,  1.5644e-01,\n",
            "          2.2985e-01, -2.0054e-01],\n",
            "        [-1.5929e-03,  5.6669e-02,  2.7312e-02,  ...,  1.7993e-01,\n",
            "          2.5657e-01, -2.4107e-01]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "Output of encoder at last step:tensor([[[-1.5929e-03,  5.6669e-02,  2.7312e-02, -1.5404e-03, -1.4514e-01,\n",
            "           1.8985e-01,  9.3813e-02,  3.0972e-02,  2.9701e-01, -1.0544e-01,\n",
            "          -2.9301e-01,  1.3024e-02, -2.3836e-01,  9.5386e-03,  3.7403e-02,\n",
            "           5.5793e-02, -9.0754e-02,  1.1920e-02,  7.7107e-02,  3.8118e-02,\n",
            "          -1.2053e-01,  3.0888e-01,  1.0293e-01,  2.4153e-02,  3.1202e-02,\n",
            "           7.6384e-02, -1.2375e-01, -5.2292e-02,  2.2540e-03,  8.6771e-02,\n",
            "          -9.9511e-02,  9.0601e-02,  1.0622e-01,  7.2576e-03, -5.2870e-02,\n",
            "           1.1614e-01, -1.6938e-01,  3.9364e-01, -1.4311e-01,  1.5525e-02,\n",
            "          -2.2041e-01, -1.8260e-01,  1.9226e-01, -1.1516e-01,  1.2834e-01,\n",
            "           6.6663e-02, -1.2785e-01, -6.6180e-02,  1.3043e-01, -3.6450e-01,\n",
            "           1.6556e-01,  2.6708e-01,  1.5309e-01,  2.2024e-02, -1.2336e-01,\n",
            "          -2.9774e-01,  3.1434e-01,  3.7774e-04, -2.7815e-01, -9.9809e-02,\n",
            "          -2.0539e-01, -2.2588e-01,  1.4227e-01,  2.4077e-02,  9.2336e-02,\n",
            "          -2.5149e-02, -2.5014e-01, -1.0822e-01,  3.2748e-02, -1.3036e-01,\n",
            "           2.3761e-02, -5.7459e-02, -2.0943e-01, -9.2814e-02, -1.2872e-01,\n",
            "          -2.1222e-01,  1.9432e-02,  7.7305e-02, -4.7094e-03, -9.5314e-02,\n",
            "           8.9441e-02, -1.3951e-01,  2.1466e-01, -6.1777e-02, -1.0543e-01,\n",
            "          -8.7904e-03, -1.8618e-01,  2.9762e-02,  1.7009e-01,  1.9733e-01,\n",
            "           3.1509e-01,  4.6018e-02,  8.3048e-02, -1.7108e-01, -1.8064e-01,\n",
            "           4.1006e-02, -7.3220e-02, -1.2776e-01,  2.1758e-01,  2.5307e-01,\n",
            "          -2.6266e-01,  1.8299e-01, -2.5883e-01,  1.3309e-01, -1.4498e-01,\n",
            "           5.6784e-02, -2.3991e-01,  1.0463e-01, -6.8038e-02,  3.0882e-01,\n",
            "           1.1250e-01, -1.5342e-01,  1.6242e-02,  2.4169e-01,  2.0137e-01,\n",
            "          -1.4086e-01, -8.4020e-02, -1.2811e-01, -9.9395e-02, -7.9683e-02,\n",
            "          -3.1083e-02, -3.6357e-02, -1.6413e-01,  1.3577e-01,  1.2656e-01,\n",
            "           5.5104e-02,  8.2839e-02,  1.5575e-01,  1.6517e-01, -2.4785e-01,\n",
            "           3.3115e-02, -1.7711e-01, -8.9418e-02, -3.9996e-03, -1.0942e-01,\n",
            "          -1.6316e-01,  6.5693e-03, -5.9500e-02, -3.5784e-02, -3.0710e-01,\n",
            "           3.4785e-02, -1.2626e-01,  1.6168e-01,  4.1552e-02, -1.0393e-01,\n",
            "           4.1805e-02, -1.2245e-01,  1.8705e-01,  4.2643e-02,  5.5671e-02,\n",
            "          -1.4548e-01, -2.6246e-01,  1.5793e-01, -1.4431e-01, -1.2351e-01,\n",
            "           6.8565e-02,  1.4116e-01,  2.8769e-01,  2.3204e-01, -1.7598e-01,\n",
            "          -1.7006e-01,  6.8112e-03,  2.4059e-02,  7.9530e-02,  3.1439e-01,\n",
            "           5.1765e-03, -1.8310e-01, -1.2240e-01,  2.2432e-01,  3.2760e-03,\n",
            "          -8.4530e-02,  2.1389e-01, -1.2771e-01,  2.1104e-01,  5.2561e-03,\n",
            "           3.1163e-02, -2.3220e-01, -2.2353e-01, -1.3848e-01, -5.6736e-02,\n",
            "          -1.2027e-01, -1.0308e-01,  1.8032e-02,  1.3382e-01, -1.6904e-01,\n",
            "          -2.0289e-02, -1.7781e-01,  1.9604e-01,  1.9474e-01, -1.3073e-01,\n",
            "          -7.6660e-02, -8.6988e-03,  8.3472e-02, -3.1677e-01,  1.4838e-01,\n",
            "           9.0919e-02, -1.4385e-01, -1.3805e-01,  1.5933e-02,  8.2395e-02,\n",
            "          -1.2060e-02,  1.9598e-01, -6.8341e-02,  8.9081e-02,  1.7269e-01,\n",
            "           2.1832e-02,  1.9064e-01,  5.6311e-02, -9.6052e-02, -1.0474e-01,\n",
            "           1.5226e-01, -3.0543e-01, -1.1303e-01, -5.2268e-02, -1.4079e-02,\n",
            "          -4.4901e-02,  1.0104e-01,  9.9793e-02, -1.1786e-02,  3.9769e-01,\n",
            "           2.7795e-01, -2.6807e-01, -4.0248e-02, -1.7087e-01,  1.1591e-01,\n",
            "          -1.2265e-01, -2.6651e-01,  5.7891e-02, -2.8160e-02,  2.9195e-01,\n",
            "          -1.9347e-01, -3.3865e-01,  1.1354e-01, -2.0178e-01, -2.1922e-01,\n",
            "          -5.2583e-02,  1.9087e-01, -1.0404e-01, -5.5670e-03, -8.8964e-02,\n",
            "           7.5135e-02,  3.5655e-02,  2.5219e-01, -5.2191e-02,  4.2814e-02,\n",
            "           9.2869e-02,  7.8437e-02, -1.1728e-01,  3.3325e-01,  9.9093e-02,\n",
            "          -2.3958e-01,  1.5123e-01,  1.2158e-01,  1.9373e-01, -5.1526e-02,\n",
            "          -9.7545e-02,  3.1913e-02,  2.5339e-01, -1.8235e-02,  8.9858e-02,\n",
            "          -3.4121e-01,  3.1857e-02, -8.2385e-02,  2.4305e-01, -1.4761e-01,\n",
            "           4.2430e-02,  1.7466e-01,  2.2278e-01, -1.1996e-01, -6.6800e-02,\n",
            "           9.8690e-02, -1.2939e-02, -6.1950e-02, -2.3761e-02, -1.8586e-02,\n",
            "          -1.8979e-01,  9.7137e-02,  2.2722e-01,  2.5839e-01, -1.0166e-01,\n",
            "          -1.0221e-02,  2.8688e-01, -1.9204e-01,  4.2134e-02,  3.9757e-02,\n",
            "          -8.9903e-03, -1.0759e-01, -2.6095e-01,  1.9817e-02, -4.9337e-02,\n",
            "           2.5912e-01,  2.5077e-01,  5.1066e-01,  1.5633e-01, -2.8809e-01,\n",
            "          -2.2533e-01,  2.6193e-02, -2.2937e-01, -1.0383e-01, -1.2723e-01,\n",
            "          -7.4753e-02,  1.2050e-02, -6.7825e-02, -3.4991e-02, -1.6527e-01,\n",
            "           1.1894e-02, -2.3331e-02,  3.2515e-01,  2.9383e-02,  1.1176e-03,\n",
            "          -1.0664e-02, -1.3255e-01,  5.6634e-02, -1.6072e-01, -6.0833e-03,\n",
            "           3.7168e-01,  1.3674e-01,  1.4689e-02, -6.4247e-02, -6.0597e-02,\n",
            "          -3.2319e-01, -5.1765e-02, -1.5449e-01, -4.8127e-02, -4.0318e-02,\n",
            "           2.4683e-01,  2.1471e-01,  1.3925e-01, -6.3258e-02, -1.0199e-01,\n",
            "          -2.0663e-01,  1.0175e-01,  1.0307e-01, -1.5511e-01, -2.1673e-01,\n",
            "           2.3561e-02,  1.7861e-01, -7.6328e-02,  1.2195e-01, -4.3249e-02,\n",
            "          -2.0244e-01, -1.0149e-01, -2.0554e-01,  1.7827e-03,  2.8604e-02,\n",
            "          -9.9503e-02,  5.5137e-03, -1.2680e-01,  4.0702e-02, -1.1344e-01,\n",
            "          -3.6190e-02,  2.2931e-01, -9.5009e-02, -1.8722e-01, -9.9746e-02,\n",
            "           5.3180e-02, -3.2570e-01,  2.1805e-01, -1.0742e-01,  2.4591e-01,\n",
            "           1.6743e-01, -8.1298e-02, -9.7444e-02, -6.0582e-02, -6.5728e-02,\n",
            "          -1.1131e-01, -1.0576e-01,  1.1510e-01,  3.5248e-02, -4.5226e-02,\n",
            "          -2.3203e-01, -3.3563e-02,  3.2447e-02,  3.3022e-01, -7.9284e-02,\n",
            "          -8.2362e-02,  5.6535e-02, -1.7837e-01,  2.0891e-01,  1.7756e-01,\n",
            "          -1.7845e-01, -2.3818e-01, -4.3823e-02,  1.3753e-01,  3.7975e-02,\n",
            "          -6.9673e-02,  2.1806e-01,  3.8478e-01,  6.4581e-02,  8.3587e-02,\n",
            "          -4.4592e-01, -1.0040e-01, -4.0733e-02,  1.3383e-01,  1.3849e-01,\n",
            "          -1.9648e-01, -2.4313e-01,  1.4789e-01,  2.4734e-01, -2.9749e-02,\n",
            "          -2.1871e-01, -2.2005e-04, -1.7280e-01,  6.0232e-02,  7.1976e-02,\n",
            "           1.3408e-01,  1.3561e-01,  1.1355e-01,  6.3179e-02,  9.5562e-02,\n",
            "          -1.1289e-01, -3.4100e-01, -6.6971e-02, -2.0184e-01, -8.5644e-02,\n",
            "          -5.2357e-03,  2.9494e-01,  8.3218e-02, -1.0471e-01, -2.2991e-01,\n",
            "           1.1043e-01, -3.1822e-02,  1.0970e-01, -1.6026e-01,  3.9404e-02,\n",
            "           1.7815e-01,  2.8373e-02, -1.5499e-01, -1.8099e-01, -3.7883e-02,\n",
            "           1.3215e-01,  1.5991e-01,  6.3667e-02,  1.6148e-01,  5.1070e-02,\n",
            "           2.7183e-01, -5.0720e-02,  1.2726e-01,  1.4511e-01, -9.7414e-02,\n",
            "          -4.2880e-03,  5.3154e-02, -1.1952e-01,  1.3313e-01,  1.9368e-01,\n",
            "          -2.1128e-01,  2.9631e-01,  1.7894e-01,  2.5177e-02, -9.8509e-02,\n",
            "          -1.3618e-01,  2.5911e-02,  5.1634e-02,  1.0921e-01, -1.8862e-01,\n",
            "           3.0261e-02, -2.4992e-01, -2.0138e-01,  7.4995e-02,  5.8163e-02,\n",
            "          -7.6366e-02,  1.2372e-01, -3.1408e-01, -5.1712e-02, -6.2698e-02,\n",
            "           7.9272e-02,  2.6425e-01, -2.1524e-01, -1.9267e-02, -1.5826e-02,\n",
            "           2.8078e-01,  3.7649e-03,  1.9960e-01,  4.4385e-02,  1.8054e-01,\n",
            "           1.7649e-02, -2.7242e-02,  2.3316e-01,  2.6439e-01, -2.4433e-01,\n",
            "           2.2872e-01, -2.8596e-01,  2.8989e-01, -8.1619e-02,  1.4512e-02,\n",
            "          -4.8951e-02, -2.4716e-01,  9.2950e-02,  1.3433e-01,  8.2181e-02,\n",
            "           1.8336e-01, -1.0359e-01,  1.1302e-01, -5.5411e-02,  2.1988e-01,\n",
            "           1.2379e-01,  8.0888e-02, -2.6024e-01,  3.1830e-01, -2.6295e-01,\n",
            "           8.8084e-02, -8.2970e-02, -1.7430e-01, -9.2080e-02, -1.6611e-02,\n",
            "           3.5555e-02,  1.8197e-01,  2.9263e-02,  1.8331e-01,  1.7993e-01,\n",
            "           2.5657e-01, -2.4107e-01]]], device='cuda:0',\n",
            "       grad_fn=<CudnnRnnBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 8.0414e-02,  1.0894e-01, -3.3392e-02,  2.7353e-02, -9.1913e-02,\n",
            "          9.2077e-02,  5.3631e-02, -3.7118e-02,  1.6752e-01,  1.1006e-02,\n",
            "         -6.8583e-02, -3.8539e-02, -8.9062e-02,  6.5656e-02, -2.0423e-02,\n",
            "          2.3885e-02, -1.6944e-02, -5.9387e-03,  4.4166e-04, -3.2078e-02,\n",
            "         -1.0741e-01,  2.0934e-01,  1.6804e-01, -1.2183e-01,  5.3940e-02,\n",
            "          3.9921e-02, -6.9086e-02,  1.4950e-02,  3.4244e-02, -1.2211e-02,\n",
            "         -1.7208e-01, -4.9750e-03,  9.0542e-02,  1.6427e-02,  3.6687e-02,\n",
            "          5.8704e-02, -1.0597e-01,  1.3792e-01, -6.2319e-02,  6.6784e-02,\n",
            "         -9.8983e-02, -1.6445e-01,  3.3493e-02, -5.2010e-02,  1.6956e-01,\n",
            "          3.0701e-02, -2.0111e-01,  1.1999e-02,  9.2893e-02, -1.6319e-01,\n",
            "          5.0565e-02,  1.4833e-01,  1.3938e-01,  9.5211e-02, -4.3085e-02,\n",
            "         -1.3121e-01,  1.1356e-01, -2.7374e-02, -1.9033e-01, -8.3865e-02,\n",
            "         -1.5961e-01, -7.3020e-02,  1.7689e-02,  1.3526e-01,  1.9324e-02,\n",
            "          5.0450e-02, -1.4337e-01, -2.1677e-02,  5.2243e-03, -1.0928e-01,\n",
            "         -5.7762e-02,  5.0091e-03, -1.7041e-01, -6.4673e-02, -1.5977e-01,\n",
            "         -7.7455e-02,  4.0050e-02,  2.4057e-02,  2.2558e-02, -7.8948e-02,\n",
            "          3.8082e-02, -5.6410e-02,  1.0325e-01, -4.1393e-02, -2.8172e-02,\n",
            "          1.3956e-01, -1.2213e-01,  5.6081e-03,  8.8857e-02,  1.2423e-01,\n",
            "          2.2411e-01,  6.4591e-02,  1.2487e-01, -6.9915e-02, -1.0435e-01,\n",
            "          2.2229e-02, -7.2971e-02, -5.0979e-02,  1.7242e-01,  8.7894e-02,\n",
            "         -1.9755e-01,  1.6034e-01, -1.5715e-01,  1.0797e-01, -1.1364e-01,\n",
            "          7.5073e-02, -2.5731e-01,  3.4698e-02, -3.7005e-02,  2.2826e-01,\n",
            "          2.8238e-02, -1.4648e-01,  6.0621e-02,  1.6200e-01,  1.0356e-01,\n",
            "         -1.1113e-01, -9.3343e-02, -4.6315e-02, -5.0243e-02, -8.5795e-02,\n",
            "         -2.4116e-02, -5.2469e-02, -3.3981e-02,  1.6501e-01,  1.1016e-01,\n",
            "          1.7447e-02,  7.9131e-02,  1.5294e-01,  5.7388e-02, -1.2004e-01,\n",
            "          1.6416e-01, -7.0125e-02,  5.1299e-03,  1.7826e-03, -8.1226e-02,\n",
            "         -9.1796e-02, -3.1598e-02, -1.1815e-02, -4.7493e-02, -1.8516e-01,\n",
            "         -2.2580e-02, -8.1540e-02,  1.2056e-01,  8.4585e-03, -6.2536e-02,\n",
            "          2.5445e-02, -4.0307e-02,  8.2437e-02, -1.0566e-04,  2.9825e-02,\n",
            "         -9.1859e-02, -8.3150e-02,  9.2908e-02, -9.9176e-02, -1.3466e-01,\n",
            "          6.4004e-02,  4.9015e-02,  1.9950e-01,  7.9644e-02, -1.0761e-01,\n",
            "         -9.3310e-02,  6.2552e-02, -1.9583e-02,  1.3793e-02,  1.5712e-01,\n",
            "         -1.5556e-02, -9.1898e-02, -1.0274e-01,  1.4140e-01,  7.9104e-04,\n",
            "         -8.2143e-02,  5.4537e-02, -1.2930e-01,  8.8593e-02, -1.7105e-02,\n",
            "          8.7897e-02, -1.2963e-01, -1.4378e-01,  1.1191e-02, -8.1741e-02,\n",
            "         -8.1583e-02, -8.7678e-02,  8.6125e-02,  7.3636e-02, -1.2772e-01,\n",
            "         -1.8422e-02, -7.4472e-02,  1.1789e-01,  2.1190e-04, -1.0279e-01,\n",
            "         -5.2561e-02,  5.1577e-02,  9.3790e-02, -2.3843e-01,  1.1059e-01,\n",
            "          9.7617e-02, -9.6305e-02, -1.7080e-01, -4.1353e-02, -5.8142e-03,\n",
            "          1.1724e-02,  1.3224e-01, -5.8445e-02,  1.1032e-01,  1.3859e-01,\n",
            "          5.0283e-02,  6.0778e-02, -6.8577e-03, -7.2594e-02, -6.3705e-02,\n",
            "          1.1286e-01, -1.3166e-01, -7.2625e-02,  2.6897e-02,  2.9881e-02,\n",
            "          4.2700e-02,  5.0202e-02,  7.4747e-02,  5.4995e-02,  1.9400e-01,\n",
            "          5.9887e-02, -1.8266e-01, -4.5199e-02, -1.0154e-01,  3.4382e-02,\n",
            "         -2.9848e-02, -1.4364e-01,  1.1074e-01, -8.5068e-02,  1.1372e-01,\n",
            "         -1.1131e-01, -2.3375e-01,  6.1426e-02, -1.0908e-01, -6.3988e-02,\n",
            "          9.8722e-03,  3.1579e-02, -6.0793e-02, -4.3038e-02, -8.8042e-02,\n",
            "          9.2653e-03,  1.9811e-02,  1.6704e-01, -2.8609e-02,  4.8543e-03,\n",
            "          4.7834e-02, -5.0503e-02, -8.1166e-02,  2.2439e-01,  3.1172e-02,\n",
            "         -1.2610e-01,  9.0606e-02,  1.5832e-01,  7.9246e-02, -2.6010e-02,\n",
            "         -7.6974e-02, -3.3646e-02,  2.0055e-01, -2.0238e-02,  1.0392e-01,\n",
            "         -2.4623e-01,  5.8447e-03, -1.2662e-02,  2.3434e-01, -8.3524e-02,\n",
            "         -2.9519e-02,  1.4965e-01,  6.9447e-02, -2.7522e-02, -3.4187e-02,\n",
            "          1.3724e-01,  7.5677e-02,  2.4775e-02,  1.1648e-02, -1.4082e-02,\n",
            "         -3.2531e-02,  1.1468e-01,  1.8274e-01,  1.0542e-01, -4.7680e-02,\n",
            "         -1.2585e-02,  2.1544e-01, -1.3551e-01,  1.5232e-02,  4.5330e-02,\n",
            "         -1.1231e-02, -3.4548e-02, -1.3486e-01,  7.7162e-02, -7.4344e-02,\n",
            "          2.4834e-01,  7.1352e-02,  2.5924e-01,  1.0608e-01, -5.9011e-02,\n",
            "         -6.7689e-02,  1.4320e-03, -2.5045e-01, -5.2039e-02,  1.8254e-03,\n",
            "         -1.6749e-02,  8.6005e-02, -9.1438e-03, -4.4226e-02, -1.7020e-01,\n",
            "         -2.1400e-02, -7.2034e-02,  2.5133e-01, -3.2066e-03, -1.6874e-02,\n",
            "          5.0141e-02, -7.0500e-02,  2.7302e-02, -8.4655e-02, -2.6795e-02,\n",
            "          2.3038e-01,  3.6241e-02,  1.0731e-02, -4.3566e-02, -1.1780e-01,\n",
            "         -1.6300e-01, -2.5592e-02, -1.7629e-01,  3.4448e-02, -5.8919e-02,\n",
            "          8.7920e-02,  7.8611e-02,  5.0397e-02, -5.0402e-02, -1.2201e-01,\n",
            "         -1.1168e-01,  4.1639e-02,  1.0555e-01, -4.7669e-02, -2.0472e-01,\n",
            "          2.4510e-02,  1.0799e-01, -4.1413e-03,  1.0323e-02,  1.2609e-03,\n",
            "         -2.4448e-02, -1.0930e-01, -1.3431e-01,  7.5297e-02, -6.1855e-04,\n",
            "         -4.7808e-02, -1.2898e-02, -4.9833e-02,  2.5897e-02, -4.7481e-02,\n",
            "         -4.0822e-02,  1.0770e-01, -8.5411e-02, -1.0830e-01, -1.0440e-01,\n",
            "          3.5526e-02, -1.2448e-01,  2.9759e-02, -1.1907e-01,  2.0888e-01,\n",
            "          6.9461e-02, -6.0362e-02, -1.2226e-01,  3.3401e-02, -1.5353e-01,\n",
            "         -8.3878e-02, -3.7988e-02,  1.4190e-01,  6.3329e-02, -2.1505e-02,\n",
            "         -1.3978e-01, -2.8608e-02,  4.0808e-02,  2.5671e-01, -6.7091e-02,\n",
            "         -7.6641e-02,  7.2947e-02, -2.4198e-02,  1.6005e-01,  1.3248e-01,\n",
            "         -7.9791e-02, -1.0635e-01,  2.6493e-02,  1.2935e-01, -4.2898e-02,\n",
            "         -1.6977e-02,  2.1224e-01,  1.5416e-01,  7.6652e-02,  9.6824e-02,\n",
            "         -2.0425e-01, -5.4163e-02,  2.6470e-02,  9.5909e-02,  6.9769e-02,\n",
            "         -8.3230e-02, -2.3805e-01,  1.2226e-01,  8.9376e-02,  1.5089e-04,\n",
            "         -8.3288e-02, -4.2237e-02, -1.0225e-01,  1.0245e-01,  7.0227e-02,\n",
            "          8.3722e-02,  5.7427e-02,  6.5690e-02, -3.4187e-02,  3.8481e-02,\n",
            "         -7.3933e-02, -1.4105e-01, -1.2786e-01, -1.8153e-01, -2.3987e-02,\n",
            "         -5.5497e-02,  1.4720e-01,  6.0503e-02,  8.3939e-03, -1.1893e-01,\n",
            "          1.4703e-01, -2.4078e-03,  1.1425e-01, -3.7901e-02, -1.6668e-02,\n",
            "          1.1321e-01,  6.7390e-02, -4.8778e-02, -1.4199e-01, -7.1918e-02,\n",
            "          1.1262e-01,  1.3844e-01,  3.0217e-04,  7.9675e-02,  4.7121e-02,\n",
            "          3.1506e-01, -4.5318e-02,  2.0152e-01,  1.4028e-01, -1.0524e-01,\n",
            "          1.9555e-03,  1.7088e-02, -2.8715e-02,  1.2604e-02,  1.5810e-01,\n",
            "         -7.7168e-02,  6.3425e-02,  5.2781e-02, -8.3598e-03, -9.6614e-02,\n",
            "         -4.4944e-02, -8.2088e-03, -3.0287e-02,  5.0200e-02, -1.3973e-01,\n",
            "          1.2432e-01, -1.2456e-01, -1.8860e-01, -2.1782e-03,  2.3406e-02,\n",
            "         -8.1613e-02,  4.4140e-02, -2.0936e-01, -4.5012e-02, -3.5309e-02,\n",
            "          3.0708e-02,  1.8981e-01, -1.4347e-01, -2.6808e-02, -1.1537e-02,\n",
            "          1.6765e-01, -5.3156e-03,  1.7686e-01,  2.9294e-02,  8.4997e-02,\n",
            "         -3.2680e-02,  4.6539e-02,  1.8352e-01,  2.0370e-01, -9.2122e-02,\n",
            "          2.1660e-01, -1.5882e-01,  1.6766e-01, -6.1953e-02,  6.4301e-02,\n",
            "         -4.8311e-02, -1.2257e-01, -2.1440e-02,  7.6616e-02, -7.3309e-02,\n",
            "          3.7225e-02, -1.0982e-01,  9.4841e-02, -3.0412e-02,  9.9956e-02,\n",
            "          7.8426e-02,  9.2239e-03, -1.2384e-01,  2.0719e-01, -2.1060e-01,\n",
            "         -8.8109e-03, -6.5390e-02, -6.7766e-02, -1.0225e-01,  6.2586e-02,\n",
            "         -7.5930e-03,  1.4765e-01, -1.9460e-02,  9.8596e-02,  1.6309e-01,\n",
            "          1.2220e-01, -1.0361e-01]], device='cuda:0', grad_fn=<SelectBackward>)\n",
            "Predicted Sentiment : Positive \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHymV6GtXT5s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}