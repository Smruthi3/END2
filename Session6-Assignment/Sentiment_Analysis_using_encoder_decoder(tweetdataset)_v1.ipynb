{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis using encoder decoder(tweetdataset)_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Smruthi3/END2/blob/main/Session6-Assignment/Sentiment_Analysis_using_encoder_decoder(tweetdataset)_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp5IzBGsPGHs"
      },
      "source": [
        "## Dataset Preview\n",
        "\n",
        "Your first step to deep learning in NLP. We will be mostly using PyTorch. Just like torchvision, PyTorch provides an official library, torchtext, for handling text-processing pipelines. \n",
        "\n",
        "We will be using previous session tweet dataset. Let's just preview the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjF33BEnUCnT",
        "outputId": "04a368a4-eb01-47bb-e19a-8a423c83319f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1-Yz-5RRFYc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "01bc8ba0-2e30-486b-f6ef-df25508b795f"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('drive/My Drive/END2/Session5-Assignment/tweets.csv')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Obama has called the GOP budget social Darwini...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In his teen years, Obama has been known to use...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IPA Congratulates President Barack Obama for L...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @Professor_Why: #WhatsRomneyHiding - his co...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @wardollarshome: Obama has approved more ta...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              tweets  labels\n",
              "0  Obama has called the GOP budget social Darwini...       1\n",
              "1  In his teen years, Obama has been known to use...       0\n",
              "2  IPA Congratulates President Barack Obama for L...       0\n",
              "3  RT @Professor_Why: #WhatsRomneyHiding - his co...       0\n",
              "4  RT @wardollarshome: Obama has approved more ta...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7JdpCW-YbAG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff1921b9-df1c-48bb-cfbf-17adfdff0798"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1364, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqRsoF6xYdgl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c79de039-701a-4a74-81d7-55c5840b3e80"
      },
      "source": [
        "df.labels.value_counts()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    931\n",
              "1    352\n",
              "2     81\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ6o_79ISSVb"
      },
      "source": [
        "## Defining Fields"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e63g08ijOrf7"
      },
      "source": [
        "Now we shall be defining LABEL as a LabelField, which is a subclass of Field that sets sequen tial to False (as it’s our numerical category class). TWEET is a standard Field object, where we have decided to use the spaCy tokenizer and convert all the text to lower‐ case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk8IP4SK1Lrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a89c0444-6a21-4e07-aee9-2ec656690a1d"
      },
      "source": [
        "# Import Library\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext.legacy import data \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ff1a29911f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6bKQax2Mf_U"
      },
      "source": [
        "Tweet = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2nfZ3bG7IAQ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mX-lYIe_O7Vy"
      },
      "source": [
        "Having defined those fields, we now need to produce a list that maps them onto the list of rows that are in the CSV:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VawdWq36O6td"
      },
      "source": [
        "fields = [('tweets', Tweet),('labels',Label)]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbtZ-Ph2P1xL"
      },
      "source": [
        "Armed with our declared fields, lets convert from pandas to list to torchtext. We could also use TabularDataset to apply that definition to the CSV directly but showing an alternative approach too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3OLcJ5B7rHz"
      },
      "source": [
        "example = [data.Example.fromlist([df.tweets[i],df.labels[i]], fields) for i in range(df.shape[0])] "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT-flpH-P1cd"
      },
      "source": [
        "# Creating dataset\n",
        "#twitterDataset = data.TabularDataset(path=\"tweets.csv\", format=\"CSV\", fields=fields, skip_header=True)\n",
        "\n",
        "twitterDataset = data.Dataset(example, fields)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6ZnyCPaR08F"
      },
      "source": [
        "Finally, we can split into training, testing, and validation sets by using the split() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPYXyuKhRpBk"
      },
      "source": [
        "(train, valid) = twitterDataset.split(split_ratio=[0.85, 0.15], random_state=random.seed(SEED))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPjBxCt9mNsK",
        "outputId": "bc3ae981-80d8-43a6-c2db-c01280f3a381"
      },
      "source": [
        "type(valid)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchtext.legacy.data.dataset.Dataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpmKkoIO8vEO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykvsCGQMR6UD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9361256f-e7d9-42f0-d08f-57f3f984a8fb"
      },
      "source": [
        "(len(train), len(valid))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1159, 205)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kix8P2IKSBaV"
      },
      "source": [
        "An example from the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUpEOQruR9JL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1886cb05-01ec-4713-a8e9-0242d7f1711d"
      },
      "source": [
        "vars(train.examples[10])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': 0,\n",
              " 'tweets': ['Obama',\n",
              "  ',',\n",
              "  'Romney',\n",
              "  'agree',\n",
              "  ':',\n",
              "  'Admit',\n",
              "  'women',\n",
              "  'to',\n",
              "  'Augusta',\n",
              "  'golf',\n",
              "  'club',\n",
              "  ':',\n",
              "  'US',\n",
              "  'President',\n",
              "  'Barack',\n",
              "  'Obama',\n",
              "  'believes',\n",
              "  'women',\n",
              "  'should',\n",
              "  'be',\n",
              "  'allowe',\n",
              "  '...',\n",
              "  'http://t.co/PVKrepqI']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKdllP3FST4N"
      },
      "source": [
        "## Building Vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuvWQ-SpSmSz"
      },
      "source": [
        "At this point we would have built a one-hot encoding of each word that is present in the dataset—a rather tedious process. Thankfully, torchtext will do this for us, and will also allow a max_size parameter to be passed in to limit the vocabu‐ lary to the most common words. This is normally done to prevent the construction of a huge, memory-hungry model. We don’t want our GPUs too overwhelmed, after all. \n",
        "\n",
        "Let’s limit the vocabulary to a maximum of 5000 words in our training set:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx955u93SGeY"
      },
      "source": [
        "Tweet.build_vocab(train,max_size=5000)\n",
        "Label.build_vocab(train,max_size=5000)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvyEeEjXTGhX"
      },
      "source": [
        "By default, torchtext will add two more special tokens, <unk> for unknown words and <pad>, a padding token that will be used to pad all our text to roughly the same size to help with efficient batching on the GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA3tIESdcJdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf1a575c-5440-44b1-b29e-7ce56683849e"
      },
      "source": [
        "print('Size of input vocab : ', len(Tweet.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Tweet.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  4651\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [('Obama', 1069), (':', 783), ('#', 780), ('.', 761), (',', 598), ('\"', 550), ('the', 542), ('RT', 516), ('?', 419), ('to', 400)]\n",
            "Labels :  defaultdict(None, {0: 0, 1: 1, 2: 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwjD2-ebTeUX"
      },
      "source": [
        "**Lots of stopwords!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLWW221gTpNs"
      },
      "source": [
        "Now we need to create a data loader to feed into our training loop. Torchtext provides the BucketIterator method that will produce what it calls a Batch, which is almost, but not quite, like the data loader we used on images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQqMhMoDUDmn"
      },
      "source": [
        "But at first declare the device we are using."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfo2QhGJUK4l"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#device"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK2ORoqdTNsM"
      },
      "source": [
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.tweets),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg7gTFQO4fby"
      },
      "source": [
        "Save the vocabulary for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niE9Cc6-2bD_"
      },
      "source": [
        "import os, pickle\n",
        "with open('drive/My Drive/END2/Session6-Assignment/tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Tweet.vocab.stoi, tokens)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AbsQwqkVyAy"
      },
      "source": [
        "## Defining Our Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Wt6Jlgiei4C"
      },
      "source": [
        "### Defining encoder class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0xer9hSnIef"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self,input_dim,emb_dim,hid_dim,n_layers):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hid_dim=hid_dim\n",
        "    self.embedding = nn.Embedding(input_dim, emb_dim) \n",
        "    self.rnn= nn.LSTM(emb_dim, hid_dim,  num_layers=n_layers, batch_first=True)\n",
        "\n",
        "  def forward(self, text,text_lengths):\n",
        "\n",
        "      embedded =self.embedding(text)\n",
        "\n",
        "      packaged_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "\n",
        "      packed_output, (hidden, cell) = self.rnn(packaged_embedded)\n",
        "\n",
        "      print(f'Output of encoder at every step:{packed_output[0]}') ## output of each word is stroed in packaged output, it keeps appending the hidden vector after every step that is nothing but after every word\n",
        "\n",
        "      print(f'Output of encoder at last step:{hidden}') ### Hidden contains output of last time step\n",
        "    \n",
        "      return hidden,cell\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqrxoNdwenof"
      },
      "source": [
        "### Defining Decoder class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_-5XyFd4Usp"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self,out_dim,hid_dim,n_layers):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hid_dim = hid_dim\n",
        "\n",
        "    self.out_dim = out_dim\n",
        "\n",
        "    self.rnn= nn.LSTM(hid_dim,hid_dim, num_layers=n_layers)\n",
        "\n",
        "    self.fc = nn.Linear(hid_dim,out_dim)\n",
        "\n",
        "\n",
        "  def forward(self,input,hidden,cell):\n",
        "\n",
        "    output , (hidden,cell) = self.rnn(input,(hidden,cell))\n",
        "\n",
        "    print(f'Output of decoder at every step (Note that here it is single step):{output[0]}')\n",
        "\n",
        "    prediction = self.fc(hidden.squeeze(0))\n",
        "\n",
        "    return prediction,hidden,cell\n",
        "\n",
        "\n",
        "    \n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNNXgmBCesAw"
      },
      "source": [
        "### Combining encoder decoder "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gs321eMOB63M"
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "        #print(encoder.hid_dim)\n",
        "        #print(decoder.hid_dim)\n",
        "        \n",
        "        assert encoder.hid_dim == decoder.hid_dim\n",
        "        \"Hidden dimensions of encoder and decoder must be equal!\"\n",
        "        \n",
        "    def forward(self, text, text_len):\n",
        "\n",
        "        #hidden, cell = self.encoder(text,text_len)\n",
        "\n",
        "        hidden, cell = self.encoder(text,text_len)\n",
        "        \n",
        "        input = hidden\n",
        "\n",
        "        output,hidden,cell = self.decoder(input,hidden,cell)\n",
        "\n",
        "        return output"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce35h9JVkTN7"
      },
      "source": [
        "INPUT_DIM = len(Tweet.vocab)\n",
        "OUTPUT_DIM = len(Label.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "HID_DIM = 512\n",
        "NUM_LAYERS = 1\n",
        "\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM,NUM_LAYERS)\n",
        "dec = Decoder(OUTPUT_DIM,HID_DIM,NUM_LAYERS)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = EncoderDecoder(enc, dec, device).to(device)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uno1tM8f8nsp",
        "outputId": "9f2a3ac4-1792-4e37-d7b7-0b03f26f3a72"
      },
      "source": [
        "model"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EncoderDecoder(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(4651, 256)\n",
              "    (rnn): LSTM(256, 512, batch_first=True)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (rnn): LSTM(512, 512)\n",
              "    (fc): Linear(in_features=512, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79EhXrtwe1Ao"
      },
      "source": [
        "### Defining loss and accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NP5cTPh98Okg"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "    \n",
        "# push to cuda if available\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--u24wTqfHGp"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na7QT7ru9GF5"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        tweet, tweet_lengths = batch.tweets   \n",
        "\n",
        "  \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(tweet, tweet_lengths).squeeze()  \n",
        "\n",
        "        # output_dim = predictions.shape[-1]\n",
        "        \n",
        "        # predictions = predictions[1:].view(-1, output_dim)\n",
        "        # batch.labels = batch.labels[1:].view(-1)\n",
        "        \n",
        "        \n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.labels)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        #acc = binary_accuracy(predictions, batch.labels)   \n",
        "        acc = categorical_accuracy(predictions, batch.labels)   \n",
        "\n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()  \n",
        "\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzmLairPfSRs"
      },
      "source": [
        "### Evaluation Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6klmVjLo-QIH"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            tweet, tweet_lengths = batch.tweets \n",
        "            \n",
        "            #print(batch.labels.shape)\n",
        "\n",
        "            # convert to 1d tensor\n",
        "            predictions = model(tweet, tweet_lengths).squeeze()\n",
        "\n",
        "            # output_dim = predictions.shape[-1]\n",
        "        \n",
        "            # predictions = predictions[1:].view(-1, output_dim)\n",
        "            # batch.labels = batch.labels[1:].view(-1)\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.labels)\n",
        "\n",
        "            # acc = binary_accuracy(predictions, batch.labels)\n",
        "            acc = categorical_accuracy(predictions, batch.labels)   \n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R87A5IoCfVNl"
      },
      "source": [
        "### Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6EsJZDZqZb9",
        "outputId": "adc729ac-d9b9-4f4c-d551-4e30562a548a"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'drive/My Drive/END2/Session6-Assignment/encoder_decoder_classification_saved_weights.pt')\n",
        "    \n",
        "    print(f'\\t Epoch: {epoch} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Epoch: {epoch} | Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "         [ 0.1336,  0.0911, -0.1526,  ...,  0.2353, -0.0429, -0.0723],\n",
            "         ...,\n",
            "         [ 0.3678,  0.1980, -0.0983,  ...,  0.0250, -0.2127, -0.0458],\n",
            "         [ 0.2773,  0.4156, -0.0337,  ...,  0.0858, -0.1497,  0.1823],\n",
            "         [ 0.1534, -0.0517, -0.2318,  ...,  0.1784, -0.1263,  0.0393]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0887,  0.2883, -0.2749,  ...,  0.2495, -0.2922,  0.0555],\n",
            "        [-0.0624,  0.1514, -0.0721,  ..., -0.0136, -0.0993,  0.0414],\n",
            "        [ 0.1532,  0.2274, -0.2197,  ...,  0.2170, -0.0982, -0.0130],\n",
            "        ...,\n",
            "        [ 0.4349,  0.3245, -0.2796,  ...,  0.2363, -0.3241, -0.0992],\n",
            "        [ 0.1515,  0.5107, -0.2450,  ...,  0.2697, -0.1256,  0.1829],\n",
            "        [ 0.1587,  0.1588, -0.2308,  ...,  0.2555, -0.1925, -0.0125]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0080, -0.0864, -0.0025,  ..., -0.0437,  0.0522,  0.1183],\n",
            "        [-0.0204, -0.1857,  0.0032,  ...,  0.0239, -0.1014, -0.0341],\n",
            "        [ 0.0433, -0.1303, -0.0651,  ...,  0.0575, -0.1028,  0.0223],\n",
            "        ...,\n",
            "        [ 0.1772,  0.2044,  0.0028,  ...,  0.2659, -0.3049, -0.0260],\n",
            "        [ 0.1833,  0.4143, -0.2809,  ...,  0.4063, -0.3200, -0.0503],\n",
            "        [ 0.4767,  0.1207, -0.0449,  ...,  0.1807, -0.1604,  0.0268]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0671, -0.0279, -0.0165,  ...,  0.2380, -0.0176,  0.1285],\n",
            "         [ 0.0041,  0.1702, -0.0535,  ...,  0.0310, -0.2034,  0.0739],\n",
            "         [ 0.3504,  0.1227, -0.1466,  ...,  0.0988, -0.3481, -0.0792],\n",
            "         ...,\n",
            "         [ 0.1764,  0.0268, -0.1729,  ...,  0.0407, -0.2663, -0.0543],\n",
            "         [ 0.0348, -0.1087,  0.0784,  ..., -0.0424,  0.0377,  0.0667],\n",
            "         [ 0.1227, -0.0196, -0.0059,  ...,  0.3761, -0.1820,  0.1193]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0256,  0.1247, -0.0993,  ...,  0.1201,  0.0455,  0.1819],\n",
            "        [ 0.1499,  0.1856, -0.2243,  ...,  0.1829, -0.3053, -0.0319],\n",
            "        [ 0.5116,  0.3087, -0.4185,  ...,  0.3498, -0.5369, -0.1153],\n",
            "        ...,\n",
            "        [ 0.4375,  0.0804, -0.3999,  ...,  0.3063, -0.4745, -0.2038],\n",
            "        [ 0.0075, -0.0602,  0.1146,  ..., -0.0869,  0.0513,  0.0602],\n",
            "        [ 0.1603,  0.1469, -0.2420,  ...,  0.2933, -0.2736,  0.0311]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2041, -0.0185,  0.0864,  ..., -0.0498,  0.0656,  0.0954],\n",
            "        [ 0.0520, -0.0547, -0.0710,  ...,  0.0608,  0.0901,  0.0673],\n",
            "        [ 0.2854, -0.0553,  0.0307,  ...,  0.2172, -0.1661, -0.1604],\n",
            "        ...,\n",
            "        [ 0.2001,  0.1052, -0.1607,  ...,  0.1648, -0.3314, -0.2897],\n",
            "        [ 0.1202,  0.2543, -0.2824,  ...,  0.3030, -0.0834, -0.2543],\n",
            "        [-0.0403,  0.2876, -0.1368,  ...,  0.1553, -0.1452, -0.1976]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1202,  0.2543, -0.2824,  ...,  0.3030, -0.0834, -0.2543],\n",
            "         [-0.0403,  0.2876, -0.1368,  ...,  0.1553, -0.1452, -0.1976],\n",
            "         [ 0.0902, -0.2761,  0.0588,  ..., -0.0890, -0.0600,  0.0635],\n",
            "         ...,\n",
            "         [ 0.1117,  0.2724, -0.0792,  ...,  0.1498, -0.1043, -0.1077],\n",
            "         [-0.0465,  0.0838,  0.0766,  ...,  0.3560, -0.3790, -0.1832],\n",
            "         [ 0.2001,  0.1052, -0.1607,  ...,  0.1648, -0.3314, -0.2897]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2642,  0.4600, -0.4961,  ...,  0.4605, -0.4595, -0.2417],\n",
            "        [-0.1316,  0.4500, -0.1928,  ...,  0.1264, -0.1370, -0.0198],\n",
            "        [ 0.3849, -0.0580, -0.2160,  ...,  0.1421, -0.3290, -0.1036],\n",
            "        ...,\n",
            "        [ 0.0332,  0.4897, -0.1872,  ...,  0.1526,  0.0036,  0.1332],\n",
            "        [ 0.2354,  0.3223, -0.2672,  ...,  0.4317, -0.4588, -0.2408],\n",
            "        [ 0.6831,  0.2272, -0.6465,  ...,  0.5885, -0.7676, -0.5718]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0953,  0.0518, -0.0202,  ..., -0.0507, -0.1134, -0.0204],\n",
            "        [ 0.2838, -0.0565,  0.0319,  ...,  0.2155, -0.1640, -0.1581],\n",
            "        [ 0.2838, -0.0565,  0.0319,  ...,  0.2155, -0.1640, -0.1581],\n",
            "        ...,\n",
            "        [-0.0711,  0.2356, -0.4249,  ...,  0.1632, -0.1425, -0.1173],\n",
            "        [ 0.1070,  0.0771, -0.0694,  ..., -0.0289, -0.0543, -0.1571],\n",
            "        [-0.2162,  0.1415, -0.0606,  ...,  0.1976, -0.0144,  0.0962]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0711,  0.2356, -0.4249,  ...,  0.1632, -0.1425, -0.1173],\n",
            "         [ 0.1070,  0.0771, -0.0694,  ..., -0.0289, -0.0543, -0.1571],\n",
            "         [-0.2162,  0.1415, -0.0606,  ...,  0.1976, -0.0144,  0.0962],\n",
            "         ...,\n",
            "         [-0.0827,  0.2087,  0.1197,  ...,  0.0220, -0.0767, -0.3344],\n",
            "         [ 0.0980,  0.0209,  0.0733,  ...,  0.1140, -0.0312,  0.0757],\n",
            "         [ 0.1725, -0.1123,  0.0321,  ..., -0.0317,  0.1511,  0.0356]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0488,  0.2291, -0.3292,  ...,  0.1852, -0.2233, -0.0170],\n",
            "        [ 0.2791,  0.1232, -0.2364,  ...,  0.0481, -0.2635, -0.1964],\n",
            "        [-0.1182,  0.2723, -0.1959,  ...,  0.1498, -0.0637,  0.1311],\n",
            "        ...,\n",
            "        [ 0.0094,  0.1275, -0.0376,  ...,  0.1237, -0.1398, -0.1644],\n",
            "        [ 0.0812,  0.0475, -0.0127,  ...,  0.1335, -0.0802,  0.0366],\n",
            "        [ 0.1004,  0.0056, -0.0492,  ...,  0.0332, -0.0025, -0.0162]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0234, -0.0287, -0.0187,  ...,  0.1536,  0.0799,  0.0517],\n",
            "        [-0.0924,  0.0187, -0.0408,  ...,  0.0669,  0.0147, -0.0771],\n",
            "        [ 0.1117,  0.0119, -0.0742,  ...,  0.0201,  0.0591, -0.0370],\n",
            "        ...,\n",
            "        [ 0.3625,  0.0813, -0.1434,  ...,  0.3754, -0.2891, -0.0591],\n",
            "        [ 0.2706,  0.4817, -0.2645,  ...,  0.2472, -0.0797, -0.1364],\n",
            "        [ 0.1839, -0.0855, -0.0228,  ...,  0.1561, -0.1815, -0.0267]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1839, -0.0855, -0.0228,  ...,  0.1561, -0.1815, -0.0267],\n",
            "         [-0.0074,  0.2518, -0.0273,  ...,  0.0721,  0.0955,  0.0950],\n",
            "         [ 0.1935, -0.2293, -0.1072,  ...,  0.0302, -0.0965, -0.0664],\n",
            "         ...,\n",
            "         [ 0.0721, -0.1453, -0.1812,  ...,  0.1413, -0.2938, -0.2879],\n",
            "         [ 0.3625,  0.0813, -0.1434,  ...,  0.3754, -0.2891, -0.0591],\n",
            "         [ 0.2706,  0.4817, -0.2645,  ...,  0.2472, -0.0797, -0.1364]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1748,  0.1982, -0.1864,  ...,  0.1379, -0.2165,  0.0621],\n",
            "        [-0.0535,  0.2458,  0.0593,  ..., -0.0382,  0.1822,  0.1838],\n",
            "        [ 0.0698,  0.1361, -0.2193,  ...,  0.1259, -0.1037,  0.0809],\n",
            "        ...,\n",
            "        [ 0.2581,  0.2974, -0.4618,  ...,  0.3505, -0.4957, -0.2758],\n",
            "        [ 0.2295,  0.3573, -0.2929,  ...,  0.2221, -0.2322, -0.0655],\n",
            "        [ 0.0098,  0.6506, -0.2165,  ...,  0.0916, -0.0321,  0.0743]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0093, -0.0870, -0.0029,  ..., -0.0442,  0.0523,  0.1190],\n",
            "        [ 0.0093, -0.0870, -0.0029,  ..., -0.0442,  0.0523,  0.1190],\n",
            "        [ 0.0093, -0.0870, -0.0029,  ..., -0.0442,  0.0523,  0.1190],\n",
            "        ...,\n",
            "        [ 0.2618, -0.1211, -0.1811,  ...,  0.4440, -0.4928, -0.1797],\n",
            "        [ 0.2618, -0.1211, -0.1811,  ...,  0.4440, -0.4928, -0.1797],\n",
            "        [ 0.2618, -0.1211, -0.1811,  ...,  0.4440, -0.4928, -0.1797]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2618, -0.1211, -0.1811,  ...,  0.4440, -0.4928, -0.1797],\n",
            "         [ 0.2618, -0.1211, -0.1811,  ...,  0.4440, -0.4928, -0.1797],\n",
            "         [ 0.2618, -0.1211, -0.1811,  ...,  0.4440, -0.4928, -0.1797],\n",
            "         ...,\n",
            "         [ 0.1805,  0.3107, -0.1091,  ...,  0.0940, -0.2790, -0.1491],\n",
            "         [ 0.0027, -0.1053, -0.1310,  ..., -0.0540, -0.0115, -0.1006],\n",
            "         [ 0.0669,  0.1966,  0.1001,  ...,  0.2411, -0.1778, -0.0894]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6040,  0.2668, -0.5357,  ...,  0.5693, -0.6706, -0.4128],\n",
            "        [ 0.6040,  0.2668, -0.5357,  ...,  0.5693, -0.6706, -0.4128],\n",
            "        [ 0.6040,  0.2668, -0.5357,  ...,  0.5693, -0.6706, -0.4128],\n",
            "        ...,\n",
            "        [ 0.5102,  0.4305, -0.4659,  ...,  0.4003, -0.5970, -0.2121],\n",
            "        [ 0.1253,  0.1210, -0.3058,  ...,  0.1652, -0.2131, -0.0435],\n",
            "        [-0.0320,  0.1740,  0.0955,  ...,  0.0731,  0.0335, -0.0063]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0095, -0.0875, -0.0030,  ..., -0.0444,  0.0523,  0.1193],\n",
            "        [ 0.0095, -0.0875, -0.0030,  ..., -0.0444,  0.0523,  0.1193],\n",
            "        [ 0.0247,  0.0670,  0.2047,  ..., -0.0630,  0.0274,  0.0839],\n",
            "        ...,\n",
            "        [ 0.4275, -0.1225, -0.1124,  ..., -0.0816, -0.3074, -0.1692],\n",
            "        [-0.0662,  0.3571,  0.1307,  ...,  0.0904, -0.1945, -0.0786],\n",
            "        [ 0.0673,  0.3453,  0.0125,  ...,  0.1462, -0.1753, -0.0769]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0413, -0.2280, -0.3594,  ...,  0.2593, -0.4214, -0.2235],\n",
            "         [ 0.4693,  0.0832, -0.0300,  ...,  0.3347, -0.3062, -0.4022],\n",
            "         [ 0.2580, -0.0122,  0.0901,  ...,  0.3274, -0.1126,  0.0670],\n",
            "         ...,\n",
            "         [ 0.4275, -0.1225, -0.1124,  ..., -0.0816, -0.3074, -0.1692],\n",
            "         [-0.0662,  0.3571,  0.1307,  ...,  0.0904, -0.1945, -0.0786],\n",
            "         [ 0.0673,  0.3453,  0.0125,  ...,  0.1462, -0.1753, -0.0769]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4082,  0.1019, -0.5545,  ...,  0.5051, -0.6664, -0.2829],\n",
            "        [ 0.4234,  0.2220, -0.2639,  ...,  0.2499, -0.4252, -0.3791],\n",
            "        [ 0.0862,  0.2160, -0.1280,  ...,  0.2105, -0.1527,  0.0597],\n",
            "        ...,\n",
            "        [ 0.5210,  0.0494, -0.3432,  ...,  0.1904, -0.5008, -0.3064],\n",
            "        [-0.0956,  0.4991, -0.1319,  ...,  0.1313, -0.0915,  0.0695],\n",
            "        [-0.0650,  0.5240, -0.0763,  ...,  0.1506, -0.0414,  0.1499]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1057,  0.0862, -0.0292,  ...,  0.0740, -0.0035, -0.0804],\n",
            "        [-0.0081,  0.0651, -0.0721,  ..., -0.0066,  0.0529,  0.1014],\n",
            "        [-0.0925, -0.0670,  0.0296,  ..., -0.0312, -0.0358, -0.0816],\n",
            "        ...,\n",
            "        [ 0.0644,  0.2410,  0.1579,  ...,  0.0668,  0.0380,  0.2211],\n",
            "        [ 0.0763, -0.1664, -0.1743,  ..., -0.0894, -0.2443,  0.0334],\n",
            "        [ 0.0860,  0.1341, -0.0160,  ...,  0.2893, -0.1945,  0.0035]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0803,  0.2255, -0.1350,  ...,  0.1347, -0.2347, -0.2923],\n",
            "         [ 0.0516, -0.1025, -0.0690,  ...,  0.2931,  0.1076, -0.0461],\n",
            "         [ 0.0644,  0.2410,  0.1579,  ...,  0.0668,  0.0380,  0.2211],\n",
            "         ...,\n",
            "         [ 0.0644,  0.2410,  0.1579,  ...,  0.0668,  0.0380,  0.2211],\n",
            "         [ 0.0763, -0.1664, -0.1743,  ..., -0.0894, -0.2443,  0.0334],\n",
            "         [ 0.0860,  0.1341, -0.0160,  ...,  0.2893, -0.1945,  0.0035]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4612,  0.2186, -0.5052,  ...,  0.4283, -0.6128, -0.4559],\n",
            "        [ 0.0591, -0.0323, -0.0073,  ...,  0.1272, -0.0135, -0.0093],\n",
            "        [-0.0534,  0.4210,  0.1029,  ...,  0.0870,  0.1509,  0.2580],\n",
            "        ...,\n",
            "        [-0.0534,  0.4210,  0.1029,  ...,  0.0870,  0.1509,  0.2580],\n",
            "        [ 0.2571, -0.1503, -0.0857,  ..., -0.0195, -0.2078, -0.0823],\n",
            "        [ 0.2371,  0.2821, -0.2573,  ...,  0.3263, -0.2876, -0.0409]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0702,  0.0191, -0.1218,  ...,  0.0630,  0.0739, -0.0752],\n",
            "        [ 0.0097, -0.0880, -0.0032,  ..., -0.0447,  0.0522,  0.1196],\n",
            "        [ 0.0097, -0.0880, -0.0032,  ..., -0.0447,  0.0522,  0.1196],\n",
            "        ...,\n",
            "        [ 0.1806,  0.0149, -0.1445,  ...,  0.2392, -0.1833,  0.0680],\n",
            "        [ 0.2480,  0.1730,  0.0955,  ...,  0.1348, -0.0401, -0.0345],\n",
            "        [ 0.1806,  0.0149, -0.1445,  ...,  0.2392, -0.1833,  0.0680]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3716,  0.0934, -0.2215,  ...,  0.0079, -0.2114, -0.3764],\n",
            "         [ 0.1806,  0.0149, -0.1445,  ...,  0.2392, -0.1833,  0.0680],\n",
            "         [ 0.2480,  0.1730,  0.0955,  ...,  0.1348, -0.0401, -0.0345],\n",
            "         ...,\n",
            "         [ 0.1324,  0.2120, -0.0987,  ...,  0.1951, -0.3047, -0.3368],\n",
            "         [ 0.0147,  0.3273, -0.0471,  ...,  0.0930,  0.0753,  0.1405],\n",
            "         [ 0.1473, -0.1775,  0.0275,  ...,  0.0830, -0.0677,  0.0263]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 6.3573e-01,  2.7381e-01, -4.5776e-01,  ...,  2.7534e-01,\n",
            "         -4.8986e-01, -4.5517e-01],\n",
            "        [ 4.0787e-01,  6.7923e-02, -3.5377e-01,  ...,  3.9966e-01,\n",
            "         -4.3947e-01, -1.4065e-01],\n",
            "        [ 3.1208e-01,  1.0935e-01, -3.8402e-02,  ...,  1.4305e-01,\n",
            "         -1.6928e-01, -1.3089e-01],\n",
            "        ...,\n",
            "        [ 5.7393e-01,  2.7170e-01, -4.7839e-01,  ...,  5.2189e-01,\n",
            "         -6.9926e-01, -4.6602e-01],\n",
            "        [-1.0758e-01,  5.0754e-01, -1.5478e-02,  ...,  2.4287e-02,\n",
            "          2.0665e-01,  2.7919e-01],\n",
            "        [ 8.0962e-02, -1.2264e-01,  1.9626e-02,  ...,  1.1951e-04,\n",
            "         -3.6995e-02,  1.1588e-02]], grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0100, -0.0881, -0.0034,  ..., -0.0449,  0.0521,  0.1197],\n",
            "        [ 0.1141,  0.1028, -0.0835,  ...,  0.1046,  0.0653, -0.0005],\n",
            "        [ 0.0252, -0.0623,  0.0606,  ...,  0.1567, -0.1065, -0.1362],\n",
            "        ...,\n",
            "        [ 0.1448,  0.2189, -0.1199,  ...,  0.0132, -0.0296,  0.0488],\n",
            "        [ 0.0607,  0.0826,  0.1849,  ...,  0.0748,  0.0509,  0.1709],\n",
            "        [ 0.0864,  0.3034, -0.0699,  ...,  0.0554, -0.1274, -0.0059]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0607,  0.0826,  0.1849,  ...,  0.0748,  0.0509,  0.1709],\n",
            "         [ 0.0864,  0.3034, -0.0699,  ...,  0.0554, -0.1274, -0.0059],\n",
            "         [ 0.1162, -0.0709,  0.0528,  ...,  0.3307, -0.4195, -0.1690],\n",
            "         ...,\n",
            "         [ 0.2818,  0.1217,  0.1114,  ...,  0.1077, -0.2262, -0.0905],\n",
            "         [ 0.0813, -0.0109,  0.0403,  ...,  0.1181, -0.0148, -0.1394],\n",
            "         [ 0.1448,  0.2189, -0.1199,  ...,  0.0132, -0.0296,  0.0488]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0106,  0.2426,  0.0583,  ...,  0.1353,  0.0704,  0.1300],\n",
            "        [-0.0075,  0.4768, -0.1122,  ...,  0.1008,  0.0031,  0.2235],\n",
            "        [ 0.2255,  0.1541, -0.1930,  ...,  0.3340, -0.4212, -0.1901],\n",
            "        ...,\n",
            "        [ 0.5432,  0.2160, -0.2526,  ...,  0.3232, -0.4704, -0.2595],\n",
            "        [ 0.0304, -0.0220,  0.0130,  ...,  0.0052, -0.0381, -0.0839],\n",
            "        [ 0.0533,  0.2739, -0.1172,  ...,  0.0183, -0.0006,  0.1497]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0104, -0.0883, -0.0036,  ..., -0.0450,  0.0521,  0.1198],\n",
            "        [ 0.0104, -0.0883, -0.0036,  ..., -0.0450,  0.0521,  0.1198],\n",
            "        [ 0.0104, -0.0883, -0.0036,  ..., -0.0450,  0.0521,  0.1198],\n",
            "        ...,\n",
            "        [ 0.0942, -0.0566, -0.0911,  ...,  0.1943, -0.3072, -0.0509],\n",
            "        [ 0.1014, -0.1233, -0.0965,  ...,  0.3180, -0.2969,  0.0751],\n",
            "        [ 0.0529, -0.0274,  0.0115,  ...,  0.0184, -0.1204,  0.1092]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1014, -0.1233, -0.0965,  ...,  0.3180, -0.2969,  0.0751],\n",
            "         [ 0.0529, -0.0274,  0.0115,  ...,  0.0184, -0.1204,  0.1092],\n",
            "         [ 0.0584, -0.1741,  0.0885,  ..., -0.0561, -0.0552,  0.0694],\n",
            "         ...,\n",
            "         [-0.0574,  0.1166, -0.0018,  ...,  0.3567, -0.1088, -0.0702],\n",
            "         [ 0.1442, -0.0850, -0.1238,  ..., -0.0430, -0.1043, -0.0800],\n",
            "         [ 0.1726, -0.1033, -0.1107,  ...,  0.0507, -0.1594, -0.0420]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4232,  0.1106, -0.4200,  ...,  0.4969, -0.5723, -0.1747],\n",
            "        [-0.0234,  0.0831,  0.0180,  ...,  0.0221, -0.0103,  0.1277],\n",
            "        [ 0.0986, -0.0888,  0.1042,  ..., -0.0595, -0.0536,  0.0101],\n",
            "        ...,\n",
            "        [-0.0308,  0.0580, -0.0127,  ...,  0.1613, -0.0912, -0.0494],\n",
            "        [ 0.2130, -0.0379, -0.1606,  ...,  0.0299, -0.2038, -0.0976],\n",
            "        [ 0.1314,  0.0109, -0.1379,  ...,  0.0693, -0.1020,  0.0266]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0108, -0.0885, -0.0038,  ..., -0.0453,  0.0521,  0.1197],\n",
            "        [ 0.0108, -0.0885, -0.0038,  ..., -0.0453,  0.0521,  0.1197],\n",
            "        [ 0.0108, -0.0885, -0.0038,  ..., -0.0453,  0.0521,  0.1197],\n",
            "        ...,\n",
            "        [ 0.0181,  0.5152, -0.0877,  ...,  0.1860, -0.2223, -0.2038],\n",
            "        [ 0.0554,  0.3389,  0.0986,  ..., -0.0312, -0.1454,  0.0081],\n",
            "        [ 0.0529,  0.2210,  0.1652,  ...,  0.0592,  0.0439,  0.2204]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0529,  0.2210,  0.1652,  ...,  0.0592,  0.0439,  0.2204],\n",
            "         [ 0.3023,  0.1013,  0.0066,  ...,  0.1311, -0.2549, -0.2116],\n",
            "         [ 0.1827, -0.1796,  0.0085,  ...,  0.1813, -0.2243, -0.1232],\n",
            "         ...,\n",
            "         [ 0.0554,  0.3389,  0.0986,  ..., -0.0312, -0.1454,  0.0081],\n",
            "         [ 0.0529,  0.2210,  0.1652,  ...,  0.0592,  0.0439,  0.2204],\n",
            "         [ 0.3994, -0.0206, -0.0567,  ..., -0.1458, -0.3794, -0.1159]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0522,  0.3783,  0.1177,  ...,  0.0722,  0.1504,  0.2440],\n",
            "        [ 0.2766,  0.1368, -0.0486,  ...,  0.0663, -0.2676, -0.1612],\n",
            "        [ 0.3559, -0.1055, -0.1609,  ...,  0.1725, -0.3622, -0.1904],\n",
            "        ...,\n",
            "        [ 0.0059,  0.3359,  0.0093,  ...,  0.0161, -0.0268,  0.0599],\n",
            "        [-0.0522,  0.3783,  0.1177,  ...,  0.0722,  0.1504,  0.2440],\n",
            "        [ 0.5497,  0.1661, -0.3776,  ...,  0.2476, -0.5860, -0.2982]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1139,  0.0099, -0.0716,  ...,  0.0205,  0.0615, -0.0318],\n",
            "        [ 0.0114, -0.0886, -0.0040,  ..., -0.0455,  0.0520,  0.1196],\n",
            "        [ 0.0576,  0.0473, -0.1931,  ...,  0.0818,  0.1195,  0.0706],\n",
            "        ...,\n",
            "        [ 0.2232,  0.1661, -0.0340,  ...,  0.0406, -0.2167,  0.0755],\n",
            "        [ 0.3480, -0.3492, -0.1595,  ...,  0.1514, -0.3771, -0.2415],\n",
            "        [ 0.1741, -0.2309,  0.1938,  ...,  0.2058, -0.0977,  0.0801]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1554, -0.0091, -0.3411,  ...,  0.3009,  0.0260, -0.1978],\n",
            "         [ 0.3480, -0.3492, -0.1595,  ...,  0.1514, -0.3771, -0.2415],\n",
            "         [ 0.0745,  0.3628, -0.1146,  ...,  0.1508, -0.1681, -0.2627],\n",
            "         ...,\n",
            "         [ 0.2232,  0.1661, -0.0340,  ...,  0.0406, -0.2167,  0.0755],\n",
            "         [ 0.3480, -0.3492, -0.1595,  ...,  0.1514, -0.3771, -0.2415],\n",
            "         [ 0.1741, -0.2309,  0.1938,  ...,  0.2058, -0.0977,  0.0801]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0626,  0.2441, -0.3245,  ...,  0.2660, -0.0386, -0.0087],\n",
            "        [ 0.5592, -0.1141, -0.3954,  ...,  0.3685, -0.5795, -0.4313],\n",
            "        [ 0.2687,  0.4004, -0.3878,  ...,  0.3843, -0.4154, -0.1887],\n",
            "        ...,\n",
            "        [ 0.3494,  0.1782, -0.2014,  ...,  0.1073, -0.3203, -0.0793],\n",
            "        [ 0.5592, -0.1141, -0.3954,  ...,  0.3685, -0.5795, -0.4313],\n",
            "        [ 0.0687,  0.0229,  0.0467,  ...,  0.1281, -0.0814,  0.1173]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0119, -0.0887, -0.0044,  ..., -0.0457,  0.0519,  0.1195],\n",
            "        [ 0.2591, -0.0701,  0.0337,  ...,  0.2198, -0.1659, -0.1676],\n",
            "        [ 0.2591, -0.0701,  0.0337,  ...,  0.2198, -0.1659, -0.1676],\n",
            "        ...,\n",
            "        [ 0.1075,  0.2698,  0.0041,  ...,  0.3207, -0.0916, -0.1886],\n",
            "        [ 0.0469, -0.0586,  0.0344,  ...,  0.3574, -0.2071,  0.0114],\n",
            "        [-0.0444,  0.2412, -0.2599,  ...,  0.0796, -0.1978, -0.1264]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1075,  0.2698,  0.0041,  ...,  0.3207, -0.0916, -0.1886],\n",
            "         [ 0.0382, -0.0579, -0.0632,  ...,  0.0716, -0.2928, -0.1961],\n",
            "         [ 0.2523, -0.3975, -0.0395,  ..., -0.0342, -0.1436, -0.1206],\n",
            "         ...,\n",
            "         [ 0.0307,  0.2132, -0.0609,  ...,  0.1249, -0.2272, -0.3159],\n",
            "         [ 0.1410,  0.1751, -0.2648,  ...,  0.2376, -0.2062, -0.0078],\n",
            "         [ 0.0564, -0.1641,  0.0499,  ..., -0.1209, -0.1075,  0.1624]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0900,  0.5229, -0.1565,  ...,  0.2220,  0.0484,  0.1001],\n",
            "        [ 0.3348,  0.0608, -0.2932,  ...,  0.2669, -0.4486, -0.2870],\n",
            "        [ 0.3841, -0.0639, -0.3230,  ...,  0.2210, -0.3676, -0.2414],\n",
            "        ...,\n",
            "        [ 0.1953,  0.2202, -0.2260,  ...,  0.3193, -0.4007, -0.2177],\n",
            "        [ 0.2605,  0.2090, -0.3728,  ...,  0.2201, -0.2770, -0.1355],\n",
            "        [ 0.0611, -0.0111, -0.0502,  ..., -0.0418, -0.1106,  0.0446]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0375,  0.0720, -0.0115,  ..., -0.0854, -0.1421,  0.0689],\n",
            "        [ 0.0628, -0.0633,  0.1144,  ...,  0.0918, -0.1579, -0.0352],\n",
            "        [ 0.0124, -0.0890, -0.0047,  ..., -0.0460,  0.0519,  0.1194],\n",
            "        ...,\n",
            "        [ 0.3383,  0.2127,  0.2084,  ..., -0.0516, -0.3520, -0.0892],\n",
            "        [ 0.0624, -0.0140, -0.0168,  ...,  0.2115, -0.2865, -0.1906],\n",
            "        [-0.0924,  0.1700, -0.1490,  ..., -0.0168,  0.0317,  0.0955]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0168, -0.1572, -0.2256,  ..., -0.0292,  0.0018,  0.2365],\n",
            "         [ 0.3383,  0.2127,  0.2084,  ..., -0.0516, -0.3520, -0.0892],\n",
            "         [ 0.0624, -0.0140, -0.0168,  ...,  0.2115, -0.2865, -0.1906],\n",
            "         ...,\n",
            "         [ 0.0277, -0.0891,  0.1885,  ...,  0.1880, -0.1803, -0.0530],\n",
            "         [ 0.2363, -0.0169,  0.0303,  ...,  0.2590, -0.2500, -0.0100],\n",
            "         [ 0.0276,  0.2465, -0.1043,  ...,  0.1579, -0.2617, -0.2388]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0645,  0.0932, -0.3050,  ...,  0.1229,  0.0156,  0.2764],\n",
            "        [ 0.2472,  0.2495,  0.0012,  ...,  0.0814, -0.2367, -0.0409],\n",
            "        [ 0.3850,  0.0491, -0.3316,  ...,  0.3815, -0.4757, -0.3440],\n",
            "        ...,\n",
            "        [ 0.1041, -0.0083,  0.0489,  ...,  0.2512, -0.2271, -0.1043],\n",
            "        [ 0.3113,  0.0141, -0.0949,  ...,  0.1642, -0.3203, -0.0841],\n",
            "        [ 0.3078,  0.1641, -0.4227,  ...,  0.4223, -0.5207, -0.3255]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0024,  0.0010, -0.1805,  ..., -0.0017, -0.1311, -0.0187],\n",
            "        [ 0.0153, -0.0853,  0.0153,  ...,  0.1501,  0.0329,  0.0180],\n",
            "        [-0.0652,  0.0375, -0.0243,  ...,  0.0158,  0.2242,  0.1426],\n",
            "        ...,\n",
            "        [ 0.1105,  0.2348,  0.0458,  ...,  0.0619, -0.1647, -0.0254],\n",
            "        [ 0.1196, -0.1987, -0.0206,  ...,  0.0953, -0.1861, -0.0342],\n",
            "        [ 0.0814,  0.3414,  0.1467,  ...,  0.0368,  0.1729,  0.0161]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0967,  0.2413, -0.0767,  ...,  0.1576, -0.2003, -0.1582],\n",
            "         [ 0.0278, -0.1562, -0.0523,  ..., -0.1335, -0.0563,  0.0250],\n",
            "         [-0.1493,  0.0384, -0.1004,  ..., -0.0183, -0.1706,  0.1557],\n",
            "         ...,\n",
            "         [ 0.1105,  0.2348,  0.0458,  ...,  0.0619, -0.1647, -0.0254],\n",
            "         [ 0.1196, -0.1987, -0.0206,  ...,  0.0953, -0.1861, -0.0342],\n",
            "         [ 0.0814,  0.3414,  0.1467,  ...,  0.0368,  0.1729,  0.0161]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 5.0984e-01,  1.7284e-01, -4.2771e-01,  ...,  4.5225e-01,\n",
            "         -5.9073e-01, -3.5190e-01],\n",
            "        [ 1.2009e-01, -6.8002e-02, -6.1070e-02,  ..., -2.7500e-02,\n",
            "         -1.2805e-01,  1.2885e-04],\n",
            "        [ 5.1509e-02,  1.1833e-01, -2.6932e-01,  ...,  1.6883e-01,\n",
            "         -3.2382e-01,  5.6848e-02],\n",
            "        ...,\n",
            "        [ 8.5207e-02,  2.2348e-01,  4.3480e-03,  ...,  3.8413e-02,\n",
            "         -8.2226e-02,  7.3411e-02],\n",
            "        [ 2.7798e-01, -5.6005e-02, -1.6376e-01,  ...,  1.0555e-01,\n",
            "         -2.9954e-01, -1.2293e-01],\n",
            "        [-1.0156e-01,  4.4201e-01,  7.2131e-02,  ...,  6.2631e-02,\n",
            "          2.1344e-01,  1.6074e-01]], grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0230,  0.0637, -0.1022,  ..., -0.0545,  0.0262, -0.0232],\n",
            "        [ 0.0266, -0.0760,  0.1508,  ...,  0.1599, -0.0545, -0.0688],\n",
            "        [ 0.0134, -0.0892, -0.0052,  ..., -0.0462,  0.0519,  0.1195],\n",
            "        ...,\n",
            "        [ 0.1167,  0.1191, -0.2529,  ..., -0.0485, -0.0131, -0.1274],\n",
            "        [ 0.0497,  0.1920, -0.0254,  ...,  0.1046, -0.0488, -0.0528],\n",
            "        [ 0.1452,  0.2976, -0.2393,  ...,  0.1775, -0.0682, -0.1210]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0110,  0.1555,  0.1458,  ...,  0.0107, -0.0740, -0.0182],\n",
            "         [-0.0631, -0.0208,  0.0054,  ...,  0.1354, -0.1855,  0.1216],\n",
            "         [ 0.0934, -0.3633, -0.0451,  ...,  0.1785, -0.2961, -0.1801],\n",
            "         ...,\n",
            "         [ 0.1876,  0.0690, -0.1207,  ...,  0.1825, -0.1189,  0.0205],\n",
            "         [ 0.0986,  0.2582,  0.0091,  ...,  0.3130, -0.0767, -0.1812],\n",
            "         [ 0.1034, -0.0061, -0.0802,  ...,  0.1370, -0.0715, -0.1765]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1842,  0.1709, -0.0373,  ...,  0.2048, -0.2174, -0.1357],\n",
            "        [-0.0147, -0.0527,  0.0702,  ...,  0.0211, -0.0263,  0.0648],\n",
            "        [ 0.2806, -0.0649, -0.2590,  ...,  0.2445, -0.3766, -0.2275],\n",
            "        ...,\n",
            "        [ 0.2821,  0.1117, -0.2315,  ...,  0.2729, -0.2325, -0.0378],\n",
            "        [-0.0965,  0.5072, -0.1356,  ...,  0.2023,  0.0740,  0.1073],\n",
            "        [ 0.3755,  0.0915, -0.3420,  ...,  0.3703, -0.4063, -0.3138]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.1654, -0.1193, -0.1975,  ...,  0.1634,  0.0478,  0.1178],\n",
            "        [ 0.1271,  0.0713,  0.0732,  ..., -0.0504, -0.1464, -0.0027],\n",
            "        [ 0.0370,  0.1288,  0.1054,  ...,  0.0359, -0.0483, -0.0487],\n",
            "        ...,\n",
            "        [ 0.3076, -0.0447, -0.0391,  ...,  0.2253, -0.1904, -0.2747],\n",
            "        [ 0.1957,  0.0355,  0.0143,  ..., -0.0034, -0.1624, -0.2061],\n",
            "        [ 0.0028,  0.0080,  0.0570,  ..., -0.1214,  0.0462,  0.0934]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3076, -0.0447, -0.0391,  ...,  0.2253, -0.1904, -0.2747],\n",
            "         [ 0.1957,  0.0355,  0.0143,  ..., -0.0034, -0.1624, -0.2061],\n",
            "         [ 0.0028,  0.0080,  0.0570,  ..., -0.1214,  0.0462,  0.0934],\n",
            "         ...,\n",
            "         [ 0.0797,  0.1143,  0.1555,  ...,  0.0031, -0.1101,  0.0531],\n",
            "         [ 0.1669,  0.1464, -0.2181,  ...,  0.1474, -0.0561, -0.1375],\n",
            "         [ 0.1263,  0.0069, -0.1235,  ..., -0.0462, -0.1113, -0.1789]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3195,  0.0999, -0.2260,  ...,  0.2030, -0.3185, -0.2568],\n",
            "        [ 0.2590,  0.0899, -0.0961,  ...,  0.1025, -0.2442, -0.1614],\n",
            "        [ 0.0263,  0.0564, -0.0285,  ...,  0.0005, -0.0078,  0.1300],\n",
            "        ...,\n",
            "        [ 0.1566,  0.1337, -0.0341,  ...,  0.1661, -0.2018, -0.0250],\n",
            "        [ 0.2077,  0.1513, -0.2042,  ...,  0.1849, -0.1131, -0.1367],\n",
            "        [ 0.2089,  0.0320, -0.2041,  ...,  0.0592, -0.2305, -0.1526]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2565, -0.0727,  0.0325,  ...,  0.2212, -0.1664, -0.1724],\n",
            "        [ 0.2565, -0.0727,  0.0325,  ...,  0.2212, -0.1664, -0.1724],\n",
            "        [ 0.0258,  0.0909, -0.1182,  ..., -0.0745, -0.0214, -0.1008],\n",
            "        ...,\n",
            "        [ 0.1660,  0.1459,  0.0182,  ...,  0.1371,  0.0250, -0.1092],\n",
            "        [ 0.0880,  0.4138, -0.0196,  ...,  0.0840,  0.0457,  0.1897],\n",
            "        [ 0.2296, -0.2249, -0.2652,  ...,  0.2130, -0.1270, -0.1480]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1660,  0.1459,  0.0182,  ...,  0.1371,  0.0250, -0.1092],\n",
            "         [ 0.0880,  0.4138, -0.0196,  ...,  0.0840,  0.0457,  0.1897],\n",
            "         [ 0.2296, -0.2249, -0.2652,  ...,  0.2130, -0.1270, -0.1480],\n",
            "         ...,\n",
            "         [ 0.1077,  0.0170, -0.1290,  ...,  0.1528, -0.3285, -0.2623],\n",
            "         [ 0.0710,  0.0262, -0.0952,  ...,  0.1184, -0.1364, -0.1735],\n",
            "         [ 0.1361,  0.0370,  0.0081,  ...,  0.3568, -0.1875,  0.2408]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1518,  0.1539, -0.0605,  ...,  0.0916, -0.0675, -0.0265],\n",
            "        [-0.0486,  0.5071,  0.0272,  ..., -0.0192,  0.1818,  0.2914],\n",
            "        [ 0.4616,  0.0670, -0.4602,  ...,  0.3366, -0.4822, -0.3346],\n",
            "        ...,\n",
            "        [ 0.6332,  0.0637, -0.6157,  ...,  0.5738, -0.7563, -0.5268],\n",
            "        [ 0.3601,  0.0968, -0.3471,  ...,  0.3685, -0.4169, -0.2860],\n",
            "        [-0.0133,  0.3516, -0.0673,  ...,  0.2150, -0.0026,  0.3172]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0272, -0.0764,  0.1524,  ...,  0.1580, -0.0537, -0.0680],\n",
            "        [ 0.1573,  0.1413, -0.0407,  ...,  0.1023, -0.1043, -0.1051],\n",
            "        [ 0.1452,  0.0483, -0.1459,  ..., -0.0721,  0.0876,  0.0588],\n",
            "        ...,\n",
            "        [ 0.0108,  0.3932, -0.0294,  ...,  0.0579,  0.0174,  0.1564],\n",
            "        [ 0.0579,  0.2263, -0.0507,  ...,  0.0607,  0.1130,  0.0243],\n",
            "        [ 0.1019,  0.4176, -0.1441,  ...,  0.0985, -0.2136, -0.1772]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1483,  0.0527,  0.0887,  ...,  0.0520,  0.1359,  0.0762],\n",
            "         [ 0.0881,  0.1766, -0.0743,  ...,  0.1447, -0.0907, -0.1484],\n",
            "         [-0.0329,  0.0218, -0.1704,  ...,  0.0912,  0.0020,  0.0523],\n",
            "         ...,\n",
            "         [ 0.0247, -0.2566, -0.0491,  ...,  0.1653, -0.1893,  0.0501],\n",
            "         [ 0.0101,  0.4454, -0.0725,  ...,  0.0854,  0.0515, -0.0772],\n",
            "         [ 0.0101,  0.4454, -0.0725,  ...,  0.0854,  0.0515, -0.0772]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.1297,  0.0955,  0.0350,  ..., -0.0075,  0.1261,  0.1153],\n",
            "        [ 0.2041,  0.1734, -0.2003,  ...,  0.2778, -0.2280, -0.1046],\n",
            "        [-0.0517,  0.0525, -0.0046,  ...,  0.0636,  0.0379,  0.0889],\n",
            "        ...,\n",
            "        [ 0.1975, -0.0853, -0.1746,  ...,  0.1831, -0.3025, -0.0915],\n",
            "        [-0.0782,  0.5629, -0.0679,  ...,  0.0408,  0.1729,  0.1740],\n",
            "        [-0.0782,  0.5629, -0.0679,  ...,  0.0408,  0.1729,  0.1740]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2535, -0.0713,  0.0320,  ...,  0.2251, -0.1684, -0.1758],\n",
            "        [-0.0689,  0.0194, -0.1215,  ...,  0.0635,  0.0743, -0.0730],\n",
            "        [ 0.0907,  0.0842, -0.0243,  ...,  0.0710,  0.0031, -0.0790],\n",
            "        ...,\n",
            "        [ 0.0573, -0.1681, -0.1427,  ..., -0.0238, -0.1156,  0.0609],\n",
            "        [ 0.2316, -0.1687, -0.0518,  ...,  0.1038, -0.2042, -0.0677],\n",
            "        [ 0.0264, -0.2667,  0.0318,  ...,  0.2112, -0.2143,  0.0834]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1299, -0.0150, -0.2250,  ...,  0.2126, -0.0654, -0.1006],\n",
            "         [-0.0252,  0.0265,  0.2708,  ..., -0.1768, -0.1240,  0.0385],\n",
            "         [ 0.3979, -0.0710, -0.0240,  ...,  0.3021, -0.2917, -0.3768],\n",
            "         ...,\n",
            "         [ 0.0298,  0.1130, -0.0427,  ...,  0.1207, -0.0705,  0.0278],\n",
            "         [ 0.2192, -0.4194, -0.0930,  ..., -0.0084, -0.2256, -0.0637],\n",
            "         [ 0.2397, -0.1174, -0.0498,  ...,  0.3204, -0.1662, -0.1764]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1874,  0.1933, -0.2988,  ...,  0.2557, -0.2386, -0.1479],\n",
            "        [ 0.1248,  0.0446,  0.0760,  ..., -0.0303, -0.2010, -0.0366],\n",
            "        [ 0.4805,  0.0413, -0.2664,  ...,  0.2590, -0.4568, -0.3991],\n",
            "        ...,\n",
            "        [ 0.0198,  0.1056,  0.0090,  ...,  0.0539,  0.0113,  0.0975],\n",
            "        [ 0.2414, -0.1756, -0.1337,  ...,  0.0748, -0.2504, -0.1696],\n",
            "        [ 0.2343,  0.0663, -0.2671,  ...,  0.2429, -0.2970, -0.2211]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0148, -0.0895, -0.0062,  ..., -0.0462,  0.0518,  0.1196],\n",
            "        [ 0.0148, -0.0895, -0.0062,  ..., -0.0462,  0.0518,  0.1196],\n",
            "        [ 0.1360,  0.1495, -0.0528,  ...,  0.0322, -0.0238,  0.0298],\n",
            "        ...,\n",
            "        [ 0.0698,  0.1449, -0.1079,  ...,  0.1961, -0.2103, -0.0728],\n",
            "        [-0.0015,  0.1187,  0.2912,  ..., -0.0241,  0.0309,  0.1095],\n",
            "        [ 0.0660,  0.0706, -0.0213,  ...,  0.1217, -0.1411,  0.0550]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0924,  0.1969,  0.0552,  ...,  0.1341, -0.0942,  0.0794],\n",
            "         [ 0.2373,  0.4893, -0.0979,  ...,  0.0896, -0.1833, -0.3128],\n",
            "         [ 0.1118,  0.0369, -0.1310,  ..., -0.0264, -0.3067,  0.0073],\n",
            "         ...,\n",
            "         [ 0.1029,  0.2275,  0.0044,  ...,  0.0742, -0.1317, -0.0692],\n",
            "         [ 0.0803, -0.0922, -0.0502,  ...,  0.1325, -0.0887, -0.0060],\n",
            "         [ 0.0663,  0.1828, -0.0648,  ...,  0.1874, -0.2378, -0.2459]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0095,  0.2645, -0.1105,  ...,  0.2166, -0.1352,  0.0874],\n",
            "        [ 0.1596,  0.3945, -0.0735,  ...,  0.0457, -0.0853, -0.0197],\n",
            "        [ 0.2760,  0.0710, -0.2095,  ...,  0.1133, -0.3377, -0.1234],\n",
            "        ...,\n",
            "        [ 0.0952,  0.2559, -0.0510,  ...,  0.0549, -0.1197,  0.0482],\n",
            "        [ 0.2591, -0.0662, -0.1616,  ...,  0.1907, -0.2043,  0.0041],\n",
            "        [ 0.2930,  0.3260, -0.2941,  ...,  0.3381, -0.3724, -0.2662]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0151, -0.0898, -0.0063,  ..., -0.0464,  0.0518,  0.1197],\n",
            "        [ 0.0151, -0.0898, -0.0063,  ..., -0.0464,  0.0518,  0.1197],\n",
            "        [ 0.0151, -0.0898, -0.0063,  ..., -0.0464,  0.0518,  0.1197],\n",
            "        ...,\n",
            "        [ 0.2504, -0.0348,  0.0603,  ..., -0.1449, -0.1191, -0.0082],\n",
            "        [ 0.1383, -0.0305,  0.1987,  ..., -0.0567, -0.0135,  0.0589],\n",
            "        [ 0.1048,  0.1976, -0.0412,  ...,  0.0499, -0.1284, -0.0612]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1048,  0.1976, -0.0412,  ...,  0.0499, -0.1284, -0.0612],\n",
            "         [ 0.1383, -0.0305,  0.1987,  ..., -0.0567, -0.0135,  0.0589],\n",
            "         [ 0.0748, -0.2105, -0.2220,  ...,  0.0388, -0.2787,  0.0058],\n",
            "         ...,\n",
            "         [ 0.1789, -0.1762, -0.1441,  ...,  0.4169, -0.4742, -0.1709],\n",
            "         [ 0.1789, -0.1762, -0.1441,  ...,  0.4169, -0.4742, -0.1709],\n",
            "         [ 0.1789, -0.1762, -0.1441,  ...,  0.4169, -0.4742, -0.1709]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3354,  0.0357, -0.1547,  ...,  0.1679, -0.3461, -0.1686],\n",
            "        [ 0.0084,  0.2965, -0.0354,  ...,  0.0912,  0.0321,  0.1764],\n",
            "        [ 0.3699, -0.1535, -0.2076,  ...,  0.1448, -0.3739, -0.1615],\n",
            "        ...,\n",
            "        [ 0.5604,  0.1680, -0.5083,  ...,  0.5482, -0.6450, -0.4102],\n",
            "        [ 0.5604,  0.1680, -0.5083,  ...,  0.5482, -0.6450, -0.4102],\n",
            "        [ 0.5604,  0.1680, -0.5083,  ...,  0.5482, -0.6450, -0.4102]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0155, -0.0901, -0.0065,  ..., -0.0465,  0.0518,  0.1198],\n",
            "        [ 0.0155, -0.0901, -0.0065,  ..., -0.0465,  0.0518,  0.1198],\n",
            "        [ 0.0418,  0.0147,  0.0934,  ...,  0.1698, -0.0100,  0.0983],\n",
            "        ...,\n",
            "        [ 0.0553,  0.3077, -0.0968,  ...,  0.0741,  0.0078, -0.0776],\n",
            "        [ 0.0553,  0.3077, -0.0968,  ...,  0.0741,  0.0078, -0.0776],\n",
            "        [-0.0301,  0.3749,  0.0775,  ...,  0.2116,  0.0552, -0.0391]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0064,  0.3211, -0.0161,  ...,  0.0836,  0.0802,  0.0930],\n",
            "         [ 0.2573, -0.1633, -0.0422,  ..., -0.0618,  0.0076, -0.0398],\n",
            "         [ 0.1813,  0.0802, -0.0476,  ...,  0.1861, -0.1236, -0.2847],\n",
            "         ...,\n",
            "         [ 0.1383,  0.0137, -0.1174,  ...,  0.0980, -0.1187, -0.2002],\n",
            "         [ 0.1882,  0.0823, -0.0647,  ...,  0.1253, -0.1255, -0.1530],\n",
            "         [ 0.2663, -0.0128, -0.0644,  ...,  0.1267, -0.3634,  0.2295]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0826,  0.3912,  0.0637,  ..., -0.0542,  0.1765,  0.2444],\n",
            "        [ 0.2856,  0.0144, -0.2287,  ...,  0.2275, -0.1948, -0.0677],\n",
            "        [ 0.2254,  0.1249, -0.1782,  ...,  0.2833, -0.2781, -0.2115],\n",
            "        ...,\n",
            "        [ 0.3642,  0.0699, -0.2835,  ...,  0.2666, -0.3903, -0.2379],\n",
            "        [ 0.2358,  0.1415, -0.1873,  ...,  0.1505, -0.2564, -0.1804],\n",
            "        [ 0.3080,  0.1654, -0.2022,  ...,  0.2864, -0.3920,  0.1292]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.2324,  0.0025,  0.0083,  ...,  0.0793,  0.1007, -0.1331],\n",
            "        [ 0.2567, -0.0691,  0.0291,  ...,  0.2283, -0.1717, -0.1814],\n",
            "        [ 0.0157, -0.0904, -0.0067,  ..., -0.0466,  0.0518,  0.1199],\n",
            "        ...,\n",
            "        [-0.1202,  0.0184, -0.2739,  ...,  0.2473, -0.1023,  0.0115],\n",
            "        [ 0.2407,  0.0257,  0.0057,  ...,  0.0063, -0.1936, -0.2298],\n",
            "        [-0.1240, -0.1121,  0.0074,  ...,  0.0114, -0.0194,  0.1171]])\n",
            "Output of encoder at last step:tensor([[[-0.0161,  0.0299, -0.0654,  ..., -0.0943,  0.0329, -0.0102],\n",
            "         [-0.1202,  0.0184, -0.2739,  ...,  0.2473, -0.1023,  0.0115],\n",
            "         [ 0.2407,  0.0257,  0.0057,  ...,  0.0063, -0.1936, -0.2298],\n",
            "         ...,\n",
            "         [ 0.3000, -0.0665,  0.1048,  ...,  0.2408, -0.2951, -0.2686],\n",
            "         [ 0.2148,  0.0630,  0.0147,  ..., -0.0019, -0.1741, -0.1376],\n",
            "         [-0.1027,  0.0036, -0.2277,  ...,  0.0609, -0.0629,  0.0133]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0712,  0.1071, -0.2245,  ...,  0.0951, -0.0957, -0.0138],\n",
            "        [ 0.0105,  0.1546, -0.3290,  ...,  0.1726, -0.1365, -0.0635],\n",
            "        [ 0.3731,  0.1266, -0.1923,  ...,  0.1781, -0.3506, -0.2390],\n",
            "        ...,\n",
            "        [ 0.2653,  0.0818, -0.1414,  ...,  0.2024, -0.3739, -0.2453],\n",
            "        [ 0.0920,  0.0868, -0.0633,  ...,  0.0575, -0.1141, -0.0756],\n",
            "        [-0.0559,  0.0347, -0.2122,  ...,  0.0529, -0.0524,  0.0337]])\n",
            "Output of encoder at every step:tensor([[-0.1126, -0.0022, -0.1971,  ...,  0.1009,  0.0175, -0.0281],\n",
            "        [ 0.2567, -0.0691,  0.0291,  ...,  0.2283, -0.1717, -0.1814],\n",
            "        [ 0.0017,  0.0668,  0.1160,  ..., -0.0137, -0.0291, -0.1568],\n",
            "        ...,\n",
            "        [-0.1230,  0.0977, -0.2708,  ...,  0.2070, -0.0734, -0.0570],\n",
            "        [ 0.0580, -0.0217, -0.0805,  ...,  0.1681, -0.1783, -0.0999],\n",
            "        [-0.0666, -0.0482, -0.2923,  ...,  0.1686, -0.0724, -0.0035]])\n",
            "Output of encoder at last step:tensor([[[ 0.0066,  0.2225, -0.0510,  ...,  0.0617, -0.0318, -0.0176],\n",
            "         [-0.1223, -0.0574, -0.3053,  ...,  0.2061,  0.0203, -0.0128],\n",
            "         [-0.0789,  0.0500, -0.2107,  ...,  0.1741, -0.0094, -0.1675],\n",
            "         ...,\n",
            "         [-0.1076,  0.0026, -0.2457,  ...,  0.2045, -0.1266, -0.0593],\n",
            "         [ 0.2060, -0.0349, -0.0638,  ...,  0.0389, -0.1888, -0.2099],\n",
            "         [-0.0569, -0.0793, -0.2418,  ...,  0.3500, -0.2012, -0.3290]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0107,  0.1791, -0.0061,  ...,  0.0527,  0.0460,  0.0463],\n",
            "        [-0.0654,  0.1373, -0.3132,  ...,  0.1724,  0.0020, -0.0063],\n",
            "        [-0.0450,  0.1128, -0.2064,  ...,  0.0879, -0.0066, -0.0503],\n",
            "        ...,\n",
            "        [ 0.0485,  0.1181, -0.3433,  ...,  0.2348, -0.2215, -0.0979],\n",
            "        [ 0.3182,  0.0731, -0.1726,  ...,  0.1737, -0.2512, -0.2603],\n",
            "        [ 0.0766,  0.2021, -0.4014,  ...,  0.3092, -0.3252, -0.2501]])\n",
            "Output of encoder at every step:tensor([[ 0.0157, -0.0904, -0.0067,  ..., -0.0466,  0.0518,  0.1199],\n",
            "        [ 0.2567, -0.0691,  0.0291,  ...,  0.2283, -0.1717, -0.1814],\n",
            "        [-0.0969,  0.1688, -0.0851,  ..., -0.0933,  0.0250,  0.0804],\n",
            "        ...,\n",
            "        [-0.1721, -0.0063, -0.1386,  ...,  0.0874,  0.0525,  0.1097],\n",
            "        [-0.0917, -0.0053, -0.0460,  ...,  0.1026,  0.0198, -0.0422],\n",
            "        [ 0.0256,  0.0063,  0.2125,  ...,  0.4055, -0.2224,  0.0552]])\n",
            "Output of encoder at last step:tensor([[[-0.1408, -0.0302, -0.3689,  ...,  0.2151, -0.1676, -0.2026],\n",
            "         [-0.0293, -0.0780, -0.2584,  ...,  0.2784, -0.0785, -0.0980],\n",
            "         [ 0.1440,  0.1975, -0.1025,  ...,  0.1829, -0.2668, -0.2889],\n",
            "         ...,\n",
            "         [ 0.0332,  0.1168, -0.0872,  ...,  0.1052, -0.1111, -0.0851],\n",
            "         [-0.1213, -0.0727, -0.2056,  ...,  0.1757,  0.0399,  0.0910],\n",
            "         [-0.0117,  0.2093,  0.1478,  ...,  0.0033, -0.0596,  0.0354]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2706,  0.2467, -0.6371,  ...,  0.4316, -0.5419, -0.4262],\n",
            "        [ 0.1414,  0.1187, -0.4185,  ...,  0.2664, -0.2422, -0.1650],\n",
            "        [ 0.4299,  0.3928, -0.4425,  ...,  0.4419, -0.5347, -0.3583],\n",
            "        ...,\n",
            "        [ 0.1661,  0.1551, -0.2439,  ...,  0.2573, -0.2123, -0.1756],\n",
            "        [-0.0834,  0.0735, -0.2241,  ...,  0.1109,  0.0332,  0.0651],\n",
            "        [-0.0060,  0.1512,  0.0064,  ...,  0.0590, -0.0510,  0.0306]])\n",
            "Output of encoder at every step:tensor([[ 0.0937,  0.0921, -0.0259,  ...,  0.0726,  0.0038, -0.0785],\n",
            "        [-0.0719,  0.1182,  0.0546,  ..., -0.0772,  0.0875,  0.0514],\n",
            "        [ 0.0157, -0.0904, -0.0067,  ..., -0.0466,  0.0518,  0.1199],\n",
            "        ...,\n",
            "        [ 0.0219,  0.0815, -0.1169,  ...,  0.1175, -0.2084, -0.0886],\n",
            "        [ 0.1118, -0.0575,  0.1198,  ..., -0.0062,  0.0226, -0.1350],\n",
            "        [-0.0488,  0.2618,  0.1034,  ...,  0.0783,  0.1418,  0.1892]])\n",
            "Output of encoder at last step:tensor([[[ 0.2673,  0.0764, -0.0073,  ...,  0.1411, -0.0745,  0.0437],\n",
            "         [ 0.0521,  0.3647, -0.1236,  ...,  0.1098, -0.1683, -0.2189],\n",
            "         [-0.0161,  0.1421, -0.1816,  ...,  0.1182,  0.0404,  0.0480],\n",
            "         ...,\n",
            "         [ 0.2968, -0.0651, -0.1915,  ...,  0.3789, -0.3720, -0.0987],\n",
            "         [-0.0102,  0.1145, -0.1226,  ...,  0.1300, -0.2033, -0.2238],\n",
            "         [ 0.0431,  0.2255, -0.0694,  ...,  0.0726, -0.1632, -0.0643]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 1.7810e-01,  4.6474e-03,  2.4277e-02,  ...,  5.9882e-02,\n",
            "         -1.2602e-01, -9.1077e-02],\n",
            "        [ 2.2496e-01,  3.9272e-01, -3.8472e-01,  ...,  3.3607e-01,\n",
            "         -3.1634e-01, -2.1805e-01],\n",
            "        [-6.1005e-02,  2.2715e-01, -1.4004e-01,  ...,  4.9540e-04,\n",
            "          7.6083e-02,  1.1428e-01],\n",
            "        ...,\n",
            "        [ 4.1513e-01,  1.5232e-01, -3.8719e-01,  ...,  3.2052e-01,\n",
            "         -4.1535e-01, -2.8120e-01],\n",
            "        [ 3.2604e-01,  2.5333e-01, -4.9278e-01,  ...,  4.9311e-01,\n",
            "         -5.7550e-01, -4.1133e-01],\n",
            "        [ 6.9922e-02,  2.1185e-01, -1.1490e-01,  ...,  1.1401e-01,\n",
            "         -1.0020e-01,  7.0290e-03]])\n",
            "Output of encoder at every step:tensor([[ 0.2567, -0.0691,  0.0291,  ...,  0.2283, -0.1717, -0.1814],\n",
            "        [ 0.0157, -0.0904, -0.0067,  ..., -0.0466,  0.0518,  0.1199],\n",
            "        [-0.1126, -0.0022, -0.1971,  ...,  0.1009,  0.0175, -0.0281],\n",
            "        ...,\n",
            "        [ 0.0987, -0.2035, -0.1398,  ..., -0.2585, -0.0620, -0.0383],\n",
            "        [-0.1152,  0.3127,  0.0625,  ...,  0.1593, -0.1825,  0.0006],\n",
            "        [ 0.0085,  0.0286, -0.0399,  ...,  0.3883, -0.4542, -0.1214]])\n",
            "Output of encoder at last step:tensor([[[ 0.0415,  0.2315,  0.0403,  ...,  0.2917, -0.0136,  0.0492],\n",
            "         [-0.1434,  0.1292,  0.2491,  ...,  0.1326,  0.0369, -0.0238],\n",
            "         [-0.0086,  0.0121, -0.1179,  ...,  0.0733, -0.0288,  0.0222],\n",
            "         ...,\n",
            "         [-0.0488,  0.2618,  0.1034,  ...,  0.0783,  0.1418,  0.1892],\n",
            "         [ 0.0016, -0.1132, -0.0716,  ...,  0.1158, -0.1929, -0.2466],\n",
            "         [-0.0371, -0.2716, -0.1507,  ..., -0.2627, -0.0468, -0.0467]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1460,  0.1705, -0.1792,  ...,  0.3184, -0.2204, -0.0554],\n",
            "        [-0.0983,  0.1898,  0.0233,  ...,  0.1604,  0.0277,  0.0186],\n",
            "        [ 0.0796,  0.1590, -0.2420,  ...,  0.1717, -0.0485, -0.0250],\n",
            "        ...,\n",
            "        [-0.1271,  0.4116, -0.0117,  ...,  0.1438,  0.1920,  0.3447],\n",
            "        [ 0.2214,  0.0614, -0.2221,  ...,  0.2579, -0.3042, -0.2314],\n",
            "        [ 0.1013, -0.1492, -0.3037,  ...,  0.0495, -0.1942, -0.0598]])\n",
            "Output of encoder at every step:tensor([[ 0.0157, -0.0904, -0.0067,  ..., -0.0466,  0.0518,  0.1199],\n",
            "        [ 0.0157, -0.0904, -0.0067,  ..., -0.0466,  0.0518,  0.1199],\n",
            "        [ 0.0157, -0.0904, -0.0067,  ..., -0.0466,  0.0518,  0.1199],\n",
            "        ...,\n",
            "        [ 0.1251, -0.1671, -0.2058,  ...,  0.2314, -0.1509,  0.1325],\n",
            "        [ 0.1860, -0.1790, -0.1528,  ...,  0.4166, -0.4764, -0.1756],\n",
            "        [ 0.1860, -0.1790, -0.1528,  ...,  0.4166, -0.4764, -0.1756]])\n",
            "Output of encoder at last step:tensor([[[ 0.1860, -0.1790, -0.1528,  ...,  0.4166, -0.4764, -0.1756],\n",
            "         [ 0.1860, -0.1790, -0.1528,  ...,  0.4166, -0.4764, -0.1756],\n",
            "         [ 0.1251, -0.1671, -0.2058,  ...,  0.2314, -0.1509,  0.1325],\n",
            "         ...,\n",
            "         [ 0.0442,  0.3238, -0.0597,  ...,  0.0868,  0.0669, -0.0427],\n",
            "         [ 0.0826,  0.1563, -0.1251,  ...,  0.1112, -0.1582, -0.0423],\n",
            "         [ 0.0035,  0.0700,  0.2518,  ..., -0.0340,  0.0543,  0.0460]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5747,  0.1739, -0.5202,  ...,  0.5565, -0.6532, -0.4220],\n",
            "        [ 0.5747,  0.1739, -0.5202,  ...,  0.5565, -0.6532, -0.4220],\n",
            "        [ 0.1956,  0.0773, -0.2636,  ...,  0.3449, -0.3377,  0.0037],\n",
            "        ...,\n",
            "        [-0.0808,  0.5043, -0.0190,  ..., -0.0036,  0.2334,  0.2162],\n",
            "        [ 0.2192,  0.1920, -0.3871,  ...,  0.3061, -0.3746, -0.1534],\n",
            "        [ 0.0032,  0.1438,  0.0943,  ...,  0.0514,  0.0697,  0.0424]])\n",
            "Output of encoder at every step:tensor([[ 0.0157, -0.0904, -0.0067,  ..., -0.0466,  0.0518,  0.1199],\n",
            "        [ 0.0157, -0.0904, -0.0067,  ..., -0.0466,  0.0518,  0.1199],\n",
            "        [ 0.0157, -0.0904, -0.0067,  ..., -0.0466,  0.0518,  0.1199],\n",
            "        ...,\n",
            "        [ 0.1860, -0.1790, -0.1528,  ...,  0.4166, -0.4764, -0.1756],\n",
            "        [ 0.1860, -0.1790, -0.1528,  ...,  0.4166, -0.4764, -0.1756],\n",
            "        [ 0.1860, -0.1790, -0.1528,  ...,  0.4166, -0.4764, -0.1756]])\n",
            "Output of encoder at last step:tensor([[[ 0.1860, -0.1790, -0.1528,  ...,  0.4166, -0.4764, -0.1756],\n",
            "         [ 0.1860, -0.1790, -0.1528,  ...,  0.4166, -0.4764, -0.1756],\n",
            "         [ 0.1860, -0.1790, -0.1528,  ...,  0.4166, -0.4764, -0.1756],\n",
            "         ...,\n",
            "         [ 0.1860, -0.1790, -0.1528,  ...,  0.4166, -0.4764, -0.1756],\n",
            "         [ 0.1860, -0.1790, -0.1528,  ...,  0.4166, -0.4764, -0.1756],\n",
            "         [ 0.1860, -0.1790, -0.1528,  ...,  0.4166, -0.4764, -0.1756]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5747,  0.1739, -0.5202,  ...,  0.5565, -0.6532, -0.4220],\n",
            "        [ 0.5747,  0.1739, -0.5202,  ...,  0.5565, -0.6532, -0.4220],\n",
            "        [ 0.5747,  0.1739, -0.5202,  ...,  0.5565, -0.6532, -0.4220],\n",
            "        ...,\n",
            "        [ 0.5747,  0.1739, -0.5202,  ...,  0.5565, -0.6532, -0.4220],\n",
            "        [ 0.5747,  0.1739, -0.5202,  ...,  0.5565, -0.6532, -0.4220],\n",
            "        [ 0.5747,  0.1739, -0.5202,  ...,  0.5565, -0.6532, -0.4220]])\n",
            "\t Epoch: 5 | Train Loss: 0.258 | Train Acc: 90.71%\n",
            "\t Epoch: 5 | Val. Loss: 0.811 |  Val. Acc: 82.59% \n",
            "\n",
            "Output of encoder at every step:tensor([[ 0.2567, -0.0691,  0.0291,  ...,  0.2283, -0.1717, -0.1814],\n",
            "        [ 0.0970,  0.0113,  0.0108,  ...,  0.0258,  0.0487, -0.0495],\n",
            "        [-0.1325, -0.0283,  0.0242,  ...,  0.1014,  0.0899,  0.0684],\n",
            "        ...,\n",
            "        [ 0.0313, -0.0949, -0.0949,  ..., -0.0056,  0.0385,  0.1124],\n",
            "        [ 0.0484, -0.0587, -0.1848,  ..., -0.1491, -0.1180,  0.0359],\n",
            "        [ 0.1076, -0.4299,  0.1413,  ...,  0.0850, -0.0653, -0.1331]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0057, -0.0849, -0.0634,  ...,  0.0840, -0.1541,  0.0852],\n",
            "         [ 0.0275,  0.1139, -0.0323,  ...,  0.0214, -0.0154, -0.1086],\n",
            "         [ 0.2397, -0.2179, -0.2595,  ..., -0.0753, -0.3005,  0.0410],\n",
            "         ...,\n",
            "         [ 0.1888,  0.1769,  0.0073,  ...,  0.1467,  0.0148, -0.1241],\n",
            "         [ 0.2853,  0.4419,  0.1488,  ...,  0.1841, -0.4391,  0.0784],\n",
            "         [ 0.0556, -0.0907, -0.1031,  ...,  0.1053, -0.1807, -0.0078]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0965,  0.1076, -0.2234,  ...,  0.1928, -0.2204,  0.0043],\n",
            "        [-0.0070,  0.1514, -0.0268,  ..., -0.0071,  0.0203,  0.0086],\n",
            "        [ 0.4222,  0.0992, -0.4586,  ...,  0.1539, -0.3958, -0.2198],\n",
            "        ...,\n",
            "        [ 0.1804,  0.2156, -0.1079,  ...,  0.1299, -0.0957, -0.0364],\n",
            "        [ 0.0572,  0.6121, -0.1453,  ...,  0.2368, -0.2148,  0.1868],\n",
            "        [ 0.2983, -0.0403, -0.2783,  ...,  0.2717, -0.3844, -0.1615]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0936, -0.1375,  0.0110,  ..., -0.0362,  0.0492,  0.0780],\n",
            "        [ 0.0160, -0.0907, -0.0069,  ..., -0.0467,  0.0517,  0.1200],\n",
            "        [ 0.0160, -0.0907, -0.0069,  ..., -0.0467,  0.0517,  0.1200],\n",
            "        ...,\n",
            "        [ 0.1376, -0.1752, -0.2182,  ...,  0.1815, -0.2963,  0.0257],\n",
            "        [ 0.0242,  0.1965, -0.0120,  ...,  0.2569, -0.0203,  0.0563],\n",
            "        [ 0.0096,  0.5070, -0.0808,  ...,  0.1770, -0.2003, -0.1688]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0694, -0.0762, -0.1709,  ...,  0.0264, -0.1242,  0.0770],\n",
            "         [ 0.1486,  0.0242, -0.1351,  ...,  0.1056, -0.1284, -0.2128],\n",
            "         [-0.0157,  0.0419,  0.2684,  ..., -0.0560,  0.1977,  0.1970],\n",
            "         ...,\n",
            "         [ 0.0242,  0.1965, -0.0120,  ...,  0.2569, -0.0203,  0.0563],\n",
            "         [ 0.0096,  0.5070, -0.0808,  ...,  0.1770, -0.2003, -0.1688],\n",
            "         [ 0.0449,  0.3267, -0.0597,  ...,  0.0870,  0.0668, -0.0409]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0373, -0.0641, -0.0091,  ...,  0.0052, -0.0655,  0.0411],\n",
            "        [ 0.3983,  0.0926, -0.3260,  ...,  0.2962, -0.4261, -0.2650],\n",
            "        [-0.0259, -0.0720,  0.2120,  ..., -0.1346,  0.1742,  0.1415],\n",
            "        ...,\n",
            "        [-0.0178,  0.2502, -0.0776,  ...,  0.0740,  0.0131,  0.1276],\n",
            "        [ 0.2208,  0.4782, -0.3700,  ...,  0.4508, -0.4694, -0.2278],\n",
            "        [-0.0828,  0.5128, -0.0196,  ..., -0.0031,  0.2358,  0.2214]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0771,  0.2848, -0.1384,  ..., -0.1317,  0.0999,  0.1061],\n",
            "        [ 0.2591, -0.0682,  0.0277,  ...,  0.2296, -0.1730, -0.1833],\n",
            "        [ 0.0163, -0.0908, -0.0071,  ..., -0.0468,  0.0517,  0.1201],\n",
            "        ...,\n",
            "        [ 0.3066,  0.0465, -0.1178,  ...,  0.0358, -0.2581, -0.0117],\n",
            "        [-0.1654,  0.0608, -0.1085,  ...,  0.1135, -0.2046, -0.0388],\n",
            "        [ 0.0197,  0.4221, -0.0443,  ...,  0.1148,  0.0031, -0.0523]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1261, -0.1072, -0.2691,  ...,  0.0046, -0.3226, -0.2351],\n",
            "         [ 0.1736,  0.3535, -0.0931,  ...,  0.0062, -0.1463, -0.1856],\n",
            "         [ 0.1647,  0.4024, -0.0848,  ...,  0.1467, -0.2423, -0.3442],\n",
            "         ...,\n",
            "         [ 0.3916, -0.1982, -0.1241,  ..., -0.0969, -0.3136, -0.1831],\n",
            "         [ 0.0413, -0.2746,  0.0177,  ...,  0.2223, -0.2345,  0.0726],\n",
            "         [-0.0206,  0.1784, -0.1748,  ...,  0.2037,  0.1032, -0.0687]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3587,  0.0299, -0.4393,  ...,  0.2337, -0.4559, -0.3245],\n",
            "        [ 0.3726,  0.3645, -0.3896,  ...,  0.2546, -0.4079, -0.1499],\n",
            "        [ 0.6697,  0.3615, -0.5473,  ...,  0.5474, -0.6895, -0.5485],\n",
            "        ...,\n",
            "        [ 0.5789, -0.0194, -0.3935,  ...,  0.2212, -0.5497, -0.3643],\n",
            "        [ 0.3041, -0.0135, -0.2876,  ...,  0.3817, -0.4664, -0.1206],\n",
            "        [-0.0796,  0.2543, -0.1455,  ...,  0.0909,  0.0441,  0.0862]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0777, -0.2010, -0.1163,  ...,  0.0168, -0.1051,  0.0582],\n",
            "        [-0.0777, -0.2010, -0.1163,  ...,  0.0168, -0.1051,  0.0582],\n",
            "        [ 0.0165, -0.0910, -0.0073,  ..., -0.0469,  0.0516,  0.1203],\n",
            "        ...,\n",
            "        [ 0.3989,  0.1015, -0.0186,  ...,  0.3425, -0.2982, -0.4032],\n",
            "        [ 0.1184, -0.0420, -0.1475,  ...,  0.1725, -0.2849,  0.0176],\n",
            "        [-0.0593, -0.1244, -0.0996,  ...,  0.1261,  0.0415,  0.0083]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0519,  0.3267,  0.0168,  ...,  0.1421, -0.1712, -0.0762],\n",
            "         [ 0.0519,  0.3267,  0.0168,  ...,  0.1421, -0.1712, -0.0762],\n",
            "         [-0.0084,  0.2352, -0.0242,  ...,  0.0648,  0.1127,  0.0946],\n",
            "         ...,\n",
            "         [ 0.3989,  0.1015, -0.0186,  ...,  0.3425, -0.2982, -0.4032],\n",
            "         [ 0.1184, -0.0420, -0.1475,  ...,  0.1725, -0.2849,  0.0176],\n",
            "         [-0.0593, -0.1244, -0.0996,  ...,  0.1261,  0.0415,  0.0083]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0640,  0.5034, -0.0681,  ...,  0.1492, -0.0403,  0.1429],\n",
            "        [-0.0640,  0.5034, -0.0681,  ...,  0.1492, -0.0403,  0.1429],\n",
            "        [-0.0543,  0.1798,  0.0802,  ..., -0.0635,  0.1834,  0.1723],\n",
            "        ...,\n",
            "        [ 0.3492,  0.2266, -0.2281,  ...,  0.2380, -0.3827, -0.3531],\n",
            "        [ 0.2768,  0.1529, -0.3234,  ...,  0.3578, -0.4300, -0.1076],\n",
            "        [-0.0525, -0.0781, -0.0010,  ...,  0.0606,  0.0869,  0.0950]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 9.7030e-02,  1.0136e-01, -2.8532e-02,  ...,  7.7051e-02,\n",
            "          1.7232e-03, -7.9446e-02],\n",
            "        [ 1.6703e-02, -9.1121e-02, -7.3817e-03,  ..., -4.6992e-02,\n",
            "          5.1609e-02,  1.2041e-01],\n",
            "        [ 1.6703e-02, -9.1121e-02, -7.3817e-03,  ..., -4.6992e-02,\n",
            "          5.1609e-02,  1.2041e-01],\n",
            "        ...,\n",
            "        [ 1.3825e-01,  2.9315e-01,  6.4966e-03,  ...,  3.3080e-01,\n",
            "         -8.7753e-02, -1.8063e-01],\n",
            "        [-3.1475e-04,  4.3105e-01, -6.5080e-02,  ...,  1.1133e-01,\n",
            "         -4.0973e-02, -1.0694e-01],\n",
            "        [ 5.6383e-02,  3.1742e-01, -5.3947e-03,  ...,  3.5609e-01,\n",
            "         -9.7217e-02,  1.8810e-02]], grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0899,  0.1570,  0.0084,  ...,  0.2865, -0.2658, -0.1783],\n",
            "         [ 0.1383,  0.2931,  0.0065,  ...,  0.3308, -0.0878, -0.1806],\n",
            "         [ 0.1383,  0.2931,  0.0065,  ...,  0.3308, -0.0878, -0.1806],\n",
            "         ...,\n",
            "         [ 0.1699,  0.0486,  0.2001,  ...,  0.0343, -0.2166,  0.0427],\n",
            "         [ 0.4822, -0.0818, -0.0796,  ...,  0.3691, -0.3331, -0.4400],\n",
            "         [ 0.1982, -0.0389, -0.1560,  ...,  0.0116, -0.2913, -0.2611]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2549,  0.1847, -0.2863,  ...,  0.3903, -0.4141, -0.2426],\n",
            "        [-0.1191,  0.6047, -0.1837,  ...,  0.2495,  0.0948,  0.1704],\n",
            "        [-0.1191,  0.6047, -0.1837,  ...,  0.2495,  0.0948,  0.1704],\n",
            "        ...,\n",
            "        [ 0.5705,  0.1845, -0.2980,  ...,  0.4026, -0.5503, -0.2657],\n",
            "        [ 0.6663,  0.2350, -0.4795,  ...,  0.4819, -0.6538, -0.5186],\n",
            "        [ 0.6338,  0.2192, -0.5354,  ...,  0.3845, -0.6388, -0.5171]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0169, -0.0911, -0.0075,  ..., -0.0471,  0.0516,  0.1205],\n",
            "        [ 0.0169, -0.0911, -0.0075,  ..., -0.0471,  0.0516,  0.1205],\n",
            "        [ 0.0169, -0.0911, -0.0075,  ..., -0.0471,  0.0516,  0.1205],\n",
            "        ...,\n",
            "        [ 0.1970,  0.0572, -0.1682,  ...,  0.2628, -0.2001,  0.0633],\n",
            "        [ 0.2663,  0.2599,  0.0749,  ...,  0.1667, -0.0796, -0.0557],\n",
            "        [-0.0010, -0.1566, -0.1376,  ..., -0.0695, -0.0170, -0.1100]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0484,  0.1656,  0.0999,  ...,  0.2190, -0.1521, -0.0884],\n",
            "         [ 0.1970,  0.0572, -0.1682,  ...,  0.2628, -0.2001,  0.0633],\n",
            "         [ 0.2663,  0.2599,  0.0749,  ...,  0.1667, -0.0796, -0.0557],\n",
            "         ...,\n",
            "         [ 0.0075,  0.3016, -0.0354,  ...,  0.0880,  0.1096,  0.1569],\n",
            "         [ 0.0881, -0.0149,  0.0150,  ...,  0.0321, -0.1342,  0.1206],\n",
            "         [ 0.1893,  0.0554, -0.1401,  ..., -0.0426, -0.1575, -0.1321]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0269,  0.0935,  0.1189,  ...,  0.0429,  0.0339, -0.0253],\n",
            "        [ 0.4930,  0.1552, -0.4550,  ...,  0.4822, -0.5117, -0.1961],\n",
            "        [ 0.3915,  0.2230, -0.1455,  ...,  0.2507, -0.2620, -0.1907],\n",
            "        ...,\n",
            "        [-0.1156,  0.4754,  0.0363,  ..., -0.0239,  0.2272,  0.2943],\n",
            "        [-0.0388,  0.1840, -0.0091,  ...,  0.0608,  0.0014,  0.1787],\n",
            "        [ 0.3536,  0.1659, -0.3328,  ...,  0.1632, -0.3405, -0.1939]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2584, -0.0650,  0.0281,  ...,  0.2315, -0.1713, -0.1805],\n",
            "        [ 0.0981,  0.1053, -0.0286,  ...,  0.0781,  0.0019, -0.0790],\n",
            "        [ 0.0266,  0.0862, -0.1172,  ..., -0.0782, -0.0188, -0.0973],\n",
            "        ...,\n",
            "        [ 0.2491,  0.2460, -0.1142,  ..., -0.1234, -0.0177, -0.1873],\n",
            "        [ 0.1553, -0.0310, -0.1012,  ...,  0.0753, -0.0220,  0.1783],\n",
            "        [ 0.1630,  0.1122, -0.2380,  ...,  0.0999, -0.1880, -0.2250]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1364,  0.0380, -0.1007,  ...,  0.1377,  0.1232, -0.1908],\n",
            "         [ 0.1152,  0.2193, -0.0895,  ...,  0.1908, -0.2997, -0.3504],\n",
            "         [ 0.1576, -0.2586, -0.1173,  ...,  0.3196, -0.1627, -0.0441],\n",
            "         ...,\n",
            "         [-0.0491, -0.1243, -0.1178,  ..., -0.2337, -0.1181, -0.0361],\n",
            "         [ 0.2279,  0.0285, -0.1490,  ...,  0.1353, -0.1154,  0.0638],\n",
            "         [ 0.3586, -0.0653,  0.0433,  ...,  0.3996, -0.2714, -0.4302]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.1395,  0.2257, -0.1475,  ...,  0.1634,  0.0611, -0.0824],\n",
            "        [ 0.5562,  0.3591, -0.5084,  ...,  0.5212, -0.6565, -0.5134],\n",
            "        [ 0.4532,  0.0717, -0.4737,  ...,  0.4363, -0.5308, -0.2881],\n",
            "        ...,\n",
            "        [ 0.1309, -0.0147, -0.2463,  ...,  0.0630, -0.2328, -0.1314],\n",
            "        [ 0.3368,  0.1663, -0.2561,  ...,  0.2672, -0.2608, -0.0609],\n",
            "        [ 0.3750,  0.1302, -0.2113,  ...,  0.3168, -0.3913, -0.3642]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0097, -0.0208,  0.0088,  ...,  0.1349, -0.1556, -0.1228],\n",
            "        [ 0.2589, -0.0640,  0.0280,  ...,  0.2318, -0.1710, -0.1799],\n",
            "        [-0.1103,  0.0919, -0.0356,  ...,  0.0037,  0.0549,  0.0512],\n",
            "        ...,\n",
            "        [-0.0055,  0.1725,  0.1004,  ...,  0.1188, -0.2274,  0.1160],\n",
            "        [ 0.1801,  0.0929, -0.0130,  ...,  0.4212, -0.2286,  0.2362],\n",
            "        [ 0.0838,  0.1815, -0.0906,  ...,  0.0740, -0.3212,  0.0487]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0511,  0.1579,  0.1072,  ...,  0.1746, -0.2973, -0.1571],\n",
            "         [ 0.1574, -0.0626, -0.0343,  ..., -0.0577,  0.0088, -0.0088],\n",
            "         [ 0.0231,  0.2598, -0.2664,  ...,  0.0731, -0.1773,  0.0712],\n",
            "         ...,\n",
            "         [ 0.2172, -0.1896,  0.0719,  ...,  0.1381, -0.2500, -0.2344],\n",
            "         [ 0.2795,  0.6117, -0.1359,  ...,  0.1284, -0.2169, -0.3518],\n",
            "         [-0.0961,  0.2393,  0.0626,  ...,  0.1423, -0.0873,  0.0884]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1347,  0.3552, -0.2129,  ...,  0.3217, -0.4303, -0.1799],\n",
            "        [ 0.2411,  0.0652, -0.1111,  ...,  0.0850, -0.1848, -0.1056],\n",
            "        [ 0.4239,  0.2173, -0.5299,  ...,  0.3827, -0.5688, -0.2648],\n",
            "        ...,\n",
            "        [ 0.3654,  0.1411, -0.2473,  ...,  0.3884, -0.3708, -0.2794],\n",
            "        [ 0.1811,  0.5775, -0.1612,  ...,  0.1230, -0.1115, -0.0016],\n",
            "        [-0.0405,  0.3322, -0.1071,  ...,  0.2246, -0.0989,  0.1256]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2601, -0.0635,  0.0282,  ...,  0.2309, -0.1695, -0.1782],\n",
            "        [ 0.0993,  0.1089, -0.0285,  ...,  0.0786,  0.0024, -0.0785],\n",
            "        [ 0.2601, -0.0635,  0.0282,  ...,  0.2309, -0.1695, -0.1782],\n",
            "        ...,\n",
            "        [ 0.0903,  0.0666, -0.0826,  ..., -0.0189, -0.0732, -0.1835],\n",
            "        [ 0.0821, -0.0920, -0.1219,  ..., -0.0438, -0.2965, -0.1332],\n",
            "        [ 0.2084, -0.0844, -0.1447,  ...,  0.1048, -0.2584,  0.0236]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0903,  0.0666, -0.0826,  ..., -0.0189, -0.0732, -0.1835],\n",
            "         [ 0.0821, -0.0920, -0.1219,  ..., -0.0438, -0.2965, -0.1332],\n",
            "         [ 0.2084, -0.0844, -0.1447,  ...,  0.1048, -0.2584,  0.0236],\n",
            "         ...,\n",
            "         [ 0.2577, -0.1077,  0.0494,  ..., -0.1080, -0.0287,  0.0473],\n",
            "         [-0.0755,  0.1982,  0.1150,  ...,  0.0189, -0.0815, -0.3356],\n",
            "         [ 0.1716, -0.1174,  0.0309,  ..., -0.0296,  0.1499,  0.0314]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3578,  0.1101, -0.3137,  ...,  0.1311, -0.3545, -0.2773],\n",
            "        [ 0.2799,  0.1577, -0.3571,  ...,  0.1584, -0.4069, -0.2409],\n",
            "        [ 0.4114,  0.0952, -0.3320,  ...,  0.3294, -0.3965, -0.1570],\n",
            "        ...,\n",
            "        [ 0.2076, -0.0378, -0.0401,  ...,  0.0334, -0.0610,  0.0068],\n",
            "        [ 0.0314,  0.1278, -0.0599,  ...,  0.1408, -0.1636, -0.1846],\n",
            "        [ 0.1133,  0.0010, -0.0576,  ...,  0.0434, -0.0150, -0.0308]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0191, -0.0916, -0.0081,  ..., -0.0477,  0.0516,  0.1209],\n",
            "        [ 0.0191, -0.0916, -0.0081,  ..., -0.0477,  0.0516,  0.1209],\n",
            "        [ 0.0191, -0.0916, -0.0081,  ..., -0.0477,  0.0516,  0.1209],\n",
            "        ...,\n",
            "        [ 0.3479, -0.0531, -0.0012,  ..., -0.1287, -0.1900, -0.0384],\n",
            "        [ 0.3669, -0.0112,  0.1670,  ..., -0.0249, -0.0730,  0.0360],\n",
            "        [ 0.1721,  0.2371, -0.0808,  ...,  0.0630, -0.1899, -0.1090]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1721,  0.2371, -0.0808,  ...,  0.0630, -0.1899, -0.1090],\n",
            "         [ 0.3669, -0.0112,  0.1670,  ..., -0.0249, -0.0730,  0.0360],\n",
            "         [ 0.2522, -0.2013, -0.2471,  ...,  0.4352, -0.5252, -0.2301],\n",
            "         ...,\n",
            "         [ 0.2522, -0.2013, -0.2471,  ...,  0.4352, -0.5252, -0.2301],\n",
            "         [ 0.2522, -0.2013, -0.2471,  ...,  0.4352, -0.5252, -0.2301],\n",
            "         [ 0.2522, -0.2013, -0.2471,  ...,  0.4352, -0.5252, -0.2301]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6155,  0.1206, -0.4768,  ...,  0.4008, -0.6021, -0.3916],\n",
            "        [ 0.2871,  0.4543, -0.2358,  ...,  0.2869, -0.1682,  0.0777],\n",
            "        [ 0.6996,  0.2081, -0.6283,  ...,  0.6368, -0.7434, -0.5364],\n",
            "        ...,\n",
            "        [ 0.6996,  0.2081, -0.6283,  ...,  0.6368, -0.7434, -0.5364],\n",
            "        [ 0.6996,  0.2081, -0.6283,  ...,  0.6368, -0.7434, -0.5364],\n",
            "        [ 0.6996,  0.2081, -0.6283,  ...,  0.6368, -0.7434, -0.5364]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0195, -0.0917, -0.0082,  ..., -0.0478,  0.0517,  0.1208],\n",
            "        [ 0.0195, -0.0917, -0.0082,  ..., -0.0478,  0.0517,  0.1208],\n",
            "        [ 0.0195, -0.0917, -0.0082,  ..., -0.0478,  0.0517,  0.1208],\n",
            "        ...,\n",
            "        [ 0.2246, -0.1878, -0.1898,  ...,  0.4145, -0.4824, -0.1887],\n",
            "        [ 0.2246, -0.1878, -0.1898,  ...,  0.4145, -0.4824, -0.1887],\n",
            "        [ 0.2246, -0.1878, -0.1898,  ...,  0.4145, -0.4824, -0.1887]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2246, -0.1878, -0.1898,  ...,  0.4145, -0.4824, -0.1887],\n",
            "         [ 0.2246, -0.1878, -0.1898,  ...,  0.4145, -0.4824, -0.1887],\n",
            "         [ 0.2246, -0.1878, -0.1898,  ...,  0.4145, -0.4824, -0.1887],\n",
            "         ...,\n",
            "         [ 0.2246, -0.1878, -0.1898,  ...,  0.4145, -0.4824, -0.1887],\n",
            "         [ 0.2246, -0.1878, -0.1898,  ...,  0.4145, -0.4824, -0.1887],\n",
            "         [ 0.2246, -0.1878, -0.1898,  ...,  0.4145, -0.4824, -0.1887]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6306,  0.2141, -0.5659,  ...,  0.5884, -0.6856, -0.4686],\n",
            "        [ 0.6306,  0.2141, -0.5659,  ...,  0.5884, -0.6856, -0.4686],\n",
            "        [ 0.6306,  0.2141, -0.5659,  ...,  0.5884, -0.6856, -0.4686],\n",
            "        ...,\n",
            "        [ 0.6306,  0.2141, -0.5659,  ...,  0.5884, -0.6856, -0.4686],\n",
            "        [ 0.6306,  0.2141, -0.5659,  ...,  0.5884, -0.6856, -0.4686],\n",
            "        [ 0.6306,  0.2141, -0.5659,  ...,  0.5884, -0.6856, -0.4686]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 1.0079e-01,  1.1370e-01, -2.8279e-02,  ...,  7.9423e-02,\n",
            "          2.9984e-03, -7.8021e-02],\n",
            "        [ 1.5827e-04,  1.2476e-01, -5.7502e-02,  ..., -9.1988e-02,\n",
            "          1.4784e-01,  4.9328e-02],\n",
            "        [-6.9157e-02,  2.0227e-02, -1.2033e-01,  ...,  6.2800e-02,\n",
            "          7.2917e-02, -7.1928e-02],\n",
            "        ...,\n",
            "        [ 1.4883e-01,  4.3641e-01, -3.4863e-02,  ...,  1.4307e-01,\n",
            "         -1.8488e-01,  1.0857e-01],\n",
            "        [ 2.1991e-02, -2.9922e-01, -3.4247e-01,  ...,  2.4223e-01,\n",
            "         -4.0498e-01, -2.1623e-01],\n",
            "        [-7.6284e-02,  3.4717e-01,  1.6028e-01,  ...,  6.3821e-02,\n",
            "         -1.6282e-01, -5.4263e-02]], grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.4788,  0.0195, -0.1140,  ...,  0.3683, -0.3455, -0.4372],\n",
            "         [ 0.1937,  0.1365,  0.0142,  ...,  0.2440, -0.0494, -0.0232],\n",
            "         [ 0.0038,  0.0320,  0.2647,  ..., -0.1775, -0.1317,  0.0364],\n",
            "         ...,\n",
            "         [ 0.1503, -0.0190,  0.1570,  ...,  0.0572, -0.3158, -0.0074],\n",
            "         [ 0.2581, -0.1054, -0.0650,  ...,  0.3295, -0.1714, -0.1843],\n",
            "         [ 0.1494,  0.1086, -0.1468,  ...,  0.2302, -0.1039, -0.0764]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 6.3059e-01,  2.2554e-01, -4.5275e-01,  ...,  4.3363e-01,\n",
            "         -5.9607e-01, -5.1930e-01],\n",
            "        [-4.0921e-02,  3.5734e-01, -6.6452e-02,  ...,  1.9950e-01,\n",
            "          3.6972e-03,  7.8232e-02],\n",
            "        [ 1.7582e-01,  1.0127e-01,  1.2113e-02,  ...,  2.0955e-02,\n",
            "         -2.4748e-01, -5.9995e-02],\n",
            "        ...,\n",
            "        [ 1.9833e-01,  1.7965e-01, -1.1224e-01,  ...,  1.7562e-01,\n",
            "         -2.8734e-01,  1.8070e-04],\n",
            "        [ 2.4077e-01,  1.1929e-01, -2.9324e-01,  ...,  2.6927e-01,\n",
            "         -3.0749e-01, -2.3103e-01],\n",
            "        [ 3.3229e-01,  2.0168e-01, -3.0426e-01,  ...,  2.9864e-01,\n",
            "         -2.7105e-01, -1.7004e-01]], grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1157, -0.0026, -0.0685,  ...,  0.0192,  0.0621, -0.0273],\n",
            "        [ 0.2708, -0.0630,  0.0258,  ...,  0.2286, -0.1695, -0.1775],\n",
            "        [ 0.0131,  0.0193,  0.1911,  ...,  0.0198,  0.0592,  0.2307],\n",
            "        ...,\n",
            "        [ 0.1978,  0.1812, -0.1721,  ...,  0.0699, -0.2919, -0.1586],\n",
            "        [ 0.4111, -0.3758, -0.1449,  ...,  0.1291, -0.3305, -0.2108],\n",
            "        [ 0.0818,  0.1968, -0.0022,  ..., -0.1493,  0.0076,  0.0586]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1701, -0.0104, -0.3489,  ...,  0.2854,  0.0342, -0.2073],\n",
            "         [-0.0913,  0.1965, -0.1317,  ..., -0.0216,  0.0534,  0.1355],\n",
            "         [ 0.0099, -0.1182,  0.1373,  ...,  0.2397, -0.4330, -0.1219],\n",
            "         ...,\n",
            "         [ 0.1978,  0.1812, -0.1721,  ...,  0.0699, -0.2919, -0.1586],\n",
            "         [ 0.4111, -0.3758, -0.1449,  ...,  0.1291, -0.3305, -0.2108],\n",
            "         [ 0.0818,  0.1968, -0.0022,  ..., -0.1493,  0.0076,  0.0586]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0651,  0.3010, -0.3549,  ...,  0.2952, -0.0317,  0.0078],\n",
            "        [-0.0189,  0.2084, -0.2277,  ...,  0.0686, -0.0441,  0.0915],\n",
            "        [ 0.3553,  0.1829, -0.2667,  ...,  0.3942, -0.5238, -0.2700],\n",
            "        ...,\n",
            "        [ 0.3775,  0.3279, -0.4018,  ...,  0.3145, -0.4233, -0.1959],\n",
            "        [ 0.6167, -0.0665, -0.4396,  ...,  0.4059, -0.5942, -0.4600],\n",
            "        [-0.0468,  0.3591, -0.1147,  ...,  0.0729,  0.0454,  0.1851]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 1.2711e-01,  4.1754e-02,  9.8160e-02,  ...,  1.0509e-02,\n",
            "         -2.4311e-04, -9.0980e-02],\n",
            "        [ 8.4281e-02,  5.0656e-02,  5.0055e-02,  ...,  2.3798e-02,\n",
            "         -3.0427e-02,  7.8757e-02],\n",
            "        [ 2.0578e-02, -9.1832e-02, -8.4425e-03,  ..., -4.7915e-02,\n",
            "          5.1892e-02,  1.2061e-01],\n",
            "        ...,\n",
            "        [ 3.7574e-03,  2.4878e-01,  1.1464e-01,  ...,  2.7219e-01,\n",
            "         -8.8220e-02,  3.1081e-02],\n",
            "        [ 8.4840e-03,  4.1967e-01, -6.1392e-02,  ...,  7.0746e-02,\n",
            "          9.1525e-02, -3.6844e-02],\n",
            "        [-1.0614e-01, -4.1672e-02, -1.4904e-01,  ...,  6.6265e-02,\n",
            "          1.4592e-01, -5.1810e-02]], grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0843,  0.0805, -0.1104,  ...,  0.1715, -0.0826,  0.1013],\n",
            "         [-0.0674, -0.0358,  0.0113,  ...,  0.2568,  0.0258,  0.0358],\n",
            "         [ 0.0085,  0.4197, -0.0614,  ...,  0.0707,  0.0915, -0.0368],\n",
            "         ...,\n",
            "         [ 0.3047,  0.3810,  0.0402,  ..., -0.0883, -0.0878,  0.0054],\n",
            "         [ 0.1150,  0.0203, -0.1401,  ...,  0.0427, -0.2572, -0.0682],\n",
            "         [-0.0075,  0.0764, -0.1000,  ...,  0.2768, -0.0434,  0.0673]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1797,  0.1678, -0.2622,  ...,  0.2337, -0.1472,  0.1002],\n",
            "        [-0.0623, -0.0127,  0.0630,  ...,  0.0448,  0.0530,  0.0636],\n",
            "        [-0.0996,  0.5722, -0.0127,  ..., -0.0113,  0.2103,  0.2429],\n",
            "        ...,\n",
            "        [ 0.4406,  0.3457, -0.1428,  ...,  0.1143, -0.2644, -0.0456],\n",
            "        [ 0.4114,  0.0707, -0.3832,  ...,  0.3168, -0.4672, -0.2317],\n",
            "        [-0.0577,  0.2797, -0.1105,  ...,  0.0676,  0.0492,  0.1866]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0206, -0.0915, -0.0084,  ..., -0.0480,  0.0520,  0.1206],\n",
            "        [-0.0036, -0.1420, -0.0028,  ..., -0.0540, -0.0558,  0.0185],\n",
            "        [ 0.0206, -0.0915, -0.0084,  ..., -0.0480,  0.0520,  0.1206],\n",
            "        ...,\n",
            "        [ 0.0108,  0.1106, -0.1195,  ..., -0.1462,  0.0754,  0.0355],\n",
            "        [ 0.0533,  0.3689, -0.0730,  ...,  0.1239, -0.1279, -0.2607],\n",
            "        [ 0.0533,  0.3689, -0.0730,  ...,  0.1239, -0.1279, -0.2607]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.4045, -0.2462, -0.0831,  ..., -0.0999, -0.2847, -0.1563],\n",
            "         [ 0.0039,  0.1134,  0.3031,  ..., -0.0337,  0.0308,  0.1163],\n",
            "         [-0.0185,  0.2314, -0.0709,  ...,  0.0266, -0.1135, -0.3526],\n",
            "         ...,\n",
            "         [-0.0508,  0.3172, -0.2128,  ...,  0.0737,  0.0126, -0.0726],\n",
            "         [ 0.3611, -0.0485, -0.1026,  ..., -0.0926, -0.1444, -0.1351],\n",
            "         [-0.0608,  0.2726, -0.2892,  ...,  0.0832, -0.0768, -0.0519]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5823, -0.0109, -0.3872,  ...,  0.2290, -0.5375, -0.3611],\n",
            "        [ 0.0229,  0.2077,  0.1213,  ...,  0.0788,  0.0584,  0.1322],\n",
            "        [ 0.0634,  0.3565, -0.2648,  ...,  0.1892, -0.2320, -0.1180],\n",
            "        ...,\n",
            "        [ 0.0507,  0.4714, -0.4406,  ...,  0.2681, -0.1580, -0.0664],\n",
            "        [ 0.3739,  0.2570, -0.2972,  ...,  0.1725, -0.2057, -0.0467],\n",
            "        [ 0.2350,  0.2814, -0.5464,  ...,  0.3184, -0.3939, -0.1978]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0397, -0.0666, -0.1999,  ..., -0.1051,  0.0524,  0.0380],\n",
            "        [ 0.0438, -0.0325,  0.0876,  ..., -0.0602,  0.0250, -0.0720],\n",
            "        [ 0.0203, -0.0912, -0.0082,  ..., -0.0481,  0.0520,  0.1208],\n",
            "        ...,\n",
            "        [ 0.0568,  0.2265,  0.0435,  ...,  0.2533,  0.0474,  0.0415],\n",
            "        [ 0.2674, -0.1378,  0.1197,  ..., -0.1598, -0.0792,  0.0503],\n",
            "        [ 0.2573,  0.0215,  0.2141,  ...,  0.1676,  0.1124,  0.1587]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2004,  0.4091,  0.0095,  ...,  0.0730, -0.0889,  0.1785],\n",
            "         [ 0.1578, -0.2140, -0.0085,  ...,  0.1371, -0.1833,  0.0229],\n",
            "         [ 0.1028,  0.3459,  0.1571,  ...,  0.0143,  0.1574,  0.0178],\n",
            "         ...,\n",
            "         [ 0.0568,  0.2265,  0.0435,  ...,  0.2533,  0.0474,  0.0415],\n",
            "         [ 0.2674, -0.1378,  0.1197,  ..., -0.1598, -0.0792,  0.0503],\n",
            "         [ 0.2573,  0.0215,  0.2141,  ...,  0.1676,  0.1124,  0.1587]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0738,  0.4929, -0.1884,  ...,  0.2499, -0.0543,  0.1917],\n",
            "        [ 0.1570,  0.1471, -0.2945,  ...,  0.2627, -0.3267, -0.0196],\n",
            "        [-0.1194,  0.5124,  0.0635,  ...,  0.0858,  0.2297,  0.2160],\n",
            "        ...,\n",
            "        [ 0.1043,  0.1470, -0.1002,  ...,  0.2743, -0.1183, -0.0275],\n",
            "        [ 0.2114,  0.0247, -0.0453,  ...,  0.0039, -0.0978,  0.0237],\n",
            "        [ 0.1168,  0.1141,  0.0617,  ...,  0.1049,  0.0725,  0.1808]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2677, -0.0601,  0.0239,  ...,  0.2376, -0.1787, -0.1859],\n",
            "        [ 0.0201, -0.0911, -0.0080,  ..., -0.0482,  0.0521,  0.1209],\n",
            "        [ 0.1963, -0.1216, -0.0293,  ..., -0.0536,  0.0182,  0.0223],\n",
            "        ...,\n",
            "        [ 0.2100,  0.1340, -0.1107,  ..., -0.0316, -0.0612, -0.1492],\n",
            "        [ 0.1119,  0.2279, -0.0562,  ...,  0.1371, -0.0989, -0.0530],\n",
            "        [ 0.0839,  0.0119, -0.0418,  ...,  0.2187, -0.3231, -0.2354]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1381, -0.2363,  0.2268,  ...,  0.1740, -0.0517,  0.1155],\n",
            "         [ 0.2100,  0.1340, -0.1107,  ..., -0.0316, -0.0612, -0.1492],\n",
            "         [ 0.1119,  0.2279, -0.0562,  ...,  0.1371, -0.0989, -0.0530],\n",
            "         ...,\n",
            "         [ 0.2757,  0.0085,  0.0351,  ...,  0.2654, -0.2368, -0.0040],\n",
            "         [ 0.1467,  0.1146, -0.0993,  ..., -0.0204, -0.0538, -0.1364],\n",
            "         [-0.0137,  0.0090,  0.1630,  ..., -0.0136, -0.1609, -0.0241]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0136,  0.0190,  0.1115,  ...,  0.0672,  0.0410,  0.1970],\n",
            "        [ 0.5724,  0.1980, -0.4409,  ...,  0.2559, -0.4567, -0.3665],\n",
            "        [ 0.0902,  0.4915, -0.1715,  ...,  0.1494, -0.0028,  0.1092],\n",
            "        ...,\n",
            "        [ 0.3359,  0.1047, -0.1604,  ...,  0.2231, -0.3308, -0.0730],\n",
            "        [ 0.3899,  0.1751, -0.3676,  ...,  0.1540, -0.3445, -0.2821],\n",
            "        [ 0.0578,  0.1753, -0.1440,  ...,  0.2010, -0.2072, -0.1019]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0208,  0.0079, -0.1354,  ...,  0.1456, -0.0278, -0.0665],\n",
            "        [ 0.0200, -0.0909, -0.0079,  ..., -0.0483,  0.0522,  0.1211],\n",
            "        [ 0.0200, -0.0909, -0.0079,  ..., -0.0483,  0.0522,  0.1211],\n",
            "        ...,\n",
            "        [ 0.1184, -0.0508, -0.0070,  ...,  0.0580,  0.0363,  0.1084],\n",
            "        [ 0.1986, -0.3161,  0.1278,  ...,  0.3088, -0.1570,  0.0132],\n",
            "        [ 0.0032,  0.0600, -0.3068,  ...,  0.1558, -0.2106, -0.1062]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1050,  0.0650,  0.1379,  ..., -0.0988, -0.0121,  0.0564],\n",
            "         [ 0.0572, -0.2233, -0.1425,  ..., -0.0294, -0.0599,  0.0857],\n",
            "         [ 0.0032,  0.0600, -0.3068,  ...,  0.1558, -0.2106, -0.1062],\n",
            "         ...,\n",
            "         [ 0.1184, -0.0508, -0.0070,  ...,  0.0580,  0.0363,  0.1084],\n",
            "         [ 0.1986, -0.3161,  0.1278,  ...,  0.3088, -0.1570,  0.0132],\n",
            "         [ 0.0032,  0.0600, -0.3068,  ...,  0.1558, -0.2106, -0.1062]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0836,  0.0343,  0.1192,  ..., -0.1208,  0.0358,  0.1055],\n",
            "        [ 0.1207, -0.1714,  0.0095,  ..., -0.0498, -0.0520,  0.0058],\n",
            "        [ 0.1322,  0.1582, -0.4268,  ...,  0.2909, -0.3820, -0.1176],\n",
            "        ...,\n",
            "        [ 0.0077,  0.1511,  0.0031,  ...,  0.0801,  0.0752,  0.1893],\n",
            "        [ 0.3569,  0.0714, -0.2535,  ...,  0.3404, -0.3877, -0.2060],\n",
            "        [ 0.1322,  0.1582, -0.4268,  ...,  0.2909, -0.3820, -0.1176]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0206,  0.1160, -0.0331,  ..., -0.2021,  0.0107,  0.0333],\n",
            "        [-0.0827,  0.0074, -0.0438,  ...,  0.0617,  0.0153, -0.0732],\n",
            "        [ 0.2663, -0.0585,  0.0224,  ...,  0.2429, -0.1841, -0.1907],\n",
            "        ...,\n",
            "        [ 0.0788,  0.1385, -0.0742,  ...,  0.1224, -0.2358, -0.2382],\n",
            "        [ 0.1157, -0.0670, -0.1739,  ...,  0.0598, -0.3303, -0.2629],\n",
            "        [ 0.2939,  0.1154, -0.0321,  ...,  0.3058, -0.0607, -0.1041]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 2.9395e-01,  1.1543e-01, -3.2137e-02,  ...,  3.0585e-01,\n",
            "          -6.0730e-02, -1.0408e-01],\n",
            "         [ 2.6782e-04,  2.6313e-01, -1.8713e-02,  ...,  6.4899e-02,\n",
            "           8.5604e-02,  9.8338e-02],\n",
            "         [ 1.6562e-01,  4.4143e-01, -2.5458e-01,  ...,  2.4801e-01,\n",
            "          -7.6612e-02, -1.3889e-01],\n",
            "         ...,\n",
            "         [ 9.9586e-02, -2.3765e-01, -9.3869e-02,  ..., -8.9547e-02,\n",
            "           1.3006e-01,  6.4538e-02],\n",
            "         [ 7.8770e-02,  1.3853e-01, -7.4206e-02,  ...,  1.2242e-01,\n",
            "          -2.3585e-01, -2.3821e-01],\n",
            "         [ 1.1569e-01, -6.7017e-02, -1.7395e-01,  ...,  5.9770e-02,\n",
            "          -3.3029e-01, -2.6294e-01]]], grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5368,  0.1453, -0.3543,  ...,  0.3693, -0.3561, -0.2925],\n",
            "        [-0.0586,  0.2859,  0.0763,  ..., -0.0453,  0.1978,  0.2081],\n",
            "        [-0.0242,  0.5886, -0.1875,  ...,  0.0943, -0.0466,  0.0215],\n",
            "        ...,\n",
            "        [ 0.0255, -0.1341, -0.0402,  ..., -0.0361,  0.0574,  0.0201],\n",
            "        [ 0.4058,  0.2161, -0.3599,  ...,  0.3555, -0.4997, -0.3366],\n",
            "        [ 0.4746,  0.1531, -0.4592,  ...,  0.3286, -0.5429, -0.4525]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0713,  0.0177, -0.1146,  ...,  0.0593,  0.0716, -0.0690],\n",
            "        [-0.1867, -0.0650,  0.0728,  ..., -0.0757, -0.0712,  0.1312],\n",
            "        [ 0.0200, -0.0905, -0.0077,  ..., -0.0484,  0.0523,  0.1211],\n",
            "        ...,\n",
            "        [ 0.1147,  0.4171, -0.1488,  ...,  0.0804, -0.2239, -0.2058],\n",
            "        [ 0.0680, -0.1833, -0.1292,  ..., -0.0113, -0.0827, -0.0371],\n",
            "        [ 0.2302,  0.1259,  0.0762,  ...,  0.2768, -0.1721, -0.2067]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0218,  0.2192, -0.0983,  ...,  0.1092, -0.1535, -0.1504],\n",
            "         [-0.0069,  0.2053, -0.0392,  ...,  0.0927,  0.0943,  0.1320],\n",
            "         [ 0.0680, -0.1833, -0.1292,  ..., -0.0113, -0.0827, -0.0371],\n",
            "         ...,\n",
            "         [ 0.1147,  0.4171, -0.1488,  ...,  0.0804, -0.2239, -0.2058],\n",
            "         [ 0.0680, -0.1833, -0.1292,  ..., -0.0113, -0.0827, -0.0371],\n",
            "         [ 0.2302,  0.1259,  0.0762,  ...,  0.2768, -0.1721, -0.2067]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2331,  0.1864, -0.3189,  ...,  0.3109, -0.3556, -0.1850],\n",
            "        [-0.0405,  0.1790, -0.1362,  ...,  0.1328,  0.0282,  0.0759],\n",
            "        [ 0.3275, -0.0410, -0.3721,  ...,  0.2180, -0.3679, -0.2623],\n",
            "        ...,\n",
            "        [ 0.5432,  0.3265, -0.5783,  ...,  0.4820, -0.6246, -0.4618],\n",
            "        [ 0.3275, -0.0410, -0.3721,  ...,  0.2180, -0.3679, -0.2623],\n",
            "        [ 0.5276,  0.2441, -0.3132,  ...,  0.3717, -0.4876, -0.3862]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.1687,  0.0539,  0.0381,  ...,  0.0290,  0.0302,  0.0159],\n",
            "        [ 0.1547,  0.1661, -0.0419,  ...,  0.0055, -0.0670, -0.1092],\n",
            "        [-0.1637, -0.1246, -0.2005,  ...,  0.1651,  0.0439,  0.1195],\n",
            "        ...,\n",
            "        [ 0.0173,  0.1224, -0.0433,  ...,  0.0963,  0.0384, -0.1312],\n",
            "        [ 0.1790, -0.0360, -0.1612,  ..., -0.0255, -0.0855, -0.2177],\n",
            "        [ 0.3142, -0.0200, -0.0430,  ...,  0.2445, -0.2003, -0.2868]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0173,  0.1224, -0.0433,  ...,  0.0963,  0.0384, -0.1312],\n",
            "         [ 0.1790, -0.0360, -0.1612,  ..., -0.0255, -0.0855, -0.2177],\n",
            "         [ 0.3142, -0.0200, -0.0430,  ...,  0.2445, -0.2003, -0.2868],\n",
            "         ...,\n",
            "         [ 0.0098,  0.0095, -0.0782,  ...,  0.2656, -0.3211, -0.1012],\n",
            "         [ 0.1461,  0.0870, -0.1594,  ..., -0.0077, -0.1506, -0.2164],\n",
            "         [ 0.1600,  0.1683, -0.2439,  ...,  0.1633, -0.1069, -0.1620]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0008,  0.0570,  0.0413,  ..., -0.0069,  0.0769,  0.0184],\n",
            "        [ 0.5662,  0.0738, -0.5037,  ...,  0.2723, -0.4729, -0.3940],\n",
            "        [ 0.3373,  0.1473, -0.2491,  ...,  0.2351, -0.3388, -0.2835],\n",
            "        ...,\n",
            "        [ 0.0169, -0.0047, -0.0936,  ...,  0.1254, -0.2111, -0.0932],\n",
            "        [ 0.3013,  0.1766, -0.3517,  ...,  0.1895, -0.3389, -0.2373],\n",
            "        [ 0.2612,  0.1873, -0.2882,  ...,  0.2481, -0.2018, -0.2085]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0199, -0.0903, -0.0076,  ..., -0.0486,  0.0524,  0.1213],\n",
            "        [ 0.0465,  0.0131,  0.0872,  ...,  0.1705, -0.0211,  0.0731],\n",
            "        [ 0.0199, -0.0903, -0.0076,  ..., -0.0486,  0.0524,  0.1213],\n",
            "        ...,\n",
            "        [ 0.2523,  0.0095,  0.1421,  ...,  0.0609, -0.2004, -0.0800],\n",
            "        [ 0.2877,  0.0916, -0.0380,  ...,  0.3063, -0.0756, -0.1152],\n",
            "        [ 0.1118,  0.4044, -0.1511,  ...,  0.0789, -0.2332, -0.2210]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2877,  0.0916, -0.0380,  ...,  0.3063, -0.0756, -0.1152],\n",
            "         [ 0.1118,  0.4044, -0.1511,  ...,  0.0789, -0.2332, -0.2210],\n",
            "         [ 0.1070, -0.2362, -0.2289,  ..., -0.0281, -0.2586, -0.0121],\n",
            "         ...,\n",
            "         [ 0.0901,  0.0037,  0.0258,  ...,  0.1186, -0.0296, -0.1453],\n",
            "         [ 0.1070, -0.2362, -0.2289,  ..., -0.0281, -0.2586, -0.0121],\n",
            "         [ 0.2523,  0.0095,  0.1421,  ...,  0.0609, -0.2004, -0.0800]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5764,  0.1148, -0.3859,  ...,  0.3960, -0.4044, -0.3293],\n",
            "        [ 0.5773,  0.2870, -0.5961,  ...,  0.4972, -0.6501, -0.4896],\n",
            "        [ 0.4476, -0.1646, -0.2701,  ...,  0.1284, -0.3842, -0.2421],\n",
            "        ...,\n",
            "        [ 0.0412, -0.0116, -0.0008,  ...,  0.0138, -0.0562, -0.0944],\n",
            "        [ 0.4476, -0.1646, -0.2701,  ...,  0.1284, -0.3842, -0.2421],\n",
            "        [ 0.5983,  0.1641, -0.2934,  ...,  0.3458, -0.5077, -0.3351]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1443, -0.1089, -0.0306,  ..., -0.0734, -0.0918,  0.0450],\n",
            "        [ 0.0315, -0.0883,  0.1638,  ...,  0.1405, -0.0471, -0.0633],\n",
            "        [ 0.0198, -0.0902, -0.0075,  ..., -0.0487,  0.0525,  0.1214],\n",
            "        ...,\n",
            "        [ 0.0872,  0.0317, -0.1357,  ...,  0.1439, -0.2206, -0.1873],\n",
            "        [ 0.2999, -0.0157, -0.1791,  ..., -0.0056,  0.0428,  0.0010],\n",
            "        [ 0.0370, -0.3823, -0.2406,  ...,  0.0918, -0.0775, -0.0642]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2115, -0.1660,  0.0695,  ...,  0.0558, -0.1161, -0.1521],\n",
            "         [ 0.1823, -0.0844,  0.1901,  ...,  0.2030, -0.3352,  0.1145],\n",
            "         [-0.0612, -0.1191,  0.0053,  ...,  0.0898, -0.0087,  0.0737],\n",
            "         ...,\n",
            "         [ 0.0872,  0.0317, -0.1357,  ...,  0.1439, -0.2206, -0.1873],\n",
            "         [ 0.2999, -0.0157, -0.1791,  ..., -0.0056,  0.0428,  0.0010],\n",
            "         [ 0.0370, -0.3823, -0.2406,  ...,  0.0918, -0.0775, -0.0642]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4749,  0.0520, -0.3057,  ...,  0.3383, -0.4443, -0.3830],\n",
            "        [ 0.4415,  0.1631, -0.2044,  ...,  0.3765, -0.4988, -0.1038],\n",
            "        [ 0.1471,  0.0791, -0.2581,  ...,  0.2026, -0.2350, -0.0577],\n",
            "        ...,\n",
            "        [ 0.6000,  0.1409, -0.5701,  ...,  0.5384, -0.6620, -0.4802],\n",
            "        [ 0.5375,  0.1160, -0.4085,  ...,  0.2432, -0.3012, -0.2859],\n",
            "        [ 0.2664, -0.1064, -0.3599,  ...,  0.2771, -0.3757, -0.2885]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0460, -0.0333,  0.0879,  ..., -0.0599,  0.0248, -0.0718],\n",
            "        [ 0.2605, -0.0544,  0.0207,  ...,  0.2549, -0.1938, -0.1978],\n",
            "        [ 0.2605, -0.0544,  0.0207,  ...,  0.2549, -0.1938, -0.1978],\n",
            "        ...,\n",
            "        [-0.0856, -0.0771, -0.0450,  ...,  0.0561,  0.1292,  0.1830],\n",
            "        [ 0.1098,  0.4383, -0.0128,  ...,  0.0738,  0.0060,  0.1830],\n",
            "        [ 0.1098,  0.4383, -0.0128,  ...,  0.0738,  0.0060,  0.1830]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0856, -0.0771, -0.0450,  ...,  0.0561,  0.1292,  0.1830],\n",
            "         [ 0.1098,  0.4383, -0.0128,  ...,  0.0738,  0.0060,  0.1830],\n",
            "         [ 0.1098,  0.4383, -0.0128,  ...,  0.0738,  0.0060,  0.1830],\n",
            "         ...,\n",
            "         [ 0.0220,  0.0325, -0.0842,  ...,  0.0849, -0.0147,  0.0485],\n",
            "         [ 0.1950,  0.0668, -0.3429,  ...,  0.1959, -0.1692,  0.0396],\n",
            "         [ 0.2177,  0.1721, -0.1582,  ..., -0.0326, -0.1219, -0.2250]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0631,  0.1382, -0.1779,  ...,  0.1521,  0.0565,  0.2179],\n",
            "        [-0.0252,  0.5804, -0.0254,  ...,  0.0396,  0.1599,  0.3172],\n",
            "        [-0.0252,  0.5804, -0.0254,  ...,  0.0396,  0.1599,  0.3172],\n",
            "        ...,\n",
            "        [ 0.2858,  0.1403, -0.3868,  ...,  0.3737, -0.2709, -0.1777],\n",
            "        [ 0.2046,  0.0868, -0.2904,  ...,  0.2260, -0.2344, -0.0288],\n",
            "        [ 0.5986,  0.1939, -0.5108,  ...,  0.2641, -0.5068, -0.4234]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0195, -0.0901, -0.0073,  ..., -0.0488,  0.0527,  0.1214],\n",
            "        [ 0.0195, -0.0901, -0.0073,  ..., -0.0488,  0.0527,  0.1214],\n",
            "        [ 0.0195, -0.0901, -0.0073,  ..., -0.0488,  0.0527,  0.1214],\n",
            "        ...,\n",
            "        [ 0.0199,  0.3637, -0.0180,  ...,  0.1117, -0.0558, -0.0936],\n",
            "        [-0.0551,  0.2543,  0.1048,  ...,  0.0685,  0.1287,  0.1711],\n",
            "        [-0.0211,  0.2820, -0.2576,  ...,  0.2873, -0.2776, -0.0203]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0551,  0.2543,  0.1048,  ...,  0.0685,  0.1287,  0.1711],\n",
            "         [-0.0211,  0.2820, -0.2576,  ...,  0.2873, -0.2776, -0.0203],\n",
            "         [ 0.0329,  0.2781, -0.1237,  ...,  0.3366,  0.0341, -0.0749],\n",
            "         ...,\n",
            "         [ 0.0693,  0.3391, -0.0452,  ...,  0.0315, -0.0783,  0.0178],\n",
            "         [ 0.0802,  0.2104, -0.0849,  ...,  0.1206, -0.1997, -0.2286],\n",
            "         [ 0.0199,  0.3637, -0.0180,  ...,  0.1117, -0.0558, -0.0936]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.1284,  0.4114, -0.0337,  ...,  0.1681,  0.1705,  0.3451],\n",
            "        [ 0.2210,  0.3083, -0.4117,  ...,  0.2759, -0.3453, -0.2025],\n",
            "        [-0.1516,  0.4473, -0.0718,  ...,  0.2137,  0.1589,  0.1970],\n",
            "        ...,\n",
            "        [ 0.0379,  0.4417, -0.0895,  ...,  0.0739,  0.0466,  0.1608],\n",
            "        [ 0.4924,  0.1888, -0.4876,  ...,  0.4903, -0.5895, -0.4193],\n",
            "        [-0.0274,  0.5158, -0.0773,  ...,  0.2098,  0.0432,  0.0818]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0529,  0.0898, -0.1543,  ...,  0.1152,  0.0869,  0.0452],\n",
            "        [ 0.0194, -0.0900, -0.0073,  ..., -0.0487,  0.0527,  0.1212],\n",
            "        [ 0.0194, -0.0900, -0.0073,  ..., -0.0487,  0.0527,  0.1212],\n",
            "        ...,\n",
            "        [ 0.0289, -0.2712, -0.1520,  ..., -0.1390, -0.0166, -0.2885],\n",
            "        [ 0.0664,  0.3408, -0.0420,  ...,  0.0306, -0.0704,  0.0260],\n",
            "        [ 0.0340,  0.1544, -0.0908,  ...,  0.0807, -0.2275, -0.0685]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0654,  0.3221, -0.0784,  ...,  0.1147, -0.1216,  0.0593],\n",
            "         [-0.0144, -0.0898, -0.1063,  ...,  0.1339, -0.2106, -0.2005],\n",
            "         [ 0.1137, -0.0279,  0.0313,  ..., -0.1142, -0.1888, -0.0018],\n",
            "         ...,\n",
            "         [-0.0309, -0.0797, -0.1338,  ...,  0.1183, -0.1049,  0.2451],\n",
            "         [ 0.2428,  0.0558, -0.1489,  ...,  0.1027, -0.1472, -0.0375],\n",
            "         [ 0.1531, -0.0055, -0.1572,  ...,  0.0011, -0.1487, -0.1208]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0774,  0.2142, -0.0989,  ...,  0.1140, -0.0711,  0.0523],\n",
            "        [ 0.2654,  0.0922, -0.3334,  ...,  0.3410, -0.4117, -0.3216],\n",
            "        [ 0.1233, -0.1015,  0.0834,  ..., -0.0969, -0.0996,  0.0326],\n",
            "        ...,\n",
            "        [-0.0575,  0.0851, -0.1687,  ...,  0.1181, -0.0373,  0.2829],\n",
            "        [ 0.4259,  0.1299, -0.3409,  ...,  0.2392, -0.3089, -0.1880],\n",
            "        [ 0.3388,  0.1160, -0.3618,  ...,  0.1990, -0.3540, -0.2123]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0193, -0.0898, -0.0072,  ..., -0.0486,  0.0527,  0.1209],\n",
            "        [ 0.0193, -0.0898, -0.0072,  ..., -0.0486,  0.0527,  0.1209],\n",
            "        [ 0.0193, -0.0898, -0.0072,  ..., -0.0486,  0.0527,  0.1209],\n",
            "        ...,\n",
            "        [ 0.1506, -0.1584, -0.1480,  ...,  0.3873, -0.4694, -0.1835],\n",
            "        [ 0.1506, -0.1584, -0.1480,  ...,  0.3873, -0.4694, -0.1835],\n",
            "        [-0.0411,  0.0581,  0.3014,  ...,  0.0606, -0.0716,  0.0326]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1506, -0.1584, -0.1480,  ...,  0.3873, -0.4694, -0.1835],\n",
            "         [ 0.1506, -0.1584, -0.1480,  ...,  0.3873, -0.4694, -0.1835],\n",
            "         [ 0.1506, -0.1584, -0.1480,  ...,  0.3873, -0.4694, -0.1835],\n",
            "         ...,\n",
            "         [ 0.1112,  0.1533, -0.0960,  ...,  0.0657, -0.2803, -0.1978],\n",
            "         [ 0.1646, -0.0075, -0.1511,  ...,  0.2311, -0.2021,  0.0460],\n",
            "         [ 0.1625,  0.4691, -0.1225,  ...,  0.2348, -0.1003, -0.2857]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5881,  0.1669, -0.5336,  ...,  0.5693, -0.6682, -0.4736],\n",
            "        [ 0.5881,  0.1669, -0.5336,  ...,  0.5693, -0.6682, -0.4736],\n",
            "        [ 0.5881,  0.1669, -0.5336,  ...,  0.5693, -0.6682, -0.4736],\n",
            "        ...,\n",
            "        [ 0.6431,  0.1681, -0.5592,  ...,  0.4913, -0.7204, -0.4785],\n",
            "        [ 0.5639,  0.0942, -0.4990,  ...,  0.5107, -0.5651, -0.2827],\n",
            "        [ 0.1919,  0.2486, -0.1609,  ...,  0.1908, -0.2849, -0.2501]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0193, -0.0896, -0.0072,  ..., -0.0484,  0.0527,  0.1206],\n",
            "        [ 0.0193, -0.0896, -0.0072,  ..., -0.0484,  0.0527,  0.1206],\n",
            "        [ 0.0193, -0.0896, -0.0072,  ..., -0.0484,  0.0527,  0.1206],\n",
            "        ...,\n",
            "        [ 0.1472, -0.1524, -0.1449,  ...,  0.3870, -0.4662, -0.1796],\n",
            "        [ 0.1472, -0.1524, -0.1449,  ...,  0.3870, -0.4662, -0.1796],\n",
            "        [ 0.0794, -0.2381, -0.2230,  ...,  0.0349, -0.2649,  0.0041]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1472, -0.1524, -0.1449,  ...,  0.3870, -0.4662, -0.1796],\n",
            "         [ 0.1472, -0.1524, -0.1449,  ...,  0.3870, -0.4662, -0.1796],\n",
            "         [ 0.1472, -0.1524, -0.1449,  ...,  0.3870, -0.4662, -0.1796],\n",
            "         ...,\n",
            "         [ 0.1472, -0.1524, -0.1449,  ...,  0.3870, -0.4662, -0.1796],\n",
            "         [ 0.1472, -0.1524, -0.1449,  ...,  0.3870, -0.4662, -0.1796],\n",
            "         [ 0.0794, -0.2381, -0.2230,  ...,  0.0349, -0.2649,  0.0041]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5794,  0.1702, -0.5279,  ...,  0.5646, -0.6624, -0.4674],\n",
            "        [ 0.5794,  0.1702, -0.5279,  ...,  0.5646, -0.6624, -0.4674],\n",
            "        [ 0.5794,  0.1702, -0.5279,  ...,  0.5646, -0.6624, -0.4674],\n",
            "        ...,\n",
            "        [ 0.5794,  0.1702, -0.5279,  ...,  0.5646, -0.6624, -0.4674],\n",
            "        [ 0.5794,  0.1702, -0.5279,  ...,  0.5646, -0.6624, -0.4674],\n",
            "        [ 0.4454, -0.1602, -0.2928,  ...,  0.2083, -0.4392, -0.2266]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0240,  0.0099, -0.1463,  ..., -0.0677,  0.0007, -0.0032],\n",
            "        [ 0.0193, -0.0895, -0.0072,  ..., -0.0483,  0.0527,  0.1204],\n",
            "        [ 0.1086, -0.0685, -0.1490,  ...,  0.0608, -0.0618, -0.0011],\n",
            "        ...,\n",
            "        [ 0.0732, -0.0442, -0.0510,  ...,  0.2106, -0.3403, -0.2424],\n",
            "        [ 0.1662, -0.1359, -0.0299,  ...,  0.2765, -0.3334, -0.1356],\n",
            "        [ 0.0097, -0.4142, -0.0812,  ..., -0.0575, -0.0051,  0.1174]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0957,  0.1634, -0.0937,  ...,  0.0968, -0.1879, -0.2836],\n",
            "         [ 0.1260, -0.2996, -0.2633,  ...,  0.1263, -0.1785, -0.1047],\n",
            "         [ 0.0894,  0.1601, -0.0528,  ...,  0.3892, -0.4397, -0.2233],\n",
            "         ...,\n",
            "         [ 0.3216, -0.4171, -0.1318,  ...,  0.1041, -0.3244, -0.2085],\n",
            "         [-0.1668, -0.1313, -0.1300,  ..., -0.1169,  0.0978,  0.1178],\n",
            "         [ 0.0535,  0.2841, -0.1015,  ...,  0.1113, -0.1583, -0.2489]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4170,  0.2232, -0.4272,  ...,  0.4043, -0.4813, -0.4093],\n",
            "        [ 0.4612, -0.0321, -0.4968,  ...,  0.3519, -0.4551, -0.3369],\n",
            "        [ 0.2500,  0.3747, -0.3558,  ...,  0.4398, -0.4846, -0.2729],\n",
            "        ...,\n",
            "        [ 0.6385, -0.1319, -0.4644,  ...,  0.4201, -0.6281, -0.4923],\n",
            "        [-0.0343, -0.0960,  0.0349,  ..., -0.0636,  0.0093,  0.0136],\n",
            "        [ 0.3690,  0.2895, -0.4332,  ...,  0.4185, -0.4972, -0.3075]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0193, -0.0894, -0.0072,  ..., -0.0482,  0.0527,  0.1202],\n",
            "        [ 0.0193, -0.0894, -0.0072,  ..., -0.0482,  0.0527,  0.1202],\n",
            "        [ 0.0193, -0.0894, -0.0072,  ..., -0.0482,  0.0527,  0.1202],\n",
            "        ...,\n",
            "        [ 0.0650,  0.0668, -0.0591,  ...,  0.0867,  0.0308, -0.0066],\n",
            "        [ 0.0571,  0.3373, -0.0883,  ...,  0.0686, -0.0094, -0.0912],\n",
            "        [ 0.0571,  0.3373, -0.0883,  ...,  0.0686, -0.0094, -0.0912]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1618, -0.0283, -0.1397,  ..., -0.0215, -0.1210, -0.0932],\n",
            "         [ 0.2513, -0.2074, -0.0405,  ..., -0.0600, -0.0068, -0.0481],\n",
            "         [-0.0046,  0.3742, -0.0092,  ...,  0.0840,  0.0530,  0.0735],\n",
            "         ...,\n",
            "         [-0.0045,  0.0311,  0.2682,  ..., -0.0685,  0.1809,  0.2026],\n",
            "         [ 0.2478, -0.0371, -0.0490,  ...,  0.1127, -0.3687,  0.2044],\n",
            "         [ 0.1053, -0.0349, -0.1124,  ...,  0.1471, -0.1240, -0.0993]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2694,  0.0700, -0.2718,  ...,  0.1235, -0.2679, -0.1409],\n",
            "        [ 0.3732, -0.0020, -0.2921,  ...,  0.2753, -0.2775, -0.1502],\n",
            "        [-0.1085,  0.5217,  0.0568,  ..., -0.0409,  0.1829,  0.2931],\n",
            "        ...,\n",
            "        [-0.0204, -0.0941,  0.2281,  ..., -0.1540,  0.1678,  0.1371],\n",
            "        [ 0.3933,  0.1325, -0.2606,  ...,  0.3270, -0.4612,  0.0603],\n",
            "        [ 0.1281,  0.0600, -0.1629,  ...,  0.1353, -0.2202, -0.1196]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2534, -0.0502,  0.0251,  ...,  0.2563, -0.1882, -0.1902],\n",
            "        [ 0.0259,  0.0731, -0.1049,  ..., -0.0484,  0.0224, -0.0281],\n",
            "        [ 0.0301, -0.0935,  0.1679,  ...,  0.1335, -0.0447, -0.0622],\n",
            "        ...,\n",
            "        [ 0.1605, -0.0141, -0.1427,  ..., -0.0877, -0.0656, -0.1164],\n",
            "        [ 0.0497,  0.2085, -0.0017,  ...,  0.0897, -0.0207,  0.0068],\n",
            "        [ 0.2221, -0.0253, -0.2622,  ...,  0.0496, -0.0459, -0.0618]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0694,  0.1575, -0.1856,  ..., -0.0648,  0.0676, -0.0901],\n",
            "         [-0.0062,  0.1179,  0.1946,  ..., -0.0221, -0.0197,  0.0155],\n",
            "         [-0.0562, -0.0305,  0.0107,  ...,  0.1331, -0.2104,  0.1187],\n",
            "         ...,\n",
            "         [ 0.0792, -0.2084,  0.0484,  ...,  0.1741, -0.2174, -0.1349],\n",
            "         [ 0.2591, -0.2209, -0.0811,  ...,  0.1047, -0.1204, -0.1829],\n",
            "         [-0.0548,  0.2011, -0.2393,  ...,  0.0375, -0.1445, -0.0841]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0017,  0.0950, -0.0812,  ..., -0.0688,  0.0716,  0.0109],\n",
            "        [ 0.1541,  0.1482,  0.0036,  ...,  0.1707, -0.1284, -0.1008],\n",
            "        [ 0.0071, -0.0575,  0.0636,  ...,  0.0319, -0.0600,  0.0474],\n",
            "        ...,\n",
            "        [ 0.3017,  0.0186, -0.2482,  ...,  0.2907, -0.3483, -0.1910],\n",
            "        [ 0.4523, -0.0526, -0.2865,  ...,  0.3168, -0.3891, -0.2796],\n",
            "        [ 0.3794,  0.1445, -0.5757,  ...,  0.3628, -0.5462, -0.3680]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0195, -0.0890, -0.0072,  ..., -0.0480,  0.0527,  0.1196],\n",
            "        [ 0.0195, -0.0890, -0.0072,  ..., -0.0480,  0.0527,  0.1196],\n",
            "        [ 0.0301, -0.0938,  0.1682,  ...,  0.1330, -0.0446, -0.0621],\n",
            "        ...,\n",
            "        [ 0.1199,  0.1311, -0.1606,  ..., -0.0253,  0.0291, -0.3769],\n",
            "        [ 0.0367,  0.2721, -0.0396,  ...,  0.0644,  0.0776, -0.0070],\n",
            "        [ 0.0929,  0.3956, -0.1242,  ...,  0.0678, -0.1879, -0.1461]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0367,  0.2721, -0.0396,  ...,  0.0644,  0.0776, -0.0070],\n",
            "         [ 0.0929,  0.3956, -0.1242,  ...,  0.0678, -0.1879, -0.1461],\n",
            "         [ 0.1100,  0.1479, -0.1118,  ...,  0.1729, -0.0791, -0.0909],\n",
            "         ...,\n",
            "         [ 0.0726,  0.2495, -0.0746,  ...,  0.1343, -0.1483, -0.0211],\n",
            "         [ 0.0462, -0.0357, -0.0119,  ...,  0.2128,  0.0067,  0.1233],\n",
            "         [ 0.0512,  0.2048, -0.1067,  ...,  0.0956, -0.0982, -0.1747]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0912,  0.4468,  0.0280,  ..., -0.0391,  0.2405,  0.2408],\n",
            "        [ 0.4526,  0.3073, -0.5120,  ...,  0.4328, -0.5499, -0.3883],\n",
            "        [ 0.0335,  0.1723, -0.0622,  ...,  0.0776, -0.0968, -0.0105],\n",
            "        ...,\n",
            "        [ 0.0177,  0.5394, -0.2186,  ...,  0.2212, -0.0356,  0.1646],\n",
            "        [ 0.0376,  0.0516, -0.0651,  ...,  0.1032,  0.0530,  0.1508],\n",
            "        [ 0.2583,  0.3362, -0.4339,  ...,  0.3622, -0.3377, -0.2817]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0879, -0.1572, -0.0940,  ..., -0.0311,  0.1070, -0.0545],\n",
            "        [ 0.0196, -0.0888, -0.0073,  ..., -0.0479,  0.0527,  0.1193],\n",
            "        [ 0.0196, -0.0888, -0.0073,  ..., -0.0479,  0.0527,  0.1193],\n",
            "        ...,\n",
            "        [ 0.0439,  0.0469,  0.0035,  ...,  0.2276, -0.0183, -0.0931],\n",
            "        [ 0.0467, -0.0791, -0.0812,  ...,  0.0892, -0.1710,  0.0485],\n",
            "        [ 0.0508, -0.1520,  0.0258,  ...,  0.2742, -0.2162,  0.0988]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0467, -0.0791, -0.0812,  ...,  0.0892, -0.1710,  0.0485],\n",
            "         [ 0.0508, -0.1520,  0.0258,  ...,  0.2742, -0.2162,  0.0988],\n",
            "         [-0.0902, -0.0352,  0.0967,  ...,  0.2806, -0.1832, -0.0069],\n",
            "         ...,\n",
            "         [-0.0051,  0.3671, -0.0090,  ...,  0.0813,  0.0652,  0.0770],\n",
            "         [ 0.1753,  0.0409, -0.1171,  ..., -0.0445, -0.1326, -0.1176],\n",
            "         [ 0.2476, -0.2053, -0.0379,  ..., -0.0611, -0.0014, -0.0429]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0911,  0.0318, -0.0968,  ...,  0.1523, -0.1894, -0.0179],\n",
            "        [ 0.3688,  0.1420, -0.3776,  ...,  0.4915, -0.5161, -0.0975],\n",
            "        [ 0.0545,  0.0820, -0.1462,  ...,  0.2672, -0.2478, -0.0479],\n",
            "        ...,\n",
            "        [-0.1065,  0.5037,  0.0695,  ..., -0.0544,  0.1840,  0.2878],\n",
            "        [ 0.3195,  0.1521, -0.3033,  ...,  0.1495, -0.3063, -0.1748],\n",
            "        [ 0.3541, -0.0013, -0.2802,  ...,  0.2673, -0.2596, -0.1344]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.1343, -0.0194,  0.0103,  ..., -0.0344, -0.0436,  0.0149],\n",
            "        [ 0.0196, -0.0886, -0.0072,  ..., -0.0478,  0.0527,  0.1189],\n",
            "        [ 0.0196, -0.0886, -0.0072,  ..., -0.0478,  0.0527,  0.1189],\n",
            "        ...,\n",
            "        [ 0.1874,  0.0121, -0.1189,  ...,  0.0562, -0.3306, -0.0630],\n",
            "        [ 0.2007, -0.1430,  0.1123,  ..., -0.1150, -0.1550, -0.0429],\n",
            "        [ 0.0849,  0.1340, -0.0592,  ...,  0.1420, -0.2356, -0.2300]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 4.8747e-02, -2.0086e-01, -2.2129e-01,  ...,  1.3595e-01,\n",
            "          -2.3155e-01, -5.6551e-03],\n",
            "         [ 3.1427e-02, -1.0189e-01,  8.8300e-02,  ..., -5.4118e-02,\n",
            "           5.7375e-02,  6.6114e-02],\n",
            "         [ 9.1277e-02, -1.0107e-01, -6.2701e-02,  ..., -6.5117e-02,\n",
            "          -1.4100e-01, -5.5608e-02],\n",
            "         ...,\n",
            "         [ 7.3032e-02,  3.2861e-01,  1.6205e-01,  ...,  3.9950e-03,\n",
            "           1.4072e-01,  4.1042e-03],\n",
            "         [ 1.0834e-01,  1.6045e-01, -1.5021e-01,  ...,  3.0718e-02,\n",
            "           6.7777e-02, -2.3821e-03],\n",
            "         [-4.8366e-05,  2.4553e-01, -2.1605e-02,  ...,  5.9860e-02,\n",
            "           8.8890e-02,  8.3232e-02]]], grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3502,  0.1218, -0.4403,  ...,  0.3936, -0.4825, -0.2489],\n",
            "        [ 0.0035, -0.0880,  0.1425,  ..., -0.1291,  0.0595,  0.0488],\n",
            "        [ 0.1899,  0.0174, -0.1953,  ...,  0.0785, -0.2273, -0.1138],\n",
            "        ...,\n",
            "        [-0.1252,  0.4860,  0.0520,  ...,  0.1031,  0.2110,  0.1878],\n",
            "        [ 0.1427,  0.1468, -0.1956,  ...,  0.1222, -0.0766, -0.0688],\n",
            "        [-0.0414,  0.1959,  0.0868,  ..., -0.0612,  0.1787,  0.1680]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2478, -0.0510,  0.0289,  ...,  0.2538, -0.1824, -0.1834],\n",
            "        [ 0.0203,  0.0868,  0.0271,  ..., -0.1210, -0.0764, -0.0355],\n",
            "        [-0.1574,  0.1669, -0.1011,  ...,  0.1051, -0.1328, -0.0401],\n",
            "        ...,\n",
            "        [ 0.0408, -0.1234, -0.0659,  ...,  0.0945, -0.2006, -0.1974],\n",
            "        [ 0.1104,  0.0888, -0.1571,  ..., -0.0968, -0.1032,  0.0471],\n",
            "        [ 0.0479, -0.0128, -0.1341,  ..., -0.0393, -0.1015,  0.0117]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1410,  0.1048, -0.0593,  ...,  0.1576,  0.0388,  0.0296],\n",
            "         [ 0.1238,  0.3679, -0.0614,  ...,  0.0597, -0.1957, -0.1683],\n",
            "         [-0.1186, -0.1045, -0.1132,  ...,  0.2515,  0.1290, -0.0490],\n",
            "         ...,\n",
            "         [ 0.0408, -0.1234, -0.0659,  ...,  0.0945, -0.2006, -0.1974],\n",
            "         [ 0.1104,  0.0888, -0.1571,  ..., -0.0968, -0.1032,  0.0471],\n",
            "         [ 0.0479, -0.0128, -0.1341,  ..., -0.0393, -0.1015,  0.0117]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0228,  0.1860, -0.0301,  ...,  0.0485,  0.0313,  0.1632],\n",
            "        [ 0.0276,  0.3773, -0.0939,  ...,  0.0583, -0.0575,  0.0307],\n",
            "        [-0.0566,  0.0026, -0.0562,  ...,  0.0860,  0.1140,  0.0187],\n",
            "        ...,\n",
            "        [ 0.3411,  0.0143, -0.3117,  ...,  0.3138, -0.4773, -0.2774],\n",
            "        [ 0.3306,  0.1418, -0.3611,  ...,  0.1559, -0.3318, -0.1730],\n",
            "        [ 0.0503, -0.0927,  0.0240,  ..., -0.0887, -0.0276,  0.0120]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0197, -0.0882, -0.0074,  ..., -0.0478,  0.0527,  0.1184],\n",
            "        [-0.0822, -0.2408,  0.1600,  ...,  0.0028,  0.0557, -0.0450],\n",
            "        [ 0.0197, -0.0882, -0.0074,  ..., -0.0478,  0.0527,  0.1184],\n",
            "        ...,\n",
            "        [ 0.0880, -0.0630, -0.1005,  ...,  0.0948, -0.2627, -0.1780],\n",
            "        [ 0.0850,  0.2474, -0.0171,  ..., -0.1249, -0.0887, -0.0935],\n",
            "        [ 0.0262, -0.3786, -0.2301,  ...,  0.0874, -0.0615, -0.0517]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0850,  0.2474, -0.0171,  ..., -0.1249, -0.0887, -0.0935],\n",
            "         [ 0.0262, -0.3786, -0.2301,  ...,  0.0874, -0.0615, -0.0517],\n",
            "         [-0.0081,  0.4263, -0.0507,  ...,  0.1768, -0.2106, -0.1219],\n",
            "         ...,\n",
            "         [ 0.0880, -0.0630, -0.1005,  ...,  0.0948, -0.2627, -0.1780],\n",
            "         [ 0.0211,  0.3441, -0.1590,  ...,  0.1452, -0.1309, -0.0947],\n",
            "         [ 0.0880, -0.0630, -0.1005,  ...,  0.0948, -0.2627, -0.1780]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2785,  0.2999, -0.2597,  ...,  0.1867, -0.2735, -0.2510],\n",
            "        [ 0.2293, -0.1148, -0.3213,  ...,  0.2468, -0.3345, -0.2594],\n",
            "        [ 0.0827,  0.4605, -0.1904,  ...,  0.2102, -0.2707, -0.1998],\n",
            "        ...,\n",
            "        [ 0.6647,  0.0049, -0.6162,  ...,  0.5782, -0.7538, -0.5627],\n",
            "        [ 0.0074,  0.3370, -0.2319,  ...,  0.2552, -0.1809, -0.0832],\n",
            "        [ 0.6647,  0.0049, -0.6162,  ...,  0.5782, -0.7538, -0.5627]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-1.0899e-01,  1.6808e-01, -1.8816e-02,  ...,  1.9816e-01,\n",
            "         -1.7116e-01, -6.2950e-02],\n",
            "        [-2.3297e-02,  5.0948e-03, -1.4631e-01,  ..., -7.1731e-02,\n",
            "          1.9382e-03, -3.3891e-03],\n",
            "        [ 1.9824e-02, -8.8016e-02, -7.4426e-03,  ..., -4.7847e-02,\n",
            "          5.2723e-02,  1.1810e-01],\n",
            "        ...,\n",
            "        [ 1.3849e-01,  2.5885e-01, -2.6709e-02,  ..., -2.0748e-01,\n",
            "         -7.5025e-02, -2.5348e-03],\n",
            "        [ 2.1589e-04,  1.2327e-01,  3.2058e-01,  ...,  4.9178e-02,\n",
            "          2.3728e-03,  1.6807e-01],\n",
            "        [ 1.4035e-01, -1.8440e-01,  1.7486e-02,  ...,  1.8028e-01,\n",
            "         -2.9144e-01, -1.2885e-01]], grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 1.3187e-01,  4.7200e-02, -9.1856e-02,  ...,  8.9616e-02,\n",
            "          -1.0471e-01, -1.8650e-01],\n",
            "         [-4.3700e-02, -6.2875e-02,  3.0635e-02,  ...,  4.0136e-02,\n",
            "          -9.6445e-02,  9.6444e-02],\n",
            "         [ 1.9337e-01,  3.4784e-01, -2.6335e-01,  ...,  1.5133e-01,\n",
            "          -1.2621e-01, -1.7149e-01],\n",
            "         ...,\n",
            "         [ 1.3849e-01,  2.5885e-01, -2.6709e-02,  ..., -2.0748e-01,\n",
            "          -7.5025e-02, -2.5348e-03],\n",
            "         [ 2.1589e-04,  1.2327e-01,  3.2058e-01,  ...,  4.9178e-02,\n",
            "           2.3728e-03,  1.6807e-01],\n",
            "         [ 1.4035e-01, -1.8440e-01,  1.7486e-02,  ...,  1.8028e-01,\n",
            "          -2.9144e-01, -1.2885e-01]]], grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 3.6903e-01,  1.2360e-01, -2.9345e-01,  ...,  2.8536e-01,\n",
            "         -3.8886e-01, -2.5004e-01],\n",
            "        [-2.3464e-02,  5.0153e-02, -2.3375e-04,  ...,  9.0055e-02,\n",
            "         -7.4179e-02,  8.5143e-02],\n",
            "        [ 2.4629e-01,  4.2876e-01, -3.7571e-01,  ...,  2.1086e-01,\n",
            "         -3.1942e-01, -2.6229e-01],\n",
            "        ...,\n",
            "        [ 2.9949e-01,  2.0267e-01, -1.2632e-01,  ...,  6.9689e-02,\n",
            "         -1.8639e-01, -7.9551e-02],\n",
            "        [ 2.6591e-02,  2.2375e-01,  1.1064e-01,  ...,  1.8756e-01,\n",
            "         -1.2198e-02,  1.0910e-01],\n",
            "        [ 4.7513e-01, -6.6719e-02, -2.8311e-01,  ...,  3.6211e-01,\n",
            "         -5.6541e-01, -3.5627e-01]], grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.2316,  0.0103,  0.0103,  ...,  0.0794,  0.1003, -0.1259],\n",
            "        [ 0.2455, -0.0517,  0.0292,  ...,  0.2521, -0.1806, -0.1814],\n",
            "        [ 0.0199, -0.0877, -0.0076,  ..., -0.0479,  0.0528,  0.1179],\n",
            "        ...,\n",
            "        [-0.1336, -0.0519, -0.2723,  ...,  0.1890, -0.0858,  0.0166],\n",
            "        [ 0.1882,  0.0404,  0.0332,  ...,  0.0050, -0.1681, -0.2104],\n",
            "        [-0.1391, -0.1106,  0.0126,  ...,  0.0019, -0.0205,  0.1077]])\n",
            "Output of encoder at last step:tensor([[[-0.0185,  0.0600, -0.0616,  ..., -0.0956,  0.0418, -0.0019],\n",
            "         [-0.1336, -0.0519, -0.2723,  ...,  0.1890, -0.0858,  0.0166],\n",
            "         [ 0.1882,  0.0404,  0.0332,  ...,  0.0050, -0.1681, -0.2104],\n",
            "         ...,\n",
            "         [ 0.2986, -0.0347,  0.1074,  ...,  0.2605, -0.2940, -0.2570],\n",
            "         [ 0.2201,  0.0429,  0.0176,  ..., -0.0073, -0.1701, -0.1404],\n",
            "         [-0.1058, -0.0013, -0.2335,  ...,  0.0639, -0.0666,  0.0071]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0654,  0.1437, -0.2367,  ...,  0.1107, -0.0832, -0.0056],\n",
            "        [ 0.0176,  0.0764, -0.3180,  ...,  0.1401, -0.1214, -0.0654],\n",
            "        [ 0.3392,  0.1416, -0.1833,  ...,  0.1888, -0.3334, -0.2385],\n",
            "        ...,\n",
            "        [ 0.2378,  0.1460, -0.1477,  ...,  0.2225, -0.3640, -0.2426],\n",
            "        [ 0.1174,  0.0673, -0.0787,  ...,  0.0687, -0.1298, -0.0922],\n",
            "        [-0.0475,  0.0272, -0.2221,  ...,  0.0614, -0.0682,  0.0193]])\n",
            "Output of encoder at every step:tensor([[-0.1165, -0.0077, -0.2014,  ...,  0.0978,  0.0155, -0.0314],\n",
            "        [ 0.2455, -0.0517,  0.0292,  ...,  0.2521, -0.1806, -0.1814],\n",
            "        [-0.0054,  0.0663,  0.1198,  ..., -0.0132, -0.0276, -0.1554],\n",
            "        ...,\n",
            "        [-0.1837,  0.0348, -0.2521,  ...,  0.1360, -0.0238, -0.0053],\n",
            "        [ 0.0471, -0.0807, -0.0547,  ...,  0.1251, -0.1459, -0.0584],\n",
            "        [-0.0704, -0.1324, -0.3186,  ...,  0.1391, -0.0972, -0.0155]])\n",
            "Output of encoder at last step:tensor([[[ 0.0092,  0.2029, -0.0418,  ...,  0.0493, -0.0503, -0.0186],\n",
            "         [-0.1350, -0.1067, -0.3192,  ...,  0.1724,  0.0092, -0.0224],\n",
            "         [-0.0945,  0.0669, -0.2099,  ...,  0.1675, -0.0041, -0.1648],\n",
            "         ...,\n",
            "         [-0.1154, -0.0429, -0.2552,  ...,  0.1820, -0.1294, -0.0675],\n",
            "         [ 0.1687, -0.0331, -0.0751,  ...,  0.0481, -0.2204, -0.2429],\n",
            "         [-0.0962, -0.0835, -0.2456,  ...,  0.3357, -0.1931, -0.3190]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0318,  0.1483, -0.0181,  ...,  0.0839, -0.0156, -0.0050],\n",
            "        [-0.0273,  0.0924, -0.3590,  ...,  0.2017, -0.0612, -0.0733],\n",
            "        [-0.0572,  0.1178, -0.2023,  ...,  0.0854, -0.0044, -0.0488],\n",
            "        ...,\n",
            "        [ 0.1103,  0.0889, -0.3971,  ...,  0.2790, -0.2996, -0.1734],\n",
            "        [ 0.3589,  0.0842, -0.2501,  ...,  0.2350, -0.3398, -0.3352],\n",
            "        [ 0.0499,  0.1889, -0.4027,  ...,  0.3211, -0.3349, -0.2757]])\n",
            "Output of encoder at every step:tensor([[ 0.0199, -0.0877, -0.0076,  ..., -0.0479,  0.0528,  0.1179],\n",
            "        [ 0.2455, -0.0517,  0.0292,  ...,  0.2521, -0.1806, -0.1814],\n",
            "        [-0.0958,  0.1795, -0.0852,  ..., -0.0954,  0.0262,  0.0764],\n",
            "        ...,\n",
            "        [-0.1912, -0.0279, -0.1273,  ...,  0.0591,  0.0589,  0.1071],\n",
            "        [-0.0968, -0.0302, -0.0508,  ...,  0.1112, -0.0132, -0.0559],\n",
            "        [-0.0092,  0.1077,  0.2223,  ...,  0.4117, -0.2271,  0.0527]])\n",
            "Output of encoder at last step:tensor([[[-0.1829, -0.1253, -0.3187,  ...,  0.1154, -0.0648, -0.0499],\n",
            "         [-0.0641, -0.1300, -0.2454,  ...,  0.2130, -0.0494, -0.0556],\n",
            "         [ 0.1091,  0.2255, -0.0882,  ...,  0.1511, -0.2606, -0.2741],\n",
            "         ...,\n",
            "         [ 0.0202,  0.0900, -0.0675,  ...,  0.0787, -0.0888, -0.0490],\n",
            "         [-0.1320, -0.0900, -0.1798,  ...,  0.1390,  0.0688,  0.1335],\n",
            "         [-0.0185,  0.2257,  0.1511,  ...,  0.0062, -0.0657,  0.0299]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1389,  0.1550, -0.5343,  ...,  0.3423, -0.3791, -0.3018],\n",
            "        [ 0.1353,  0.0276, -0.3979,  ...,  0.2424, -0.2179, -0.1741],\n",
            "        [ 0.4311,  0.4372, -0.4629,  ...,  0.4741, -0.5639, -0.4050],\n",
            "        ...,\n",
            "        [ 0.1630,  0.1115, -0.2139,  ...,  0.2377, -0.1829, -0.1747],\n",
            "        [-0.1044,  0.0360, -0.1747,  ...,  0.0630,  0.0913,  0.1264],\n",
            "        [-0.0061,  0.1671, -0.0064,  ...,  0.0783, -0.0636,  0.0209]])\n",
            "Output of encoder at every step:tensor([[ 0.1027,  0.1222, -0.0238,  ...,  0.0769,  0.0103, -0.0733],\n",
            "        [-0.0806,  0.1188,  0.0606,  ..., -0.0789,  0.0884,  0.0503],\n",
            "        [ 0.0199, -0.0877, -0.0076,  ..., -0.0479,  0.0528,  0.1179],\n",
            "        ...,\n",
            "        [ 0.0135,  0.0071, -0.0961,  ...,  0.0857, -0.1801, -0.0559],\n",
            "        [ 0.1000, -0.0095,  0.1288,  ..., -0.0033,  0.0401, -0.1160],\n",
            "        [-0.0571,  0.2636,  0.1114,  ...,  0.0603,  0.1372,  0.1799]])\n",
            "Output of encoder at last step:tensor([[[ 0.2847,  0.0743,  0.0033,  ...,  0.1216, -0.0789,  0.0412],\n",
            "         [ 0.0382,  0.3352, -0.1160,  ...,  0.0850, -0.1716, -0.2275],\n",
            "         [-0.0360,  0.1290, -0.1856,  ...,  0.0911,  0.0200,  0.0424],\n",
            "         ...,\n",
            "         [ 0.2326, -0.0951, -0.1468,  ...,  0.3233, -0.3110, -0.0643],\n",
            "         [-0.0197,  0.0278, -0.0872,  ...,  0.0851, -0.1524, -0.1452],\n",
            "         [ 0.0458,  0.2004, -0.0575,  ...,  0.0566, -0.1719, -0.0577]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2598,  0.0056, -0.0419,  ...,  0.1103, -0.2030, -0.1531],\n",
            "        [ 0.3334,  0.3536, -0.4539,  ...,  0.4028, -0.4395, -0.3512],\n",
            "        [-0.0772,  0.2188, -0.1375,  ..., -0.0151,  0.0813,  0.1356],\n",
            "        ...,\n",
            "        [ 0.3010,  0.1198, -0.3104,  ...,  0.2459, -0.3333, -0.2218],\n",
            "        [ 0.3307,  0.1901, -0.4530,  ...,  0.4649, -0.5299, -0.4092],\n",
            "        [ 0.1550,  0.1917, -0.1818,  ...,  0.1858, -0.2145, -0.0712]])\n",
            "Output of encoder at every step:tensor([[ 0.2455, -0.0517,  0.0292,  ...,  0.2521, -0.1806, -0.1814],\n",
            "        [ 0.0199, -0.0877, -0.0076,  ..., -0.0479,  0.0528,  0.1179],\n",
            "        [-0.1165, -0.0077, -0.2014,  ...,  0.0978,  0.0155, -0.0314],\n",
            "        ...,\n",
            "        [ 0.1006, -0.1994, -0.1458,  ..., -0.2618, -0.0380, -0.0580],\n",
            "        [-0.1433,  0.2918,  0.0866,  ...,  0.1266, -0.1577, -0.0045],\n",
            "        [-0.0863,  0.0892,  0.0412,  ...,  0.3314, -0.4153, -0.0491]])\n",
            "Output of encoder at last step:tensor([[[ 0.0289,  0.2446,  0.0736,  ...,  0.2662,  0.0048,  0.0522],\n",
            "         [-0.1462,  0.1339,  0.2646,  ...,  0.1282,  0.0279, -0.0130],\n",
            "         [-0.0427, -0.0339, -0.1197,  ...,  0.0480, -0.0351,  0.0185],\n",
            "         ...,\n",
            "         [-0.0571,  0.2636,  0.1114,  ...,  0.0603,  0.1372,  0.1799],\n",
            "         [-0.0189, -0.1420, -0.0636,  ...,  0.1004, -0.1927, -0.2482],\n",
            "         [-0.0428, -0.3022, -0.1481,  ..., -0.2663, -0.0531, -0.0466]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1398,  0.1774, -0.1794,  ...,  0.3247, -0.2208, -0.0661],\n",
            "        [-0.1070,  0.2359, -0.0032,  ...,  0.1939,  0.0233,  0.0365],\n",
            "        [ 0.1063,  0.1039, -0.2743,  ...,  0.1914, -0.0975, -0.0788],\n",
            "        ...,\n",
            "        [-0.1420,  0.4286, -0.0222,  ...,  0.1596,  0.1897,  0.3712],\n",
            "        [ 0.2651,  0.0721, -0.2721,  ...,  0.3002, -0.3662, -0.2897],\n",
            "        [ 0.1486, -0.1657, -0.3428,  ...,  0.0819, -0.2482, -0.1066]])\n",
            "Output of encoder at every step:tensor([[ 0.0199, -0.0877, -0.0076,  ..., -0.0479,  0.0528,  0.1179],\n",
            "        [ 0.0199, -0.0877, -0.0076,  ..., -0.0479,  0.0528,  0.1179],\n",
            "        [ 0.0199, -0.0877, -0.0076,  ..., -0.0479,  0.0528,  0.1179],\n",
            "        ...,\n",
            "        [ 0.1504, -0.2933, -0.2961,  ...,  0.2232, -0.2596,  0.0815],\n",
            "        [ 0.1256, -0.1104, -0.1358,  ...,  0.3919, -0.4574, -0.1666],\n",
            "        [ 0.1256, -0.1104, -0.1358,  ...,  0.3919, -0.4574, -0.1666]])\n",
            "Output of encoder at last step:tensor([[[ 0.1256, -0.1104, -0.1358,  ...,  0.3919, -0.4574, -0.1666],\n",
            "         [ 0.1256, -0.1104, -0.1358,  ...,  0.3919, -0.4574, -0.1666],\n",
            "         [ 0.1504, -0.2933, -0.2961,  ...,  0.2232, -0.2596,  0.0815],\n",
            "         ...,\n",
            "         [ 0.0380,  0.2669, -0.0378,  ...,  0.0616,  0.0834,  0.0018],\n",
            "         [ 0.0695,  0.1377, -0.1081,  ...,  0.0855, -0.1393, -0.0138],\n",
            "         [-0.0110,  0.0316,  0.2659,  ..., -0.0589,  0.0643,  0.0478]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5315,  0.1991, -0.5002,  ...,  0.5438, -0.6362, -0.4418],\n",
            "        [ 0.5315,  0.1991, -0.5002,  ...,  0.5438, -0.6362, -0.4418],\n",
            "        [ 0.5906, -0.0151, -0.5477,  ...,  0.5188, -0.6413, -0.2676],\n",
            "        ...,\n",
            "        [-0.0927,  0.4354,  0.0387,  ..., -0.0508,  0.2431,  0.2484],\n",
            "        [ 0.2417,  0.1774, -0.3929,  ...,  0.3137, -0.3828, -0.1740],\n",
            "        [-0.0034,  0.0770,  0.1226,  ...,  0.0157,  0.0832,  0.0426]])\n",
            "Output of encoder at every step:tensor([[ 0.0199, -0.0877, -0.0076,  ..., -0.0479,  0.0528,  0.1179],\n",
            "        [ 0.0199, -0.0877, -0.0076,  ..., -0.0479,  0.0528,  0.1179],\n",
            "        [ 0.0199, -0.0877, -0.0076,  ..., -0.0479,  0.0528,  0.1179],\n",
            "        ...,\n",
            "        [ 0.1256, -0.1104, -0.1358,  ...,  0.3919, -0.4574, -0.1666],\n",
            "        [ 0.1256, -0.1104, -0.1358,  ...,  0.3919, -0.4574, -0.1666],\n",
            "        [ 0.1256, -0.1104, -0.1358,  ...,  0.3919, -0.4574, -0.1666]])\n",
            "Output of encoder at last step:tensor([[[ 0.1256, -0.1104, -0.1358,  ...,  0.3919, -0.4574, -0.1666],\n",
            "         [ 0.1256, -0.1104, -0.1358,  ...,  0.3919, -0.4574, -0.1666],\n",
            "         [ 0.1256, -0.1104, -0.1358,  ...,  0.3919, -0.4574, -0.1666],\n",
            "         ...,\n",
            "         [ 0.1256, -0.1104, -0.1358,  ...,  0.3919, -0.4574, -0.1666],\n",
            "         [ 0.1256, -0.1104, -0.1358,  ...,  0.3919, -0.4574, -0.1666],\n",
            "         [ 0.1256, -0.1104, -0.1358,  ...,  0.3919, -0.4574, -0.1666]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5315,  0.1991, -0.5002,  ...,  0.5438, -0.6362, -0.4418],\n",
            "        [ 0.5315,  0.1991, -0.5002,  ...,  0.5438, -0.6362, -0.4418],\n",
            "        [ 0.5315,  0.1991, -0.5002,  ...,  0.5438, -0.6362, -0.4418],\n",
            "        ...,\n",
            "        [ 0.5315,  0.1991, -0.5002,  ...,  0.5438, -0.6362, -0.4418],\n",
            "        [ 0.5315,  0.1991, -0.5002,  ...,  0.5438, -0.6362, -0.4418],\n",
            "        [ 0.5315,  0.1991, -0.5002,  ...,  0.5438, -0.6362, -0.4418]])\n",
            "\t Epoch: 6 | Train Loss: 0.170 | Train Acc: 94.93%\n",
            "\t Epoch: 6 | Val. Loss: 0.758 |  Val. Acc: 81.70% \n",
            "\n",
            "Output of encoder at every step:tensor([[ 0.0766,  0.0868,  0.0619,  ...,  0.0956, -0.0571, -0.1679],\n",
            "        [ 0.0011,  0.1542, -0.1303,  ...,  0.1413, -0.1827, -0.2127],\n",
            "        [-0.0676,  0.0188, -0.1207,  ...,  0.0603,  0.0715, -0.0704],\n",
            "        ...,\n",
            "        [ 0.1192,  0.4001, -0.2300,  ...,  0.2232, -0.0492, -0.1205],\n",
            "        [ 0.1365,  0.3874, -0.2277,  ...,  0.2202, -0.0441, -0.1134],\n",
            "        [ 0.0472, -0.1486, -0.0820,  ...,  0.0935, -0.2188, -0.2189]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0472, -0.1486, -0.0820,  ...,  0.0935, -0.2188, -0.2189],\n",
            "         [ 0.1163,  0.2189,  0.0156,  ...,  0.1063, -0.2932,  0.0207],\n",
            "         [-0.1060, -0.2806, -0.1052,  ...,  0.0224, -0.1955, -0.2027],\n",
            "         ...,\n",
            "         [ 0.0407, -0.3903,  0.0314,  ...,  0.1357, -0.2310, -0.1263],\n",
            "         [ 0.1192,  0.4001, -0.2300,  ...,  0.2232, -0.0492, -0.1205],\n",
            "         [ 0.1365,  0.3874, -0.2277,  ...,  0.2202, -0.0441, -0.1134]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4520,  0.0119, -0.4207,  ...,  0.4074, -0.5757, -0.3802],\n",
            "        [ 0.3786,  0.1812, -0.3008,  ...,  0.3002, -0.4638, -0.1685],\n",
            "        [ 0.1072,  0.0148, -0.3018,  ...,  0.2219, -0.3455, -0.2676],\n",
            "        ...,\n",
            "        [ 0.2051, -0.0979, -0.1773,  ...,  0.1910, -0.2766, -0.1765],\n",
            "        [-0.0639,  0.5441, -0.1016,  ...,  0.0199,  0.0222,  0.0722],\n",
            "        [-0.0539,  0.5224, -0.0894,  ...,  0.0077,  0.0287,  0.0777]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0317, -0.0153, -0.1595,  ...,  0.0590,  0.0054,  0.1382],\n",
            "        [ 0.1034,  0.1224, -0.0238,  ...,  0.0762,  0.0110, -0.0729],\n",
            "        [ 0.0917,  0.0764, -0.1492,  ...,  0.0753,  0.0933,  0.0605],\n",
            "        ...,\n",
            "        [ 0.0631, -0.1925,  0.0893,  ..., -0.1253, -0.0749,  0.1718],\n",
            "        [ 0.0685,  0.0595, -0.0083,  ...,  0.0975, -0.1381,  0.0604],\n",
            "        [ 0.1957, -0.1298,  0.0810,  ...,  0.2624, -0.1422, -0.0276]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1721, -0.1903, -0.0169,  ..., -0.0593, -0.0795,  0.1228],\n",
            "         [ 0.0166, -0.0947, -0.0504,  ...,  0.0783, -0.1936, -0.1424],\n",
            "         [ 0.0122,  0.2372, -0.0085,  ...,  0.0848, -0.1145, -0.1809],\n",
            "         ...,\n",
            "         [-0.0821, -0.0867,  0.0201,  ...,  0.0831,  0.0485,  0.0942],\n",
            "         [ 0.0657,  0.1270,  0.0869,  ...,  0.3886, -0.2500, -0.1530],\n",
            "         [ 0.1476, -0.0214,  0.1985,  ...,  0.2097, -0.3127,  0.1454]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4513,  0.1289, -0.3943,  ...,  0.2777, -0.4682, -0.1742],\n",
            "        [ 0.3873,  0.0099, -0.3204,  ...,  0.3333, -0.4803, -0.3493],\n",
            "        [-0.0741,  0.3098,  0.0503,  ...,  0.0168,  0.0737,  0.1659],\n",
            "        ...,\n",
            "        [ 0.0241,  0.1004, -0.1661,  ...,  0.1348, -0.0975,  0.0393],\n",
            "        [ 0.2590,  0.2839, -0.2333,  ...,  0.4000, -0.3697, -0.1864],\n",
            "        [ 0.3064,  0.2095, -0.1432,  ...,  0.3317, -0.4077,  0.0289]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0459, -0.0180,  0.0740,  ...,  0.0871,  0.0264,  0.2066],\n",
            "        [ 0.1042,  0.1226, -0.0239,  ...,  0.0755,  0.0116, -0.0727],\n",
            "        [ 0.1042,  0.1226, -0.0239,  ...,  0.0755,  0.0116, -0.0727],\n",
            "        ...,\n",
            "        [ 0.1539, -0.1073, -0.0208,  ...,  0.2696, -0.3080, -0.1021],\n",
            "        [ 0.1125, -0.2654, -0.2380,  ...,  0.1155, -0.1454, -0.0814],\n",
            "        [ 0.2241, -0.0077, -0.1542,  ...,  0.1225, -0.1333,  0.0531]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0337, -0.3229, -0.2719,  ...,  0.1872, -0.3599, -0.1776],\n",
            "         [-0.0367, -0.1581,  0.1000,  ...,  0.2976, -0.3229, -0.0237],\n",
            "         [-0.0730,  0.1689,  0.1922,  ...,  0.1272, -0.1067,  0.0920],\n",
            "         ...,\n",
            "         [ 0.0922,  0.2445, -0.0474,  ...,  0.1278, -0.0905, -0.0329],\n",
            "         [ 0.0554,  0.0318, -0.0449,  ...,  0.2183, -0.3375, -0.2464],\n",
            "         [-0.0036, -0.1120, -0.1104,  ..., -0.0683, -0.2103, -0.0261]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4031, -0.0422, -0.5213,  ...,  0.4911, -0.6491, -0.3203],\n",
            "        [ 0.2785,  0.0720, -0.2973,  ...,  0.4015, -0.4929, -0.2058],\n",
            "        [-0.0667,  0.2756,  0.0765,  ...,  0.0210, -0.0370,  0.1394],\n",
            "        ...,\n",
            "        [ 0.0433,  0.4829, -0.1235,  ...,  0.1136,  0.0357,  0.1473],\n",
            "        [ 0.5096,  0.1264, -0.4630,  ...,  0.4962, -0.6076, -0.4937],\n",
            "        [ 0.1899,  0.0564, -0.3345,  ...,  0.1885, -0.4213, -0.1182]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0202, -0.0872, -0.0080,  ..., -0.0478,  0.0528,  0.1174],\n",
            "        [ 0.0202, -0.0872, -0.0080,  ..., -0.0478,  0.0528,  0.1174],\n",
            "        [ 0.0895, -0.2842,  0.0069,  ..., -0.0076, -0.0484,  0.0042],\n",
            "        ...,\n",
            "        [-0.0888, -0.0380, -0.0628,  ...,  0.1189, -0.0303, -0.0612],\n",
            "        [ 0.0746, -0.1664,  0.0585,  ...,  0.1682, -0.1767, -0.1044],\n",
            "        [ 0.0882, -0.0341,  0.0149,  ..., -0.0035, -0.0534,  0.1203]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0204, -0.0022, -0.0609,  ..., -0.0745, -0.0468, -0.0477],\n",
            "         [ 0.0972,  0.3046,  0.0408,  ...,  0.3034, -0.0612, -0.1535],\n",
            "         [-0.0574,  0.2907,  0.1599,  ...,  0.0009,  0.1383,  0.1049],\n",
            "         ...,\n",
            "         [ 0.0649,  0.1174, -0.0861,  ...,  0.1080, -0.0619, -0.2991],\n",
            "         [ 0.2279, -0.1363, -0.2553,  ...,  0.1220, -0.2723,  0.0335],\n",
            "         [ 0.0719,  0.0498, -0.0112,  ...,  0.0981, -0.1457,  0.0499]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0364, -0.0718,  0.0823,  ..., -0.1454,  0.0323,  0.0223],\n",
            "        [-0.1823,  0.6399, -0.1524,  ...,  0.2366,  0.1582,  0.2672],\n",
            "        [-0.0887,  0.1905,  0.1589,  ..., -0.0404,  0.1275,  0.0873],\n",
            "        ...,\n",
            "        [ 0.3094,  0.2398, -0.2781,  ...,  0.3101, -0.2816, -0.2925],\n",
            "        [ 0.5571,  0.1039, -0.5095,  ...,  0.4247, -0.5714, -0.2842],\n",
            "        [ 0.1163,  0.1760, -0.0651,  ...,  0.1445, -0.0609,  0.0506]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0203, -0.0871, -0.0081,  ..., -0.0479,  0.0528,  0.1173],\n",
            "        [ 0.0458,  0.0646,  0.0200,  ..., -0.0211, -0.2107, -0.0853],\n",
            "        [ 0.1040, -0.2174,  0.0781,  ..., -0.0619, -0.2338,  0.2208],\n",
            "        ...,\n",
            "        [ 0.3868,  0.0954, -0.0338,  ...,  0.3572, -0.3093, -0.3822],\n",
            "        [ 0.1909, -0.0044,  0.1113,  ...,  0.3528, -0.1043,  0.0711],\n",
            "        [ 0.1134,  0.1410, -0.0976,  ..., -0.0516, -0.2342, -0.0322]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0038,  0.2297, -0.0208,  ...,  0.0554,  0.0813,  0.0848],\n",
            "         [ 0.2098, -0.2304, -0.0766,  ...,  0.1123, -0.2348, -0.1229],\n",
            "         [-0.0417, -0.3970, -0.0077,  ...,  0.1946, -0.0196,  0.0217],\n",
            "         ...,\n",
            "         [ 0.3868,  0.0954, -0.0338,  ...,  0.3572, -0.3093, -0.3822],\n",
            "         [ 0.1909, -0.0044,  0.1113,  ...,  0.3528, -0.1043,  0.0711],\n",
            "         [ 0.1134,  0.1410, -0.0976,  ..., -0.0516, -0.2342, -0.0322]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0228,  0.1393,  0.0950,  ..., -0.0688,  0.1707,  0.1500],\n",
            "        [ 0.6314,  0.0618, -0.4951,  ...,  0.3503, -0.5676, -0.3632],\n",
            "        [ 0.2487, -0.0176, -0.3821,  ...,  0.3926, -0.3098, -0.2368],\n",
            "        ...,\n",
            "        [ 0.4410,  0.2656, -0.3163,  ...,  0.3389, -0.4741, -0.4313],\n",
            "        [ 0.0201,  0.2478, -0.0998,  ...,  0.2126, -0.1084,  0.0829],\n",
            "        [ 0.3554,  0.1845, -0.2951,  ...,  0.2138, -0.3797, -0.2481]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0169,  0.0320,  0.2177,  ..., -0.0763,  0.0264,  0.0823],\n",
            "        [ 0.1066,  0.1239, -0.0245,  ...,  0.0743,  0.0127, -0.0721],\n",
            "        [ 0.1066,  0.1239, -0.0245,  ...,  0.0743,  0.0127, -0.0721],\n",
            "        ...,\n",
            "        [ 0.0625,  0.0914,  0.1833,  ..., -0.0170, -0.0788,  0.0610],\n",
            "        [ 0.1241,  0.1460, -0.1151,  ..., -0.0246, -0.0994, -0.1735],\n",
            "        [ 0.3868,  0.1159,  0.0071,  ...,  0.3475, -0.2206, -0.3215]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0625,  0.0914,  0.1833,  ..., -0.0170, -0.0788,  0.0610],\n",
            "         [ 0.1241,  0.1460, -0.1151,  ..., -0.0246, -0.0994, -0.1735],\n",
            "         [ 0.3868,  0.1159,  0.0071,  ...,  0.3475, -0.2206, -0.3215],\n",
            "         ...,\n",
            "         [-0.0722,  0.1869,  0.1196,  ...,  0.0135, -0.0817, -0.3357],\n",
            "         [ 0.1040,  0.0214,  0.0707,  ...,  0.1136, -0.0355,  0.0704],\n",
            "         [ 0.1698, -0.1152,  0.0327,  ..., -0.0266,  0.1475,  0.0297]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 1.3356e-01,  1.2837e-01, -3.3715e-02,  ...,  1.6353e-01,\n",
            "         -1.7114e-01, -1.8475e-02],\n",
            "        [ 1.4206e-01,  1.8674e-01, -2.0791e-01,  ...,  8.3342e-02,\n",
            "         -1.9434e-01, -9.8336e-02],\n",
            "        [ 2.6806e-01,  2.6690e-01, -1.5978e-01,  ...,  1.9411e-01,\n",
            "         -2.7788e-01, -2.3462e-01],\n",
            "        ...,\n",
            "        [ 5.2918e-02,  1.1958e-01, -7.4856e-02,  ...,  1.5246e-01,\n",
            "         -1.8273e-01, -2.0647e-01],\n",
            "        [ 1.0260e-01,  5.4949e-02, -3.7451e-02,  ...,  1.5779e-01,\n",
            "         -1.0073e-01,  1.6654e-02],\n",
            "        [ 1.2153e-01, -6.7064e-05, -6.3901e-02,  ...,  5.4077e-02,\n",
            "         -2.5555e-02, -4.1941e-02]], grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0727,  0.1414, -0.1892,  ..., -0.0208, -0.2196,  0.1247],\n",
            "        [-0.1010, -0.0131,  0.0133,  ...,  0.0731, -0.0363, -0.1210],\n",
            "        [ 0.1386,  0.0877, -0.1298,  ...,  0.1056, -0.1054, -0.0698],\n",
            "        ...,\n",
            "        [ 0.0812,  0.2966, -0.0450,  ...,  0.0311, -0.1056,  0.0361],\n",
            "        [ 0.0414,  0.2778, -0.0388,  ...,  0.0631,  0.0806,  0.0038],\n",
            "        [-0.1505,  0.0588,  0.1134,  ...,  0.0432,  0.1252,  0.0954]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1954,  0.1892,  0.1102,  ...,  0.2666, -0.1183, -0.1618],\n",
            "         [ 0.2308, -0.0355, -0.2502,  ...,  0.1375, -0.3292,  0.0499],\n",
            "         [ 0.2306, -0.0353, -0.2497,  ...,  0.1373, -0.3289,  0.0500],\n",
            "         ...,\n",
            "         [ 0.0812,  0.2966, -0.0450,  ...,  0.0311, -0.1056,  0.0361],\n",
            "         [ 0.0414,  0.2778, -0.0388,  ...,  0.0631,  0.0806,  0.0038],\n",
            "         [-0.1505,  0.0588,  0.1134,  ...,  0.0432,  0.1252,  0.0954]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3607,  0.2771, -0.1941,  ...,  0.2880, -0.3376, -0.2702],\n",
            "        [ 0.6152,  0.2070, -0.5503,  ...,  0.4718, -0.6433, -0.2589],\n",
            "        [ 0.6141,  0.2074, -0.5496,  ...,  0.4712, -0.6425, -0.2576],\n",
            "        ...,\n",
            "        [-0.0554,  0.5442, -0.0838,  ...,  0.0907,  0.0843,  0.3276],\n",
            "        [-0.0988,  0.4698,  0.0299,  ..., -0.0412,  0.2508,  0.2646],\n",
            "        [-0.1531,  0.1649,  0.0134,  ...,  0.0088,  0.1420,  0.1755]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2487, -0.0520,  0.0256,  ...,  0.2518, -0.1818, -0.1812],\n",
            "        [ 0.0206, -0.0869, -0.0086,  ..., -0.0478,  0.0526,  0.1170],\n",
            "        [ 0.2487, -0.0520,  0.0256,  ...,  0.2518, -0.1818, -0.1812],\n",
            "        ...,\n",
            "        [ 0.0893, -0.0402,  0.0068,  ..., -0.0477, -0.1355, -0.0421],\n",
            "        [ 0.0705,  0.0636,  0.2816,  ...,  0.0873,  0.0158,  0.1391],\n",
            "        [ 0.0118,  0.3037, -0.2990,  ...,  0.3075, -0.3132, -0.0274]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1864,  0.4701, -0.2511,  ...,  0.2305, -0.0737, -0.1285],\n",
            "         [ 0.1708,  0.0853, -0.1425,  ...,  0.0345, -0.0708, -0.1758],\n",
            "         [ 0.0355,  0.1326, -0.0402,  ...,  0.0884,  0.0565, -0.1147],\n",
            "         ...,\n",
            "         [ 0.1175,  0.3237,  0.0372,  ...,  0.3154, -0.0830, -0.1648],\n",
            "         [ 0.0320, -0.1491, -0.0216,  ...,  0.0338, -0.2625, -0.1530],\n",
            "         [ 0.1458, -0.1335,  0.1081,  ...,  0.0807, -0.1847,  0.0882]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0336,  0.6328, -0.2088,  ...,  0.1059, -0.0469,  0.0500],\n",
            "        [ 0.6112,  0.2655, -0.5325,  ...,  0.3245, -0.5265, -0.4629],\n",
            "        [ 0.0157, -0.0506,  0.0888,  ..., -0.0755,  0.1001,  0.0122],\n",
            "        ...,\n",
            "        [-0.1847,  0.6763, -0.2019,  ...,  0.2865,  0.1311,  0.2813],\n",
            "        [ 0.4020, -0.0011, -0.3213,  ...,  0.2895, -0.4800, -0.3496],\n",
            "        [ 0.4089,  0.1502, -0.3270,  ...,  0.3437, -0.4541, -0.1234]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0207, -0.0868, -0.0088,  ..., -0.0477,  0.0525,  0.1169],\n",
            "        [ 0.0207, -0.0868, -0.0088,  ..., -0.0477,  0.0525,  0.1169],\n",
            "        [-0.0657,  0.0220, -0.1242,  ...,  0.0614,  0.0709, -0.0706],\n",
            "        ...,\n",
            "        [ 0.1157,  0.4734, -0.0717,  ...,  0.2146, -0.0271, -0.2402],\n",
            "        [ 0.3203,  0.1779, -0.1463,  ..., -0.0060, -0.1416, -0.3499],\n",
            "        [ 0.0486,  0.1544,  0.1026,  ...,  0.2034, -0.1876, -0.0939]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2327,  0.3494,  0.0961,  ...,  0.1461, -0.0463, -0.0442],\n",
            "         [ 0.1157,  0.4734, -0.0717,  ...,  0.2146, -0.0271, -0.2402],\n",
            "         [ 0.3203,  0.1779, -0.1463,  ..., -0.0060, -0.1416, -0.3499],\n",
            "         ...,\n",
            "         [ 0.1231,  0.0600,  0.0446,  ...,  0.1871, -0.0417, -0.0468],\n",
            "         [ 0.1747,  0.1333, -0.1006,  ..., -0.0476, -0.1193, -0.1040],\n",
            "         [ 0.0595, -0.0838, -0.0924,  ...,  0.0953, -0.1875,  0.0452]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2798,  0.3197, -0.0996,  ...,  0.2174, -0.1787, -0.1236],\n",
            "        [ 0.0066,  0.2327,  0.0220,  ...,  0.0193, -0.0619, -0.0933],\n",
            "        [ 0.6406,  0.3859, -0.4639,  ...,  0.3228, -0.4780, -0.5055],\n",
            "        ...,\n",
            "        [ 0.0362,  0.3390, -0.1267,  ...,  0.1855, -0.0748,  0.0308],\n",
            "        [ 0.2507,  0.2402, -0.2636,  ...,  0.1286, -0.2508, -0.1097],\n",
            "        [ 0.1320,  0.0496, -0.1445,  ...,  0.1966, -0.2374, -0.0468]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0798, -0.0971,  0.0511,  ...,  0.0740, -0.0630,  0.0792],\n",
            "        [ 0.0211, -0.0867, -0.0091,  ..., -0.0477,  0.0524,  0.1167],\n",
            "        [ 0.2520, -0.0538,  0.0246,  ...,  0.2502, -0.1820, -0.1815],\n",
            "        ...,\n",
            "        [ 0.0008,  0.2285, -0.1905,  ...,  0.2130,  0.0700, -0.0755],\n",
            "        [ 0.0262, -0.2078, -0.0481,  ..., -0.0810,  0.0172, -0.0267],\n",
            "        [ 0.0415,  0.2909,  0.0405,  ...,  0.1188, -0.1702, -0.0764]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1001,  0.3856, -0.1755,  ...,  0.1000, -0.2686, -0.0098],\n",
            "         [ 0.3308, -0.2117, -0.1175,  ..., -0.0814, -0.3072, -0.1838],\n",
            "         [ 0.2079, -0.1486, -0.2983,  ...,  0.2368, -0.1157, -0.1024],\n",
            "         ...,\n",
            "         [ 0.2252,  0.1245,  0.0818,  ...,  0.3081, -0.4370, -0.1504],\n",
            "         [ 0.1363, -0.0130, -0.0811,  ...,  0.0693, -0.0054,  0.1995],\n",
            "         [-0.1402, -0.0196, -0.0817,  ...,  0.2651, -0.2040, -0.0036]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3108,  0.3105, -0.3435,  ...,  0.1903, -0.3509, -0.1872],\n",
            "        [ 0.6147, -0.0149, -0.4352,  ...,  0.2752, -0.5958, -0.4424],\n",
            "        [ 0.4413,  0.0370, -0.4256,  ...,  0.3256, -0.4576, -0.3035],\n",
            "        ...,\n",
            "        [ 0.6353,  0.3061, -0.4271,  ...,  0.5483, -0.6815, -0.5100],\n",
            "        [-0.0307,  0.1132, -0.1041,  ...,  0.0386,  0.0056,  0.2150],\n",
            "        [ 0.2125,  0.2051, -0.3915,  ...,  0.4050, -0.4445, -0.1985]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0214, -0.0868, -0.0094,  ..., -0.0476,  0.0523,  0.1165],\n",
            "        [ 0.0214, -0.0868, -0.0094,  ..., -0.0476,  0.0523,  0.1165],\n",
            "        [ 0.0214, -0.0868, -0.0094,  ..., -0.0476,  0.0523,  0.1165],\n",
            "        ...,\n",
            "        [-0.0418,  0.0508,  0.3093,  ...,  0.0798, -0.1036,  0.0050],\n",
            "        [ 0.1529, -0.1307, -0.1952,  ...,  0.4097, -0.5023, -0.2157],\n",
            "        [ 0.1529, -0.1307, -0.1952,  ...,  0.4097, -0.5023, -0.2157]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1529, -0.1307, -0.1952,  ...,  0.4097, -0.5023, -0.2157],\n",
            "         [ 0.1529, -0.1307, -0.1952,  ...,  0.4097, -0.5023, -0.2157],\n",
            "         [-0.0418,  0.0508,  0.3093,  ...,  0.0798, -0.1036,  0.0050],\n",
            "         ...,\n",
            "         [ 0.1904,  0.0182, -0.1570,  ...,  0.2369, -0.1964,  0.0512],\n",
            "         [ 0.1279,  0.1743, -0.1150,  ...,  0.0654, -0.2912, -0.2153],\n",
            "         [ 0.1904,  0.0182, -0.1570,  ...,  0.2369, -0.1964,  0.0512]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6500,  0.2011, -0.5837,  ...,  0.6098, -0.7247, -0.5627],\n",
            "        [ 0.6500,  0.2011, -0.5837,  ...,  0.6098, -0.7247, -0.5627],\n",
            "        [ 0.1887,  0.2200, -0.1277,  ...,  0.3199, -0.3315, -0.2085],\n",
            "        ...,\n",
            "        [ 0.6254,  0.1441, -0.5384,  ...,  0.5459, -0.6011, -0.3401],\n",
            "        [ 0.7168,  0.2059, -0.6246,  ...,  0.5406, -0.7738, -0.5813],\n",
            "        [ 0.6254,  0.1441, -0.5384,  ...,  0.5459, -0.6011, -0.3401]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0218, -0.0868, -0.0098,  ..., -0.0476,  0.0522,  0.1163],\n",
            "        [ 0.0218, -0.0868, -0.0098,  ..., -0.0476,  0.0522,  0.1163],\n",
            "        [ 0.0218, -0.0868, -0.0098,  ..., -0.0476,  0.0522,  0.1163],\n",
            "        ...,\n",
            "        [ 0.1568, -0.1367, -0.1998,  ...,  0.4098, -0.5052, -0.2188],\n",
            "        [ 0.1568, -0.1367, -0.1998,  ...,  0.4098, -0.5052, -0.2188],\n",
            "        [ 0.1568, -0.1367, -0.1998,  ...,  0.4098, -0.5052, -0.2188]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1568, -0.1367, -0.1998,  ...,  0.4098, -0.5052, -0.2188],\n",
            "         [ 0.1568, -0.1367, -0.1998,  ...,  0.4098, -0.5052, -0.2188],\n",
            "         [ 0.1568, -0.1367, -0.1998,  ...,  0.4098, -0.5052, -0.2188],\n",
            "         ...,\n",
            "         [ 0.1568, -0.1367, -0.1998,  ...,  0.4098, -0.5052, -0.2188],\n",
            "         [ 0.1568, -0.1367, -0.1998,  ...,  0.4098, -0.5052, -0.2188],\n",
            "         [ 0.1568, -0.1367, -0.1998,  ...,  0.4098, -0.5052, -0.2188]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6608,  0.1990, -0.5907,  ...,  0.6155, -0.7323, -0.5733],\n",
            "        [ 0.6608,  0.1990, -0.5907,  ...,  0.6155, -0.7323, -0.5733],\n",
            "        [ 0.6608,  0.1990, -0.5907,  ...,  0.6155, -0.7323, -0.5733],\n",
            "        ...,\n",
            "        [ 0.6608,  0.1990, -0.5907,  ...,  0.6155, -0.7323, -0.5733],\n",
            "        [ 0.6608,  0.1990, -0.5907,  ...,  0.6155, -0.7323, -0.5733],\n",
            "        [ 0.6608,  0.1990, -0.5907,  ...,  0.6155, -0.7323, -0.5733]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0222, -0.0869, -0.0102,  ..., -0.0476,  0.0521,  0.1162],\n",
            "        [ 0.0222, -0.0869, -0.0102,  ..., -0.0476,  0.0521,  0.1162],\n",
            "        [ 0.0222, -0.0869, -0.0102,  ..., -0.0476,  0.0521,  0.1162],\n",
            "        ...,\n",
            "        [ 0.0484, -0.1355,  0.1502,  ..., -0.0619, -0.1361,  0.0193],\n",
            "        [ 0.1239, -0.2499, -0.2246,  ..., -0.0552, -0.2341,  0.0111],\n",
            "        [ 0.2720, -0.1315, -0.3530,  ..., -0.0263, -0.3235, -0.0638]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1239, -0.2499, -0.2246,  ..., -0.0552, -0.2341,  0.0111],\n",
            "         [ 0.2720, -0.1315, -0.3530,  ..., -0.0263, -0.3235, -0.0638],\n",
            "         [ 0.3380, -0.4881, -0.2653,  ...,  0.1520, -0.3344, -0.1093],\n",
            "         ...,\n",
            "         [ 0.0971,  0.2423, -0.0940,  ...,  0.1178, -0.2033, -0.2328],\n",
            "         [ 0.0508,  0.3181, -0.1273,  ...,  0.3603,  0.0307, -0.0706],\n",
            "         [ 0.0484, -0.1355,  0.1502,  ..., -0.0619, -0.1361,  0.0193]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4941, -0.1852, -0.2788,  ...,  0.1164, -0.4014, -0.2773],\n",
            "        [ 0.6731,  0.1326, -0.5756,  ...,  0.3787, -0.6679, -0.4670],\n",
            "        [ 0.6809, -0.0645, -0.5751,  ...,  0.4394, -0.6098, -0.4495],\n",
            "        ...,\n",
            "        [ 0.5735,  0.2654, -0.5442,  ...,  0.5363, -0.6460, -0.5164],\n",
            "        [-0.1959,  0.5559, -0.1067,  ...,  0.2635,  0.1966,  0.2864],\n",
            "        [ 0.0127, -0.0982,  0.1566,  ..., -0.1204, -0.0037,  0.0347]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0511,  0.0091,  0.0874,  ...,  0.1707, -0.0242,  0.0752],\n",
            "        [ 0.0225, -0.0869, -0.0105,  ..., -0.0475,  0.0520,  0.1161],\n",
            "        [ 0.0225, -0.0869, -0.0105,  ..., -0.0475,  0.0520,  0.1161],\n",
            "        ...,\n",
            "        [ 0.0661,  0.4091, -0.0824,  ...,  0.0695,  0.0025, -0.0618],\n",
            "        [ 0.0661,  0.4091, -0.0824,  ...,  0.0695,  0.0025, -0.0618],\n",
            "        [ 0.1525,  0.0522, -0.1096,  ..., -0.0307, -0.0827, -0.0682]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 2.4572e-01,  1.5195e-01, -9.7243e-02,  ...,  1.8908e-01,\n",
            "          -1.7065e-01, -3.1843e-01],\n",
            "         [ 1.0875e-01,  9.7974e-03,  1.6786e-01,  ..., -7.6370e-02,\n",
            "          -7.8600e-02,  2.8495e-02],\n",
            "         [-2.2570e-03,  4.4967e-01,  4.2608e-04,  ...,  9.3409e-02,\n",
            "           5.8044e-02,  1.1906e-01],\n",
            "         ...,\n",
            "         [ 3.9965e-02,  2.7796e-01,  2.2382e-01,  ...,  3.9577e-02,\n",
            "           6.8621e-02,  2.5837e-01],\n",
            "         [-2.9343e-02,  2.1615e-01,  3.6626e-02,  ...,  1.2195e-01,\n",
            "          -3.4949e-03, -5.1057e-02],\n",
            "         [ 1.0466e-01,  2.4833e-01, -1.8430e-02,  ...,  2.8868e-01,\n",
            "          -1.1014e-01,  3.8381e-02]]], grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4725,  0.2823, -0.3838,  ...,  0.4384, -0.4940, -0.4140],\n",
            "        [ 0.4246,  0.0852, -0.1698,  ...,  0.2276, -0.3451, -0.2411],\n",
            "        [-0.1623,  0.6845,  0.0540,  ..., -0.0366,  0.2285,  0.4226],\n",
            "        ...,\n",
            "        [-0.1397,  0.5550,  0.1452,  ...,  0.0753,  0.2264,  0.4007],\n",
            "        [-0.0823,  0.2113,  0.0618,  ..., -0.0266,  0.0804,  0.1358],\n",
            "        [ 0.0786,  0.4244, -0.2293,  ...,  0.2202, -0.1182,  0.1230]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 2.2845e-02, -8.6878e-02, -1.0851e-02,  ..., -4.7408e-02,\n",
            "          5.1860e-02,  1.1586e-01],\n",
            "        [ 1.4807e-01, -1.1230e-01, -3.3173e-02,  ..., -7.6582e-02,\n",
            "         -9.2366e-02,  4.6431e-02],\n",
            "        [-2.3839e-02,  4.4058e-03, -1.4618e-01,  ..., -7.5286e-02,\n",
            "          3.3460e-03, -1.8053e-03],\n",
            "        ...,\n",
            "        [ 2.6231e-01,  5.3549e-01,  1.6557e-01,  ...,  2.0908e-01,\n",
            "         -4.4519e-01,  6.3358e-02],\n",
            "        [ 9.8586e-02,  5.6337e-02, -1.4089e-01,  ...,  1.4043e-01,\n",
            "         -2.0671e-01, -1.5644e-01],\n",
            "        [-1.4217e-01, -3.8053e-01, -2.7087e-01,  ...,  2.3307e-01,\n",
            "         -2.6284e-01, -1.5892e-05]], grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 1.8566e-01,  3.7967e-01, -2.7703e-01,  ...,  3.7193e-01,\n",
            "          -2.6950e-01, -1.8734e-01],\n",
            "         [ 1.0682e-02,  2.7510e-01, -6.9633e-02,  ...,  8.5472e-02,\n",
            "          -7.8481e-02,  2.2895e-02],\n",
            "         [ 4.9308e-02, -1.6278e-01, -1.1204e-01,  ...,  4.0623e-02,\n",
            "          -1.1225e-01,  6.7886e-02],\n",
            "         ...,\n",
            "         [ 2.6231e-01,  5.3549e-01,  1.6557e-01,  ...,  2.0908e-01,\n",
            "          -4.4519e-01,  6.3358e-02],\n",
            "         [ 9.8586e-02,  5.6337e-02, -1.4089e-01,  ...,  1.4043e-01,\n",
            "          -2.0671e-01, -1.5644e-01],\n",
            "         [-1.4217e-01, -3.8053e-01, -2.7087e-01,  ...,  2.3307e-01,\n",
            "          -2.6284e-01, -1.5892e-05]]], grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5374,  0.4794, -0.4682,  ...,  0.4172, -0.5340, -0.3811],\n",
            "        [ 0.4926,  0.2125, -0.4839,  ...,  0.4741, -0.5410, -0.3885],\n",
            "        [ 0.0857,  0.0560, -0.1925,  ...,  0.2138, -0.1968,  0.0018],\n",
            "        ...,\n",
            "        [ 0.0228,  0.7072, -0.1859,  ...,  0.3059, -0.2457,  0.2740],\n",
            "        [ 0.6350,  0.2388, -0.5907,  ...,  0.5574, -0.6760, -0.5371],\n",
            "        [ 0.1195,  0.0122, -0.4198,  ...,  0.3589, -0.4085, -0.2103]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0232, -0.0868, -0.0112,  ..., -0.0473,  0.0517,  0.1157],\n",
            "        [ 0.0232, -0.0868, -0.0112,  ..., -0.0473,  0.0517,  0.1157],\n",
            "        [ 0.0232, -0.0868, -0.0112,  ..., -0.0473,  0.0517,  0.1157],\n",
            "        ...,\n",
            "        [ 0.1655, -0.1526, -0.2045,  ...,  0.4073, -0.5094, -0.2212],\n",
            "        [ 0.1655, -0.1526, -0.2045,  ...,  0.4073, -0.5094, -0.2212],\n",
            "        [ 0.1655, -0.1526, -0.2045,  ...,  0.4073, -0.5094, -0.2212]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1655, -0.1526, -0.2045,  ...,  0.4073, -0.5094, -0.2212],\n",
            "         [ 0.1655, -0.1526, -0.2045,  ...,  0.4073, -0.5094, -0.2212],\n",
            "         [ 0.1655, -0.1526, -0.2045,  ...,  0.4073, -0.5094, -0.2212],\n",
            "         ...,\n",
            "         [ 0.1655, -0.1526, -0.2045,  ...,  0.4073, -0.5094, -0.2212],\n",
            "         [ 0.1655, -0.1526, -0.2045,  ...,  0.4073, -0.5094, -0.2212],\n",
            "         [ 0.1655, -0.1526, -0.2045,  ...,  0.4073, -0.5094, -0.2212]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6820,  0.1892, -0.6008,  ...,  0.6241, -0.7458, -0.5941],\n",
            "        [ 0.6820,  0.1892, -0.6008,  ...,  0.6241, -0.7458, -0.5941],\n",
            "        [ 0.6820,  0.1892, -0.6008,  ...,  0.6241, -0.7458, -0.5941],\n",
            "        ...,\n",
            "        [ 0.6820,  0.1892, -0.6008,  ...,  0.6241, -0.7458, -0.5941],\n",
            "        [ 0.6820,  0.1892, -0.6008,  ...,  0.6241, -0.7458, -0.5941],\n",
            "        [ 0.6820,  0.1892, -0.6008,  ...,  0.6241, -0.7458, -0.5941]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0141,  0.0313,  0.2226,  ..., -0.0771,  0.0286,  0.0845],\n",
            "        [ 0.1123,  0.1354, -0.0348,  ...,  0.0816,  0.0005, -0.0789],\n",
            "        [ 0.0235, -0.0868, -0.0114,  ..., -0.0473,  0.0516,  0.1155],\n",
            "        ...,\n",
            "        [ 0.1579,  0.2175, -0.1203,  ...,  0.0019, -0.0292,  0.0489],\n",
            "        [ 0.0102, -0.1266,  0.2862,  ..., -0.1385, -0.0606,  0.1419],\n",
            "        [ 0.0590,  0.1461, -0.0680,  ...,  0.0785,  0.0169,  0.1287]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 1.0240e-02, -1.2662e-01,  2.8618e-01,  ..., -1.3845e-01,\n",
            "          -6.0649e-02,  1.4189e-01],\n",
            "         [ 5.8993e-02,  1.4611e-01, -6.8035e-02,  ...,  7.8547e-02,\n",
            "           1.6934e-02,  1.2870e-01],\n",
            "         [ 1.3201e-01, -2.6648e-01, -2.3989e-01,  ..., -5.1025e-02,\n",
            "          -2.4943e-01,  5.8040e-03],\n",
            "         ...,\n",
            "         [ 1.1425e-02,  7.3196e-02, -3.1981e-01,  ...,  1.5362e-01,\n",
            "          -2.1391e-01, -1.0984e-01],\n",
            "         [ 1.2352e-01, -2.1950e-01, -2.6692e-01,  ..., -1.9902e-05,\n",
            "          -2.8528e-01, -3.4155e-02],\n",
            "         [ 1.5790e-01,  2.1753e-01, -1.2029e-01,  ...,  1.9393e-03,\n",
            "          -2.9190e-02,  4.8938e-02]]], grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 3.4868e-01,  4.7304e-02, -1.6759e-01,  ...,  2.3410e-01,\n",
            "         -3.5321e-01, -1.7521e-01],\n",
            "        [-8.2946e-02,  4.4244e-01, -6.8241e-02,  ...,  5.6426e-02,\n",
            "          1.9925e-01,  3.6837e-01],\n",
            "        [ 5.4559e-01, -1.8685e-01, -3.2670e-01,  ...,  1.5744e-01,\n",
            "         -4.4980e-01, -3.1433e-01],\n",
            "        ...,\n",
            "        [ 1.8613e-01,  2.1614e-01, -4.8254e-01,  ...,  3.3798e-01,\n",
            "         -4.3179e-01, -1.6345e-01],\n",
            "        [ 5.8352e-01, -1.3995e-01, -4.0808e-01,  ...,  2.4768e-01,\n",
            "         -5.1479e-01, -3.6069e-01],\n",
            "        [ 6.0457e-02,  3.3062e-01, -1.5126e-01,  ...,  3.9180e-02,\n",
            "          1.0498e-04,  1.9788e-01]], grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1128,  0.1362, -0.0356,  ...,  0.0822, -0.0004, -0.0794],\n",
            "        [ 0.0238, -0.0868, -0.0117,  ..., -0.0472,  0.0515,  0.1154],\n",
            "        [ 0.0549,  0.0516,  0.0343,  ...,  0.1407, -0.2428,  0.0503],\n",
            "        ...,\n",
            "        [ 0.0410, -0.1576,  0.2533,  ..., -0.1040, -0.1606,  0.0602],\n",
            "        [ 0.0509, -0.0613, -0.0149,  ...,  0.2609,  0.1660, -0.0169],\n",
            "        [ 0.1182,  0.0022, -0.2639,  ...,  0.1143, -0.2581,  0.0064]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1321,  0.1119, -0.0911,  ...,  0.1500, -0.2728, -0.2859],\n",
            "         [ 0.0314, -0.0801,  0.0967,  ..., -0.0647,  0.0814,  0.0753],\n",
            "         [-0.0179,  0.0258,  0.2869,  ..., -0.0777,  0.2023,  0.2212],\n",
            "         ...,\n",
            "         [ 0.0410, -0.1576,  0.2533,  ..., -0.1040, -0.1606,  0.0602],\n",
            "         [ 0.0509, -0.0613, -0.0149,  ...,  0.2609,  0.1660, -0.0169],\n",
            "         [ 0.1182,  0.0022, -0.2639,  ...,  0.1143, -0.2581,  0.0064]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.7584,  0.2197, -0.6236,  ...,  0.6551, -0.8052, -0.6609],\n",
            "        [-0.0078, -0.0978,  0.1594,  ..., -0.1561,  0.0806,  0.0616],\n",
            "        [-0.0304, -0.1295,  0.2384,  ..., -0.1764,  0.1657,  0.1301],\n",
            "        ...,\n",
            "        [ 0.5401, -0.0476, -0.2854,  ...,  0.2401, -0.5559, -0.3140],\n",
            "        [ 0.0125, -0.0573,  0.0881,  ...,  0.0346,  0.0708,  0.0436],\n",
            "        [ 0.5118,  0.2110, -0.5119,  ...,  0.4302, -0.5734, -0.3651]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0241, -0.0746,  0.0728,  ...,  0.0030, -0.1703,  0.0013],\n",
            "        [ 0.0850,  0.0006, -0.1915,  ..., -0.1783, -0.1550,  0.0474],\n",
            "        [ 0.0436, -0.0661, -0.2014,  ..., -0.1075,  0.0557,  0.0397],\n",
            "        ...,\n",
            "        [ 0.2966, -0.0242, -0.0204,  ...,  0.2244, -0.1836, -0.1246],\n",
            "        [ 0.0009, -0.0723, -0.1861,  ...,  0.0814, -0.1655,  0.0458],\n",
            "        [ 0.4362, -0.1444, -0.0056,  ...,  0.2910, -0.2285, -0.2333]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0102,  0.6340, -0.1584,  ...,  0.2164, -0.1106, -0.0306],\n",
            "         [ 0.2625, -0.0357, -0.0880,  ...,  0.1191, -0.1943, -0.1761],\n",
            "         [ 0.1720, -0.0863, -0.0100,  ..., -0.1522, -0.3593, -0.2106],\n",
            "         ...,\n",
            "         [-0.0482, -0.3745, -0.2381,  ...,  0.3102, -0.0301, -0.0806],\n",
            "         [-0.0255, -0.1563, -0.1375,  ..., -0.2249, -0.1342, -0.0417],\n",
            "         [ 0.0711,  0.1027, -0.1546,  ...,  0.0511,  0.0167,  0.2617]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0558,  0.4441, -0.2634,  ...,  0.2305, -0.2171, -0.0331],\n",
            "        [ 0.4416,  0.1814, -0.3628,  ...,  0.3317, -0.4321, -0.2380],\n",
            "        [ 0.3984,  0.0412, -0.2894,  ...,  0.1818, -0.4866, -0.3704],\n",
            "        ...,\n",
            "        [ 0.1632, -0.0729, -0.3894,  ...,  0.3395, -0.2575, -0.2586],\n",
            "        [ 0.2280, -0.0178, -0.3219,  ...,  0.1219, -0.3156, -0.2130],\n",
            "        [-0.0328,  0.3260, -0.2047,  ...,  0.1550, -0.0059,  0.2626]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0243, -0.0866, -0.0119,  ..., -0.0472,  0.0513,  0.1149],\n",
            "        [ 0.0243, -0.0866, -0.0119,  ..., -0.0472,  0.0513,  0.1149],\n",
            "        [ 0.2643, -0.0639,  0.0218,  ...,  0.2397, -0.1785, -0.1811],\n",
            "        ...,\n",
            "        [-0.0599, -0.0128,  0.0170,  ...,  0.2544,  0.0347,  0.0478],\n",
            "        [ 0.0585, -0.3111, -0.0768,  ...,  0.1579, -0.2033,  0.0432],\n",
            "        [ 0.0416, -0.0103, -0.0820,  ...,  0.0890, -0.1314, -0.1853]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0608, -0.0175,  0.0076,  ...,  0.2281,  0.0353,  0.1459],\n",
            "         [ 0.2981, -0.2004,  0.0056,  ...,  0.2087, -0.1737,  0.0726],\n",
            "         [ 0.1574,  0.0237, -0.0885,  ...,  0.0183,  0.0814,  0.2212],\n",
            "         ...,\n",
            "         [ 0.0026,  0.1965,  0.3554,  ...,  0.0778,  0.0308,  0.2041],\n",
            "         [ 0.0086,  0.0168,  0.1529,  ..., -0.0635,  0.0321,  0.2266],\n",
            "         [ 0.0542,  0.1675, -0.1228,  ...,  0.0900, -0.2049, -0.2529]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0347,  0.1686, -0.0317,  ...,  0.0936,  0.1422,  0.2578],\n",
            "        [ 0.5827,  0.2776, -0.4165,  ...,  0.4549, -0.4625, -0.1578],\n",
            "        [ 0.0072, -0.0664,  0.0336,  ..., -0.0945,  0.0859,  0.1163],\n",
            "        ...,\n",
            "        [-0.0647,  0.3979,  0.1338,  ...,  0.2025,  0.0942,  0.2436],\n",
            "        [ 0.0821,  0.1565, -0.0253,  ...,  0.1250,  0.0161,  0.1147],\n",
            "        [ 0.5921,  0.1644, -0.5713,  ...,  0.4927, -0.6805, -0.5781]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1117,  0.1322, -0.0328,  ...,  0.0788,  0.0029, -0.0776],\n",
            "        [ 0.0245, -0.0866, -0.0120,  ..., -0.0472,  0.0513,  0.1147],\n",
            "        [ 0.0245, -0.0866, -0.0120,  ..., -0.0472,  0.0513,  0.1147],\n",
            "        ...,\n",
            "        [ 0.1162, -0.1462, -0.1337,  ...,  0.0514, -0.1526,  0.0066],\n",
            "        [ 0.1127, -0.3901, -0.1044,  ...,  0.1479, -0.0478, -0.0591],\n",
            "        [ 0.0176, -0.0287,  0.0779,  ...,  0.2699, -0.1267,  0.1774]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0289,  0.0652,  0.1174,  ..., -0.0912,  0.1512,  0.0667],\n",
            "         [ 0.0644, -0.2154, -0.1285,  ..., -0.0478, -0.0350,  0.0935],\n",
            "         [ 0.0041,  0.0790, -0.3075,  ...,  0.1433, -0.2037, -0.0959],\n",
            "         ...,\n",
            "         [ 0.1162, -0.1462, -0.1337,  ...,  0.0514, -0.1526,  0.0066],\n",
            "         [ 0.1127, -0.3901, -0.1044,  ...,  0.1479, -0.0478, -0.0591],\n",
            "         [ 0.0176, -0.0287,  0.0779,  ...,  0.2699, -0.1267,  0.1774]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0185, -0.1093,  0.1857,  ..., -0.1475,  0.0981,  0.1008],\n",
            "        [ 0.1099, -0.1929,  0.0614,  ..., -0.1058, -0.0166,  0.0173],\n",
            "        [ 0.1323,  0.2046, -0.4352,  ...,  0.3066, -0.3777, -0.1160],\n",
            "        ...,\n",
            "        [ 0.2833, -0.0533, -0.0838,  ...,  0.0972, -0.1491, -0.0616],\n",
            "        [ 0.4629, -0.1695, -0.3733,  ...,  0.3370, -0.3313, -0.2806],\n",
            "        [-0.0051,  0.0243,  0.0455,  ...,  0.0858, -0.0267,  0.2043]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0671,  0.0253, -0.1230,  ...,  0.0625,  0.0712, -0.0697],\n",
            "        [ 0.0248, -0.0867, -0.0120,  ..., -0.0473,  0.0512,  0.1145],\n",
            "        [ 0.0105,  0.0283,  0.0218,  ..., -0.0375,  0.1440, -0.0819],\n",
            "        ...,\n",
            "        [ 0.0580,  0.0321, -0.0275,  ...,  0.0791,  0.0053, -0.1719],\n",
            "        [ 0.0089,  0.4243, -0.0057,  ...,  0.0419,  0.0625,  0.2318],\n",
            "        [ 0.0089,  0.4243, -0.0057,  ...,  0.0419,  0.0625,  0.2318]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0208,  0.2409, -0.0929,  ...,  0.1027, -0.1457, -0.1394],\n",
            "         [ 0.0405,  0.3151, -0.0356,  ...,  0.0667,  0.0911,  0.0201],\n",
            "         [ 0.4014, -0.0608, -0.0676,  ..., -0.1324, -0.3854, -0.1509],\n",
            "         ...,\n",
            "         [ 0.2585, -0.0708, -0.1260,  ...,  0.2967, -0.1443, -0.2419],\n",
            "         [-0.0401,  0.1629, -0.0469,  ...,  0.0057, -0.2072,  0.0545],\n",
            "         [ 0.1355,  0.0908,  0.0017,  ..., -0.2013,  0.0151,  0.0873]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2164,  0.2062, -0.2892,  ...,  0.3020, -0.3260, -0.1682],\n",
            "        [-0.1254,  0.5308,  0.0560,  ..., -0.0690,  0.2640,  0.3138],\n",
            "        [ 0.6992,  0.1993, -0.4660,  ...,  0.3346, -0.6895, -0.4866],\n",
            "        ...,\n",
            "        [ 0.5700,  0.0929, -0.4586,  ...,  0.3927, -0.5094, -0.4765],\n",
            "        [ 0.2176,  0.1176, -0.2742,  ...,  0.2246, -0.3913, -0.1718],\n",
            "        [ 0.1592,  0.0164,  0.0423,  ..., -0.0851, -0.0043,  0.0214]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0249, -0.0868, -0.0120,  ..., -0.0475,  0.0512,  0.1144],\n",
            "        [-0.0509, -0.0201,  0.1001,  ..., -0.0768, -0.0063,  0.2405],\n",
            "        [ 0.0249, -0.0868, -0.0120,  ..., -0.0475,  0.0512,  0.1144],\n",
            "        ...,\n",
            "        [ 0.1085,  0.0997, -0.0097,  ...,  0.0831, -0.0515,  0.1941],\n",
            "        [ 0.2762, -0.0406, -0.0444,  ...,  0.1034, -0.3641,  0.2088],\n",
            "        [ 0.0078,  0.0674, -0.0759,  ...,  0.1280, -0.2021, -0.0654]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2232, -0.1814,  0.0175,  ...,  0.2061, -0.2339, -0.1464],\n",
            "         [ 0.0854,  0.2973, -0.2858,  ...,  0.1384, -0.2070, -0.2222],\n",
            "         [ 0.0181, -0.1405,  0.0205,  ...,  0.1654, -0.1829,  0.1217],\n",
            "         ...,\n",
            "         [ 0.2762, -0.0406, -0.0444,  ...,  0.1034, -0.3641,  0.2088],\n",
            "         [ 0.0078,  0.0674, -0.0759,  ...,  0.1280, -0.2021, -0.0654],\n",
            "         [ 0.0877,  0.3384, -0.0426,  ...,  0.0332, -0.1033,  0.0480]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5230,  0.0136, -0.3234,  ...,  0.3436, -0.5108, -0.3377],\n",
            "        [ 0.3888,  0.3341, -0.4910,  ...,  0.4422, -0.5490, -0.4325],\n",
            "        [ 0.1903, -0.0275, -0.1785,  ...,  0.2767, -0.3086,  0.0022],\n",
            "        ...,\n",
            "        [ 0.4429,  0.1720, -0.2922,  ...,  0.3469, -0.4891,  0.0686],\n",
            "        [ 0.3217,  0.0446, -0.3252,  ...,  0.3940, -0.4559, -0.2649],\n",
            "        [-0.0992,  0.6138, -0.0574,  ...,  0.0722,  0.1418,  0.3977]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0251, -0.0868, -0.0120,  ..., -0.0476,  0.0512,  0.1142],\n",
            "        [ 0.0251, -0.0868, -0.0120,  ..., -0.0476,  0.0512,  0.1142],\n",
            "        [ 0.0251, -0.0868, -0.0120,  ..., -0.0476,  0.0512,  0.1142],\n",
            "        ...,\n",
            "        [ 0.2935, -0.0520,  0.0560,  ..., -0.1346, -0.1509, -0.0279],\n",
            "        [-0.0277,  0.1361,  0.3055,  ..., -0.0695,  0.0872,  0.0877],\n",
            "        [ 0.1304,  0.2194, -0.0371,  ...,  0.0408, -0.1466, -0.0736]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1304,  0.2194, -0.0371,  ...,  0.0408, -0.1466, -0.0736],\n",
            "         [-0.0277,  0.1361,  0.3055,  ..., -0.0695,  0.0872,  0.0877],\n",
            "         [ 0.1532, -0.1296, -0.1487,  ...,  0.3845, -0.4689, -0.1673],\n",
            "         ...,\n",
            "         [ 0.1532, -0.1296, -0.1487,  ...,  0.3845, -0.4689, -0.1673],\n",
            "         [ 0.1532, -0.1296, -0.1487,  ...,  0.3845, -0.4689, -0.1673],\n",
            "         [ 0.1532, -0.1296, -0.1487,  ...,  0.3845, -0.4689, -0.1673]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5508,  0.0499, -0.3539,  ...,  0.3352, -0.5309, -0.3664],\n",
            "        [-0.1500,  0.4534,  0.1953,  ..., -0.1021,  0.2007,  0.4407],\n",
            "        [ 0.6079,  0.1992, -0.5292,  ...,  0.5643, -0.6775, -0.5132],\n",
            "        ...,\n",
            "        [ 0.6079,  0.1992, -0.5292,  ...,  0.5643, -0.6775, -0.5132],\n",
            "        [ 0.6079,  0.1992, -0.5292,  ...,  0.5643, -0.6775, -0.5132],\n",
            "        [ 0.6079,  0.1992, -0.5292,  ...,  0.5643, -0.6775, -0.5132]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2686, -0.0727,  0.0229,  ...,  0.2287, -0.1703, -0.1761],\n",
            "        [-0.2032, -0.0353,  0.0031,  ...,  0.0261,  0.0733,  0.0025],\n",
            "        [ 0.0252, -0.0868, -0.0120,  ..., -0.0477,  0.0511,  0.1141],\n",
            "        ...,\n",
            "        [ 0.0675,  0.4912, -0.0955,  ...,  0.1889, -0.2494, -0.1502],\n",
            "        [ 0.0719,  0.1459, -0.1035,  ...,  0.1302, -0.1474, -0.3053],\n",
            "        [-0.0991,  0.2404,  0.0408,  ...,  0.0949, -0.1078, -0.0503]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 4.6886e-02, -3.8496e-01,  9.7873e-02,  ..., -9.9273e-02,\n",
            "          -6.0036e-02,  5.4139e-02],\n",
            "         [ 1.0555e-01, -1.0593e-02, -1.2080e-01,  ...,  1.0284e-01,\n",
            "          -2.8092e-01, -2.0311e-01],\n",
            "         [ 8.5804e-02,  3.2481e-01, -4.1121e-02,  ...,  8.7792e-02,\n",
            "          -1.1452e-01, -8.8507e-02],\n",
            "         ...,\n",
            "         [ 4.4787e-02,  3.1231e-01,  4.6283e-02,  ...,  1.1958e-01,\n",
            "          -1.5668e-01, -6.7947e-02],\n",
            "         [ 1.0959e-01,  3.9019e-01, -1.5656e-01,  ...,  8.9601e-02,\n",
            "          -2.4396e-01,  4.5365e-05],\n",
            "         [ 7.3130e-02, -2.1249e-01, -1.4797e-01,  ..., -2.7850e-02,\n",
            "          -1.1977e-01,  5.6050e-02]]], grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5005, -0.1304, -0.2997,  ...,  0.2166, -0.4360, -0.2646],\n",
            "        [ 0.7258,  0.0775, -0.6568,  ...,  0.6125, -0.7951, -0.6407],\n",
            "        [ 0.0020,  0.4211,  0.0032,  ...,  0.0628,  0.0627,  0.1250],\n",
            "        ...,\n",
            "        [-0.0969,  0.5354, -0.0629,  ...,  0.1580,  0.0027,  0.2083],\n",
            "        [ 0.2783,  0.3343, -0.3118,  ...,  0.1621, -0.3079, -0.1416],\n",
            "        [ 0.3622, -0.0152, -0.3335,  ...,  0.2730, -0.4006, -0.1926]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1039,  0.0754,  0.0803,  ..., -0.0297, -0.0084,  0.0319],\n",
            "        [-0.1699,  0.0524,  0.0378,  ...,  0.0290,  0.0297,  0.0140],\n",
            "        [-0.0680,  0.0253, -0.1224,  ...,  0.0620,  0.0716, -0.0688],\n",
            "        ...,\n",
            "        [ 0.0328,  0.2630, -0.1017,  ...,  0.1250, -0.2582, -0.2166],\n",
            "        [ 0.0192,  0.1441, -0.0382,  ...,  0.0930,  0.0307, -0.1271],\n",
            "        [ 0.1197,  0.1869, -0.0921,  ..., -0.0186, -0.0479, -0.1181]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0328,  0.2630, -0.1017,  ...,  0.1250, -0.2582, -0.2166],\n",
            "         [ 0.0192,  0.1441, -0.0382,  ...,  0.0930,  0.0307, -0.1271],\n",
            "         [ 0.1197,  0.1869, -0.0921,  ..., -0.0186, -0.0479, -0.1181],\n",
            "         ...,\n",
            "         [ 0.1533,  0.0065, -0.0731,  ..., -0.1153, -0.0450, -0.1174],\n",
            "         [ 0.0642,  0.1903, -0.0882,  ...,  0.2319, -0.1726, -0.1632],\n",
            "         [-0.0854,  0.2005, -0.4309,  ...,  0.1577, -0.1675, -0.1584]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4765,  0.2180, -0.5299,  ...,  0.5204, -0.6387, -0.4827],\n",
            "        [-0.0152,  0.0575,  0.0777,  ..., -0.0471,  0.0962,  0.0420],\n",
            "        [ 0.3374,  0.2268, -0.3360,  ...,  0.1340, -0.3109, -0.2727],\n",
            "        ...,\n",
            "        [ 0.4585,  0.0621, -0.3414,  ...,  0.0849, -0.3516, -0.3111],\n",
            "        [ 0.1503,  0.2687, -0.2834,  ...,  0.2909, -0.3798, -0.2128],\n",
            "        [ 0.1127,  0.1550, -0.3649,  ...,  0.2299, -0.3054, -0.1160]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0253, -0.0866, -0.0120,  ..., -0.0479,  0.0511,  0.1139],\n",
            "        [ 0.0253, -0.0866, -0.0120,  ..., -0.0479,  0.0511,  0.1139],\n",
            "        [ 0.0288, -0.0625, -0.0691,  ..., -0.0485,  0.0016, -0.1917],\n",
            "        ...,\n",
            "        [ 0.0743, -0.0388, -0.0642,  ...,  0.1600, -0.2559, -0.0202],\n",
            "        [ 0.2657,  0.2512, -0.0976,  ...,  0.1352, -0.1382, -0.1623],\n",
            "        [ 0.0073,  0.3326, -0.0218,  ...,  0.0802,  0.1085,  0.1661]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2657,  0.2512, -0.0976,  ...,  0.1352, -0.1382, -0.1623],\n",
            "         [ 0.0073,  0.3326, -0.0218,  ...,  0.0802,  0.1085,  0.1661],\n",
            "         [ 0.1883,  0.0272, -0.1740,  ...,  0.0208,  0.0131,  0.0064],\n",
            "         ...,\n",
            "         [ 0.0640,  0.3839, -0.0779,  ...,  0.0677,  0.0152, -0.0498],\n",
            "         [ 0.0640,  0.3839, -0.0779,  ...,  0.0677,  0.0152, -0.0498],\n",
            "         [ 0.1460,  0.0494, -0.1009,  ..., -0.0406, -0.0555, -0.0648]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3902,  0.3528, -0.3385,  ...,  0.2796, -0.3792, -0.2924],\n",
            "        [-0.1432,  0.5230,  0.0786,  ..., -0.0563,  0.2438,  0.3463],\n",
            "        [ 0.3055,  0.1925, -0.3811,  ...,  0.2400, -0.2139, -0.2130],\n",
            "        ...,\n",
            "        [-0.1390,  0.6039,  0.0359,  ..., -0.0889,  0.2104,  0.2994],\n",
            "        [-0.1390,  0.6039,  0.0359,  ..., -0.0889,  0.2104,  0.2994],\n",
            "        [ 0.1034,  0.0590, -0.0823,  ..., -0.0210, -0.0822,  0.0071]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0254, -0.0864, -0.0120,  ..., -0.0479,  0.0511,  0.1139],\n",
            "        [ 0.2688, -0.0756,  0.0230,  ...,  0.2270, -0.1697, -0.1764],\n",
            "        [ 0.0254, -0.0864, -0.0120,  ..., -0.0479,  0.0511,  0.1139],\n",
            "        ...,\n",
            "        [ 0.0120,  0.0980, -0.0337,  ...,  0.1201, -0.0442, -0.0041],\n",
            "        [ 0.0046,  0.1515,  0.0594,  ...,  0.2743, -0.2109,  0.0441],\n",
            "        [-0.0549,  0.0475,  0.0988,  ...,  0.0955, -0.1384,  0.1867]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0549,  0.0475,  0.0988,  ...,  0.0955, -0.1384,  0.1867],\n",
            "         [ 0.2007,  0.0674, -0.3475,  ...,  0.1923, -0.1677,  0.0369],\n",
            "         [ 0.1069, -0.0158, -0.1230,  ...,  0.1032, -0.2856, -0.2078],\n",
            "         ...,\n",
            "         [ 0.2298,  0.3491, -0.1142,  ..., -0.0645, -0.1472, -0.0553],\n",
            "         [ 0.0503,  0.3525, -0.0765,  ...,  0.1140, -0.1738, -0.2978],\n",
            "         [ 0.1194, -0.1486, -0.2137,  ...,  0.0407, -0.2594,  0.0451]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.2030,  0.4209, -0.0215,  ...,  0.1719,  0.0516,  0.3720],\n",
            "        [ 0.2141,  0.0857, -0.2876,  ...,  0.2264, -0.2378, -0.0370],\n",
            "        [ 0.7347,  0.0837, -0.6624,  ...,  0.6168, -0.8038, -0.6526],\n",
            "        ...,\n",
            "        [ 0.2788,  0.3534, -0.2661,  ...,  0.1424, -0.2330, -0.1089],\n",
            "        [ 0.3865,  0.2687, -0.3518,  ...,  0.3955, -0.4893, -0.4092],\n",
            "        [ 0.4810,  0.0404, -0.4447,  ...,  0.3569, -0.5291, -0.2368]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1142,  0.1216, -0.0806,  ...,  0.1130,  0.0662,  0.0006],\n",
            "        [ 0.0863, -0.0810, -0.0078,  ..., -0.1085, -0.0219, -0.0535],\n",
            "        [ 0.0255, -0.0862, -0.0121,  ..., -0.0480,  0.0510,  0.1139],\n",
            "        ...,\n",
            "        [-0.1970,  0.1067, -0.2082,  ..., -0.0235, -0.0911,  0.0099],\n",
            "        [ 0.0938,  0.3719,  0.1819,  ..., -0.0018,  0.1594,  0.0298],\n",
            "        [ 0.2053,  0.4798,  0.0233,  ...,  0.0731, -0.0696,  0.1908]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0921,  0.3366, -0.0476,  ...,  0.0342, -0.1090,  0.0339],\n",
            "         [-0.0959, -0.1311, -0.1351,  ...,  0.1642, -0.0173,  0.1162],\n",
            "         [-0.0477,  0.2129, -0.2350,  ...,  0.2172, -0.1456, -0.0040],\n",
            "         ...,\n",
            "         [-0.1970,  0.1067, -0.2082,  ..., -0.0235, -0.0911,  0.0099],\n",
            "         [ 0.0938,  0.3719,  0.1819,  ..., -0.0018,  0.1594,  0.0298],\n",
            "         [ 0.2053,  0.4798,  0.0233,  ...,  0.0731, -0.0696,  0.1908]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0827,  0.6136, -0.0844,  ...,  0.1027,  0.1218,  0.3863],\n",
            "        [ 0.0648, -0.0264, -0.1951,  ...,  0.1723, -0.1436,  0.0588],\n",
            "        [ 0.0070,  0.1911, -0.2091,  ...,  0.0590, -0.0826, -0.0295],\n",
            "        ...,\n",
            "        [-0.0736, -0.0126,  0.0139,  ..., -0.0827, -0.0834, -0.0185],\n",
            "        [-0.1774,  0.5912,  0.0806,  ...,  0.0974,  0.2646,  0.3245],\n",
            "        [ 0.0035,  0.5936, -0.1947,  ...,  0.2724,  0.0062,  0.3056]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0259, -0.0861, -0.0123,  ..., -0.0480,  0.0510,  0.1138],\n",
            "        [ 0.0259, -0.0861, -0.0123,  ..., -0.0480,  0.0510,  0.1138],\n",
            "        [-0.0516,  0.0800, -0.0142,  ...,  0.2365, -0.2232,  0.0565],\n",
            "        ...,\n",
            "        [ 0.3465, -0.3173, -0.1379,  ...,  0.1056, -0.3234, -0.2066],\n",
            "        [ 0.0702, -0.1637, -0.2115,  ...,  0.1478, -0.1713,  0.1861],\n",
            "        [ 0.0797,  0.0551, -0.0349,  ...,  0.2082, -0.3113, -0.2132]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1895, -0.2374, -0.0417,  ..., -0.1212, -0.1908, -0.0636],\n",
            "         [ 0.0797,  0.0551, -0.0349,  ...,  0.2082, -0.3113, -0.2132],\n",
            "         [-0.0356, -0.0460, -0.1595,  ...,  0.1100, -0.0901,  0.1216],\n",
            "         ...,\n",
            "         [ 0.3465, -0.3173, -0.1379,  ...,  0.1056, -0.3234, -0.2066],\n",
            "         [ 0.0702, -0.1637, -0.2115,  ...,  0.1478, -0.1713,  0.1861],\n",
            "         [ 0.0797,  0.0551, -0.0349,  ...,  0.2082, -0.3113, -0.2132]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4749, -0.0041, -0.3420,  ...,  0.2060, -0.3928, -0.2875],\n",
            "        [ 0.5193,  0.1835, -0.4480,  ...,  0.4791, -0.5870, -0.4992],\n",
            "        [-0.0092,  0.2031, -0.2202,  ...,  0.2566, -0.1811,  0.1079],\n",
            "        ...,\n",
            "        [ 0.6404, -0.0683, -0.4547,  ...,  0.4171, -0.6238, -0.5303],\n",
            "        [ 0.2880,  0.2022, -0.4435,  ...,  0.4263, -0.4505,  0.0354],\n",
            "        [ 0.5193,  0.1835, -0.4480,  ...,  0.4791, -0.5870, -0.4992]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0786,  0.0845,  0.0616,  ...,  0.0942, -0.0572, -0.1681],\n",
            "        [-0.2032, -0.0357,  0.0032,  ...,  0.0259,  0.0741,  0.0025],\n",
            "        [ 0.0786,  0.0845,  0.0616,  ...,  0.0942, -0.0572, -0.1681],\n",
            "        ...,\n",
            "        [ 0.0752,  0.4859, -0.1050,  ...,  0.1215, -0.1549, -0.1649],\n",
            "        [-0.1220, -0.1086, -0.0985,  ...,  0.2436,  0.1417, -0.0345],\n",
            "        [ 0.1285, -0.0529, -0.0285,  ...,  0.1259, -0.1848, -0.0592]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0611, -0.1107, -0.0943,  ...,  0.1035, -0.2386, -0.2454],\n",
            "         [ 0.0572, -0.0071, -0.1166,  ..., -0.0659, -0.0504,  0.0287],\n",
            "         [ 0.0657,  0.1899,  0.0639,  ...,  0.0797, -0.0605, -0.0052],\n",
            "         ...,\n",
            "         [ 0.0752,  0.4859, -0.1050,  ...,  0.1215, -0.1549, -0.1649],\n",
            "         [-0.1220, -0.1086, -0.0985,  ...,  0.2436,  0.1417, -0.0345],\n",
            "         [ 0.1285, -0.0529, -0.0285,  ...,  0.1259, -0.1848, -0.0592]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5030,  0.1013, -0.4646,  ...,  0.4517, -0.6265, -0.4442],\n",
            "        [ 0.0334, -0.1191,  0.0676,  ..., -0.1351,  0.0208,  0.0401],\n",
            "        [-0.0038,  0.2210, -0.0226,  ...,  0.0501, -0.0090,  0.0442],\n",
            "        ...,\n",
            "        [ 0.2377,  0.4549, -0.2613,  ...,  0.2506, -0.3356, -0.3124],\n",
            "        [-0.0640, -0.0218, -0.0045,  ...,  0.0453,  0.1388,  0.0399],\n",
            "        [ 0.2093,  0.1688, -0.2256,  ...,  0.1875, -0.2845, -0.0697]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0613, -0.0555, -0.0757,  ...,  0.0566,  0.0911,  0.0697],\n",
            "        [-0.0120,  0.1131, -0.0557,  ...,  0.0415,  0.0282,  0.0746],\n",
            "        [-0.2031, -0.0357,  0.0031,  ...,  0.0259,  0.0742,  0.0026],\n",
            "        ...,\n",
            "        [ 0.0581,  0.1560, -0.3591,  ...,  0.1369, -0.2723, -0.1207],\n",
            "        [-0.0553,  0.3019, -0.1366,  ...,  0.1272, -0.1451, -0.1928],\n",
            "        [ 0.0666,  0.3202, -0.0365,  ...,  0.0896, -0.0677, -0.0120]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0553,  0.3019, -0.1366,  ...,  0.1272, -0.1451, -0.1928],\n",
            "         [ 0.0666,  0.3202, -0.0365,  ...,  0.0896, -0.0677, -0.0120],\n",
            "         [ 0.1091,  0.0079, -0.1271,  ...,  0.1039, -0.2863, -0.2138],\n",
            "         ...,\n",
            "         [ 0.1554,  0.0773, -0.0704,  ...,  0.0516, -0.1786, -0.0747],\n",
            "         [-0.1709,  0.0661, -0.0842,  ...,  0.0992, -0.1717, -0.0201],\n",
            "         [ 0.0581,  0.1560, -0.3591,  ...,  0.1369, -0.2723, -0.1207]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.1664,  0.4811, -0.2064,  ...,  0.1524, -0.1425, -0.0155],\n",
            "        [-0.0171,  0.4766, -0.0111,  ...,  0.0485,  0.0938,  0.2488],\n",
            "        [ 0.7339,  0.1007, -0.6614,  ...,  0.6137, -0.8007, -0.6556],\n",
            "        ...,\n",
            "        [ 0.5084,  0.1784, -0.3683,  ...,  0.3104, -0.4705, -0.3010],\n",
            "        [ 0.1327,  0.0566, -0.2192,  ...,  0.1933, -0.3760, -0.1926],\n",
            "        [ 0.1471,  0.3944, -0.4438,  ...,  0.3372, -0.3413,  0.0452]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0265, -0.0865, -0.0126,  ..., -0.0482,  0.0508,  0.1137],\n",
            "        [ 0.0265, -0.0865, -0.0126,  ..., -0.0482,  0.0508,  0.1137],\n",
            "        [ 0.0560,  0.0965,  0.1202,  ..., -0.0554,  0.0132, -0.0121],\n",
            "        ...,\n",
            "        [ 0.3562, -0.3175, -0.1455,  ...,  0.1089, -0.3271, -0.2148],\n",
            "        [ 0.2124,  0.3208, -0.0911,  ..., -0.1182,  0.0005, -0.1519],\n",
            "        [ 0.3562, -0.3175, -0.1455,  ...,  0.1089, -0.3271, -0.2148]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3562, -0.3175, -0.1455,  ...,  0.1089, -0.3271, -0.2148],\n",
            "         [ 0.3562, -0.3175, -0.1455,  ...,  0.1089, -0.3271, -0.2148],\n",
            "         [ 0.2124,  0.3208, -0.0911,  ..., -0.1182,  0.0005, -0.1519],\n",
            "         ...,\n",
            "         [ 0.2002,  0.1081, -0.1765,  ..., -0.0552, -0.1010, -0.1632],\n",
            "         [ 0.1991,  0.0741,  0.0276,  ...,  0.0055, -0.1576, -0.2045],\n",
            "         [ 0.0343, -0.0296,  0.0776,  ..., -0.1268,  0.0329,  0.0862]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6572, -0.0614, -0.4662,  ...,  0.4273, -0.6350, -0.5458],\n",
            "        [ 0.6572, -0.0614, -0.4662,  ...,  0.4273, -0.6350, -0.5458],\n",
            "        [ 0.3575,  0.3748, -0.2770,  ...,  0.0910, -0.1795, -0.1667],\n",
            "        ...,\n",
            "        [ 0.6195,  0.1297, -0.5207,  ...,  0.2688, -0.5189, -0.4458],\n",
            "        [ 0.3163,  0.1603, -0.1635,  ...,  0.1747, -0.2955, -0.2164],\n",
            "        [ 0.0971,  0.0577, -0.0851,  ...,  0.0482, -0.0565,  0.1199]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0794,  0.0824,  0.0612,  ...,  0.0940, -0.0575, -0.1682],\n",
            "        [ 0.0266, -0.0870, -0.0125,  ..., -0.0483,  0.0508,  0.1140],\n",
            "        [ 0.0794,  0.0824,  0.0612,  ...,  0.0940, -0.0575, -0.1682],\n",
            "        ...,\n",
            "        [ 0.2137,  0.2552, -0.0832,  ...,  0.1430, -0.0933,  0.0618],\n",
            "        [ 0.0448,  0.3344, -0.1191,  ...,  0.3552,  0.0511, -0.0591],\n",
            "        [ 0.3463, -0.0192, -0.0410,  ...,  0.0389, -0.2258, -0.0727]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0050,  0.4811, -0.0651,  ...,  0.1370, -0.1806, -0.1557],\n",
            "         [ 0.0188, -0.1440, -0.1072,  ...,  0.1356, -0.2086, -0.1853],\n",
            "         [ 0.0326,  0.3694, -0.0870,  ...,  0.1027, -0.1430, -0.0510],\n",
            "         ...,\n",
            "         [ 0.1806,  0.4441, -0.0693,  ...,  0.0577, -0.2094, -0.1678],\n",
            "         [-0.1506,  0.0137, -0.0644,  ..., -0.0408, -0.1597,  0.1413],\n",
            "         [ 0.0085,  0.3180, -0.0084,  ...,  0.0619,  0.1024,  0.1238]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2074,  0.4667, -0.3114,  ...,  0.4141, -0.4169, -0.2137],\n",
            "        [ 0.3590,  0.1329, -0.3840,  ...,  0.3963, -0.4651, -0.3983],\n",
            "        [ 0.3126,  0.4305, -0.3878,  ...,  0.4122, -0.4894, -0.2361],\n",
            "        ...,\n",
            "        [ 0.0197,  0.5215, -0.1475,  ...,  0.0957, -0.0457,  0.1083],\n",
            "        [ 0.1573,  0.1348, -0.3356,  ...,  0.2468, -0.4200, -0.0608],\n",
            "        [-0.1062,  0.3891,  0.1283,  ..., -0.1037,  0.2256,  0.2996]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0600, -0.0971,  0.1369,  ...,  0.0155,  0.0410, -0.1053],\n",
            "        [ 0.2665, -0.0782,  0.0212,  ...,  0.2287, -0.1726, -0.1802],\n",
            "        [ 0.0261,  0.0737, -0.1169,  ..., -0.0838, -0.0224, -0.0981],\n",
            "        ...,\n",
            "        [ 0.2585, -0.1277,  0.0470,  ...,  0.0660, -0.0725, -0.0823],\n",
            "        [ 0.1453,  0.5336, -0.0119,  ...,  0.0786, -0.0085,  0.1932],\n",
            "        [ 0.2522, -0.2537, -0.2450,  ...,  0.2074, -0.1062, -0.1335]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2585, -0.1277,  0.0470,  ...,  0.0660, -0.0725, -0.0823],\n",
            "         [ 0.1453,  0.5336, -0.0119,  ...,  0.0786, -0.0085,  0.1932],\n",
            "         [ 0.2522, -0.2537, -0.2450,  ...,  0.2074, -0.1062, -0.1335],\n",
            "         ...,\n",
            "         [-0.0162,  0.2995, -0.1432,  ...,  0.2693, -0.1909, -0.1024],\n",
            "         [-0.0868,  0.1264,  0.1776,  ...,  0.1214, -0.2258, -0.1221],\n",
            "         [ 0.1119, -0.0119, -0.1338,  ...,  0.1067, -0.3001, -0.2358]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5670,  0.1418, -0.3593,  ...,  0.3592, -0.4496, -0.3797],\n",
            "        [-0.0831,  0.7493, -0.0723,  ...,  0.0918,  0.2154,  0.4677],\n",
            "        [ 0.5512,  0.1535, -0.5176,  ...,  0.4068, -0.5333, -0.4521],\n",
            "        ...,\n",
            "        [-0.0384,  0.4581, -0.2494,  ...,  0.2226, -0.1337,  0.1601],\n",
            "        [ 0.0989,  0.3340, -0.1602,  ...,  0.2915, -0.3646, -0.1513],\n",
            "        [ 0.7572,  0.0969, -0.6808,  ...,  0.6301, -0.8239, -0.6816]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0084,  0.0377,  0.2247,  ..., -0.0715,  0.0244,  0.0815],\n",
            "        [ 0.0036, -0.1401, -0.0053,  ..., -0.0549, -0.0601,  0.0192],\n",
            "        [ 0.0266, -0.0879, -0.0123,  ..., -0.0484,  0.0509,  0.1144],\n",
            "        ...,\n",
            "        [ 0.0604,  0.3733, -0.0883,  ...,  0.1212, -0.1983, -0.3259],\n",
            "        [ 0.0761,  0.3090, -0.1229,  ...,  0.1832, -0.2302, -0.1176],\n",
            "        [ 0.3792, -0.2522, -0.1077,  ..., -0.0823, -0.2987, -0.1688]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1680, -0.2652,  0.0907,  ...,  0.1154, -0.2448, -0.2178],\n",
            "         [-0.0093,  0.1067,  0.3209,  ..., -0.0317,  0.0256,  0.1102],\n",
            "         [-0.0178,  0.2454, -0.1012,  ...,  0.0504, -0.1664, -0.3996],\n",
            "         ...,\n",
            "         [ 0.1567,  0.3711,  0.0115,  ...,  0.0855, -0.1348, -0.0586],\n",
            "         [ 0.3424, -0.1006, -0.1244,  ..., -0.0656, -0.2187, -0.1733],\n",
            "         [ 0.1533, -0.1964, -0.3176,  ...,  0.0453, -0.1790,  0.0135]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4245,  0.0775, -0.2772,  ...,  0.4034, -0.4246, -0.3736],\n",
            "        [ 0.0168,  0.1972,  0.1229,  ...,  0.0940,  0.0542,  0.1310],\n",
            "        [ 0.1863,  0.3808, -0.3565,  ...,  0.2738, -0.3957, -0.2898],\n",
            "        ...,\n",
            "        [ 0.0801,  0.5335, -0.1474,  ...,  0.1425, -0.1137,  0.1782],\n",
            "        [ 0.5594,  0.2047, -0.4124,  ...,  0.2506, -0.4057, -0.2890],\n",
            "        [ 0.2910, -0.0788, -0.4439,  ...,  0.1535, -0.3343, -0.2091]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0699, -0.1042,  0.0453,  ..., -0.0941, -0.1245,  0.0401],\n",
            "        [ 0.0267, -0.0883, -0.0122,  ..., -0.0485,  0.0509,  0.1146],\n",
            "        [ 0.0267, -0.0883, -0.0122,  ..., -0.0485,  0.0509,  0.1146],\n",
            "        ...,\n",
            "        [ 0.1241, -0.2355, -0.1773,  ...,  0.0126, -0.2841,  0.0078],\n",
            "        [ 0.1241, -0.2355, -0.1773,  ...,  0.0126, -0.2841,  0.0078],\n",
            "        [-0.0055,  0.1841,  0.0680,  ...,  0.2444, -0.0366,  0.0977]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1531,  0.5495, -0.1723,  ...,  0.1348, -0.2453, -0.1758],\n",
            "         [ 0.2761, -0.0973, -0.2210,  ...,  0.0729, -0.2450, -0.1394],\n",
            "         [ 0.0759,  0.3838, -0.1307,  ...,  0.0783, -0.2235, -0.2471],\n",
            "         ...,\n",
            "         [ 0.2180, -0.0966, -0.1090,  ...,  0.2020, -0.1845, -0.3259],\n",
            "         [ 0.2682,  0.0270,  0.2220,  ...,  0.1729,  0.0853,  0.1476],\n",
            "         [ 0.0771,  0.2683,  0.0389,  ...,  0.2561,  0.0149,  0.0328]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5663,  0.4152, -0.5012,  ...,  0.3969, -0.5828, -0.5298],\n",
            "        [ 0.6590,  0.1332, -0.5160,  ...,  0.3587, -0.6086, -0.4321],\n",
            "        [ 0.6390,  0.3515, -0.6156,  ...,  0.5545, -0.7239, -0.6551],\n",
            "        ...,\n",
            "        [ 0.7137,  0.1488, -0.5348,  ...,  0.4888, -0.6300, -0.6486],\n",
            "        [ 0.1680,  0.1469,  0.0212,  ...,  0.1572,  0.0275,  0.1707],\n",
            "        [ 0.2606,  0.2059, -0.2245,  ...,  0.3698, -0.2531, -0.1426]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.2306,  0.0266,  0.0116,  ...,  0.0867,  0.1011, -0.1227],\n",
            "        [ 0.2654, -0.0786,  0.0208,  ...,  0.2295, -0.1733, -0.1813],\n",
            "        [ 0.0267, -0.0890, -0.0121,  ..., -0.0488,  0.0509,  0.1149],\n",
            "        ...,\n",
            "        [-0.0878,  0.0091, -0.3212,  ...,  0.2193, -0.1242,  0.0061],\n",
            "        [ 0.2373,  0.0512,  0.0228,  ...,  0.0170, -0.1919, -0.2311],\n",
            "        [-0.1343, -0.0945,  0.0076,  ...,  0.0204, -0.0324,  0.1012]])\n",
            "Output of encoder at last step:tensor([[[-0.0181,  0.0580, -0.0615,  ..., -0.0971,  0.0421, -0.0016],\n",
            "         [-0.0878,  0.0091, -0.3212,  ...,  0.2193, -0.1242,  0.0061],\n",
            "         [ 0.2373,  0.0512,  0.0228,  ...,  0.0170, -0.1919, -0.2311],\n",
            "         ...,\n",
            "         [ 0.3457, -0.0726,  0.0869,  ...,  0.2413, -0.3008, -0.2776],\n",
            "         [ 0.2315,  0.0411,  0.0069,  ..., -0.0055, -0.1761, -0.1455],\n",
            "         [-0.1051,  0.0061, -0.2436,  ...,  0.0606, -0.0652,  0.0094]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0713,  0.1749, -0.2601,  ...,  0.1308, -0.0866, -0.0090],\n",
            "        [ 0.0688,  0.2045, -0.3951,  ...,  0.2242, -0.1783, -0.1113],\n",
            "        [ 0.4740,  0.1920, -0.2788,  ...,  0.2667, -0.4430, -0.3681],\n",
            "        ...,\n",
            "        [ 0.3523,  0.1160, -0.2158,  ...,  0.2716, -0.4314, -0.3322],\n",
            "        [ 0.1442,  0.0679, -0.1001,  ...,  0.0891, -0.1549, -0.1126],\n",
            "        [-0.0495,  0.0346, -0.2267,  ...,  0.0638, -0.0676,  0.0211]])\n",
            "Output of encoder at every step:tensor([[-0.1163,  0.0025, -0.2109,  ...,  0.1013,  0.0137, -0.0336],\n",
            "        [ 0.2654, -0.0786,  0.0208,  ...,  0.2295, -0.1733, -0.1813],\n",
            "        [-0.0112,  0.0634,  0.1213,  ..., -0.0113, -0.0256, -0.1531],\n",
            "        ...,\n",
            "        [-0.1484,  0.0904, -0.3134,  ...,  0.1928, -0.0998, -0.1136],\n",
            "        [ 0.0815, -0.0251, -0.0813,  ...,  0.1407, -0.1775, -0.1056],\n",
            "        [-0.0470, -0.0828, -0.3521,  ...,  0.1653, -0.1283, -0.0563]])\n",
            "Output of encoder at last step:tensor([[[ 0.0163,  0.2458, -0.0499,  ...,  0.0561, -0.0589, -0.0335],\n",
            "         [-0.1158, -0.0849, -0.3566,  ...,  0.1906, -0.0150, -0.0594],\n",
            "         [-0.0750,  0.1094, -0.2388,  ...,  0.1799, -0.0252, -0.1982],\n",
            "         ...,\n",
            "         [-0.0935,  0.0018, -0.2792,  ...,  0.1970, -0.1382, -0.0832],\n",
            "         [ 0.2243, -0.0011, -0.0899,  ...,  0.0561, -0.2258, -0.2464],\n",
            "         [-0.0607, -0.1095, -0.2905,  ...,  0.3349, -0.2272, -0.3654]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0367,  0.2036, -0.0285,  ...,  0.1085, -0.0221, -0.0113],\n",
            "        [ 0.0228,  0.1726, -0.4313,  ...,  0.2787, -0.1423, -0.1530],\n",
            "        [-0.0346,  0.1893, -0.2641,  ...,  0.1436, -0.0519, -0.0894],\n",
            "        ...,\n",
            "        [ 0.1567,  0.1650, -0.4344,  ...,  0.3239, -0.3456, -0.2281],\n",
            "        [ 0.4356,  0.1614, -0.3255,  ...,  0.2852, -0.3811, -0.4053],\n",
            "        [ 0.2226,  0.2132, -0.4916,  ...,  0.4027, -0.4843, -0.4378]])\n",
            "Output of encoder at every step:tensor([[ 0.0267, -0.0890, -0.0121,  ..., -0.0488,  0.0509,  0.1149],\n",
            "        [ 0.2654, -0.0786,  0.0208,  ...,  0.2295, -0.1733, -0.1813],\n",
            "        [-0.0914,  0.1793, -0.0879,  ..., -0.0957,  0.0248,  0.0722],\n",
            "        ...,\n",
            "        [-0.1959, -0.0144, -0.1380,  ...,  0.0790,  0.0445,  0.1056],\n",
            "        [-0.0637, -0.0538, -0.0842,  ...,  0.1369, -0.0629, -0.0695],\n",
            "        [ 0.0463,  0.1200,  0.2513,  ...,  0.4261, -0.2566,  0.0710]])\n",
            "Output of encoder at last step:tensor([[[-0.1443, -0.0335, -0.4110,  ...,  0.1917, -0.1547, -0.1968],\n",
            "         [ 0.0108, -0.1391, -0.2989,  ...,  0.2476, -0.1124, -0.1300],\n",
            "         [ 0.1547,  0.2347, -0.1216,  ...,  0.1500, -0.2920, -0.3246],\n",
            "         ...,\n",
            "         [ 0.0483,  0.0912, -0.0958,  ...,  0.0843, -0.1408, -0.0992],\n",
            "         [-0.0887, -0.0957, -0.2237,  ...,  0.1673,  0.0306,  0.0998],\n",
            "         [-0.0418,  0.2680,  0.1643,  ...,  0.0104, -0.0338,  0.0465]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4012,  0.2598, -0.6670,  ...,  0.4749, -0.6197, -0.5886],\n",
            "        [ 0.3717,  0.0879, -0.5279,  ...,  0.3664, -0.4288, -0.3802],\n",
            "        [ 0.6571,  0.4896, -0.5877,  ...,  0.5706, -0.7162, -0.6187],\n",
            "        ...,\n",
            "        [ 0.4307,  0.1811, -0.4383,  ...,  0.4226, -0.4864, -0.4298],\n",
            "        [-0.0784,  0.1533, -0.2989,  ...,  0.1730,  0.0243,  0.1072],\n",
            "        [-0.0644,  0.2181,  0.0258,  ...,  0.0627,  0.0044,  0.0767]])\n",
            "Output of encoder at every step:tensor([[ 0.1159,  0.1219, -0.0364,  ...,  0.0740,  0.0053, -0.0771],\n",
            "        [-0.0831,  0.1125,  0.0602,  ..., -0.0779,  0.0895,  0.0495],\n",
            "        [ 0.0267, -0.0890, -0.0121,  ..., -0.0488,  0.0509,  0.1149],\n",
            "        ...,\n",
            "        [ 0.0415,  0.0070, -0.1334,  ...,  0.0965, -0.2159, -0.1058],\n",
            "        [ 0.1344, -0.0420,  0.1070,  ...,  0.0091, -0.0082, -0.1671],\n",
            "        [-0.0314,  0.2809,  0.1199,  ...,  0.0850,  0.1061,  0.1736]])\n",
            "Output of encoder at last step:tensor([[[ 0.3962,  0.0858, -0.0242,  ...,  0.1261, -0.1395,  0.0278],\n",
            "         [ 0.0526,  0.4003, -0.1261,  ...,  0.0898, -0.1691, -0.2264],\n",
            "         [ 0.0164,  0.2018, -0.1987,  ...,  0.1034,  0.0104,  0.0482],\n",
            "         ...,\n",
            "         [ 0.3079, -0.0908, -0.1994,  ...,  0.3303, -0.3297, -0.0680],\n",
            "         [ 0.0006,  0.0729, -0.1306,  ...,  0.1033, -0.1999, -0.2341],\n",
            "         [ 0.0621,  0.2528, -0.0652,  ...,  0.0646, -0.1834, -0.0597]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5258,  0.0628, -0.2698,  ...,  0.2870, -0.4099, -0.3233],\n",
            "        [ 0.3399,  0.4718, -0.4632,  ...,  0.4149, -0.4189, -0.3491],\n",
            "        [-0.1209,  0.4158, -0.1746,  ...,  0.0124,  0.1279,  0.2533],\n",
            "        ...,\n",
            "        [ 0.4202,  0.1921, -0.3907,  ...,  0.3173, -0.3924, -0.3010],\n",
            "        [ 0.5456,  0.3025, -0.5907,  ...,  0.5737, -0.7065, -0.6326],\n",
            "        [ 0.1914,  0.3309, -0.2538,  ...,  0.2578, -0.2370, -0.0762]])\n",
            "Output of encoder at every step:tensor([[ 0.2654, -0.0786,  0.0208,  ...,  0.2295, -0.1733, -0.1813],\n",
            "        [ 0.0267, -0.0890, -0.0121,  ..., -0.0488,  0.0509,  0.1149],\n",
            "        [-0.1163,  0.0025, -0.2109,  ...,  0.1013,  0.0137, -0.0336],\n",
            "        ...,\n",
            "        [ 0.1566, -0.2951, -0.1715,  ..., -0.2469, -0.1178, -0.0982],\n",
            "        [-0.1221,  0.3505,  0.0659,  ...,  0.1700, -0.2320, -0.0420],\n",
            "        [ 0.0026,  0.0074,  0.0165,  ...,  0.3536, -0.4321, -0.1124]])\n",
            "Output of encoder at last step:tensor([[[ 0.0560,  0.3038,  0.0329,  ...,  0.2987, -0.0610,  0.0196],\n",
            "         [-0.1361,  0.1711,  0.3038,  ...,  0.1400,  0.0390,  0.0264],\n",
            "         [-0.0018, -0.0162, -0.1456,  ...,  0.0719, -0.0845, -0.0345],\n",
            "         ...,\n",
            "         [-0.0314,  0.2809,  0.1199,  ...,  0.0850,  0.1061,  0.1736],\n",
            "         [ 0.0476, -0.1605, -0.1544,  ...,  0.1451, -0.3104, -0.3158],\n",
            "         [ 0.0170, -0.4026, -0.1965,  ..., -0.2500, -0.1224, -0.0734]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3989,  0.2928, -0.3628,  ...,  0.4626, -0.4403, -0.2804],\n",
            "        [-0.1608,  0.4017, -0.0314,  ...,  0.2471,  0.0881,  0.1684],\n",
            "        [ 0.2443,  0.1749, -0.3750,  ...,  0.2868, -0.2485, -0.2206],\n",
            "        ...,\n",
            "        [-0.1716,  0.5304, -0.0818,  ...,  0.2334,  0.1961,  0.4725],\n",
            "        [ 0.5381,  0.1657, -0.4760,  ...,  0.4634, -0.6451, -0.5685],\n",
            "        [ 0.4137, -0.1575, -0.4983,  ...,  0.2203, -0.4898, -0.3250]])\n",
            "Output of encoder at every step:tensor([[ 0.0267, -0.0890, -0.0121,  ..., -0.0488,  0.0509,  0.1149],\n",
            "        [ 0.0267, -0.0890, -0.0121,  ..., -0.0488,  0.0509,  0.1149],\n",
            "        [ 0.0267, -0.0890, -0.0121,  ..., -0.0488,  0.0509,  0.1149],\n",
            "        ...,\n",
            "        [ 0.2145, -0.2667, -0.2393,  ...,  0.2860, -0.2640,  0.1042],\n",
            "        [ 0.1748, -0.1897, -0.1770,  ...,  0.3790, -0.4891, -0.1924],\n",
            "        [ 0.1748, -0.1897, -0.1770,  ...,  0.3790, -0.4891, -0.1924]])\n",
            "Output of encoder at last step:tensor([[[ 0.1748, -0.1897, -0.1770,  ...,  0.3790, -0.4891, -0.1924],\n",
            "         [ 0.1748, -0.1897, -0.1770,  ...,  0.3790, -0.4891, -0.1924],\n",
            "         [ 0.2145, -0.2667, -0.2393,  ...,  0.2860, -0.2640,  0.1042],\n",
            "         ...,\n",
            "         [ 0.0529,  0.3203, -0.0467,  ...,  0.0719,  0.0576, -0.0193],\n",
            "         [ 0.0933,  0.1766, -0.1342,  ...,  0.0931, -0.1770, -0.0448],\n",
            "         [ 0.0026,  0.0271,  0.2829,  ..., -0.0395,  0.0135,  0.0516]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6818,  0.1698, -0.5734,  ...,  0.5940, -0.7316, -0.5956],\n",
            "        [ 0.6818,  0.1698, -0.5734,  ...,  0.5940, -0.7316, -0.5956],\n",
            "        [ 0.6459,  0.0749, -0.5386,  ...,  0.5593, -0.6593, -0.3019],\n",
            "        ...,\n",
            "        [-0.1156,  0.5636, -0.0081,  ...,  0.0044,  0.2741,  0.3006],\n",
            "        [ 0.4373,  0.2835, -0.5178,  ...,  0.4394, -0.5456, -0.3555],\n",
            "        [ 0.0909,  0.1337,  0.0085,  ...,  0.1438, -0.0401, -0.0300]])\n",
            "Output of encoder at every step:tensor([[ 0.0267, -0.0890, -0.0121,  ..., -0.0488,  0.0509,  0.1149],\n",
            "        [ 0.0267, -0.0890, -0.0121,  ..., -0.0488,  0.0509,  0.1149],\n",
            "        [ 0.0267, -0.0890, -0.0121,  ..., -0.0488,  0.0509,  0.1149],\n",
            "        ...,\n",
            "        [ 0.1748, -0.1897, -0.1770,  ...,  0.3790, -0.4891, -0.1924],\n",
            "        [ 0.1748, -0.1897, -0.1770,  ...,  0.3790, -0.4891, -0.1924],\n",
            "        [ 0.1748, -0.1897, -0.1770,  ...,  0.3790, -0.4891, -0.1924]])\n",
            "Output of encoder at last step:tensor([[[ 0.1748, -0.1897, -0.1770,  ...,  0.3790, -0.4891, -0.1924],\n",
            "         [ 0.1748, -0.1897, -0.1770,  ...,  0.3790, -0.4891, -0.1924],\n",
            "         [ 0.1748, -0.1897, -0.1770,  ...,  0.3790, -0.4891, -0.1924],\n",
            "         ...,\n",
            "         [ 0.1748, -0.1897, -0.1770,  ...,  0.3790, -0.4891, -0.1924],\n",
            "         [ 0.1748, -0.1897, -0.1770,  ...,  0.3790, -0.4891, -0.1924],\n",
            "         [ 0.1748, -0.1897, -0.1770,  ...,  0.3790, -0.4891, -0.1924]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6818,  0.1698, -0.5734,  ...,  0.5940, -0.7316, -0.5956],\n",
            "        [ 0.6818,  0.1698, -0.5734,  ...,  0.5940, -0.7316, -0.5956],\n",
            "        [ 0.6818,  0.1698, -0.5734,  ...,  0.5940, -0.7316, -0.5956],\n",
            "        ...,\n",
            "        [ 0.6818,  0.1698, -0.5734,  ...,  0.5940, -0.7316, -0.5956],\n",
            "        [ 0.6818,  0.1698, -0.5734,  ...,  0.5940, -0.7316, -0.5956],\n",
            "        [ 0.6818,  0.1698, -0.5734,  ...,  0.5940, -0.7316, -0.5956]])\n",
            "\t Epoch: 7 | Train Loss: 0.100 | Train Acc: 96.79%\n",
            "\t Epoch: 7 | Val. Loss: 1.133 |  Val. Acc: 83.93% \n",
            "\n",
            "Output of encoder at every step:tensor([[-0.2026, -0.0351,  0.0026,  ...,  0.0260,  0.0751,  0.0028],\n",
            "        [ 0.2654, -0.0786,  0.0208,  ...,  0.2295, -0.1733, -0.1813],\n",
            "        [-0.2026, -0.0351,  0.0026,  ...,  0.0260,  0.0751,  0.0028],\n",
            "        ...,\n",
            "        [-0.1441,  0.0004, -0.0375,  ...,  0.1573, -0.1490, -0.0462],\n",
            "        [ 0.0796, -0.1244, -0.1102,  ..., -0.0144, -0.1860,  0.0423],\n",
            "        [ 0.2855, -0.0250, -0.0086,  ...,  0.1496, -0.1706, -0.1090]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1126,  0.0114, -0.1346,  ...,  0.1069, -0.2966, -0.2349],\n",
            "         [-0.0483,  0.1611,  0.0665,  ...,  0.3753, -0.2527, -0.2197],\n",
            "         [ 0.1126,  0.0114, -0.1346,  ...,  0.1069, -0.2966, -0.2349],\n",
            "         ...,\n",
            "         [ 0.3728, -0.2309, -0.1030,  ..., -0.0867, -0.2939, -0.1606],\n",
            "         [ 0.0555,  0.3204,  0.0421,  ...,  0.1259, -0.1726, -0.0786],\n",
            "         [ 0.1390,  0.4232, -0.0290,  ...,  0.1234, -0.2107,  0.0714]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.7543,  0.1085, -0.6765,  ...,  0.6255, -0.8182, -0.6794],\n",
            "        [ 0.3234,  0.3901, -0.3621,  ...,  0.4884, -0.5103, -0.4713],\n",
            "        [ 0.7543,  0.1085, -0.6765,  ...,  0.6255, -0.8182, -0.6794],\n",
            "        ...,\n",
            "        [ 0.6390, -0.0164, -0.4284,  ...,  0.2696, -0.5932, -0.4622],\n",
            "        [-0.0859,  0.5450, -0.0899,  ...,  0.1884, -0.0354,  0.1943],\n",
            "        [ 0.3931,  0.5292, -0.3999,  ...,  0.3367, -0.4303, -0.2114]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2653, -0.0789,  0.0211,  ...,  0.2290, -0.1725, -0.1808],\n",
            "        [-0.0113, -0.1923,  0.1559,  ..., -0.0090,  0.0252, -0.0868],\n",
            "        [ 0.0267, -0.0897, -0.0119,  ..., -0.0492,  0.0510,  0.1152],\n",
            "        ...,\n",
            "        [ 0.0779, -0.1495, -0.0283,  ..., -0.1609, -0.2783, -0.1076],\n",
            "        [ 0.2107, -0.0471, -0.0699,  ..., -0.0482, -0.2696,  0.0129],\n",
            "        [-0.0572,  0.2598,  0.1595,  ..., -0.0087,  0.1610,  0.1112]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0813, -0.1507, -0.0381,  ...,  0.0445, -0.2859, -0.1826],\n",
            "         [-0.0644, -0.0510, -0.0799,  ...,  0.1351, -0.0580, -0.0671],\n",
            "         [ 0.0983, -0.1876,  0.0469,  ...,  0.1647, -0.1852, -0.1020],\n",
            "         ...,\n",
            "         [ 0.0927, -0.1041, -0.2074,  ..., -0.1320, -0.1221,  0.0351],\n",
            "         [ 0.0103, -0.1189, -0.0635,  ...,  0.0718, -0.1578,  0.0797],\n",
            "         [ 0.2463,  0.1892, -0.0928,  ..., -0.0408, -0.0552, -0.1321]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5095,  0.0296, -0.3917,  ...,  0.3401, -0.5547, -0.4506],\n",
            "        [ 0.2002,  0.2912, -0.3678,  ...,  0.3519, -0.3784, -0.2245],\n",
            "        [ 0.3078,  0.0519, -0.2541,  ...,  0.2940, -0.3163, -0.1671],\n",
            "        ...,\n",
            "        [ 0.2446,  0.2718, -0.4498,  ...,  0.2670, -0.4712, -0.2529],\n",
            "        [ 0.1858,  0.1361, -0.3064,  ...,  0.2643, -0.3003, -0.0567],\n",
            "        [ 0.6512,  0.2295, -0.4622,  ...,  0.2893, -0.4893, -0.4503]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0268, -0.0903, -0.0118,  ..., -0.0494,  0.0510,  0.1154],\n",
            "        [ 0.0268, -0.0903, -0.0118,  ..., -0.0494,  0.0510,  0.1154],\n",
            "        [ 0.0268, -0.0903, -0.0118,  ..., -0.0494,  0.0510,  0.1154],\n",
            "        ...,\n",
            "        [ 0.0667,  0.2961,  0.0072,  ...,  0.2737, -0.0455,  0.0496],\n",
            "        [ 0.3230,  0.2439, -0.1279,  ...,  0.1362, -0.1534, -0.1801],\n",
            "        [ 0.0142,  0.0620, -0.0798,  ...,  0.1317, -0.2129, -0.0738]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0417,  0.0196, -0.0978,  ...,  0.1394,  0.0144,  0.1180],\n",
            "         [-0.0248,  0.0331,  0.2920,  ..., -0.0750,  0.2097,  0.2243],\n",
            "         [ 0.0829, -0.0193, -0.1420,  ...,  0.0373, -0.2274,  0.0411],\n",
            "         ...,\n",
            "         [ 0.3230,  0.2439, -0.1279,  ...,  0.1362, -0.1534, -0.1801],\n",
            "         [ 0.0142,  0.0620, -0.0798,  ...,  0.1317, -0.2129, -0.0738],\n",
            "         [ 0.1209,  0.0230, -0.0257,  ...,  0.2284, -0.1202, -0.1210]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0824, -0.0235,  0.0982,  ..., -0.0491,  0.0789,  0.1300],\n",
            "        [-0.0300, -0.1467,  0.2497,  ..., -0.1945,  0.1582,  0.1134],\n",
            "        [ 0.2089, -0.0729, -0.1014,  ...,  0.0369, -0.1969, -0.0433],\n",
            "        ...,\n",
            "        [ 0.5453,  0.3538, -0.4191,  ...,  0.3405, -0.4757, -0.4281],\n",
            "        [ 0.3941,  0.0699, -0.3913,  ...,  0.4435, -0.5263, -0.3414],\n",
            "        [ 0.4539,  0.0821, -0.3066,  ...,  0.3547, -0.4192, -0.3865]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0498, -0.2487,  0.0051,  ...,  0.0088,  0.0161,  0.0059],\n",
            "        [-0.1548,  0.0598,  0.0776,  ..., -0.0139, -0.0492,  0.2062],\n",
            "        [-0.0253,  0.0181, -0.0844,  ..., -0.0186, -0.0118, -0.0017],\n",
            "        ...,\n",
            "        [-0.0583, -0.0556, -0.1890,  ...,  0.1586, -0.1440, -0.0488],\n",
            "        [ 0.1191, -0.5312,  0.1419,  ...,  0.0800, -0.1119, -0.1510],\n",
            "        [-0.0205,  0.2184, -0.0104,  ...,  0.1883,  0.0818, -0.1172]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0900,  0.1376, -0.1016,  ...,  0.1116, -0.0710, -0.3252],\n",
            "         [ 0.0474, -0.0749, -0.0510,  ..., -0.0405,  0.1277,  0.1350],\n",
            "         [-0.0655,  0.1535, -0.0218,  ...,  0.1422, -0.1219, -0.3394],\n",
            "         ...,\n",
            "         [ 0.3119,  0.0713, -0.1647,  ...,  0.0028,  0.0833,  0.0140],\n",
            "         [ 0.3123,  0.2571, -0.1283,  ..., -0.0336, -0.2388, -0.2550],\n",
            "         [-0.0393, -0.1395, -0.0337,  ...,  0.1080, -0.0805,  0.0484]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4081,  0.3180, -0.3528,  ...,  0.3723, -0.3546, -0.3900],\n",
            "        [-0.0418, -0.1632,  0.1352,  ..., -0.1708,  0.1075,  0.1410],\n",
            "        [ 0.3762,  0.4324, -0.4705,  ...,  0.4664, -0.5510, -0.6391],\n",
            "        ...,\n",
            "        [ 0.4859,  0.2301, -0.3706,  ...,  0.2334, -0.2204, -0.2894],\n",
            "        [ 0.2889,  0.4337, -0.3788,  ...,  0.2488, -0.4519, -0.3447],\n",
            "        [ 0.2954,  0.1579, -0.3746,  ...,  0.3076, -0.3960, -0.1908]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0776,  0.0104, -0.1024,  ..., -0.1021,  0.1048, -0.2327],\n",
            "        [ 0.0269, -0.0912, -0.0116,  ..., -0.0500,  0.0510,  0.1158],\n",
            "        [ 0.2640, -0.0800,  0.0225,  ...,  0.2275, -0.1703, -0.1790],\n",
            "        ...,\n",
            "        [ 0.0681, -0.4032,  0.0862,  ..., -0.0870, -0.0742,  0.0361],\n",
            "        [ 0.2355, -0.1676, -0.3099,  ..., -0.1425, -0.3140, -0.0523],\n",
            "        [ 0.0975,  0.1833, -0.0921,  ...,  0.1556, -0.2972, -0.3581]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2355, -0.1676, -0.3099,  ..., -0.1425, -0.3140, -0.0523],\n",
            "         [ 0.0975,  0.1833, -0.0921,  ...,  0.1556, -0.2972, -0.3581],\n",
            "         [ 0.1527, -0.4340,  0.0113,  ..., -0.0381, -0.1221,  0.1882],\n",
            "         ...,\n",
            "         [ 0.0893,  0.1687, -0.1117,  ...,  0.1304, -0.1541, -0.3201],\n",
            "         [ 0.1150,  0.0232, -0.1297,  ...,  0.1051, -0.2853, -0.2209],\n",
            "         [ 0.0681, -0.4032,  0.0862,  ..., -0.0870, -0.0742,  0.0361]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6821,  0.0113, -0.5182,  ...,  0.2854, -0.5779, -0.4279],\n",
            "        [ 0.6734,  0.4053, -0.5826,  ...,  0.6003, -0.7588, -0.6781],\n",
            "        [ 0.5091, -0.1496, -0.3825,  ...,  0.3131, -0.5220, -0.1218],\n",
            "        ...,\n",
            "        [ 0.6529,  0.3100, -0.5833,  ...,  0.6118, -0.6840, -0.6699],\n",
            "        [ 0.7502,  0.1256, -0.6663,  ...,  0.6175, -0.8095, -0.6779],\n",
            "        [ 0.5741, -0.1282, -0.3463,  ...,  0.2622, -0.4947, -0.3378]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0269, -0.0917, -0.0116,  ..., -0.0502,  0.0511,  0.1160],\n",
            "        [ 0.0056, -0.0272,  0.1207,  ..., -0.0291,  0.0344, -0.0484],\n",
            "        [ 0.0226,  0.1156,  0.0335,  ...,  0.0506, -0.0167,  0.0595],\n",
            "        ...,\n",
            "        [ 0.0564,  0.3278, -0.1222,  ...,  0.3543,  0.0439, -0.0641],\n",
            "        [-0.0310,  0.2751,  0.1301,  ...,  0.0741,  0.1167,  0.1809],\n",
            "        [ 0.0931,  0.3271, -0.0486,  ...,  0.1236, -0.0322, -0.0894]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0310,  0.2751,  0.1301,  ...,  0.0741,  0.1167,  0.1809],\n",
            "         [ 0.0931,  0.3271, -0.0486,  ...,  0.1236, -0.0322, -0.0894],\n",
            "         [ 0.1936, -0.0520, -0.0831,  ..., -0.0088, -0.3588, -0.0983],\n",
            "         ...,\n",
            "         [ 0.1156,  0.0667, -0.0999,  ...,  0.1416, -0.3060, -0.3656],\n",
            "         [ 0.0550,  0.2371, -0.1246,  ...,  0.1077, -0.2554, -0.0948],\n",
            "         [ 0.0564,  0.3278, -0.1222,  ...,  0.3543,  0.0439, -0.0641]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.1758,  0.5248, -0.0611,  ...,  0.2155,  0.2140,  0.4765],\n",
            "        [-0.0618,  0.6145,  0.0126,  ...,  0.0088,  0.2191,  0.2870],\n",
            "        [ 0.1813,  0.0431, -0.1489,  ...,  0.1816, -0.3523, -0.1014],\n",
            "        ...,\n",
            "        [ 0.7388,  0.2504, -0.6248,  ...,  0.6268, -0.8027, -0.7048],\n",
            "        [ 0.5208,  0.3164, -0.4467,  ...,  0.3894, -0.5454, -0.4168],\n",
            "        [-0.2190,  0.5885, -0.0871,  ...,  0.2498,  0.2361,  0.3371]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0475, -0.0693, -0.2052,  ..., -0.1085,  0.0557,  0.0388],\n",
            "        [-0.0662,  0.0248, -0.1282,  ...,  0.0611,  0.0710, -0.0671],\n",
            "        [ 0.0269, -0.0921, -0.0115,  ..., -0.0503,  0.0511,  0.1160],\n",
            "        ...,\n",
            "        [ 0.1494,  0.4264, -0.1774,  ...,  0.1048, -0.2609, -0.0055],\n",
            "        [ 0.1284,  0.1534, -0.1003,  ..., -0.0363, -0.2393, -0.0405],\n",
            "        [ 0.4775,  0.0298, -0.0879,  ...,  0.3217, -0.3307, -0.4063]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0285,  0.1415, -0.1736,  ...,  0.1351, -0.1695,  0.0213],\n",
            "         [ 0.0029,  0.0303,  0.2840,  ..., -0.1753, -0.1364,  0.0357],\n",
            "         [ 0.4117,  0.1717, -0.0123,  ...,  0.3325, -0.2779, -0.3720],\n",
            "         ...,\n",
            "         [-0.0321,  0.6459, -0.1196,  ...,  0.1993, -0.0284, -0.0161],\n",
            "         [ 0.2937,  0.0715,  0.0872,  ...,  0.2871, -0.4444, -0.1614],\n",
            "         [-0.0602,  0.2603,  0.1700,  ..., -0.0036,  0.0263,  0.0610]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1011,  0.3178, -0.2493,  ...,  0.2734, -0.2697, -0.1018],\n",
            "        [ 0.2411,  0.0754, -0.0086,  ...,  0.0451, -0.2991, -0.1358],\n",
            "        [ 0.2844,  0.3215, -0.2133,  ...,  0.2307, -0.3200, -0.3414],\n",
            "        ...,\n",
            "        [-0.0939,  0.4678, -0.1033,  ...,  0.0881, -0.0036,  0.1345],\n",
            "        [ 0.7281,  0.3034, -0.4498,  ...,  0.5590, -0.7236, -0.5994],\n",
            "        [-0.0819,  0.1479,  0.0853,  ..., -0.0108,  0.0600,  0.0973]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0660,  0.0248, -0.1285,  ...,  0.0611,  0.0710, -0.0671],\n",
            "        [ 0.0269, -0.0925, -0.0114,  ..., -0.0505,  0.0511,  0.1161],\n",
            "        [ 0.0124,  0.0295,  0.0163,  ..., -0.0342,  0.1419, -0.0856],\n",
            "        ...,\n",
            "        [ 0.1176,  0.3450, -0.0506,  ...,  0.0349, -0.1154,  0.0243],\n",
            "        [ 0.1573,  0.1714, -0.1524,  ...,  0.0277,  0.0465,  0.0036],\n",
            "        [-0.0346,  0.3191, -0.0191,  ...,  0.1223,  0.1579,  0.1651]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0235,  0.2553, -0.0901,  ...,  0.1031, -0.1330, -0.1161],\n",
            "         [ 0.0495,  0.3137, -0.0448,  ...,  0.0703,  0.0630, -0.0186],\n",
            "         [ 0.4544, -0.0758, -0.0739,  ..., -0.1246, -0.3852, -0.1616],\n",
            "         ...,\n",
            "         [ 0.1176,  0.3450, -0.0506,  ...,  0.0349, -0.1154,  0.0243],\n",
            "         [ 0.1573,  0.1714, -0.1524,  ...,  0.0277,  0.0465,  0.0036],\n",
            "         [-0.0346,  0.3191, -0.0191,  ...,  0.1223,  0.1579,  0.1651]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2031,  0.2559, -0.2783,  ...,  0.3006, -0.2859, -0.1305],\n",
            "        [-0.1142,  0.5335,  0.0205,  ..., -0.0265,  0.2697,  0.2916],\n",
            "        [ 0.7657,  0.2115, -0.4852,  ...,  0.3440, -0.7245, -0.5520],\n",
            "        ...,\n",
            "        [-0.0498,  0.6513, -0.1436,  ...,  0.1743,  0.1068,  0.4052],\n",
            "        [ 0.2287,  0.1912, -0.2570,  ...,  0.1746, -0.1254, -0.1128],\n",
            "        [-0.1327,  0.3146, -0.0849,  ...,  0.1049,  0.1442,  0.1978]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0860, -0.3193,  0.1898,  ..., -0.0526,  0.0635,  0.0459],\n",
            "        [-0.0091, -0.0782, -0.1238,  ...,  0.1157, -0.0482,  0.0149],\n",
            "        [ 0.1553,  0.1569, -0.0677,  ...,  0.0269, -0.0225,  0.0379],\n",
            "        ...,\n",
            "        [ 0.3026,  0.6815, -0.0728,  ...,  0.1007, -0.1478, -0.2841],\n",
            "        [ 0.0662,  0.3809, -0.0826,  ...,  0.1195, -0.1840, -0.3130],\n",
            "        [-0.0170,  0.1207,  0.3275,  ..., -0.0329,  0.0483,  0.1201]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1340, -0.1584, -0.2026,  ...,  0.0472, -0.2581,  0.0471],\n",
            "         [ 0.0616,  0.0895, -0.1712,  ...,  0.2559, -0.2482, -0.2007],\n",
            "         [ 0.1607,  0.0318, -0.1708,  ..., -0.0235, -0.3220, -0.0070],\n",
            "         ...,\n",
            "         [-0.1291,  0.0380, -0.0551,  ...,  0.3403, -0.2039,  0.0301],\n",
            "         [-0.0251,  0.2967, -0.3047,  ...,  0.0869, -0.1013, -0.1681],\n",
            "         [ 0.0734,  0.3312, -0.0372,  ...,  0.0912, -0.0717, -0.0141]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5221,  0.0562, -0.4576,  ...,  0.3734, -0.5483, -0.2688],\n",
            "        [ 0.2395,  0.1272, -0.2875,  ...,  0.3398, -0.4502, -0.2494],\n",
            "        [ 0.4630,  0.1405, -0.3513,  ...,  0.2462, -0.4732, -0.2880],\n",
            "        ...,\n",
            "        [-0.1463,  0.4002, -0.1537,  ...,  0.1242,  0.0061,  0.2398],\n",
            "        [ 0.4582,  0.3848, -0.6347,  ...,  0.4162, -0.5488, -0.5284],\n",
            "        [-0.0158,  0.4964, -0.0112,  ...,  0.0516,  0.0947,  0.2576]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0268, -0.0931, -0.0113,  ..., -0.0508,  0.0511,  0.1162],\n",
            "        [ 0.0268, -0.0931, -0.0113,  ..., -0.0508,  0.0511,  0.1162],\n",
            "        [ 0.0268, -0.0931, -0.0113,  ..., -0.0508,  0.0511,  0.1162],\n",
            "        ...,\n",
            "        [ 0.3303, -0.0487,  0.0504,  ..., -0.1251, -0.1692, -0.0434],\n",
            "        [ 0.0122,  0.1494,  0.3271,  ..., -0.0700,  0.0813,  0.0900],\n",
            "        [ 0.1574,  0.2522, -0.0490,  ...,  0.0470, -0.1670, -0.1078]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1574,  0.2522, -0.0490,  ...,  0.0470, -0.1670, -0.1078],\n",
            "         [ 0.0122,  0.1494,  0.3271,  ..., -0.0700,  0.0813,  0.0900],\n",
            "         [ 0.1766, -0.2023, -0.1531,  ...,  0.3759, -0.4719, -0.1729],\n",
            "         ...,\n",
            "         [ 0.1766, -0.2023, -0.1531,  ...,  0.3759, -0.4719, -0.1729],\n",
            "         [ 0.1766, -0.2023, -0.1531,  ...,  0.3759, -0.4719, -0.1729],\n",
            "         [ 0.1766, -0.2023, -0.1531,  ...,  0.3759, -0.4719, -0.1729]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6576,  0.1246, -0.4585,  ...,  0.4220, -0.6181, -0.4812],\n",
            "        [-0.1789,  0.5402,  0.2117,  ..., -0.0892,  0.2217,  0.5088],\n",
            "        [ 0.6705,  0.1694, -0.5488,  ...,  0.5740, -0.7158, -0.5810],\n",
            "        ...,\n",
            "        [ 0.6705,  0.1694, -0.5488,  ...,  0.5740, -0.7158, -0.5810],\n",
            "        [ 0.6705,  0.1694, -0.5488,  ...,  0.5740, -0.7158, -0.5810],\n",
            "        [ 0.6705,  0.1694, -0.5488,  ...,  0.5740, -0.7158, -0.5810]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0268, -0.0934, -0.0112,  ..., -0.0510,  0.0512,  0.1162],\n",
            "        [ 0.0268, -0.0934, -0.0112,  ..., -0.0510,  0.0512,  0.1162],\n",
            "        [ 0.0268, -0.0934, -0.0112,  ..., -0.0510,  0.0512,  0.1162],\n",
            "        ...,\n",
            "        [ 0.1777, -0.2043, -0.1530,  ...,  0.3764, -0.4719, -0.1730],\n",
            "        [ 0.1777, -0.2043, -0.1530,  ...,  0.3764, -0.4719, -0.1730],\n",
            "        [ 0.1777, -0.2043, -0.1530,  ...,  0.3764, -0.4719, -0.1730]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1777, -0.2043, -0.1530,  ...,  0.3764, -0.4719, -0.1730],\n",
            "         [ 0.1777, -0.2043, -0.1530,  ...,  0.3764, -0.4719, -0.1730],\n",
            "         [ 0.1777, -0.2043, -0.1530,  ...,  0.3764, -0.4719, -0.1730],\n",
            "         ...,\n",
            "         [ 0.2263,  0.0612, -0.1233,  ...,  0.2355, -0.1864,  0.0543],\n",
            "         [ 0.1585,  0.2361, -0.1074,  ...,  0.0633, -0.2752, -0.1845],\n",
            "         [ 0.3810,  0.2058, -0.1589,  ...,  0.0162, -0.1743, -0.3674]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6722,  0.1699, -0.5489,  ...,  0.5738, -0.7169, -0.5828],\n",
            "        [ 0.6722,  0.1699, -0.5489,  ...,  0.5738, -0.7169, -0.5828],\n",
            "        [ 0.6722,  0.1699, -0.5489,  ...,  0.5738, -0.7169, -0.5828],\n",
            "        ...,\n",
            "        [ 0.6306,  0.2048, -0.5021,  ...,  0.5309, -0.5842, -0.3533],\n",
            "        [ 0.7501,  0.3515, -0.6081,  ...,  0.5266, -0.7735, -0.6196],\n",
            "        [ 0.7330,  0.4675, -0.5015,  ...,  0.3656, -0.5464, -0.5991]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0268, -0.0936, -0.0112,  ..., -0.0511,  0.0512,  0.1162],\n",
            "        [ 0.1124,  0.1202, -0.0326,  ...,  0.0735,  0.0064, -0.0758],\n",
            "        [ 0.0584, -0.0964,  0.1366,  ...,  0.0171,  0.0401, -0.1051],\n",
            "        ...,\n",
            "        [ 0.0596,  0.3264, -0.1216,  ...,  0.3524,  0.0455, -0.0614],\n",
            "        [ 0.0144,  0.4938, -0.0658,  ...,  0.1367, -0.1834, -0.1590],\n",
            "        [ 0.2788,  0.0644, -0.1320,  ...,  0.0179, -0.1719, -0.1266]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0596,  0.3264, -0.1216,  ...,  0.3524,  0.0455, -0.0614],\n",
            "         [ 0.2547,  0.2126,  0.1745,  ...,  0.1079, -0.2768, -0.1324],\n",
            "         [ 0.0307, -0.0903,  0.1042,  ..., -0.0827,  0.1057,  0.0838],\n",
            "         ...,\n",
            "         [ 0.1046,  0.2803, -0.1125,  ...,  0.1166, -0.0823, -0.1369],\n",
            "         [-0.1342, -0.1008, -0.0884,  ...,  0.2350,  0.1530, -0.0297],\n",
            "         [ 0.1716,  0.0631, -0.2144,  ..., -0.0731, -0.1440,  0.0015]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.2218,  0.5910, -0.0842,  ...,  0.2474,  0.2414,  0.3445],\n",
            "        [ 0.5674,  0.3330, -0.2657,  ...,  0.3794, -0.5895, -0.4163],\n",
            "        [-0.0115, -0.1255,  0.1846,  ..., -0.1956,  0.0899,  0.0622],\n",
            "        ...,\n",
            "        [ 0.6731,  0.3581, -0.5960,  ...,  0.5848, -0.6467, -0.5759],\n",
            "        [-0.0586, -0.0726,  0.0448,  ...,  0.0042,  0.1360,  0.0256],\n",
            "        [ 0.5490,  0.1837, -0.4942,  ...,  0.2587, -0.5124, -0.3703]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0057, -0.0780,  0.0657,  ...,  0.1217,  0.1080,  0.1875],\n",
            "        [ 0.0268, -0.0939, -0.0112,  ..., -0.0513,  0.0512,  0.1162],\n",
            "        [ 0.0742,  0.1386, -0.0201,  ..., -0.0224,  0.0500, -0.0074],\n",
            "        ...,\n",
            "        [-0.0271,  0.2711,  0.1347,  ...,  0.0718,  0.1178,  0.1829],\n",
            "        [-0.0271,  0.2711,  0.1347,  ...,  0.0718,  0.1178,  0.1829],\n",
            "        [ 0.3453, -0.4428, -0.2129,  ...,  0.1489, -0.1694, -0.1373]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3922, -0.2380, -0.1458,  ...,  0.1284, -0.1365, -0.1699],\n",
            "         [ 0.0670, -0.1994, -0.1153,  ..., -0.0519,  0.0017,  0.0950],\n",
            "         [ 0.1459,  0.2528, -0.0753,  ...,  0.1329, -0.2170, -0.2516],\n",
            "         ...,\n",
            "         [-0.0271,  0.2711,  0.1347,  ...,  0.0718,  0.1178,  0.1829],\n",
            "         [-0.0271,  0.2711,  0.1347,  ...,  0.0718,  0.1178,  0.1829],\n",
            "         [ 0.3453, -0.4428, -0.2129,  ...,  0.1489, -0.1694, -0.1373]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.7052,  0.1239, -0.5097,  ...,  0.4019, -0.5756, -0.5530],\n",
            "        [ 0.0774, -0.2060,  0.1001,  ..., -0.1493,  0.0284,  0.0370],\n",
            "        [ 0.6572,  0.4421, -0.5299,  ...,  0.5422, -0.6660, -0.5932],\n",
            "        ...,\n",
            "        [-0.1794,  0.5282, -0.0582,  ...,  0.2138,  0.2206,  0.4857],\n",
            "        [-0.1794,  0.5282, -0.0582,  ...,  0.2138,  0.2206,  0.4857],\n",
            "        [ 0.5011, -0.0448, -0.4395,  ...,  0.2755, -0.4034, -0.3064]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0267, -0.0941, -0.0111,  ..., -0.0514,  0.0512,  0.1163],\n",
            "        [ 0.1293, -0.0034, -0.1069,  ..., -0.0751, -0.1687, -0.0348],\n",
            "        [ 0.1463,  0.0145, -0.0321,  ..., -0.0078,  0.0319,  0.0032],\n",
            "        ...,\n",
            "        [ 0.1448,  0.0009, -0.2697,  ...,  0.1137, -0.2759, -0.0089],\n",
            "        [ 0.1705,  0.0261, -0.0570,  ...,  0.0900, -0.0264, -0.0248],\n",
            "        [ 0.2867, -0.1189, -0.2097,  ...,  0.0676, -0.2448, -0.1367]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3465,  0.4327,  0.0120,  ..., -0.0774, -0.1167, -0.0265],\n",
            "         [-0.0012,  0.1747,  0.0861,  ...,  0.2353, -0.0039,  0.1244],\n",
            "         [ 0.1391, -0.0735,  0.0045,  ...,  0.2241, -0.3694, -0.0155],\n",
            "         ...,\n",
            "         [-0.0841, -0.1363, -0.1629,  ...,  0.1700, -0.0457,  0.0909],\n",
            "         [ 0.2353, -0.1047, -0.1118,  ...,  0.2101, -0.1923, -0.3307],\n",
            "         [ 0.0510,  0.3122, -0.0454,  ...,  0.0704,  0.0588, -0.0229]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6552,  0.3907, -0.3152,  ...,  0.2278, -0.4569, -0.2805],\n",
            "        [-0.0395,  0.3155,  0.0138,  ...,  0.1232,  0.0683,  0.2856],\n",
            "        [ 0.3310,  0.2112, -0.2833,  ...,  0.3448, -0.4344, -0.1260],\n",
            "        ...,\n",
            "        [ 0.1276, -0.0202, -0.2562,  ...,  0.2155, -0.2255, -0.0089],\n",
            "        [ 0.7393,  0.1591, -0.5383,  ...,  0.4900, -0.6471, -0.6716],\n",
            "        [-0.1105,  0.5297,  0.0195,  ..., -0.0240,  0.2688,  0.2871]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0265, -0.0942, -0.0110,  ..., -0.0515,  0.0512,  0.1163],\n",
            "        [ 0.0265, -0.0942, -0.0110,  ..., -0.0515,  0.0512,  0.1163],\n",
            "        [ 0.0265, -0.0942, -0.0110,  ..., -0.0515,  0.0512,  0.1163],\n",
            "        ...,\n",
            "        [ 0.1869, -0.2171, -0.1644,  ...,  0.3790, -0.4817, -0.1826],\n",
            "        [ 0.1869, -0.2171, -0.1644,  ...,  0.3790, -0.4817, -0.1826],\n",
            "        [ 0.1869, -0.2171, -0.1644,  ...,  0.3790, -0.4817, -0.1826]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1869, -0.2171, -0.1644,  ...,  0.3790, -0.4817, -0.1826],\n",
            "         [ 0.1869, -0.2171, -0.1644,  ...,  0.3790, -0.4817, -0.1826],\n",
            "         [ 0.1869, -0.2171, -0.1644,  ...,  0.3790, -0.4817, -0.1826],\n",
            "         ...,\n",
            "         [ 0.1869, -0.2171, -0.1644,  ...,  0.3790, -0.4817, -0.1826],\n",
            "         [ 0.1869, -0.2171, -0.1644,  ...,  0.3790, -0.4817, -0.1826],\n",
            "         [ 0.1869, -0.2171, -0.1644,  ...,  0.3790, -0.4817, -0.1826]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6959,  0.1629, -0.5615,  ...,  0.5813, -0.7349, -0.6085],\n",
            "        [ 0.6959,  0.1629, -0.5615,  ...,  0.5813, -0.7349, -0.6085],\n",
            "        [ 0.6959,  0.1629, -0.5615,  ...,  0.5813, -0.7349, -0.6085],\n",
            "        ...,\n",
            "        [ 0.6959,  0.1629, -0.5615,  ...,  0.5813, -0.7349, -0.6085],\n",
            "        [ 0.6959,  0.1629, -0.5615,  ...,  0.5813, -0.7349, -0.6085],\n",
            "        [ 0.6959,  0.1629, -0.5615,  ...,  0.5813, -0.7349, -0.6085]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0264, -0.0943, -0.0110,  ..., -0.0516,  0.0512,  0.1163],\n",
            "        [ 0.0264, -0.0943, -0.0110,  ..., -0.0516,  0.0512,  0.1163],\n",
            "        [ 0.0264, -0.0943, -0.0110,  ..., -0.0516,  0.0512,  0.1163],\n",
            "        ...,\n",
            "        [ 0.1903, -0.2210, -0.1699,  ...,  0.3798, -0.4860, -0.1869],\n",
            "        [ 0.1903, -0.2210, -0.1699,  ...,  0.3798, -0.4860, -0.1869],\n",
            "        [ 0.1903, -0.2210, -0.1699,  ...,  0.3798, -0.4860, -0.1869]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0360,  0.0312,  0.3378,  ...,  0.1195, -0.1345,  0.0037],\n",
            "         [ 0.1903, -0.2210, -0.1699,  ...,  0.3798, -0.4860, -0.1869],\n",
            "         [ 0.1903, -0.2210, -0.1699,  ...,  0.3798, -0.4860, -0.1869],\n",
            "         ...,\n",
            "         [ 0.1903, -0.2210, -0.1699,  ...,  0.3798, -0.4860, -0.1869],\n",
            "         [ 0.1903, -0.2210, -0.1699,  ...,  0.3798, -0.4860, -0.1869],\n",
            "         [ 0.1903, -0.2210, -0.1699,  ...,  0.3798, -0.4860, -0.1869]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3888,  0.2171, -0.2222,  ...,  0.4154, -0.5092, -0.3965],\n",
            "        [ 0.7049,  0.1593, -0.5672,  ...,  0.5848, -0.7419, -0.6180],\n",
            "        [ 0.7049,  0.1593, -0.5672,  ...,  0.5848, -0.7419, -0.6180],\n",
            "        ...,\n",
            "        [ 0.7049,  0.1593, -0.5672,  ...,  0.5848, -0.7419, -0.6180],\n",
            "        [ 0.7049,  0.1593, -0.5672,  ...,  0.5848, -0.7419, -0.6180],\n",
            "        [ 0.7049,  0.1593, -0.5672,  ...,  0.5848, -0.7419, -0.6180]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0263, -0.0944, -0.0109,  ..., -0.0517,  0.0512,  0.1164],\n",
            "        [ 0.0263, -0.0944, -0.0109,  ..., -0.0517,  0.0512,  0.1164],\n",
            "        [ 0.1093, -0.1201, -0.1887,  ...,  0.0969, -0.0271,  0.1576],\n",
            "        ...,\n",
            "        [ 0.1119, -0.1318,  0.0563,  ..., -0.0206, -0.1200,  0.0369],\n",
            "        [ 0.0358,  0.1771, -0.0368,  ...,  0.0769,  0.0052, -0.1496],\n",
            "        [ 0.1576,  0.1238,  0.0608,  ...,  0.1993, -0.0276, -0.0452]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0358,  0.1771, -0.0368,  ...,  0.0769,  0.0052, -0.1496],\n",
            "         [ 0.1576,  0.1238,  0.0608,  ...,  0.1993, -0.0276, -0.0452],\n",
            "         [ 0.0902,  0.3391, -0.0485,  ..., -0.0140, -0.0077, -0.1216],\n",
            "         ...,\n",
            "         [ 0.1571,  0.0371, -0.1004,  ..., -0.0395, -0.0608, -0.0671],\n",
            "         [ 0.1956,  0.0775, -0.1142,  ..., -0.0503, -0.1250, -0.1147],\n",
            "         [ 0.3462, -0.3022, -0.0558,  ..., -0.0650, -0.0416, -0.0661]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0218, -0.0607,  0.1320,  ..., -0.1465,  0.0981,  0.0444],\n",
            "        [-0.0021,  0.3971, -0.0642,  ...,  0.1660,  0.0032,  0.0900],\n",
            "        [ 0.0747,  0.2385, -0.0604,  ..., -0.0137, -0.0647, -0.0331],\n",
            "        ...,\n",
            "        [ 0.1250,  0.0672, -0.0965,  ..., -0.0078, -0.0945, -0.0034],\n",
            "        [ 0.3631,  0.1912, -0.3075,  ...,  0.1544, -0.3034, -0.1998],\n",
            "        [ 0.6048,  0.0113, -0.4064,  ...,  0.3469, -0.4514, -0.3562]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.1137, -0.0979, -0.0905,  ..., -0.0350, -0.0174, -0.0268],\n",
            "        [-0.1931, -0.0406, -0.0838,  ..., -0.0460, -0.0029,  0.0250],\n",
            "        [ 0.0204,  0.1634, -0.2346,  ..., -0.0110,  0.1483,  0.1706],\n",
            "        ...,\n",
            "        [-0.0033,  0.1958, -0.0401,  ...,  0.2283, -0.0272,  0.0124],\n",
            "        [ 0.1455, -0.3341, -0.0896,  ...,  0.2588, -0.1356, -0.0259],\n",
            "        [-0.0451,  0.0040, -0.1308,  ...,  0.0471, -0.0613,  0.1184]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1672, -0.0118, -0.0802,  ...,  0.0712,  0.0016,  0.2145],\n",
            "         [-0.0763,  0.0518,  0.1822,  ...,  0.1172, -0.1467,  0.2865],\n",
            "         [ 0.2477, -0.1372, -0.0909,  ...,  0.3246, -0.1813, -0.2018],\n",
            "         ...,\n",
            "         [-0.0673, -0.3519, -0.2134,  ...,  0.2965,  0.0016, -0.0620],\n",
            "         [-0.0679,  0.1619,  0.2304,  ...,  0.0968, -0.0826,  0.1219],\n",
            "         [ 0.1084,  0.1501, -0.0529,  ...,  0.3795, -0.4449, -0.2227]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0459,  0.1586, -0.1053,  ...,  0.0372,  0.0316,  0.2679],\n",
            "        [-0.0790,  0.1260,  0.0707,  ...,  0.0083, -0.0009,  0.3240],\n",
            "        [ 0.3287,  0.0989, -0.3390,  ...,  0.3118, -0.3769, -0.3444],\n",
            "        ...,\n",
            "        [ 0.1057, -0.0919, -0.2968,  ...,  0.2668, -0.1575, -0.2097],\n",
            "        [-0.0841,  0.2605,  0.1384,  ..., -0.0342,  0.0298,  0.2041],\n",
            "        [ 0.3368,  0.3895, -0.3663,  ...,  0.4421, -0.5240, -0.3474]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0263, -0.0946, -0.0110,  ..., -0.0518,  0.0512,  0.1164],\n",
            "        [ 0.0263, -0.0946, -0.0110,  ..., -0.0518,  0.0512,  0.1164],\n",
            "        [ 0.1123,  0.1207, -0.0304,  ...,  0.0732,  0.0078, -0.0744],\n",
            "        ...,\n",
            "        [ 0.0180,  0.4540,  0.0079,  ...,  0.0935,  0.0094,  0.1150],\n",
            "        [ 0.0195, -0.0193,  0.0620,  ..., -0.0206, -0.2347, -0.0746],\n",
            "        [ 0.0990,  0.1886,  0.1114,  ...,  0.1014, -0.1866, -0.2751]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0769,  0.4367, -0.0682,  ...,  0.0690,  0.0287, -0.0210],\n",
            "         [ 0.0180,  0.4540,  0.0079,  ...,  0.0935,  0.0094,  0.1150],\n",
            "         [ 0.1809, -0.1690,  0.0624,  ...,  0.1757, -0.1696,  0.0240],\n",
            "         ...,\n",
            "         [-0.0299,  0.0411,  0.2950,  ..., -0.0733,  0.2157,  0.2292],\n",
            "         [ 0.2837, -0.2842,  0.0119,  ...,  0.2033, -0.2653, -0.1838],\n",
            "         [ 0.0803, -0.1399, -0.2850,  ...,  0.0867,  0.0218,  0.1287]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.1623,  0.6770,  0.0722,  ..., -0.1380,  0.2290,  0.3645],\n",
            "        [-0.1767,  0.7128,  0.0063,  ..., -0.0012,  0.2378,  0.4785],\n",
            "        [ 0.5184,  0.0071, -0.3200,  ...,  0.3463, -0.4921, -0.2798],\n",
            "        ...,\n",
            "        [-0.0313, -0.1679,  0.2660,  ..., -0.2185,  0.1538,  0.1098],\n",
            "        [ 0.7097, -0.0414, -0.4325,  ...,  0.4203, -0.6455, -0.5323],\n",
            "        [ 0.4230,  0.1289, -0.5165,  ...,  0.3595, -0.3693, -0.1956]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1135,  0.1215, -0.0305,  ...,  0.0731,  0.0081, -0.0742],\n",
            "        [-0.0106,  0.1149, -0.0543,  ...,  0.0362,  0.0328,  0.0777],\n",
            "        [ 0.1377,  0.0917,  0.0528,  ..., -0.0411, -0.1664,  0.0543],\n",
            "        ...,\n",
            "        [ 0.2364, -0.1500, -0.1374,  ..., -0.0477, -0.2157, -0.1352],\n",
            "        [ 0.0545, -0.0472,  0.0338,  ...,  0.2460,  0.2207,  0.0045],\n",
            "        [ 0.1472, -0.2808, -0.1822,  ..., -0.0024, -0.2924,  0.0059]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1842,  0.0746, -0.1119,  ...,  0.1397, -0.2963, -0.3268],\n",
            "         [ 0.0887, -0.1901,  0.2426,  ..., -0.0967, -0.1748,  0.0501],\n",
            "         [ 0.1949,  0.4554,  0.1693,  ...,  0.2205, -0.1456, -0.1284],\n",
            "         ...,\n",
            "         [ 0.2364, -0.1500, -0.1374,  ..., -0.0477, -0.2157, -0.1352],\n",
            "         [ 0.0545, -0.0472,  0.0338,  ...,  0.2460,  0.2207,  0.0045],\n",
            "         [ 0.1472, -0.2808, -0.1822,  ..., -0.0024, -0.2924,  0.0059]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 8.4300e-01,  2.1746e-01, -6.7243e-01,  ...,  6.8495e-01,\n",
            "         -8.5718e-01, -7.5591e-01],\n",
            "        [ 6.4392e-01, -4.5815e-02, -3.5998e-01,  ...,  2.8648e-01,\n",
            "         -6.2656e-01, -4.1996e-01],\n",
            "        [ 2.9645e-01,  6.0450e-01, -1.7511e-01,  ...,  3.0073e-01,\n",
            "         -2.2550e-01,  5.3242e-04],\n",
            "        ...,\n",
            "        [ 6.0541e-01,  9.2438e-02, -5.0225e-01,  ...,  3.1063e-01,\n",
            "         -5.6847e-01, -4.5429e-01],\n",
            "        [-1.9252e-02, -1.1769e-01,  1.7231e-01,  ..., -6.6704e-02,\n",
            "          1.3055e-01,  8.6197e-02],\n",
            "        [ 5.9553e-01, -1.6165e-01, -3.6663e-01,  ...,  2.3724e-01,\n",
            "         -5.1362e-01, -3.7270e-01]], grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0263, -0.0945, -0.0111,  ..., -0.0518,  0.0512,  0.1162],\n",
            "        [ 0.0263, -0.0945, -0.0111,  ..., -0.0518,  0.0512,  0.1162],\n",
            "        [ 0.1146,  0.1222, -0.0306,  ...,  0.0729,  0.0084, -0.0740],\n",
            "        ...,\n",
            "        [ 0.1026,  0.3212, -0.0432,  ...,  0.1227, -0.0255, -0.0532],\n",
            "        [-0.0793, -0.1170, -0.2008,  ...,  0.0870,  0.0818, -0.0823],\n",
            "        [ 0.1818,  0.0504, -0.1623,  ...,  0.1682, -0.1573,  0.0492]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0524,  0.5356, -0.1416,  ...,  0.1288, -0.2519, -0.1526],\n",
            "         [ 0.2601, -0.3773, -0.1985,  ...,  0.0291, -0.3053, -0.0311],\n",
            "         [ 0.3200, -0.0939, -0.1137,  ...,  0.3039, -0.1476, -0.2414],\n",
            "         ...,\n",
            "         [ 0.1349, -0.1335, -0.2311,  ..., -0.0570, -0.3030,  0.0072],\n",
            "         [ 0.0706,  0.0680, -0.1735,  ...,  0.3032, -0.1371,  0.0403],\n",
            "         [ 0.1755, -0.0137, -0.2953,  ...,  0.1179, -0.2945, -0.0169]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3247,  0.4133, -0.3473,  ...,  0.2923, -0.4673, -0.4187],\n",
            "        [ 0.8029, -0.0012, -0.6192,  ...,  0.4742, -0.7396, -0.5900],\n",
            "        [ 0.6561,  0.1292, -0.4741,  ...,  0.4168, -0.5507, -0.5513],\n",
            "        ...,\n",
            "        [ 0.5304, -0.1349, -0.3004,  ...,  0.1518, -0.4293, -0.3071],\n",
            "        [ 0.0357,  0.3780, -0.2908,  ...,  0.2172, -0.0917,  0.1535],\n",
            "        [ 0.6634,  0.1923, -0.5755,  ...,  0.4708, -0.6641, -0.4993]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0254, -0.0851,  0.0054,  ...,  0.1550,  0.0296,  0.0205],\n",
            "        [-0.1654, -0.1087,  0.0772,  ..., -0.0254,  0.0386, -0.0701],\n",
            "        [-0.0644,  0.0246, -0.1319,  ...,  0.0608,  0.0707, -0.0671],\n",
            "        ...,\n",
            "        [ 0.0819,  0.5022, -0.1763,  ...,  0.1390, -0.2111, -0.1328],\n",
            "        [ 0.2883,  0.0247, -0.2042,  ...,  0.0422, -0.0987, -0.2085],\n",
            "        [ 0.2067, -0.3782, -0.1398,  ..., -0.1478, -0.1203, -0.0223]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2067, -0.3782, -0.1398,  ..., -0.1478, -0.1203, -0.0223],\n",
            "         [ 0.2397,  0.0411, -0.1719,  ..., -0.0817, -0.0830, -0.1286],\n",
            "         [ 0.3921, -0.2359,  0.0130,  ..., -0.0072, -0.1675, -0.0716],\n",
            "         ...,\n",
            "         [ 0.3131, -0.1706,  0.0395,  ...,  0.2734, -0.2836,  0.0269],\n",
            "         [ 0.0819,  0.5022, -0.1763,  ...,  0.1390, -0.2111, -0.1328],\n",
            "         [ 0.2883,  0.0247, -0.2042,  ...,  0.0422, -0.0987, -0.2085]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5894, -0.0781, -0.4200,  ...,  0.2299, -0.5084, -0.3625],\n",
            "        [ 0.6992,  0.0486, -0.5349,  ...,  0.2798, -0.5418, -0.5069],\n",
            "        [ 0.7635,  0.0672, -0.4589,  ...,  0.4016, -0.6524, -0.5469],\n",
            "        ...,\n",
            "        [ 0.7476,  0.1784, -0.4650,  ...,  0.5034, -0.6579, -0.4386],\n",
            "        [ 0.5409,  0.3682, -0.5043,  ...,  0.3858, -0.5846, -0.5336],\n",
            "        [ 0.7926,  0.2651, -0.6319,  ...,  0.4191, -0.6631, -0.6493]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0264, -0.0942, -0.0113,  ..., -0.0517,  0.0511,  0.1159],\n",
            "        [ 0.0484, -0.0686, -0.2045,  ..., -0.1083,  0.0555,  0.0392],\n",
            "        [-0.0888,  0.0130,  0.0013,  ...,  0.1502,  0.1275, -0.0142],\n",
            "        ...,\n",
            "        [ 0.2838, -0.0895, -0.3038,  ..., -0.0413, -0.2964, -0.0388],\n",
            "        [ 0.2658, -0.1235, -0.1256,  ...,  0.2201, -0.2084, -0.3385],\n",
            "        [ 0.0408, -0.3447,  0.0159,  ..., -0.1215, -0.3306,  0.0401]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2658, -0.1235, -0.1256,  ...,  0.2201, -0.2084, -0.3385],\n",
            "         [ 0.0408, -0.3447,  0.0159,  ..., -0.1215, -0.3306,  0.0401],\n",
            "         [-0.2294,  0.5200,  0.0453,  ...,  0.3347, -0.0139,  0.1010],\n",
            "         ...,\n",
            "         [-0.0007,  0.3357, -0.0052,  ...,  0.1175,  0.0332,  0.0333],\n",
            "         [-0.1782, -0.4671, -0.0379,  ...,  0.1332, -0.2492, -0.0789],\n",
            "         [ 0.2838, -0.0895, -0.3038,  ..., -0.0413, -0.2964, -0.0388]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.7888,  0.1576, -0.5711,  ...,  0.5126, -0.6893, -0.7104],\n",
            "        [ 0.4225, -0.1575, -0.3534,  ...,  0.1772, -0.5126, -0.3221],\n",
            "        [-0.2877,  0.6598, -0.0067,  ...,  0.2019,  0.1021,  0.3258],\n",
            "        ...,\n",
            "        [-0.0518,  0.4467, -0.0063,  ...,  0.1292,  0.1783,  0.2306],\n",
            "        [ 0.2574, -0.1461, -0.3703,  ...,  0.3624, -0.5266, -0.2936],\n",
            "        [ 0.6278,  0.1876, -0.5057,  ...,  0.3282, -0.6107, -0.4373]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1023,  0.0435, -0.0491,  ..., -0.0505, -0.1175, -0.0234],\n",
            "        [ 0.1176,  0.1234, -0.0308,  ...,  0.0724,  0.0092, -0.0733],\n",
            "        [ 0.1176,  0.1234, -0.0308,  ...,  0.0724,  0.0092, -0.0733],\n",
            "        ...,\n",
            "        [-0.0581,  0.2273, -0.4486,  ...,  0.1577, -0.1648, -0.1553],\n",
            "        [ 0.4289,  0.1052, -0.0122,  ...,  0.3266, -0.2329, -0.3337],\n",
            "        [ 0.1478,  0.1757, -0.1278,  ..., -0.0244, -0.1121, -0.1829]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0581,  0.2273, -0.4486,  ...,  0.1577, -0.1648, -0.1553],\n",
            "         [ 0.4289,  0.1052, -0.0122,  ...,  0.3266, -0.2329, -0.3337],\n",
            "         [ 0.1478,  0.1757, -0.1278,  ..., -0.0244, -0.1121, -0.1829],\n",
            "         ...,\n",
            "         [ 0.1109,  0.0180,  0.0681,  ...,  0.1055, -0.0313,  0.0726],\n",
            "         [-0.0694,  0.1844,  0.1174,  ...,  0.0151, -0.0907, -0.3374],\n",
            "         [ 0.1772, -0.1102,  0.0314,  ..., -0.0244,  0.1479,  0.0274]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1755,  0.2053, -0.4080,  ...,  0.2669, -0.3427, -0.1495],\n",
            "        [ 0.3713,  0.2533, -0.2038,  ...,  0.2238, -0.3303, -0.3167],\n",
            "        [ 0.2128,  0.2594, -0.2730,  ...,  0.1362, -0.2436, -0.1493],\n",
            "        ...,\n",
            "        [ 0.1205,  0.0517, -0.0500,  ...,  0.1652, -0.1078,  0.0053],\n",
            "        [ 0.0819,  0.1189, -0.0957,  ...,  0.1689, -0.2150, -0.2389],\n",
            "        [ 0.1324,  0.0066, -0.0711,  ...,  0.0638, -0.0330, -0.0533]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0269, -0.0931, -0.0119,  ..., -0.0511,  0.0508,  0.1150],\n",
            "        [ 0.0269, -0.0931, -0.0119,  ..., -0.0511,  0.0508,  0.1150],\n",
            "        [-0.0782, -0.1375,  0.0263,  ..., -0.1059, -0.0939,  0.0097],\n",
            "        ...,\n",
            "        [ 0.2439,  0.2584, -0.0598,  ...,  0.1650, -0.0509, -0.0583],\n",
            "        [ 0.0610,  0.3230, -0.0418,  ...,  0.0680,  0.0686,  0.0090],\n",
            "        [-0.1479,  0.0754,  0.1386,  ...,  0.0410,  0.1243,  0.1214]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1674,  0.4961, -0.1545,  ...,  0.0755, -0.2042, -0.1761],\n",
            "         [ 0.1674,  0.4961, -0.1545,  ...,  0.0755, -0.2042, -0.1761],\n",
            "         [ 0.1793, -0.1353, -0.0992,  ...,  0.1213, -0.1332,  0.1309],\n",
            "         ...,\n",
            "         [ 0.1682,  0.0248, -0.0945,  ...,  0.0210,  0.0776,  0.2208],\n",
            "         [ 0.2281,  0.5943,  0.0400,  ...,  0.0595, -0.1971, -0.1648],\n",
            "         [ 0.0231,  0.4497, -0.0613,  ...,  0.0653,  0.0649, -0.0516]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5982,  0.5567, -0.5781,  ...,  0.4818, -0.6152, -0.5183],\n",
            "        [ 0.5982,  0.5567, -0.5781,  ...,  0.4818, -0.6152, -0.5183],\n",
            "        [ 0.4721,  0.2158, -0.4114,  ...,  0.4358, -0.4745, -0.0786],\n",
            "        ...,\n",
            "        [ 0.0152, -0.1002,  0.0587,  ..., -0.1278,  0.0802,  0.0982],\n",
            "        [ 0.6755,  0.4990, -0.4316,  ...,  0.3710, -0.5923, -0.4932],\n",
            "        [-0.1144,  0.6421, -0.0424,  ...,  0.0264,  0.2281,  0.2901]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0747, -0.1136, -0.1007,  ..., -0.0853,  0.0360,  0.0140],\n",
            "        [ 0.1202,  0.1245, -0.0321,  ...,  0.0726,  0.0084, -0.0736],\n",
            "        [ 0.1202,  0.1245, -0.0321,  ...,  0.0726,  0.0084, -0.0736],\n",
            "        ...,\n",
            "        [ 0.0363, -0.3066, -0.3624,  ...,  0.2176, -0.3953, -0.2311],\n",
            "        [ 0.1544,  0.1992, -0.3790,  ...,  0.1832, -0.2996, -0.3641],\n",
            "        [-0.0699, -0.1398,  0.0191,  ...,  0.0282, -0.1271,  0.0843]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1397, -0.1575,  0.1412,  ..., -0.1487, -0.0397, -0.1517],\n",
            "         [ 0.3917, -0.0913,  0.0179,  ...,  0.3977, -0.3149, -0.4618],\n",
            "         [ 0.2494, -0.0925, -0.0452,  ...,  0.2886, -0.3398, -0.1367],\n",
            "         ...,\n",
            "         [ 0.1880, -0.2719, -0.4319,  ...,  0.1833, -0.1249, -0.1246],\n",
            "         [ 0.4352, -0.3599, -0.1954,  ...,  0.1149, -0.3550, -0.2537],\n",
            "         [ 0.1366,  0.0656, -0.0712,  ...,  0.2119, -0.3428, -0.2481]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3808, -0.0778, -0.1341,  ...,  0.0888, -0.2962, -0.2861],\n",
            "        [ 0.5570,  0.1499, -0.3148,  ...,  0.4137, -0.5425, -0.5509],\n",
            "        [ 0.7026,  0.1319, -0.4980,  ...,  0.5074, -0.7136, -0.5157],\n",
            "        ...,\n",
            "        [ 0.6365,  0.0621, -0.6222,  ...,  0.4088, -0.6220, -0.5753],\n",
            "        [ 0.7801, -0.0664, -0.5318,  ...,  0.4680, -0.7144, -0.6407],\n",
            "        [ 0.6591,  0.2086, -0.5113,  ...,  0.5085, -0.6724, -0.6172]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2522, -0.0770,  0.0212,  ...,  0.2361, -0.1717, -0.1781],\n",
            "        [ 0.2522, -0.0770,  0.0212,  ...,  0.2361, -0.1717, -0.1781],\n",
            "        [-0.0912,  0.1787, -0.0879,  ..., -0.0974,  0.0247,  0.0713],\n",
            "        ...,\n",
            "        [ 0.2322,  0.5865,  0.0016,  ...,  0.0809, -0.0190,  0.2332],\n",
            "        [ 0.2322,  0.5865,  0.0016,  ...,  0.0809, -0.0190,  0.2332],\n",
            "        [ 0.1385,  0.0171,  0.1911,  ...,  0.2987, -0.1380,  0.0226]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2322,  0.5865,  0.0016,  ...,  0.0809, -0.0190,  0.2332],\n",
            "         [ 0.2322,  0.5865,  0.0016,  ...,  0.0809, -0.0190,  0.2332],\n",
            "         [ 0.1385,  0.0171,  0.1911,  ...,  0.2987, -0.1380,  0.0226],\n",
            "         ...,\n",
            "         [ 0.1305, -0.0284,  0.2468,  ...,  0.0421, -0.1439,  0.0050],\n",
            "         [ 0.2894, -0.5046, -0.3098,  ..., -0.0073, -0.1341, -0.1161],\n",
            "         [ 0.0014,  0.1450,  0.1597,  ...,  0.0956, -0.2339,  0.0789]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0972,  0.8432, -0.1580,  ...,  0.1855,  0.2753,  0.6020],\n",
            "        [-0.0972,  0.8432, -0.1580,  ...,  0.1855,  0.2753,  0.6020],\n",
            "        [-0.1069,  0.4509, -0.1680,  ...,  0.2806,  0.0713,  0.3589],\n",
            "        ...,\n",
            "        [ 0.6243,  0.1207, -0.3200,  ...,  0.4137, -0.5579, -0.4584],\n",
            "        [ 0.6167, -0.1208, -0.5409,  ...,  0.3510, -0.5060, -0.5802],\n",
            "        [ 0.4368,  0.3279, -0.3411,  ...,  0.3832, -0.5169, -0.3580]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0671,  0.0249, -0.0177,  ...,  0.0096,  0.2223,  0.1399],\n",
            "        [ 0.0277, -0.0919, -0.0129,  ..., -0.0505,  0.0503,  0.1140],\n",
            "        [ 0.0497, -0.0689, -0.2055,  ..., -0.1085,  0.0555,  0.0387],\n",
            "        ...,\n",
            "        [ 0.2673,  0.4848, -0.0693,  ...,  0.0589, -0.2310, -0.1742],\n",
            "        [ 0.1498,  0.3035, -0.0219,  ...,  0.0392, -0.1154, -0.1171],\n",
            "        [ 0.2680,  0.1482, -0.0932,  ...,  0.1332, -0.2061, -0.1820]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.0969, -0.0098, -0.1050,  ..., -0.0283, -0.2063,  0.1356],\n",
            "         [ 0.3478, -0.6134, -0.3874,  ..., -0.1770, -0.2132, -0.0689],\n",
            "         [ 0.1634,  0.5403, -0.1366,  ...,  0.1308, -0.1904, -0.1834],\n",
            "         ...,\n",
            "         [ 0.2673,  0.4848, -0.0693,  ...,  0.0589, -0.2310, -0.1742],\n",
            "         [ 0.1498,  0.3035, -0.0219,  ...,  0.0392, -0.1154, -0.1171],\n",
            "         [ 0.2680,  0.1482, -0.0932,  ...,  0.1332, -0.2061, -0.1820]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3923,  0.1622, -0.4482,  ...,  0.3365, -0.5933, -0.2718],\n",
            "        [ 0.6237, -0.1346, -0.5500,  ...,  0.2829, -0.4900, -0.3780],\n",
            "        [ 0.4710,  0.4753, -0.3727,  ...,  0.3342, -0.4913, -0.4761],\n",
            "        ...,\n",
            "        [ 0.0637,  0.6092, -0.2058,  ...,  0.1532, -0.0669,  0.1408],\n",
            "        [ 0.0388,  0.4967, -0.0287,  ...,  0.0988,  0.0927,  0.1741],\n",
            "        [ 0.8436,  0.3690, -0.6399,  ...,  0.6037, -0.7904, -0.7162]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0278, -0.0914, -0.0131,  ..., -0.0504,  0.0502,  0.1137],\n",
            "        [ 0.0278, -0.0914, -0.0131,  ..., -0.0504,  0.0502,  0.1137],\n",
            "        [ 0.0278, -0.0914, -0.0131,  ..., -0.0504,  0.0502,  0.1137],\n",
            "        ...,\n",
            "        [ 0.3635,  0.4640,  0.0911,  ...,  0.1577, -0.1203, -0.0703],\n",
            "        [ 0.0946, -0.3202, -0.1190,  ..., -0.1076, -0.0309, -0.1143],\n",
            "        [ 0.0545,  0.1601,  0.1084,  ...,  0.2015, -0.1556, -0.0917]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0248,  0.2854, -0.0746,  ...,  0.1675, -0.1732, -0.1491],\n",
            "         [ 0.3635,  0.4640,  0.0911,  ...,  0.1577, -0.1203, -0.0703],\n",
            "         [ 0.0946, -0.3202, -0.1190,  ..., -0.1076, -0.0309, -0.1143],\n",
            "         ...,\n",
            "         [ 0.0288,  0.3923, -0.0133,  ...,  0.0814,  0.1127,  0.2028],\n",
            "         [ 0.1005, -0.3003, -0.2359,  ...,  0.1730, -0.1367, -0.0354],\n",
            "         [ 0.3458, -0.0445, -0.0604,  ..., -0.0547, -0.0182, -0.0541]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0064,  0.4038, -0.2672,  ...,  0.2458, -0.2618, -0.0573],\n",
            "        [ 0.5791,  0.4891, -0.2638,  ...,  0.3548, -0.3920, -0.3370],\n",
            "        [ 0.4951,  0.0591, -0.4633,  ...,  0.2845, -0.4449, -0.3604],\n",
            "        ...,\n",
            "        [-0.1983,  0.6822,  0.0940,  ..., -0.0570,  0.2944,  0.4749],\n",
            "        [ 0.5659,  0.0370, -0.5600,  ...,  0.4055, -0.5516, -0.4519],\n",
            "        [ 0.6779,  0.0869, -0.4516,  ...,  0.2697, -0.4253, -0.4871]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0281, -0.0909, -0.0134,  ..., -0.0501,  0.0501,  0.1133],\n",
            "        [ 0.2548, -0.0774,  0.0202,  ...,  0.2365, -0.1736, -0.1802],\n",
            "        [ 0.0411, -0.0914,  0.1636,  ...,  0.1346, -0.0483, -0.0664],\n",
            "        ...,\n",
            "        [ 0.2346, -0.2342, -0.2759,  ...,  0.2787, -0.4065, -0.0519],\n",
            "        [ 0.1208,  0.0768, -0.0876,  ...,  0.1057, -0.2448, -0.2129],\n",
            "        [ 0.2695,  0.0437, -0.1853,  ...,  0.0310, -0.2061, -0.1362]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1794, -0.5068,  0.0061,  ...,  0.1701, -0.2699, -0.1725],\n",
            "         [ 0.4001,  0.5449, -0.3092,  ...,  0.1819, -0.0856, -0.1383],\n",
            "         [ 0.2149, -0.2964, -0.1414,  ...,  0.1031, -0.4524, -0.1675],\n",
            "         ...,\n",
            "         [ 0.3045,  0.4223,  0.0551,  ...,  0.3516, -0.0949, -0.1697],\n",
            "         [-0.0443, -0.0347, -0.0196,  ...,  0.0012,  0.0068,  0.1481],\n",
            "         [ 0.3045,  0.4223,  0.0551,  ...,  0.3516, -0.0949, -0.1697]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4779, -0.0424, -0.3583,  ...,  0.3563, -0.4910, -0.4179],\n",
            "        [ 0.1005,  0.7487, -0.3338,  ...,  0.1809, -0.0820,  0.0824],\n",
            "        [ 0.7199,  0.1585, -0.5755,  ...,  0.4328, -0.7060, -0.6409],\n",
            "        ...,\n",
            "        [-0.2622,  0.8154, -0.2573,  ...,  0.3620,  0.2822,  0.4869],\n",
            "        [-0.1592,  0.4197, -0.0940,  ...,  0.1225,  0.1726,  0.4109],\n",
            "        [-0.2622,  0.8154, -0.2573,  ...,  0.3620,  0.2822,  0.4869]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0648,  0.0228, -0.1319,  ...,  0.0600,  0.0711, -0.0663],\n",
            "        [ 0.2555, -0.0778,  0.0201,  ...,  0.2364, -0.1739, -0.1806],\n",
            "        [ 0.0412, -0.0914,  0.1637,  ...,  0.1347, -0.0482, -0.0664],\n",
            "        ...,\n",
            "        [ 0.3766,  0.3792, -0.0267,  ...,  0.1571, -0.0380, -0.1696],\n",
            "        [ 0.2302,  0.6024,  0.0092,  ...,  0.0835,  0.0130,  0.2520],\n",
            "        [ 0.0041, -0.1555,  0.0095,  ...,  0.0760,  0.1089,  0.2106]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1417, -0.0489, -0.1652,  ...,  0.0822, -0.3606, -0.3345],\n",
            "         [ 0.2302,  0.6024,  0.0092,  ...,  0.0835,  0.0130,  0.2520],\n",
            "         [ 0.2905, -0.0940,  0.2042,  ...,  0.2218, -0.3586,  0.1027],\n",
            "         ...,\n",
            "         [ 0.3766,  0.3792, -0.0267,  ...,  0.1571, -0.0380, -0.1696],\n",
            "         [ 0.2302,  0.6024,  0.0092,  ...,  0.0835,  0.0130,  0.2520],\n",
            "         [ 0.0041, -0.1555,  0.0095,  ...,  0.0760,  0.1089,  0.2106]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.7103,  0.1233, -0.5566,  ...,  0.4350, -0.6747, -0.6144],\n",
            "        [-0.1733,  0.8591, -0.0614,  ...,  0.0963,  0.3130,  0.6388],\n",
            "        [ 0.6587,  0.2621, -0.2708,  ...,  0.4360, -0.6207, -0.2850],\n",
            "        ...,\n",
            "        [ 0.4904,  0.5352, -0.3573,  ...,  0.3431, -0.3130, -0.1614],\n",
            "        [-0.1733,  0.8591, -0.0614,  ...,  0.0963,  0.3130,  0.6388],\n",
            "        [-0.1322,  0.3329, -0.2535,  ...,  0.2544,  0.1296,  0.4381]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1557,  0.1635, -0.0405,  ...,  0.0072, -0.0659, -0.1104],\n",
            "        [-0.0440,  0.0905, -0.1697,  ...,  0.1204,  0.0856,  0.0444],\n",
            "        [-0.1581, -0.1351, -0.2053,  ...,  0.1653,  0.0463,  0.1219],\n",
            "        ...,\n",
            "        [ 0.2359, -0.0114, -0.1611,  ..., -0.0404, -0.0640, -0.1695],\n",
            "        [ 0.2180,  0.0844, -0.2066,  ..., -0.0362, -0.1900,  0.1097],\n",
            "        [ 0.3161, -0.0479, -0.0534,  ...,  0.2308, -0.1948, -0.2870]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2359, -0.0114, -0.1611,  ..., -0.0404, -0.0640, -0.1695],\n",
            "         [ 0.2180,  0.0844, -0.2066,  ..., -0.0362, -0.1900,  0.1097],\n",
            "         [ 0.3161, -0.0479, -0.0534,  ...,  0.2308, -0.1948, -0.2870],\n",
            "         ...,\n",
            "         [ 0.1059,  0.1076, -0.0731,  ..., -0.0224, -0.0632, -0.1486],\n",
            "         [ 0.1042,  0.2092, -0.1038,  ...,  0.2351, -0.1776, -0.1684],\n",
            "         [ 0.1064, -0.1757, -0.1293,  ..., -0.0658, -0.2880, -0.1351]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6227,  0.1229, -0.4944,  ...,  0.2608, -0.4593, -0.4594],\n",
            "        [ 0.4717,  0.2764, -0.4578,  ...,  0.2772, -0.4087, -0.0809],\n",
            "        [ 0.4057,  0.1242, -0.2756,  ...,  0.2568, -0.3754, -0.3538],\n",
            "        ...,\n",
            "        [ 0.4122,  0.1493, -0.3299,  ...,  0.1509, -0.3686, -0.3471],\n",
            "        [ 0.2354,  0.3095, -0.3299,  ...,  0.3251, -0.4309, -0.2890],\n",
            "        [ 0.4470,  0.1270, -0.4284,  ...,  0.2171, -0.5094, -0.4077]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0285, -0.0895, -0.0143,  ..., -0.0495,  0.0498,  0.1124],\n",
            "        [-0.0766, -0.0219,  0.0602,  ...,  0.0232,  0.1474, -0.0174],\n",
            "        [ 0.2568, -0.0778,  0.0200,  ...,  0.2367, -0.1749, -0.1815],\n",
            "        ...,\n",
            "        [ 0.4722, -0.1070, -0.0995,  ..., -0.1705, -0.1472, -0.1759],\n",
            "        [-0.0672,  0.1901, -0.1710,  ..., -0.0110, -0.0042,  0.0877],\n",
            "        [ 0.1463, -0.2487,  0.2529,  ...,  0.2055, -0.0638,  0.1141]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.4607, -0.4120, -0.1804,  ...,  0.1074, -0.3309, -0.2276],\n",
            "         [ 0.4722, -0.1070, -0.0995,  ..., -0.1705, -0.1472, -0.1759],\n",
            "         [-0.0672,  0.1901, -0.1710,  ..., -0.0110, -0.0042,  0.0877],\n",
            "         ...,\n",
            "         [ 0.2487,  0.0728,  0.0202,  ...,  0.0150, -0.1741, -0.2163],\n",
            "         [ 0.0474,  0.0088,  0.1484,  ...,  0.0007, -0.1798, -0.0378],\n",
            "         [ 0.0469,  0.1981, -0.0519,  ...,  0.0963,  0.0047, -0.1459]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.7875, -0.0977, -0.5264,  ...,  0.4657, -0.7051, -0.6391],\n",
            "        [ 0.7209,  0.1450, -0.4377,  ...,  0.2274, -0.5138, -0.4968],\n",
            "        [ 0.1626,  0.2149, -0.3997,  ...,  0.2091, -0.2638, -0.1116],\n",
            "        ...,\n",
            "        [ 0.4329,  0.1894, -0.2326,  ...,  0.2315, -0.3846, -0.3188],\n",
            "        [ 0.2042,  0.2500, -0.2307,  ...,  0.2792, -0.3268, -0.2305],\n",
            "        [ 0.0336,  0.2219, -0.0187,  ...,  0.0606,  0.0497,  0.0307]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1278,  0.1264, -0.0370,  ...,  0.0735,  0.0050, -0.0750],\n",
            "        [ 0.0587,  0.1197, -0.0236,  ..., -0.0836, -0.1485, -0.1041],\n",
            "        [ 0.1278,  0.1264, -0.0370,  ...,  0.0735,  0.0050, -0.0750],\n",
            "        ...,\n",
            "        [ 0.3350,  0.0094, -0.1464,  ..., -0.0329, -0.0884, -0.1679],\n",
            "        [ 0.2526, -0.2892, -0.0588,  ..., -0.1184, -0.1960, -0.0666],\n",
            "        [ 0.3333,  0.2403, -0.1476,  ..., -0.0197, -0.0745, -0.1439]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0489,  0.1737, -0.0789,  ...,  0.1146, -0.2723, -0.2467],\n",
            "         [ 0.2826, -0.0008, -0.2916,  ...,  0.1413, -0.1969, -0.2332],\n",
            "         [ 0.2381,  0.2084, -0.2008,  ...,  0.0948, -0.3004, -0.1876],\n",
            "         ...,\n",
            "         [ 0.3350,  0.0094, -0.1464,  ..., -0.0329, -0.0884, -0.1679],\n",
            "         [ 0.2526, -0.2892, -0.0588,  ..., -0.1184, -0.1960, -0.0666],\n",
            "         [ 0.3333,  0.2403, -0.1476,  ..., -0.0197, -0.0745, -0.1439]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4431,  0.4016, -0.4407,  ...,  0.4540, -0.5600, -0.4410],\n",
            "        [ 0.4245,  0.1145, -0.4004,  ...,  0.3620, -0.4418, -0.3313],\n",
            "        [ 0.5651,  0.4106, -0.4805,  ...,  0.3771, -0.5562, -0.4143],\n",
            "        ...,\n",
            "        [ 0.8268,  0.1323, -0.6108,  ...,  0.3991, -0.6795, -0.6451],\n",
            "        [ 0.6017, -0.0028, -0.4002,  ...,  0.2366, -0.4662, -0.3992],\n",
            "        [ 0.7691,  0.3320, -0.5558,  ...,  0.3741, -0.5987, -0.5773]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0019,  0.0498,  0.2221,  ..., -0.0586,  0.0158,  0.0768],\n",
            "        [ 0.0990,  0.0972, -0.0032,  ..., -0.0878, -0.0349,  0.0058],\n",
            "        [ 0.0413, -0.0914,  0.1635,  ...,  0.1352, -0.0481, -0.0665],\n",
            "        ...,\n",
            "        [ 0.4473, -0.3003, -0.1162,  ..., -0.0753, -0.2935, -0.1702],\n",
            "        [ 0.2043,  0.1243,  0.0364,  ...,  0.2330, -0.0390, -0.0062],\n",
            "        [ 0.0951,  0.3349,  0.0456,  ...,  0.1273, -0.1713, -0.0802]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2140, -0.0132,  0.1065,  ...,  0.3597, -0.1081,  0.0769],\n",
            "         [ 0.4608, -0.1698, -0.1651,  ...,  0.0510, -0.3985, -0.0556],\n",
            "         [-0.0821,  0.3572,  0.2117,  ...,  0.0535, -0.1695, -0.0526],\n",
            "         ...,\n",
            "         [ 0.4473, -0.3003, -0.1162,  ..., -0.0753, -0.2935, -0.1702],\n",
            "         [ 0.2043,  0.1243,  0.0364,  ...,  0.2330, -0.0390, -0.0062],\n",
            "         [ 0.0951,  0.3349,  0.0456,  ...,  0.1273, -0.1713, -0.0802]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0168,  0.2899, -0.1270,  ...,  0.2469, -0.1000,  0.1015],\n",
            "        [ 0.7815,  0.1161, -0.5410,  ...,  0.4176, -0.7163, -0.5014],\n",
            "        [-0.1622,  0.6079, -0.1624,  ...,  0.2147, -0.0427,  0.1674],\n",
            "        ...,\n",
            "        [ 0.7281, -0.0145, -0.4684,  ...,  0.3097, -0.6470, -0.5483],\n",
            "        [-0.0944,  0.4018, -0.0616,  ...,  0.2108,  0.0466,  0.1728],\n",
            "        [-0.0873,  0.5876, -0.1137,  ...,  0.2150, -0.0276,  0.2285]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0288, -0.0884, -0.0148,  ..., -0.0490,  0.0496,  0.1117],\n",
            "        [-0.0442,  0.0039,  0.0564,  ..., -0.0725,  0.1463,  0.1060],\n",
            "        [ 0.0288, -0.0884, -0.0148,  ..., -0.0490,  0.0496,  0.1117],\n",
            "        ...,\n",
            "        [-0.1497,  0.1829, -0.0669,  ...,  0.1493, -0.1473, -0.0530],\n",
            "        [ 0.0907, -0.0064,  0.1290,  ...,  0.0287,  0.0183,  0.1251],\n",
            "        [ 0.2508, -0.0369, -0.0427,  ..., -0.0517, -0.0209, -0.0216]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3598, -0.3185, -0.2215,  ...,  0.0005, -0.1207, -0.2213],\n",
            "         [ 0.0021,  0.1361,  0.0669,  ...,  0.2731, -0.1864,  0.0620],\n",
            "         [ 0.1700, -0.1064, -0.1433,  ...,  0.1030, -0.2710, -0.2061],\n",
            "         ...,\n",
            "         [ 0.1536,  0.0290, -0.1589,  ..., -0.1491, -0.0108,  0.0030],\n",
            "         [-0.0841,  0.2458,  0.1216,  ...,  0.1249, -0.0673,  0.1009],\n",
            "         [ 0.1479,  0.0710, -0.0736,  ...,  0.1438, -0.1962, -0.2022]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.8511, -0.0055, -0.6786,  ...,  0.4431, -0.7263, -0.7012],\n",
            "        [-0.0928,  0.3382, -0.0759,  ...,  0.1792, -0.0306,  0.2349],\n",
            "        [ 0.8213,  0.1057, -0.6998,  ...,  0.6357, -0.8438, -0.7459],\n",
            "        ...,\n",
            "        [ 0.4679,  0.2005, -0.4324,  ...,  0.2401, -0.3371, -0.0864],\n",
            "        [-0.0770,  0.4334, -0.1125,  ...,  0.2535, -0.0325,  0.2374],\n",
            "        [ 0.6907,  0.3464, -0.5213,  ...,  0.5376, -0.6670, -0.5993]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0289, -0.0882, -0.0150,  ..., -0.0489,  0.0496,  0.1116],\n",
            "        [ 0.0020,  0.0493,  0.2210,  ..., -0.0584,  0.0150,  0.0762],\n",
            "        [ 0.0289, -0.0882, -0.0150,  ..., -0.0489,  0.0496,  0.1116],\n",
            "        ...,\n",
            "        [ 0.2008,  0.5059, -0.1466,  ...,  0.0736, -0.1733, -0.1248],\n",
            "        [ 0.3144, -0.1906,  0.1061,  ..., -0.1595, -0.1467,  0.0267],\n",
            "        [ 0.3063, -0.1324, -0.0980,  ...,  0.2287, -0.1775, -0.3204]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1861,  0.4611,  0.2056,  ...,  0.0419,  0.1418,  0.0290],\n",
            "         [ 0.0464, -0.1519,  0.3346,  ..., -0.1175, -0.0559,  0.1455],\n",
            "         [ 0.0243,  0.3097, -0.2186,  ...,  0.2505, -0.1124,  0.0046],\n",
            "         ...,\n",
            "         [ 0.2008,  0.5059, -0.1466,  ...,  0.0736, -0.1733, -0.1248],\n",
            "         [ 0.3144, -0.1906,  0.1061,  ..., -0.1595, -0.1467,  0.0267],\n",
            "         [ 0.3063, -0.1324, -0.0980,  ...,  0.2287, -0.1775, -0.3204]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.2352,  0.7299,  0.0534,  ...,  0.1813,  0.3100,  0.4552],\n",
            "        [ 0.2978,  0.2421, -0.1504,  ...,  0.2807, -0.2791, -0.1408],\n",
            "        [-0.0335,  0.4309, -0.2025,  ...,  0.0752,  0.0188,  0.0857],\n",
            "        ...,\n",
            "        [ 0.5924,  0.6260, -0.5759,  ...,  0.4786, -0.5756, -0.4655],\n",
            "        [ 0.3828,  0.0443, -0.1500,  ...,  0.1088, -0.2436, -0.0965],\n",
            "        [ 0.7864,  0.2131, -0.5516,  ...,  0.5093, -0.6657, -0.7186]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.2306,  0.0333,  0.0112,  ...,  0.0939,  0.1005, -0.1239],\n",
            "        [ 0.2576, -0.0774,  0.0206,  ...,  0.2375, -0.1758, -0.1823],\n",
            "        [ 0.0289, -0.0882, -0.0152,  ..., -0.0490,  0.0496,  0.1118],\n",
            "        ...,\n",
            "        [-0.0414, -0.0274, -0.3402,  ...,  0.2254, -0.1297,  0.0077],\n",
            "        [ 0.3049,  0.0228,  0.0272,  ...,  0.0213, -0.1874, -0.2244],\n",
            "        [-0.0966, -0.1758,  0.0103,  ...,  0.0095, -0.0374,  0.1027]])\n",
            "Output of encoder at last step:tensor([[[-0.0156,  0.0543, -0.0640,  ..., -0.0950,  0.0338, -0.0056],\n",
            "         [-0.0414, -0.0274, -0.3402,  ...,  0.2254, -0.1297,  0.0077],\n",
            "         [ 0.3049,  0.0228,  0.0272,  ...,  0.0213, -0.1874, -0.2244],\n",
            "         ...,\n",
            "         [ 0.3569, -0.0702,  0.0843,  ...,  0.2513, -0.3090, -0.2857],\n",
            "         [ 0.2415,  0.0369,  0.0014,  ..., -0.0046, -0.1803, -0.1479],\n",
            "         [-0.1037,  0.0092, -0.2458,  ...,  0.0581, -0.0644,  0.0119]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0883,  0.1954, -0.2820,  ...,  0.1470, -0.1117, -0.0280],\n",
            "        [ 0.1608,  0.2092, -0.4361,  ...,  0.2660, -0.2221, -0.1768],\n",
            "        [ 0.5656,  0.2204, -0.3154,  ...,  0.2978, -0.4889, -0.4353],\n",
            "        ...,\n",
            "        [ 0.3846,  0.1306, -0.2247,  ...,  0.2871, -0.4544, -0.3696],\n",
            "        [ 0.1718,  0.0630, -0.1155,  ...,  0.1040, -0.1785, -0.1340],\n",
            "        [-0.0479,  0.0403, -0.2315,  ...,  0.0668, -0.0670,  0.0230]])\n",
            "Output of encoder at every step:tensor([[-0.1173,  0.0085, -0.2112,  ...,  0.1043,  0.0130, -0.0346],\n",
            "        [ 0.2576, -0.0774,  0.0206,  ...,  0.2375, -0.1758, -0.1823],\n",
            "        [-0.0157,  0.0610,  0.1236,  ..., -0.0086, -0.0250, -0.1507],\n",
            "        ...,\n",
            "        [-0.1165,  0.1227, -0.3139,  ...,  0.2011, -0.0839, -0.0731],\n",
            "        [ 0.1274, -0.0752, -0.0655,  ...,  0.1335, -0.1417, -0.0202],\n",
            "        [-0.0057, -0.1092, -0.3640,  ...,  0.1732, -0.1299, -0.0414]])\n",
            "Output of encoder at last step:tensor([[[ 0.0294,  0.2456, -0.0538,  ...,  0.0554, -0.0637, -0.0333],\n",
            "         [-0.0967, -0.1099, -0.3541,  ...,  0.1855, -0.0033, -0.0196],\n",
            "         [-0.0529,  0.1292, -0.2522,  ...,  0.1869, -0.0422, -0.2132],\n",
            "         ...,\n",
            "         [-0.0682, -0.0254, -0.2858,  ...,  0.1943, -0.1352, -0.0726],\n",
            "         [ 0.2896, -0.0274, -0.0945,  ...,  0.0602, -0.2242, -0.2422],\n",
            "         [-0.0329, -0.1550, -0.3071,  ...,  0.3359, -0.2287, -0.3693]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0719,  0.2328, -0.0627,  ...,  0.1541, -0.0491, -0.0383],\n",
            "        [ 0.0245,  0.1954, -0.4314,  ...,  0.2781, -0.0999, -0.1137],\n",
            "        [ 0.0048,  0.2405, -0.3117,  ...,  0.1925, -0.0977, -0.1360],\n",
            "        ...,\n",
            "        [ 0.2250,  0.1721, -0.4553,  ...,  0.3387, -0.3792, -0.2758],\n",
            "        [ 0.5198,  0.1913, -0.3762,  ...,  0.3154, -0.4257, -0.4730],\n",
            "        [ 0.3197,  0.2015, -0.5123,  ...,  0.4179, -0.5318, -0.5056]])\n",
            "Output of encoder at every step:tensor([[ 0.0289, -0.0882, -0.0152,  ..., -0.0490,  0.0496,  0.1118],\n",
            "        [ 0.2576, -0.0774,  0.0206,  ...,  0.2375, -0.1758, -0.1823],\n",
            "        [-0.0913,  0.1790, -0.0858,  ..., -0.0974,  0.0254,  0.0716],\n",
            "        ...,\n",
            "        [-0.2043, -0.0010, -0.1335,  ...,  0.0887,  0.0591,  0.1184],\n",
            "        [-0.0441, -0.1037, -0.0547,  ...,  0.1333, -0.0481, -0.0520],\n",
            "        [ 0.1134,  0.0902,  0.2825,  ...,  0.4417, -0.2291,  0.1016]])\n",
            "Output of encoder at last step:tensor([[[-0.1022, -0.1133, -0.3992,  ...,  0.1838, -0.1103, -0.1078],\n",
            "         [ 0.0902, -0.2026, -0.3062,  ...,  0.2468, -0.1204, -0.1253],\n",
            "         [ 0.2123,  0.2243, -0.1248,  ...,  0.1480, -0.2601, -0.2842],\n",
            "         ...,\n",
            "         [ 0.0897,  0.0212, -0.0917,  ...,  0.0805, -0.1129, -0.0483],\n",
            "         [-0.0410, -0.1388, -0.2285,  ...,  0.1738,  0.0211,  0.1064],\n",
            "         [-0.0474,  0.2988,  0.1750,  ...,  0.0197, -0.0130,  0.0604]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4366,  0.3005, -0.6414,  ...,  0.4508, -0.5828, -0.5638],\n",
            "        [ 0.5170,  0.0582, -0.5650,  ...,  0.3964, -0.5009, -0.4719],\n",
            "        [ 0.6909,  0.5809, -0.5873,  ...,  0.5623, -0.6879, -0.6116],\n",
            "        ...,\n",
            "        [ 0.4799,  0.2561, -0.4592,  ...,  0.4357, -0.4494, -0.4463],\n",
            "        [-0.0245,  0.1756, -0.3470,  ...,  0.2195, -0.0049,  0.0950],\n",
            "        [-0.1032,  0.2831,  0.0417,  ...,  0.0609,  0.0533,  0.1320]])\n",
            "Output of encoder at every step:tensor([[ 0.1294,  0.1269, -0.0384,  ...,  0.0740,  0.0040, -0.0755],\n",
            "        [-0.0852,  0.1100,  0.0594,  ..., -0.0774,  0.0910,  0.0496],\n",
            "        [ 0.0289, -0.0882, -0.0152,  ..., -0.0490,  0.0496,  0.1118],\n",
            "        ...,\n",
            "        [ 0.0834, -0.1073, -0.1121,  ...,  0.0887, -0.1640, -0.0132],\n",
            "        [ 0.1710, -0.1172,  0.1337,  ..., -0.0019, -0.0015, -0.1316],\n",
            "        [-0.0006,  0.2817,  0.1620,  ...,  0.0800,  0.1173,  0.1966]])\n",
            "Output of encoder at last step:tensor([[[ 0.5171, -0.0008,  0.0053,  ...,  0.1163, -0.1166,  0.0393],\n",
            "         [ 0.0745,  0.3901, -0.1243,  ...,  0.0840, -0.1474, -0.1943],\n",
            "         [ 0.0649,  0.2143, -0.1851,  ...,  0.1038,  0.0234,  0.0577],\n",
            "         ...,\n",
            "         [ 0.3490, -0.1248, -0.1810,  ...,  0.3280, -0.3057, -0.0554],\n",
            "         [ 0.0236, -0.0545, -0.1303,  ...,  0.0957, -0.1720, -0.1927],\n",
            "         [ 0.0961,  0.2787, -0.0666,  ...,  0.0672, -0.1640, -0.0353]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6139,  0.0638, -0.2734,  ...,  0.3014, -0.4182, -0.3813],\n",
            "        [ 0.3634,  0.5027, -0.4575,  ...,  0.4072, -0.3776, -0.3291],\n",
            "        [-0.1475,  0.4824, -0.1544,  ..., -0.0021,  0.1745,  0.3410],\n",
            "        ...,\n",
            "        [ 0.4360,  0.1727, -0.3682,  ...,  0.2996, -0.3651, -0.3015],\n",
            "        [ 0.6054,  0.2957, -0.5958,  ...,  0.5679, -0.7133, -0.6717],\n",
            "        [ 0.1911,  0.5003, -0.3150,  ...,  0.3041, -0.1467,  0.0119]])\n",
            "Output of encoder at every step:tensor([[ 0.2576, -0.0774,  0.0206,  ...,  0.2375, -0.1758, -0.1823],\n",
            "        [ 0.0289, -0.0882, -0.0152,  ..., -0.0490,  0.0496,  0.1118],\n",
            "        [-0.1173,  0.0085, -0.2112,  ...,  0.1043,  0.0130, -0.0346],\n",
            "        ...,\n",
            "        [ 0.2068, -0.3355, -0.1611,  ..., -0.2571, -0.0653, -0.0343],\n",
            "        [-0.0934,  0.3526,  0.0922,  ...,  0.1690, -0.1914,  0.0013],\n",
            "        [ 0.1232, -0.0934,  0.0880,  ...,  0.3585, -0.3773, -0.0182]])\n",
            "Output of encoder at last step:tensor([[[ 0.0900,  0.3180,  0.0664,  ...,  0.3153, -0.0423,  0.0370],\n",
            "         [-0.1174,  0.1922,  0.3311,  ...,  0.1465,  0.0671,  0.0642],\n",
            "         [ 0.0970, -0.0488, -0.1583,  ...,  0.0933, -0.1068, -0.0527],\n",
            "         ...,\n",
            "         [-0.0006,  0.2817,  0.1620,  ...,  0.0800,  0.1173,  0.1966],\n",
            "         [ 0.1131, -0.2584, -0.0995,  ...,  0.1507, -0.2535, -0.2904],\n",
            "         [ 0.0675, -0.4703, -0.1720,  ..., -0.2680, -0.0836, -0.0302]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.3921,  0.3911, -0.3484,  ...,  0.4627, -0.4187, -0.2351],\n",
            "        [-0.2294,  0.5084, -0.0083,  ...,  0.2488,  0.1904,  0.3324],\n",
            "        [ 0.4237,  0.2613, -0.4510,  ...,  0.3567, -0.3593, -0.3426],\n",
            "        ...,\n",
            "        [-0.2089,  0.5908, -0.0554,  ...,  0.2289,  0.2606,  0.5568],\n",
            "        [ 0.5565,  0.1988, -0.4422,  ...,  0.4382, -0.5966, -0.5491],\n",
            "        [ 0.4424, -0.1971, -0.4834,  ...,  0.2069, -0.4506, -0.3023]])\n",
            "Output of encoder at every step:tensor([[ 0.0289, -0.0882, -0.0152,  ..., -0.0490,  0.0496,  0.1118],\n",
            "        [ 0.0289, -0.0882, -0.0152,  ..., -0.0490,  0.0496,  0.1118],\n",
            "        [ 0.0289, -0.0882, -0.0152,  ..., -0.0490,  0.0496,  0.1118],\n",
            "        ...,\n",
            "        [ 0.3368, -0.2751, -0.1238,  ...,  0.3665, -0.2186,  0.1468],\n",
            "        [ 0.2416, -0.3071, -0.1772,  ...,  0.3878, -0.4749, -0.1869],\n",
            "        [ 0.2416, -0.3071, -0.1772,  ...,  0.3878, -0.4749, -0.1869]])\n",
            "Output of encoder at last step:tensor([[[ 0.2416, -0.3071, -0.1772,  ...,  0.3878, -0.4749, -0.1869],\n",
            "         [ 0.2416, -0.3071, -0.1772,  ...,  0.3878, -0.4749, -0.1869],\n",
            "         [ 0.3368, -0.2751, -0.1238,  ...,  0.3665, -0.2186,  0.1468],\n",
            "         ...,\n",
            "         [ 0.0673,  0.3220, -0.0459,  ...,  0.0694,  0.0609, -0.0011],\n",
            "         [ 0.1252,  0.1552, -0.1317,  ...,  0.0891, -0.1469, -0.0017],\n",
            "         [ 0.0053,  0.0410,  0.2940,  ..., -0.0346,  0.0268,  0.0720]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.7520,  0.1281, -0.5807,  ...,  0.5918, -0.7618, -0.6585],\n",
            "        [ 0.7520,  0.1281, -0.5807,  ...,  0.5918, -0.7618, -0.6585],\n",
            "        [ 0.5533,  0.2514, -0.4706,  ...,  0.5569, -0.5447, -0.0624],\n",
            "        ...,\n",
            "        [-0.1326,  0.6056, -0.0058,  ...,  0.0019,  0.2966,  0.3501],\n",
            "        [ 0.4049,  0.3712, -0.5041,  ...,  0.4243, -0.4809, -0.3088],\n",
            "        [ 0.0399,  0.1934,  0.0355,  ...,  0.1360,  0.0296,  0.0330]])\n",
            "Output of encoder at every step:tensor([[ 0.0289, -0.0882, -0.0152,  ..., -0.0490,  0.0496,  0.1118],\n",
            "        [ 0.0289, -0.0882, -0.0152,  ..., -0.0490,  0.0496,  0.1118],\n",
            "        [ 0.0289, -0.0882, -0.0152,  ..., -0.0490,  0.0496,  0.1118],\n",
            "        ...,\n",
            "        [ 0.2416, -0.3071, -0.1772,  ...,  0.3878, -0.4749, -0.1869],\n",
            "        [ 0.2416, -0.3071, -0.1772,  ...,  0.3878, -0.4749, -0.1869],\n",
            "        [ 0.2416, -0.3071, -0.1772,  ...,  0.3878, -0.4749, -0.1869]])\n",
            "Output of encoder at last step:tensor([[[ 0.2416, -0.3071, -0.1772,  ...,  0.3878, -0.4749, -0.1869],\n",
            "         [ 0.2416, -0.3071, -0.1772,  ...,  0.3878, -0.4749, -0.1869],\n",
            "         [ 0.2416, -0.3071, -0.1772,  ...,  0.3878, -0.4749, -0.1869],\n",
            "         ...,\n",
            "         [ 0.2416, -0.3071, -0.1772,  ...,  0.3878, -0.4749, -0.1869],\n",
            "         [ 0.2416, -0.3071, -0.1772,  ...,  0.3878, -0.4749, -0.1869],\n",
            "         [ 0.2416, -0.3071, -0.1772,  ...,  0.3878, -0.4749, -0.1869]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.7520,  0.1281, -0.5807,  ...,  0.5918, -0.7618, -0.6585],\n",
            "        [ 0.7520,  0.1281, -0.5807,  ...,  0.5918, -0.7618, -0.6585],\n",
            "        [ 0.7520,  0.1281, -0.5807,  ...,  0.5918, -0.7618, -0.6585],\n",
            "        ...,\n",
            "        [ 0.7520,  0.1281, -0.5807,  ...,  0.5918, -0.7618, -0.6585],\n",
            "        [ 0.7520,  0.1281, -0.5807,  ...,  0.5918, -0.7618, -0.6585],\n",
            "        [ 0.7520,  0.1281, -0.5807,  ...,  0.5918, -0.7618, -0.6585]])\n",
            "\t Epoch: 8 | Train Loss: 0.051 | Train Acc: 99.16%\n",
            "\t Epoch: 8 | Val. Loss: 1.252 |  Val. Acc: 80.80% \n",
            "\n",
            "Output of encoder at every step:tensor([[ 0.0739,  0.0581, -0.1192,  ..., -0.0612,  0.0490,  0.0642],\n",
            "        [-0.0248,  0.0554,  0.0237,  ..., -0.0644, -0.0554,  0.1369],\n",
            "        [ 0.0289, -0.0882, -0.0152,  ..., -0.0490,  0.0496,  0.1118],\n",
            "        ...,\n",
            "        [ 0.0274,  0.3032, -0.1205,  ...,  0.1025, -0.0840, -0.1165],\n",
            "        [ 0.0039, -0.0166,  0.0861,  ...,  0.2640, -0.0909,  0.1830],\n",
            "        [ 0.1852,  0.2679, -0.1007,  ..., -0.0087, -0.1306, -0.0165]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0039, -0.0166,  0.0861,  ...,  0.2640, -0.0909,  0.1830],\n",
            "         [ 0.1852,  0.2679, -0.1007,  ..., -0.0087, -0.1306, -0.0165],\n",
            "         [ 0.1659, -0.0092, -0.1034,  ...,  0.1372, -0.2910, -0.3465],\n",
            "         ...,\n",
            "         [ 0.4008, -0.5234, -0.2343,  ...,  0.1430, -0.3029, -0.0786],\n",
            "         [ 0.0604,  0.1470, -0.1393,  ...,  0.2358, -0.0446, -0.0062],\n",
            "         [ 0.0274,  0.3032, -0.1205,  ...,  0.1025, -0.0840, -0.1165]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0146, -0.0605,  0.1241,  ..., -0.0039,  0.0104,  0.1654],\n",
            "        [ 0.5782,  0.4319, -0.5106,  ...,  0.3883, -0.5298, -0.4982],\n",
            "        [ 0.7956,  0.2752, -0.6449,  ...,  0.6375, -0.8240, -0.7622],\n",
            "        ...,\n",
            "        [ 0.7083, -0.0664, -0.5573,  ...,  0.4292, -0.6059, -0.4965],\n",
            "        [ 0.3164,  0.3871, -0.4389,  ...,  0.3890, -0.3111, -0.2385],\n",
            "        [ 0.4192,  0.5177, -0.5080,  ...,  0.4638, -0.4301, -0.2822]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0350, -0.0152, -0.0238,  ..., -0.0129,  0.0511, -0.0128],\n",
            "        [ 0.0290, -0.0884, -0.0153,  ..., -0.0491,  0.0497,  0.1119],\n",
            "        [ 0.0290, -0.0884, -0.0153,  ..., -0.0491,  0.0497,  0.1119],\n",
            "        ...,\n",
            "        [ 0.3246,  0.5479,  0.1771,  ...,  0.1834, -0.4359,  0.0816],\n",
            "        [ 0.1413, -0.0320, -0.1316,  ...,  0.1295, -0.1723, -0.0969],\n",
            "        [ 0.0981, -0.2477, -0.1167,  ...,  0.0856, -0.1906, -0.0228]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3246,  0.5479,  0.1771,  ...,  0.1834, -0.4359,  0.0816],\n",
            "         [ 0.1413, -0.0320, -0.1316,  ...,  0.1295, -0.1723, -0.0969],\n",
            "         [ 0.0981, -0.2477, -0.1167,  ...,  0.0856, -0.1906, -0.0228],\n",
            "         ...,\n",
            "         [ 0.1436,  0.1288, -0.1045,  ...,  0.1204, -0.2396, -0.0999],\n",
            "         [ 0.1479,  0.0252, -0.1161,  ...,  0.1238, -0.1505, -0.2994],\n",
            "         [ 0.0627,  0.4199, -0.0832,  ...,  0.1183, -0.0182, -0.0336]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0190,  0.7479, -0.1792,  ...,  0.2968, -0.2145,  0.3813],\n",
            "        [ 0.6797,  0.2934, -0.5782,  ...,  0.5340, -0.6603, -0.5602],\n",
            "        [ 0.6331, -0.0768, -0.5357,  ...,  0.4793, -0.6513, -0.4775],\n",
            "        ...,\n",
            "        [ 0.6020,  0.3792, -0.5302,  ...,  0.5043, -0.6563, -0.4675],\n",
            "        [ 0.7692,  0.2960, -0.6246,  ...,  0.6418, -0.7375, -0.7517],\n",
            "        [-0.1250,  0.6820, -0.1459,  ...,  0.0978,  0.1685,  0.3037]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0289, -0.0885, -0.0154,  ..., -0.0491,  0.0497,  0.1120],\n",
            "        [ 0.0571,  0.0102,  0.0856,  ...,  0.1720, -0.0301,  0.0688],\n",
            "        [ 0.0289, -0.0885, -0.0154,  ..., -0.0491,  0.0497,  0.1120],\n",
            "        ...,\n",
            "        [ 0.0085,  0.2323, -0.0632,  ...,  0.0809,  0.0255,  0.1105],\n",
            "        [ 0.0093,  0.4241,  0.0076,  ...,  0.0859,  0.0797,  0.1370],\n",
            "        [ 0.2025, -0.1247, -0.0551,  ..., -0.0230, -0.0862,  0.0401]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0860,  0.4136, -0.0703,  ...,  0.0671,  0.0220, -0.0273],\n",
            "         [ 0.3157,  0.1733, -0.0753,  ...,  0.1844, -0.1570, -0.3006],\n",
            "         [ 0.3403, -0.3179, -0.0397,  ..., -0.0616, -0.0283, -0.0504],\n",
            "         ...,\n",
            "         [ 0.2496, -0.0321, -0.0338,  ..., -0.0626,  0.0032, -0.0447],\n",
            "         [ 0.3922,  0.2563, -0.1079,  ...,  0.1329, -0.1500, -0.1676],\n",
            "         [-0.0339,  0.0458,  0.2911,  ..., -0.0653,  0.2134,  0.2231]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.1578,  0.6506,  0.0716,  ..., -0.1371,  0.2293,  0.3493],\n",
            "        [ 0.4933,  0.3651, -0.3666,  ...,  0.4269, -0.4716, -0.4021],\n",
            "        [ 0.5645, -0.0008, -0.3770,  ...,  0.3318, -0.4090, -0.3171],\n",
            "        ...,\n",
            "        [ 0.4160,  0.0350, -0.2335,  ...,  0.0497, -0.1786, -0.2765],\n",
            "        [ 0.5772,  0.4042, -0.4021,  ...,  0.3334, -0.4718, -0.4268],\n",
            "        [-0.0315, -0.1757,  0.2744,  ..., -0.2300,  0.1511,  0.1006]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0288, -0.0885, -0.0156,  ..., -0.0491,  0.0497,  0.1120],\n",
            "        [ 0.0288, -0.0885, -0.0156,  ..., -0.0491,  0.0497,  0.1120],\n",
            "        [ 0.0288, -0.0885, -0.0156,  ..., -0.0491,  0.0497,  0.1120],\n",
            "        ...,\n",
            "        [ 0.2159, -0.2841, -0.1804,  ...,  0.3808, -0.4823, -0.1881],\n",
            "        [ 0.1215, -0.2272, -0.2357,  ...,  0.0235, -0.2521,  0.0062],\n",
            "        [ 0.2159, -0.2841, -0.1804,  ...,  0.3808, -0.4823, -0.1881]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2159, -0.2841, -0.1804,  ...,  0.3808, -0.4823, -0.1881],\n",
            "         [ 0.2159, -0.2841, -0.1804,  ...,  0.3808, -0.4823, -0.1881],\n",
            "         [ 0.2159, -0.2841, -0.1804,  ...,  0.3808, -0.4823, -0.1881],\n",
            "         ...,\n",
            "         [ 0.2159, -0.2841, -0.1804,  ...,  0.3808, -0.4823, -0.1881],\n",
            "         [ 0.1215, -0.2272, -0.2357,  ...,  0.0235, -0.2521,  0.0062],\n",
            "         [ 0.2159, -0.2841, -0.1804,  ...,  0.3808, -0.4823, -0.1881]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.7400,  0.1097, -0.5768,  ...,  0.5853, -0.7580, -0.6556],\n",
            "        [ 0.7400,  0.1097, -0.5768,  ...,  0.5853, -0.7580, -0.6556],\n",
            "        [ 0.7400,  0.1097, -0.5768,  ...,  0.5853, -0.7580, -0.6556],\n",
            "        ...,\n",
            "        [ 0.7400,  0.1097, -0.5768,  ...,  0.5853, -0.7580, -0.6556],\n",
            "        [ 0.5344, -0.1779, -0.2989,  ...,  0.2184, -0.4676, -0.3011],\n",
            "        [ 0.7400,  0.1097, -0.5768,  ...,  0.5853, -0.7580, -0.6556]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0288, -0.0885, -0.0157,  ..., -0.0491,  0.0497,  0.1121],\n",
            "        [ 0.0288, -0.0885, -0.0157,  ..., -0.0491,  0.0497,  0.1121],\n",
            "        [ 0.2502, -0.0783,  0.0223,  ...,  0.2380, -0.1728, -0.1796],\n",
            "        ...,\n",
            "        [ 0.0246,  0.4241, -0.0645,  ...,  0.0653,  0.0394, -0.0788],\n",
            "        [ 0.0929,  0.4693,  0.0721,  ...,  0.2377, -0.1824, -0.0201],\n",
            "        [ 0.1784,  0.2356,  0.0891,  ...,  0.1667,  0.0413,  0.0441]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1303, -0.1895, -0.1117,  ...,  0.1338, -0.2459, -0.1774],\n",
            "         [ 0.0918,  0.5064, -0.1430,  ...,  0.1214, -0.2455, -0.1426],\n",
            "         [ 0.1759,  0.1962,  0.0378,  ...,  0.2352, -0.2861, -0.0048],\n",
            "         ...,\n",
            "         [ 0.0321, -0.0533,  0.1058,  ..., -0.0874,  0.1276,  0.0887],\n",
            "         [ 0.1586, -0.0042, -0.2685,  ...,  0.1176, -0.2694, -0.0010],\n",
            "         [ 0.0394, -0.0329,  0.0334,  ...,  0.2414,  0.2357, -0.0048]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.7135,  0.0784, -0.6056,  ...,  0.5392, -0.7298, -0.6439],\n",
            "        [ 0.3955,  0.3904, -0.3794,  ...,  0.3099, -0.5015, -0.4613],\n",
            "        [ 0.5396,  0.3835, -0.3886,  ...,  0.3875, -0.5173, -0.3293],\n",
            "        ...,\n",
            "        [-0.0153, -0.1360,  0.1997,  ..., -0.2241,  0.0960,  0.0634],\n",
            "        [ 0.5799,  0.2179, -0.5220,  ...,  0.4351, -0.6057, -0.4471],\n",
            "        [-0.0182, -0.1361,  0.1827,  ..., -0.0896,  0.1261,  0.0614]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0659, -0.2106, -0.1172,  ...,  0.0148, -0.1008,  0.0641],\n",
            "        [ 0.0288, -0.0886, -0.0158,  ..., -0.0490,  0.0497,  0.1121],\n",
            "        [-0.0637,  0.0220, -0.1306,  ...,  0.0594,  0.0714, -0.0662],\n",
            "        ...,\n",
            "        [ 0.0852, -0.2239, -0.1456,  ..., -0.0200, -0.1210,  0.0594],\n",
            "        [ 0.0733,  0.0316, -0.1330,  ...,  0.1857, -0.0230, -0.0512],\n",
            "        [ 0.1563,  0.1411, -0.1030,  ..., -0.0217, -0.2420, -0.0399]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0685,  0.3038,  0.0448,  ...,  0.1238, -0.1722, -0.0806],\n",
            "         [ 0.1815,  0.0297,  0.0909,  ...,  0.0483, -0.2476, -0.0757],\n",
            "         [ 0.0187,  0.0080,  0.2933,  ..., -0.1892, -0.1281,  0.0449],\n",
            "         ...,\n",
            "         [ 0.0852, -0.2239, -0.1456,  ..., -0.0200, -0.1210,  0.0594],\n",
            "         [ 0.0733,  0.0316, -0.1330,  ...,  0.1857, -0.0230, -0.0512],\n",
            "         [ 0.1563,  0.1411, -0.1030,  ..., -0.0217, -0.2420, -0.0399]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0750,  0.5366, -0.0960,  ...,  0.1956, -0.0416,  0.1900],\n",
            "        [ 0.4601,  0.1502, -0.2103,  ...,  0.2315, -0.4640, -0.3183],\n",
            "        [ 0.2699,  0.0493, -0.0051,  ...,  0.0398, -0.3009, -0.1548],\n",
            "        ...,\n",
            "        [ 0.4114, -0.0051, -0.3594,  ...,  0.2979, -0.4312, -0.2495],\n",
            "        [ 0.0596,  0.2898, -0.2059,  ...,  0.2336, -0.0840, -0.0396],\n",
            "        [ 0.4356,  0.2245, -0.3227,  ...,  0.2512, -0.4282, -0.3377]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0289, -0.0883, -0.0160,  ..., -0.0489,  0.0496,  0.1120],\n",
            "        [ 0.0289, -0.0883, -0.0160,  ..., -0.0489,  0.0496,  0.1120],\n",
            "        [ 0.0561,  0.0103,  0.0866,  ...,  0.1724, -0.0303,  0.0691],\n",
            "        ...,\n",
            "        [ 0.3469,  0.4215,  0.0926,  ...,  0.1564, -0.1139, -0.0617],\n",
            "        [ 0.0128,  0.2948, -0.0167,  ...,  0.0762,  0.1081,  0.1628],\n",
            "        [ 0.1683,  0.0028,  0.0430,  ...,  0.0442, -0.1469,  0.1311]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0128,  0.2948, -0.0167,  ...,  0.0762,  0.1081,  0.1628],\n",
            "         [ 0.1683,  0.0028,  0.0430,  ...,  0.0442, -0.1469,  0.1311],\n",
            "         [ 0.1513, -0.0946, -0.0719,  ...,  0.1945, -0.2808, -0.0430],\n",
            "         ...,\n",
            "         [ 0.0790,  0.3628, -0.0640,  ...,  0.0641,  0.0202, -0.0213],\n",
            "         [ 0.0074,  0.3701,  0.0050,  ...,  0.0800,  0.0589,  0.1113],\n",
            "         [-0.0293,  0.4867,  0.0790,  ...,  0.2263,  0.0481, -0.0391]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.1337,  0.4198,  0.1232,  ..., -0.1027,  0.2439,  0.3192],\n",
            "        [-0.0994,  0.3813, -0.0515,  ...,  0.1480,  0.0599,  0.3432],\n",
            "        [ 0.5104,  0.2275, -0.4559,  ...,  0.4508, -0.5984, -0.4265],\n",
            "        ...,\n",
            "        [-0.1442,  0.5617,  0.0902,  ..., -0.1555,  0.2235,  0.3195],\n",
            "        [-0.1325,  0.5269,  0.1333,  ..., -0.1215,  0.2201,  0.3713],\n",
            "        [-0.0776,  0.3652,  0.0409,  ...,  0.0636,  0.0256,  0.1090]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0291, -0.0881, -0.0162,  ..., -0.0487,  0.0495,  0.1118],\n",
            "        [ 0.2467, -0.0778,  0.0226,  ...,  0.2391, -0.1718, -0.1785],\n",
            "        [ 0.0630,  0.1684,  0.0088,  ..., -0.0316, -0.1513,  0.0177],\n",
            "        ...,\n",
            "        [ 0.1700, -0.2998, -0.2271,  ..., -0.0526, -0.2432,  0.0139],\n",
            "        [ 0.1586, -0.3655, -0.0836,  ..., -0.1468, -0.0911,  0.0020],\n",
            "        [ 0.1829, -0.0124, -0.0932,  ..., -0.0133, -0.0642, -0.1141]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1586, -0.3655, -0.0836,  ..., -0.1468, -0.0911,  0.0020],\n",
            "         [ 0.1829, -0.0124, -0.0932,  ..., -0.0133, -0.0642, -0.1141],\n",
            "         [ 0.1442, -0.0131, -0.1072,  ...,  0.0481, -0.1625, -0.1857],\n",
            "         ...,\n",
            "         [-0.0333, -0.1689, -0.0416,  ...,  0.1175, -0.2487,  0.0122],\n",
            "         [-0.0231,  0.2530,  0.1351,  ...,  0.0828,  0.1054,  0.1748],\n",
            "         [ 0.1700, -0.2998, -0.2271,  ..., -0.0526, -0.2432,  0.0139]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4545, -0.1147, -0.3073,  ...,  0.1585, -0.3839, -0.2407],\n",
            "        [ 0.5539,  0.0824, -0.3822,  ...,  0.2175, -0.4355, -0.4132],\n",
            "        [ 0.7008,  0.0960, -0.5599,  ...,  0.4807, -0.6886, -0.5988],\n",
            "        ...,\n",
            "        [ 0.2006, -0.0402, -0.1794,  ...,  0.2910, -0.3561, -0.1473],\n",
            "        [-0.1767,  0.5184, -0.0721,  ...,  0.2289,  0.2072,  0.4909],\n",
            "        [ 0.6094, -0.2065, -0.3353,  ...,  0.1600, -0.4740, -0.3709]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1348,  0.1281, -0.0401,  ...,  0.0734,  0.0044, -0.0751],\n",
            "        [ 0.0090,  0.0204,  0.1839,  ...,  0.0271,  0.0529,  0.2308],\n",
            "        [ 0.0292, -0.0879, -0.0164,  ..., -0.0486,  0.0494,  0.1116],\n",
            "        ...,\n",
            "        [ 0.0110, -0.1514,  0.1439,  ...,  0.2460, -0.4511, -0.1255],\n",
            "        [ 0.2691,  0.1345, -0.1269,  ..., -0.0220, -0.0733, -0.1351],\n",
            "        [ 0.1453, -0.2508,  0.2488,  ...,  0.2061, -0.0736,  0.1048]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2084,  0.1744, -0.1923,  ...,  0.0984, -0.3040, -0.1889],\n",
            "         [ 0.0110, -0.1514,  0.1439,  ...,  0.2460, -0.4511, -0.1255],\n",
            "         [ 0.2691,  0.1345, -0.1269,  ..., -0.0220, -0.0733, -0.1351],\n",
            "         ...,\n",
            "         [ 0.2307,  0.0775, -0.1837,  ..., -0.0444, -0.1086, -0.1624],\n",
            "         [ 0.2281,  0.4109, -0.0150,  ...,  0.1425, -0.1840,  0.0102],\n",
            "         [ 0.3255,  0.0097,  0.0327,  ...,  0.2542, -0.2478, -0.0102]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5622,  0.3495, -0.4721,  ...,  0.3706, -0.5635, -0.4476],\n",
            "        [ 0.5115,  0.1379, -0.3238,  ...,  0.4402, -0.6278, -0.4787],\n",
            "        [ 0.7325,  0.1945, -0.5251,  ...,  0.3476, -0.5846, -0.5531],\n",
            "        ...,\n",
            "        [ 0.6996,  0.1153, -0.5491,  ...,  0.3002, -0.5781, -0.5274],\n",
            "        [ 0.1478,  0.5519, -0.2993,  ...,  0.2950, -0.2171,  0.1851],\n",
            "        [ 0.4772,  0.0877, -0.2213,  ...,  0.2791, -0.4180, -0.2050]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0294, -0.0877, -0.0166,  ..., -0.0486,  0.0494,  0.1115],\n",
            "        [ 0.0294, -0.0877, -0.0166,  ..., -0.0486,  0.0494,  0.1115],\n",
            "        [ 0.0294, -0.0877, -0.0166,  ..., -0.0486,  0.0494,  0.1115],\n",
            "        ...,\n",
            "        [ 0.3463, -0.0687,  0.0345,  ..., -0.1089, -0.1863, -0.0614],\n",
            "        [ 0.0082,  0.1120,  0.3214,  ..., -0.0673,  0.0745,  0.0800],\n",
            "        [ 0.1655,  0.1749, -0.0560,  ...,  0.0504, -0.1760, -0.1267]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1655,  0.1749, -0.0560,  ...,  0.0504, -0.1760, -0.1267],\n",
            "         [ 0.0082,  0.1120,  0.3214,  ..., -0.0673,  0.0745,  0.0800],\n",
            "         [ 0.2075, -0.2853, -0.2034,  ...,  0.3805, -0.5059, -0.2146],\n",
            "         ...,\n",
            "         [ 0.2075, -0.2853, -0.2034,  ...,  0.3805, -0.5059, -0.2146],\n",
            "         [ 0.2075, -0.2853, -0.2034,  ...,  0.3805, -0.5059, -0.2146],\n",
            "         [ 0.2075, -0.2853, -0.2034,  ...,  0.3805, -0.5059, -0.2146]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.7339,  0.0687, -0.5293,  ...,  0.4716, -0.6863, -0.5670],\n",
            "        [-0.1687,  0.4421,  0.2327,  ..., -0.1198,  0.2099,  0.4609],\n",
            "        [ 0.7592,  0.0844, -0.5978,  ...,  0.5982, -0.7823, -0.6857],\n",
            "        ...,\n",
            "        [ 0.7592,  0.0844, -0.5978,  ...,  0.5982, -0.7823, -0.6857],\n",
            "        [ 0.7592,  0.0844, -0.5978,  ...,  0.5982, -0.7823, -0.6857],\n",
            "        [ 0.7592,  0.0844, -0.5978,  ...,  0.5982, -0.7823, -0.6857]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0346, -0.0536, -0.0021,  ..., -0.0577, -0.0753, -0.0984],\n",
            "        [ 0.0296, -0.0876, -0.0167,  ..., -0.0485,  0.0493,  0.1114],\n",
            "        [ 0.0479, -0.0689, -0.2024,  ..., -0.1085,  0.0582,  0.0411],\n",
            "        ...,\n",
            "        [ 0.2881, -0.0379, -0.0284,  ...,  0.2320, -0.2164, -0.1333],\n",
            "        [-0.1346,  0.0889, -0.0796,  ...,  0.1569,  0.1141, -0.2104],\n",
            "        [ 0.1726, -0.0504,  0.1662,  ...,  0.0746, -0.3683, -0.0302]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0851, -0.0950, -0.2909,  ...,  0.0887,  0.0238,  0.0037],\n",
            "         [-0.0040,  0.1156, -0.0473,  ...,  0.2251, -0.0520,  0.0048],\n",
            "         [ 0.1735, -0.0840,  0.0026,  ..., -0.1563, -0.3399, -0.1999],\n",
            "         ...,\n",
            "         [ 0.2092, -0.2059, -0.0193,  ...,  0.2670, -0.3062, -0.0894],\n",
            "         [ 0.0592,  0.0825, -0.1497,  ...,  0.0542,  0.0104,  0.2616],\n",
            "         [ 0.1664, -0.0801, -0.2895,  ...,  0.1402, -0.1969,  0.0834]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4583,  0.0812, -0.4644,  ...,  0.3692, -0.3555, -0.3577],\n",
            "        [ 0.0348,  0.3107, -0.1976,  ...,  0.1937, -0.0521,  0.0246],\n",
            "        [ 0.3698,  0.0276, -0.2408,  ...,  0.1434, -0.4467, -0.3561],\n",
            "        ...,\n",
            "        [ 0.6589, -0.0251, -0.4423,  ...,  0.4714, -0.6748, -0.4695],\n",
            "        [-0.0434,  0.3143, -0.1951,  ...,  0.1550, -0.0043,  0.2697],\n",
            "        [ 0.4772,  0.1720, -0.4733,  ...,  0.4277, -0.5158, -0.2394]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0298, -0.0875, -0.0169,  ..., -0.0485,  0.0493,  0.1113],\n",
            "        [-0.0980, -0.0818,  0.0276,  ..., -0.0264, -0.0398, -0.0811],\n",
            "        [ 0.0298, -0.0875, -0.0169,  ..., -0.0485,  0.0493,  0.1113],\n",
            "        ...,\n",
            "        [ 0.1065, -0.0087, -0.1396,  ...,  0.0512, -0.2652, -0.0845],\n",
            "        [ 0.0344, -0.0470,  0.1080,  ..., -0.0957,  0.1366,  0.0949],\n",
            "        [ 0.3137, -0.1516, -0.2278,  ...,  0.0742, -0.2485, -0.1354]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0962,  0.2984, -0.1231,  ...,  0.0747, -0.2142, -0.2278],\n",
            "         [ 0.0306,  0.3023,  0.2332,  ...,  0.0791,  0.0182,  0.2302],\n",
            "         [ 0.3908,  0.3485, -0.3932,  ...,  0.1770, -0.1635, -0.1993],\n",
            "         ...,\n",
            "         [ 0.1065, -0.0087, -0.1396,  ...,  0.0512, -0.2652, -0.0845],\n",
            "         [ 0.0344, -0.0470,  0.1080,  ..., -0.0957,  0.1366,  0.0949],\n",
            "         [ 0.3137, -0.1516, -0.2278,  ...,  0.0742, -0.2485, -0.1354]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6964,  0.2695, -0.6181,  ...,  0.5574, -0.7462, -0.6932],\n",
            "        [-0.1481,  0.5598,  0.1485,  ...,  0.1275,  0.2042,  0.3794],\n",
            "        [ 0.7374,  0.4229, -0.6298,  ...,  0.4183, -0.6281, -0.6475],\n",
            "        ...,\n",
            "        [ 0.5347,  0.0806, -0.4361,  ...,  0.3623, -0.5587, -0.4206],\n",
            "        [-0.0172, -0.1432,  0.2043,  ..., -0.2335,  0.0995,  0.0679],\n",
            "        [ 0.7202,  0.0990, -0.5233,  ...,  0.3615, -0.6437, -0.5079]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0300, -0.0873, -0.0171,  ..., -0.0484,  0.0493,  0.1112],\n",
            "        [-0.0640,  0.0219, -0.1299,  ...,  0.0595,  0.0714, -0.0661],\n",
            "        [-0.0030,  0.0071, -0.1862,  ..., -0.0032, -0.1316, -0.0108],\n",
            "        ...,\n",
            "        [ 0.1433, -0.0448, -0.0433,  ...,  0.2327, -0.1750, -0.1298],\n",
            "        [ 0.0480,  0.1692,  0.0286,  ..., -0.0184,  0.2630,  0.0458],\n",
            "        [ 0.3416, -0.0586, -0.2617,  ...,  0.1502, -0.3396,  0.0520]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0798, -0.1602, -0.0998,  ..., -0.0265, -0.0393, -0.0193],\n",
            "         [ 0.0261,  0.1930, -0.0865,  ...,  0.0959, -0.1294, -0.1233],\n",
            "         [ 0.0336,  0.4533, -0.0560,  ...,  0.0919, -0.0704, -0.1152],\n",
            "         ...,\n",
            "         [ 0.2676, -0.2838, -0.2936,  ...,  0.2606, -0.2755,  0.0813],\n",
            "         [ 0.2053, -0.0778, -0.1188,  ...,  0.0020, -0.0850, -0.1289],\n",
            "         [ 0.1813,  0.2148, -0.3322,  ...,  0.3151, -0.3269, -0.0293]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2995, -0.0607, -0.2874,  ...,  0.1418, -0.2818, -0.2398],\n",
            "        [ 0.2721,  0.1376, -0.2784,  ...,  0.3099, -0.3440, -0.2121],\n",
            "        [-0.0754,  0.4830,  0.0218,  ...,  0.0140,  0.1413,  0.2017],\n",
            "        ...,\n",
            "        [ 0.7700,  0.0490, -0.6163,  ...,  0.5878, -0.7366, -0.4641],\n",
            "        [ 0.6783,  0.0447, -0.4998,  ...,  0.3245, -0.5756, -0.5288],\n",
            "        [ 0.5267,  0.3311, -0.5114,  ...,  0.3704, -0.4967, -0.4163]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2472, -0.0776,  0.0211,  ...,  0.2391, -0.1702, -0.1780],\n",
            "        [ 0.1125, -0.0361, -0.0449,  ..., -0.1090, -0.0056,  0.1037],\n",
            "        [ 0.0302, -0.0872, -0.0173,  ..., -0.0484,  0.0492,  0.1111],\n",
            "        ...,\n",
            "        [-0.0537,  0.0784, -0.1722,  ...,  0.1920,  0.1880, -0.0182],\n",
            "        [ 0.1342, -0.0753, -0.0301,  ...,  0.1840, -0.2952, -0.1868],\n",
            "        [ 0.0390, -0.5140, -0.1034,  ..., -0.0265, -0.0426,  0.1094]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-6.2756e-02, -3.7440e-01, -2.1487e-01,  ...,  2.9266e-01,\n",
            "          -3.6030e-03, -6.2766e-02],\n",
            "         [ 1.3139e-01, -1.1526e-01, -3.9217e-02,  ...,  2.9349e-01,\n",
            "          -3.6929e-01, -1.1480e-01],\n",
            "         [ 2.5975e-01, -1.3402e-04,  2.8850e-02,  ...,  2.5025e-02,\n",
            "          -2.0204e-01, -2.3144e-01],\n",
            "         ...,\n",
            "         [ 4.3163e-01, -4.2273e-01, -1.7128e-01,  ...,  1.1219e-01,\n",
            "          -3.3520e-01, -2.2304e-01],\n",
            "         [ 4.3163e-01, -4.2273e-01, -1.7128e-01,  ...,  1.1219e-01,\n",
            "          -3.3520e-01, -2.2304e-01],\n",
            "         [ 1.9571e-01, -1.9260e-01, -2.2563e-01,  ...,  1.4980e-01,\n",
            "          -3.2991e-01,  2.8335e-02]]], grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1374, -0.1113, -0.3102,  ...,  0.2793, -0.1888, -0.2400],\n",
            "        [ 0.5907,  0.1450, -0.4423,  ...,  0.4643, -0.6231, -0.4934],\n",
            "        [ 0.5606,  0.1622, -0.3090,  ...,  0.2898, -0.5076, -0.4751],\n",
            "        ...,\n",
            "        [ 0.7787, -0.1071, -0.5161,  ...,  0.4602, -0.7039, -0.6386],\n",
            "        [ 0.7787, -0.1071, -0.5161,  ...,  0.4602, -0.7039, -0.6386],\n",
            "        [ 0.5648,  0.0894, -0.4696,  ...,  0.4258, -0.5905, -0.3537]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1419,  0.1306, -0.0420,  ...,  0.0723,  0.0051, -0.0743],\n",
            "        [ 0.2482, -0.0777,  0.0206,  ...,  0.2386, -0.1698, -0.1779],\n",
            "        [ 0.1419,  0.1306, -0.0420,  ...,  0.0723,  0.0051, -0.0743],\n",
            "        ...,\n",
            "        [ 0.0162,  0.1052, -0.4622,  ...,  0.2428, -0.4516, -0.2074],\n",
            "        [ 0.1240,  0.0732, -0.0529,  ...,  0.0742, -0.2553, -0.2356],\n",
            "        [ 0.1163, -0.1178, -0.1274,  ...,  0.1018, -0.2916, -0.2388]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3237, -0.0783, -0.0764,  ...,  0.0451, -0.2306, -0.0448],\n",
            "         [-0.0130,  0.0941,  0.0720,  ...,  0.3646, -0.2523, -0.2117],\n",
            "         [-0.0604,  0.0238,  0.1178,  ...,  0.3247, -0.3570, -0.1431],\n",
            "         ...,\n",
            "         [ 0.1685,  0.0885,  0.0295,  ...,  0.2298, -0.0657, -0.0261],\n",
            "         [ 0.4031, -0.2994, -0.1233,  ..., -0.0631, -0.3100, -0.1939],\n",
            "         [-0.0615, -0.0945, -0.1180,  ...,  0.1390,  0.0437,  0.0016]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6892,  0.2437, -0.4950,  ...,  0.3982, -0.6930, -0.5390],\n",
            "        [ 0.4436,  0.3244, -0.3742,  ...,  0.4877, -0.5723, -0.5789],\n",
            "        [ 0.4007,  0.3116, -0.3094,  ...,  0.4692, -0.5405, -0.4286],\n",
            "        ...,\n",
            "        [-0.0447,  0.2640, -0.0529,  ...,  0.1971, -0.0221,  0.0521],\n",
            "        [ 0.7339, -0.0357, -0.4760,  ...,  0.3124, -0.6701, -0.5768],\n",
            "        [-0.0817, -0.0295, -0.0079,  ...,  0.0664,  0.1098,  0.1374]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0307, -0.0869, -0.0177,  ..., -0.0485,  0.0491,  0.1110],\n",
            "        [ 0.0307, -0.0869, -0.0177,  ..., -0.0485,  0.0491,  0.1110],\n",
            "        [ 0.2495, -0.0778,  0.0200,  ...,  0.2382, -0.1695, -0.1780],\n",
            "        ...,\n",
            "        [ 0.2568,  0.2732, -0.0737,  ...,  0.1601, -0.0579, -0.0604],\n",
            "        [ 0.0438,  0.2666, -0.0347,  ...,  0.0676,  0.0665,  0.0019],\n",
            "        [ 0.1460, -0.0934, -0.0851,  ...,  0.1158, -0.0589, -0.2098]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0438,  0.2666, -0.0347,  ...,  0.0676,  0.0665,  0.0019],\n",
            "         [ 0.0049,  0.1892, -0.0175,  ...,  0.0551,  0.1586,  0.1051],\n",
            "         [ 0.2967,  0.4626, -0.0715,  ...,  0.2664, -0.2515, -0.2077],\n",
            "         ...,\n",
            "         [ 0.2568,  0.2732, -0.0737,  ...,  0.1601, -0.0579, -0.0604],\n",
            "         [ 0.0438,  0.2666, -0.0347,  ...,  0.0676,  0.0665,  0.0019],\n",
            "         [ 0.1460, -0.0934, -0.0851,  ...,  0.1158, -0.0589, -0.2098]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.1044,  0.4595,  0.0595,  ..., -0.0586,  0.2728,  0.2827],\n",
            "        [-0.0414, -0.0747,  0.1631,  ..., -0.1778,  0.1608,  0.1163],\n",
            "        [ 0.3699,  0.4501, -0.2872,  ...,  0.2831, -0.3628, -0.2100],\n",
            "        ...,\n",
            "        [-0.0029,  0.4048, -0.0190,  ...,  0.0522,  0.0114,  0.1742],\n",
            "        [-0.1044,  0.4595,  0.0595,  ..., -0.0586,  0.2728,  0.2827],\n",
            "        [ 0.5740,  0.0799, -0.4394,  ...,  0.3854, -0.5089, -0.6268]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.0640,  0.0219, -0.1297,  ...,  0.0597,  0.0714, -0.0659],\n",
            "        [ 0.0308, -0.0869, -0.0178,  ..., -0.0485,  0.0491,  0.1109],\n",
            "        [ 0.0308, -0.0869, -0.0178,  ..., -0.0485,  0.0491,  0.1109],\n",
            "        ...,\n",
            "        [ 0.1659,  0.1238, -0.0938,  ...,  0.0610, -0.2581, -0.1687],\n",
            "        [ 0.0497, -0.3009, -0.1151,  ..., -0.1087, -0.0191, -0.1083],\n",
            "        [ 0.3815,  0.5110,  0.0973,  ...,  0.1684, -0.1178, -0.0644]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3957,  0.1347, -0.1716,  ...,  0.0232, -0.1916, -0.3618],\n",
            "         [ 0.1659,  0.1238, -0.0938,  ...,  0.0610, -0.2581, -0.1687],\n",
            "         [ 0.0497, -0.3009, -0.1151,  ..., -0.1087, -0.0191, -0.1083],\n",
            "         ...,\n",
            "         [ 0.2581,  0.1704, -0.1351,  ..., -0.0347, -0.1613, -0.1221],\n",
            "         [ 0.0338,  0.1484, -0.0316,  ...,  0.0727,  0.0141, -0.1386],\n",
            "         [ 0.2301, -0.0633, -0.0614,  ..., -0.0500, -0.0195, -0.0686]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.7849,  0.4060, -0.5282,  ...,  0.3798, -0.6082, -0.6839],\n",
            "        [ 0.7782,  0.2668, -0.6053,  ...,  0.5228, -0.7864, -0.6636],\n",
            "        [ 0.4420, -0.0051, -0.4283,  ...,  0.2419, -0.4049, -0.3523],\n",
            "        ...,\n",
            "        [ 0.5735,  0.3746, -0.4450,  ...,  0.2626, -0.4672, -0.3672],\n",
            "        [-0.0124, -0.1084,  0.1554,  ..., -0.1711,  0.0917,  0.0268],\n",
            "        [ 0.5439, -0.0139, -0.3566,  ...,  0.1601, -0.3480, -0.4105]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0309, -0.0867, -0.0180,  ..., -0.0485,  0.0491,  0.1109],\n",
            "        [ 0.0309, -0.0867, -0.0180,  ..., -0.0485,  0.0491,  0.1109],\n",
            "        [ 0.0309, -0.0867, -0.0180,  ..., -0.0485,  0.0491,  0.1109],\n",
            "        ...,\n",
            "        [ 0.2281, -0.3096, -0.2142,  ...,  0.3809, -0.5072, -0.2284],\n",
            "        [ 0.2281, -0.3096, -0.2142,  ...,  0.3809, -0.5072, -0.2284],\n",
            "        [ 0.2281, -0.3096, -0.2142,  ...,  0.3809, -0.5072, -0.2284]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2281, -0.3096, -0.2142,  ...,  0.3809, -0.5072, -0.2284],\n",
            "         [ 0.2281, -0.3096, -0.2142,  ...,  0.3809, -0.5072, -0.2284],\n",
            "         [ 0.2281, -0.3096, -0.2142,  ...,  0.3809, -0.5072, -0.2284],\n",
            "         ...,\n",
            "         [ 0.2281, -0.3096, -0.2142,  ...,  0.3809, -0.5072, -0.2284],\n",
            "         [ 0.2281, -0.3096, -0.2142,  ...,  0.3809, -0.5072, -0.2284],\n",
            "         [ 0.2281, -0.3096, -0.2142,  ...,  0.3809, -0.5072, -0.2284]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.7802,  0.0779, -0.6091,  ...,  0.6037, -0.7938, -0.7086],\n",
            "        [ 0.7802,  0.0779, -0.6091,  ...,  0.6037, -0.7938, -0.7086],\n",
            "        [ 0.7802,  0.0779, -0.6091,  ...,  0.6037, -0.7938, -0.7086],\n",
            "        ...,\n",
            "        [ 0.7802,  0.0779, -0.6091,  ...,  0.6037, -0.7938, -0.7086],\n",
            "        [ 0.7802,  0.0779, -0.6091,  ...,  0.6037, -0.7938, -0.7086],\n",
            "        [ 0.7802,  0.0779, -0.6091,  ...,  0.6037, -0.7938, -0.7086]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0235,  0.1216, -0.0408,  ..., -0.2034,  0.0067,  0.0300],\n",
            "        [ 0.0310, -0.0865, -0.0181,  ..., -0.0484,  0.0490,  0.1108],\n",
            "        [ 0.2526, -0.0775,  0.0183,  ...,  0.2378, -0.1694, -0.1788],\n",
            "        ...,\n",
            "        [ 0.0373, -0.0116, -0.3853,  ...,  0.2015, -0.1947,  0.0548],\n",
            "        [ 0.1106,  0.2644, -0.0200,  ...,  0.0426, -0.1044, -0.1243],\n",
            "        [ 0.1102,  0.4056,  0.1941,  ...,  0.0213,  0.1505,  0.0261]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3504,  0.1394, -0.0485,  ...,  0.3148, -0.0937, -0.1248],\n",
            "         [ 0.5421, -0.2865, -0.0543,  ...,  0.3395, -0.3134, -0.4278],\n",
            "         [ 0.3788,  0.2901, -0.2236,  ...,  0.0203, -0.1387, -0.0820],\n",
            "         ...,\n",
            "         [ 0.0373, -0.0116, -0.3853,  ...,  0.2015, -0.1947,  0.0548],\n",
            "         [ 0.1106,  0.2644, -0.0200,  ...,  0.0426, -0.1044, -0.1243],\n",
            "         [ 0.1102,  0.4056,  0.1941,  ...,  0.0213,  0.1505,  0.0261]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6770,  0.2297, -0.4392,  ...,  0.4356, -0.4825, -0.4826],\n",
            "        [ 0.8261,  0.1208, -0.5229,  ...,  0.5259, -0.7641, -0.7521],\n",
            "        [ 0.5105,  0.4241, -0.3699,  ...,  0.2472, -0.4302, -0.3043],\n",
            "        ...,\n",
            "        [ 0.3267,  0.2156, -0.4850,  ...,  0.3135, -0.4175, -0.2291],\n",
            "        [ 0.0266,  0.3390,  0.0363,  ...,  0.0233,  0.0823,  0.1104],\n",
            "        [-0.2192,  0.6453,  0.0989,  ...,  0.1187,  0.2855,  0.3786]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0311, -0.0863, -0.0183,  ..., -0.0484,  0.0490,  0.1107],\n",
            "        [-0.1171,  0.1058, -0.1210,  ...,  0.2118,  0.0774, -0.0452],\n",
            "        [ 0.0311, -0.0863, -0.0183,  ..., -0.0484,  0.0490,  0.1107],\n",
            "        ...,\n",
            "        [ 0.0208,  0.2917, -0.0087,  ...,  0.0638,  0.0946,  0.1082],\n",
            "        [ 0.1952,  0.4203, -0.1715,  ...,  0.1256, -0.2688, -0.0084],\n",
            "        [ 0.2874, -0.2719, -0.0588,  ...,  0.1166, -0.2153, -0.1050]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0638, -0.4631, -0.3632,  ...,  0.2045, -0.3806, -0.2441],\n",
            "         [ 0.0202,  0.2441, -0.1647,  ...,  0.2156,  0.0980, -0.0637],\n",
            "         [ 0.0638, -0.4631, -0.3632,  ...,  0.2045, -0.3806, -0.2441],\n",
            "         ...,\n",
            "         [ 0.1292, -0.1880, -0.3411,  ...,  0.0863, -0.1102,  0.0211],\n",
            "         [ 0.1158,  0.0392,  0.0233,  ..., -0.1248, -0.0647,  0.2355],\n",
            "         [-0.1344, -0.0612, -0.0361,  ...,  0.2598, -0.1560,  0.0547]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6863, -0.0941, -0.6676,  ...,  0.5896, -0.8113, -0.6389],\n",
            "        [-0.1145,  0.3975, -0.1762,  ...,  0.1274,  0.0750,  0.1897],\n",
            "        [ 0.6863, -0.0941, -0.6676,  ...,  0.5896, -0.8113, -0.6389],\n",
            "        ...,\n",
            "        [ 0.3873,  0.0353, -0.4619,  ...,  0.3617, -0.4212, -0.2154],\n",
            "        [-0.0848,  0.4422, -0.1410,  ...,  0.1081,  0.0752,  0.4080],\n",
            "        [ 0.2096,  0.2277, -0.3298,  ...,  0.3605, -0.3602, -0.0911]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0206, -0.1006, -0.1896,  ..., -0.0425, -0.0348, -0.0222],\n",
            "        [ 0.0606, -0.0525, -0.0801,  ...,  0.0589,  0.0896,  0.0688],\n",
            "        [-0.2007, -0.0274,  0.0044,  ...,  0.0281,  0.0774,  0.0036],\n",
            "        ...,\n",
            "        [-0.0585, -0.0806,  0.1320,  ...,  0.2022, -0.3214,  0.0167],\n",
            "        [ 0.2290, -0.2995, -0.3240,  ...,  0.0527, -0.1940,  0.0265],\n",
            "        [ 0.0167,  0.3224, -0.1454,  ...,  0.1524, -0.1500, -0.2042]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2290, -0.2995, -0.3240,  ...,  0.0527, -0.1940,  0.0265],\n",
            "         [ 0.0167,  0.3224, -0.1454,  ...,  0.1524, -0.1500, -0.2042],\n",
            "         [ 0.1270, -0.1352, -0.1327,  ...,  0.1033, -0.2923, -0.2514],\n",
            "         ...,\n",
            "         [ 0.2820, -0.2700, -0.1872,  ...,  0.2981, -0.3153, -0.0301],\n",
            "         [ 0.3809, -0.0758, -0.1091,  ...,  0.1434, -0.1356,  0.0353],\n",
            "         [-0.0585, -0.0806,  0.1320,  ...,  0.2022, -0.3214,  0.0167]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4479, -0.1079, -0.5260,  ...,  0.2379, -0.4430, -0.3480],\n",
            "        [-0.1552,  0.5412, -0.2509,  ...,  0.2090, -0.1802, -0.0448],\n",
            "        [ 0.8065,  0.0308, -0.6864,  ...,  0.6294, -0.8528, -0.7402],\n",
            "        ...,\n",
            "        [ 0.6670,  0.1733, -0.5352,  ...,  0.5324, -0.6372, -0.4801],\n",
            "        [ 0.6841,  0.2494, -0.5009,  ...,  0.4386, -0.5868, -0.4768],\n",
            "        [ 0.3538,  0.1971, -0.2963,  ...,  0.3931, -0.5301, -0.2663]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0369, -0.0999,  0.1686,  ...,  0.1297, -0.0455, -0.0645],\n",
            "        [ 0.0312, -0.0860, -0.0184,  ..., -0.0482,  0.0490,  0.1105],\n",
            "        [-0.0183, -0.0883,  0.0801,  ...,  0.1097, -0.0905, -0.0695],\n",
            "        ...,\n",
            "        [ 0.3005, -0.5502,  0.1203,  ...,  0.3648, -0.2079, -0.0280],\n",
            "        [-0.1383, -0.1866,  0.0369,  ...,  0.0660,  0.1201,  0.0297],\n",
            "        [ 0.1971,  0.2155, -0.2204,  ...,  0.3351, -0.2050, -0.2896]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2918,  0.0772, -0.1870,  ...,  0.1368, -0.1549, -0.0656],\n",
            "         [ 0.0516, -0.0336, -0.3304,  ...,  0.1488, -0.2103, -0.1027],\n",
            "         [-0.1631, -0.1233,  0.0665,  ...,  0.1086, -0.0607,  0.1969],\n",
            "         ...,\n",
            "         [ 0.3005, -0.5502,  0.1203,  ...,  0.3648, -0.2079, -0.0280],\n",
            "         [-0.1383, -0.1866,  0.0369,  ...,  0.0660,  0.1201,  0.0297],\n",
            "         [ 0.1971,  0.2155, -0.2204,  ...,  0.3351, -0.2050, -0.2896]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.7906,  0.2703, -0.5734,  ...,  0.4807, -0.7190, -0.6115],\n",
            "        [ 0.3360,  0.2282, -0.5491,  ...,  0.3816, -0.4990, -0.2614],\n",
            "        [-0.2021,  0.2757, -0.1560,  ...,  0.2041,  0.0562,  0.4180],\n",
            "        ...,\n",
            "        [ 0.7081, -0.0461, -0.3983,  ...,  0.4613, -0.6381, -0.5509],\n",
            "        [-0.1445,  0.1797, -0.0528,  ...,  0.0960,  0.1074,  0.2120],\n",
            "        [ 0.4663,  0.2456, -0.4625,  ...,  0.4282, -0.4940, -0.4853]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.1710, -0.0622, -0.1315,  ..., -0.0107,  0.0513,  0.0468],\n",
            "        [ 0.1452,  0.1322, -0.0433,  ...,  0.0730,  0.0035, -0.0744],\n",
            "        [ 0.0312, -0.0860, -0.0185,  ..., -0.0482,  0.0490,  0.1105],\n",
            "        ...,\n",
            "        [-0.1188,  0.1103,  0.0391,  ..., -0.0598, -0.0011,  0.2875],\n",
            "        [-0.0958,  0.2418,  0.1488,  ...,  0.1173, -0.0514,  0.1169],\n",
            "        [ 0.2215, -0.3254,  0.0939,  ...,  0.1194, -0.2552, -0.2194]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0395,  0.2070, -0.0332,  ...,  0.0910,  0.0563,  0.1289],\n",
            "         [ 0.1161,  0.2208, -0.1068,  ...,  0.1772, -0.1943, -0.0796],\n",
            "         [ 0.4577, -0.3626, -0.1337,  ..., -0.0478, -0.3093, -0.2167],\n",
            "         ...,\n",
            "         [ 0.1593, -0.3038, -0.0831,  ...,  0.1075, -0.1876, -0.1370],\n",
            "         [-0.0494,  0.3028, -0.2847,  ...,  0.0248, -0.0591, -0.0408],\n",
            "         [ 0.4006, -0.1748, -0.1130,  ..., -0.0812, -0.2043, -0.1612]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0381, -0.0557,  0.1298,  ..., -0.1518,  0.1310,  0.1226],\n",
            "        [-0.0268,  0.6403, -0.3863,  ...,  0.3579, -0.0656,  0.2732],\n",
            "        [ 0.7897, -0.0411, -0.5107,  ...,  0.3503, -0.7093, -0.6375],\n",
            "        ...,\n",
            "        [ 0.7605, -0.1115, -0.5902,  ...,  0.5497, -0.7331, -0.6319],\n",
            "        [ 0.3724,  0.3911, -0.5892,  ...,  0.3353, -0.4892, -0.4109],\n",
            "        [ 0.6180,  0.1936, -0.4148,  ...,  0.2467, -0.4232, -0.3255]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0313, -0.0860, -0.0185,  ..., -0.0482,  0.0490,  0.1105],\n",
            "        [ 0.0313, -0.0860, -0.0185,  ..., -0.0482,  0.0490,  0.1105],\n",
            "        [ 0.0313, -0.0860, -0.0185,  ..., -0.0482,  0.0490,  0.1105],\n",
            "        ...,\n",
            "        [ 0.0198,  0.0112, -0.0577,  ...,  0.1246, -0.1703, -0.0192],\n",
            "        [ 0.0438,  0.1438, -0.0332,  ...,  0.0782, -0.0198, -0.0113],\n",
            "        [-0.0257,  0.0627,  0.1121,  ...,  0.0406, -0.1546, -0.0809]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3216, -0.3328,  0.0310,  ...,  0.2152, -0.2315, -0.1380],\n",
            "         [ 0.3645, -0.0906, -0.0404,  ...,  0.1359, -0.3761,  0.2036],\n",
            "         [ 0.2744,  0.0179, -0.1539,  ...,  0.0903, -0.1390, -0.2202],\n",
            "         ...,\n",
            "         [ 0.0438,  0.1438, -0.0332,  ...,  0.0782, -0.0198, -0.0113],\n",
            "         [-0.0257,  0.0627,  0.1121,  ...,  0.0406, -0.1546, -0.0809],\n",
            "         [ 0.1162,  0.4150, -0.1027,  ...,  0.0707, -0.1278, -0.1025]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6682, -0.0415, -0.3710,  ...,  0.3907, -0.5911, -0.4779],\n",
            "        [ 0.6405,  0.2133, -0.3917,  ...,  0.3939, -0.6222, -0.0553],\n",
            "        [ 0.7030,  0.1767, -0.4933,  ...,  0.4006, -0.6271, -0.5489],\n",
            "        ...,\n",
            "        [ 0.0026, -0.0301,  0.1464,  ..., -0.1200,  0.0675,  0.0710],\n",
            "        [ 0.1917,  0.1821, -0.1018,  ...,  0.2095, -0.2640, -0.0763],\n",
            "        [ 0.3098,  0.4708, -0.3799,  ...,  0.3594, -0.3240, -0.2378]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0313, -0.0859, -0.0185,  ..., -0.0482,  0.0490,  0.1104],\n",
            "        [ 0.0313, -0.0859, -0.0185,  ..., -0.0482,  0.0490,  0.1104],\n",
            "        [ 0.0313, -0.0859, -0.0185,  ..., -0.0482,  0.0490,  0.1104],\n",
            "        ...,\n",
            "        [ 0.2518, -0.3357, -0.2158,  ...,  0.3865, -0.5026, -0.2361],\n",
            "        [ 0.2518, -0.3357, -0.2158,  ...,  0.3865, -0.5026, -0.2361],\n",
            "        [ 0.2518, -0.3357, -0.2158,  ...,  0.3865, -0.5026, -0.2361]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2518, -0.3357, -0.2158,  ...,  0.3865, -0.5026, -0.2361],\n",
            "         [ 0.2518, -0.3357, -0.2158,  ...,  0.3865, -0.5026, -0.2361],\n",
            "         [ 0.2518, -0.3357, -0.2158,  ...,  0.3865, -0.5026, -0.2361],\n",
            "         ...,\n",
            "         [ 0.0741,  0.1663, -0.1235,  ...,  0.1643, -0.2253, -0.1748],\n",
            "         [ 0.3165,  0.0615, -0.1277,  ...,  0.2567, -0.1905,  0.0574],\n",
            "         [ 0.0412,  0.1542,  0.1104,  ...,  0.2022, -0.1256, -0.0815]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.7945,  0.0822, -0.6119,  ...,  0.6035, -0.7991, -0.7253],\n",
            "        [ 0.7945,  0.0822, -0.6119,  ...,  0.6035, -0.7991, -0.7253],\n",
            "        [ 0.7945,  0.0822, -0.6119,  ...,  0.6035, -0.7991, -0.7253],\n",
            "        ...,\n",
            "        [ 0.2965,  0.3112, -0.3982,  ...,  0.3447, -0.4868, -0.3717],\n",
            "        [ 0.7115,  0.2704, -0.5327,  ...,  0.5549, -0.6270, -0.4246],\n",
            "        [-0.0452, -0.0128,  0.1979,  ..., -0.0616,  0.0632, -0.0047]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0313, -0.0859, -0.0185,  ..., -0.0481,  0.0490,  0.1104],\n",
            "        [ 0.0313, -0.0859, -0.0185,  ..., -0.0481,  0.0490,  0.1104],\n",
            "        [ 0.0313, -0.0859, -0.0185,  ..., -0.0481,  0.0490,  0.1104],\n",
            "        ...,\n",
            "        [ 0.1445, -0.3841, -0.1169,  ...,  0.1396, -0.2235, -0.1937],\n",
            "        [ 0.4084, -0.0856, -0.0454,  ...,  0.0513, -0.2389, -0.0775],\n",
            "        [ 0.1470,  0.2533,  0.0835,  ...,  0.2375, -0.0447, -0.1178]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0738,  0.3471, -0.1058,  ...,  0.3617,  0.0689, -0.0314],\n",
            "         [ 0.0738,  0.3471, -0.1058,  ...,  0.3617,  0.0689, -0.0314],\n",
            "         [ 0.0738,  0.3471, -0.1058,  ...,  0.3617,  0.0689, -0.0314],\n",
            "         ...,\n",
            "         [ 0.1470,  0.4869, -0.1071,  ...,  0.1245, -0.1790, -0.1664],\n",
            "         [ 0.0373,  0.1081,  0.2986,  ...,  0.1753, -0.1665, -0.0407],\n",
            "         [ 0.2578,  0.2993, -0.0517,  ...,  0.1676,  0.0269,  0.0448]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.2613,  0.6673, -0.0557,  ...,  0.2298,  0.3001,  0.4451],\n",
            "        [-0.2613,  0.6673, -0.0557,  ...,  0.2298,  0.3001,  0.4451],\n",
            "        [-0.2613,  0.6673, -0.0557,  ...,  0.2298,  0.3001,  0.4451],\n",
            "        ...,\n",
            "        [ 0.4390,  0.4336, -0.3301,  ...,  0.3160, -0.4714, -0.4743],\n",
            "        [ 0.4223,  0.3248, -0.2653,  ...,  0.3602, -0.5387, -0.4175],\n",
            "        [-0.0813,  0.5358, -0.0589,  ...,  0.0917,  0.1122,  0.3756]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-2.5372e-02,  1.9643e-02, -8.2410e-02,  ..., -2.1122e-02,\n",
            "         -1.1671e-02, -9.1954e-05],\n",
            "        [ 3.1288e-02, -8.5871e-02, -1.8515e-02,  ..., -4.8128e-02,\n",
            "          4.8950e-02,  1.1032e-01],\n",
            "        [ 1.4180e-01,  1.3079e-01, -4.1533e-02,  ...,  7.3421e-02,\n",
            "          3.3303e-03, -7.3861e-02],\n",
            "        ...,\n",
            "        [ 1.2163e-01,  1.5263e-01, -1.0721e-01,  ...,  1.1754e-01,\n",
            "         -8.1713e-02, -3.4904e-01],\n",
            "        [ 2.2626e-01, -2.4285e-01, -5.4455e-02,  ...,  1.0962e-02,\n",
            "         -2.3955e-01, -2.1254e-01],\n",
            "        [ 3.0754e-01,  1.4428e-01, -8.6842e-02,  ..., -2.2229e-02,\n",
            "         -6.1516e-02, -1.2843e-01]], grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0268,  0.1279, -0.0176,  ...,  0.1566, -0.1306, -0.3614],\n",
            "         [ 0.1256, -0.1735, -0.1891,  ..., -0.1148, -0.1075,  0.0418],\n",
            "         [ 0.0632, -0.2684, -0.0313,  ...,  0.0863, -0.1872, -0.1176],\n",
            "         ...,\n",
            "         [ 0.1833,  0.5730,  0.0140,  ...,  0.0825,  0.0314,  0.2506],\n",
            "         [ 0.1833,  0.5730,  0.0140,  ...,  0.0825,  0.0314,  0.2506],\n",
            "         [ 0.1226, -0.0395,  0.1179,  ...,  0.2237, -0.0529,  0.1050]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5230,  0.4434, -0.4918,  ...,  0.4825, -0.6223, -0.7449],\n",
            "        [ 0.2130,  0.2849, -0.4320,  ...,  0.2582, -0.4547, -0.2401],\n",
            "        [ 0.5691,  0.0382, -0.4136,  ...,  0.4590, -0.5666, -0.5289],\n",
            "        ...,\n",
            "        [-0.1989,  0.8383,  0.0318,  ...,  0.0030,  0.3111,  0.6293],\n",
            "        [-0.1989,  0.8383,  0.0318,  ...,  0.0030,  0.3111,  0.6293],\n",
            "        [-0.1306,  0.2275,  0.1961,  ..., -0.0325,  0.1712,  0.3244]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1491,  0.0231, -0.0324,  ..., -0.0065,  0.0299,  0.0027],\n",
            "        [ 0.0500, -0.0598, -0.1186,  ...,  0.0557, -0.1734, -0.0966],\n",
            "        [ 0.1355,  0.0895,  0.0605,  ..., -0.0412, -0.1644,  0.0547],\n",
            "        ...,\n",
            "        [ 0.2676,  0.5758, -0.1684,  ...,  0.1436, -0.2552, -0.1801],\n",
            "        [ 0.0516,  0.0224,  0.0588,  ...,  0.3611, -0.0272,  0.2386],\n",
            "        [ 0.2016, -0.0148, -0.2914,  ...,  0.1266, -0.2888, -0.0133]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1405, -0.0597,  0.0109,  ...,  0.2227, -0.3436, -0.0012],\n",
            "         [ 0.1496,  0.7006,  0.0801,  ...,  0.1608,  0.1544, -0.0896],\n",
            "         [ 0.2051,  0.4936,  0.1923,  ...,  0.2233, -0.0928, -0.0886],\n",
            "         ...,\n",
            "         [ 0.2678, -0.0949, -0.0960,  ...,  0.2342, -0.1865, -0.3352],\n",
            "         [-0.0460,  0.5134,  0.0249,  ...,  0.2126,  0.0510, -0.0304],\n",
            "         [ 0.2678, -0.0949, -0.0960,  ...,  0.2342, -0.1865, -0.3352]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.2677,  0.2139, -0.2328,  ...,  0.3007, -0.3504, -0.0609],\n",
            "        [-0.1248,  0.7105, -0.0475,  ...,  0.1301,  0.1661,  0.2308],\n",
            "        [ 0.0555,  0.6898, -0.0896,  ...,  0.2592, -0.0090,  0.2637],\n",
            "        ...,\n",
            "        [ 0.7567,  0.2273, -0.5247,  ...,  0.4855, -0.6529, -0.7159],\n",
            "        [-0.2294,  0.6584,  0.1164,  ..., -0.0467,  0.2054,  0.3979],\n",
            "        [ 0.7567,  0.2273, -0.5247,  ...,  0.4855, -0.6529, -0.7159]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 3.0754e-02, -8.7178e-02, -1.7502e-02,  ..., -4.9299e-02,\n",
            "          4.9442e-02,  1.1101e-01],\n",
            "        [-1.0463e-01, -7.7104e-02,  1.4280e-01,  ..., -8.7157e-02,\n",
            "         -4.0235e-02, -2.4295e-02],\n",
            "        [ 3.0754e-02, -8.7178e-02, -1.7502e-02,  ..., -4.9299e-02,\n",
            "          4.9442e-02,  1.1101e-01],\n",
            "        ...,\n",
            "        [ 3.4295e-01,  5.0880e-01, -2.6519e-01,  ...,  1.4730e-01,\n",
            "         -5.0352e-02, -1.2314e-01],\n",
            "        [ 2.3907e-01, -2.6016e-01, -2.8131e-01,  ...,  2.7606e-01,\n",
            "         -4.1044e-01, -5.3815e-02],\n",
            "        [ 2.7562e-04,  1.2575e-01, -5.0996e-04,  ...,  6.2155e-02,\n",
            "          2.5940e-01,  6.1681e-02]], grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 2.7562e-04,  1.2575e-01, -5.0996e-04,  ...,  6.2155e-02,\n",
            "           2.5940e-01,  6.1681e-02],\n",
            "         [ 3.1628e-01, -3.0367e-01, -1.5717e-01,  ...,  8.4135e-02,\n",
            "          -9.4331e-02, -4.3912e-02],\n",
            "         [ 3.0038e-01, -4.7917e-02, -3.0433e-01,  ...,  6.8452e-02,\n",
            "          -7.8099e-02, -8.7780e-02],\n",
            "         ...,\n",
            "         [ 3.0038e-01, -4.7917e-02, -3.0433e-01,  ...,  6.8452e-02,\n",
            "          -7.8099e-02, -8.7780e-02],\n",
            "         [ 3.4295e-01,  5.0880e-01, -2.6519e-01,  ...,  1.4730e-01,\n",
            "          -5.0352e-02, -1.2314e-01],\n",
            "         [ 2.3907e-01, -2.6016e-01, -2.8131e-01,  ...,  2.7606e-01,\n",
            "          -4.1044e-01, -5.3815e-02]]], grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.1673,  0.4607, -0.0030,  ...,  0.0302,  0.2593,  0.3729],\n",
            "        [ 0.5779, -0.0416, -0.4435,  ...,  0.3542, -0.5063, -0.2906],\n",
            "        [ 0.5690,  0.2601, -0.4795,  ...,  0.3504, -0.4566, -0.3680],\n",
            "        ...,\n",
            "        [ 0.5690,  0.2601, -0.4795,  ...,  0.3504, -0.4566, -0.3680],\n",
            "        [-0.0617,  0.7366, -0.1759,  ...,  0.0483,  0.0694,  0.2116],\n",
            "        [ 0.7095,  0.0860, -0.5737,  ...,  0.5479, -0.7285, -0.5617]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2549, -0.0828,  0.0216,  ...,  0.2309, -0.1622, -0.1742],\n",
            "        [-0.0626,  0.0231, -0.1317,  ...,  0.0600,  0.0706, -0.0653],\n",
            "        [-0.1573, -0.1365, -0.2018,  ...,  0.1641,  0.0490,  0.1253],\n",
            "        ...,\n",
            "        [ 0.1325,  0.1540, -0.3484,  ...,  0.1639, -0.2455, -0.3213],\n",
            "        [ 0.1718,  0.1599, -0.1044,  ..., -0.0167, -0.0553, -0.1203],\n",
            "        [ 0.3089, -0.0440, -0.0395,  ...,  0.2199, -0.1644, -0.2736]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.1325,  0.1540, -0.3484,  ...,  0.1639, -0.2455, -0.3213],\n",
            "         [ 0.1718,  0.1599, -0.1044,  ..., -0.0167, -0.0553, -0.1203],\n",
            "         [ 0.3089, -0.0440, -0.0395,  ...,  0.2199, -0.1644, -0.2736],\n",
            "         ...,\n",
            "         [ 0.1050,  0.0997, -0.0694,  ..., -0.0243, -0.0582, -0.1430],\n",
            "         [ 0.4905,  0.1393, -0.0382,  ...,  0.3304, -0.2595, -0.3522],\n",
            "         [ 0.2013,  0.1464, -0.2610,  ...,  0.1405, -0.1008, -0.1572]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5888,  0.3580, -0.5762,  ...,  0.4654, -0.6073, -0.6129],\n",
            "        [ 0.4650,  0.2112, -0.3775,  ...,  0.1753, -0.3752, -0.3859],\n",
            "        [ 0.3632,  0.1196, -0.2386,  ...,  0.2236, -0.3190, -0.3224],\n",
            "        ...,\n",
            "        [ 0.3943,  0.1347, -0.3021,  ...,  0.1268, -0.3445, -0.3354],\n",
            "        [ 0.4943,  0.3131, -0.2861,  ...,  0.2927, -0.4195, -0.4107],\n",
            "        [ 0.3349,  0.1587, -0.2895,  ...,  0.2386, -0.2169, -0.2599]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0302, -0.0881, -0.0167,  ..., -0.0501,  0.0498,  0.1115],\n",
            "        [ 0.0569,  0.1018,  0.1198,  ..., -0.0523,  0.0117, -0.0123],\n",
            "        [-0.0027,  0.1826,  0.0204,  ...,  0.1645, -0.0897, -0.0239],\n",
            "        ...,\n",
            "        [ 0.0615, -0.0689, -0.1877,  ...,  0.2340, -0.1758,  0.0153],\n",
            "        [ 0.2424, -0.2760, -0.0489,  ..., -0.1083, -0.1969, -0.0707],\n",
            "        [ 0.2209, -0.0801, -0.2768,  ...,  0.2238, -0.0794, -0.0774]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2841,  0.2940, -0.0687,  ...,  0.0563, -0.2301,  0.0491],\n",
            "         [ 0.2831,  0.3705, -0.1046,  ..., -0.1108, -0.0138, -0.1692],\n",
            "         [ 0.1890, -0.2760, -0.3957,  ...,  0.1918, -0.1064, -0.1131],\n",
            "         ...,\n",
            "         [ 0.0615, -0.0689, -0.1877,  ...,  0.2340, -0.1758,  0.0153],\n",
            "         [ 0.2424, -0.2760, -0.0489,  ..., -0.1083, -0.1969, -0.0707],\n",
            "         [ 0.2209, -0.0801, -0.2768,  ...,  0.2238, -0.0794, -0.0774]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5437,  0.3838, -0.3703,  ...,  0.2681, -0.4595, -0.2575],\n",
            "        [ 0.5130,  0.4565, -0.3517,  ...,  0.1684, -0.2656, -0.2825],\n",
            "        [ 0.5881,  0.0812, -0.5765,  ...,  0.3766, -0.5692, -0.5460],\n",
            "        ...,\n",
            "        [ 0.4147,  0.0296, -0.3897,  ...,  0.2994, -0.3686, -0.3248],\n",
            "        [ 0.5776,  0.0269, -0.3774,  ...,  0.2260, -0.4535, -0.3924],\n",
            "        [ 0.4823,  0.2413, -0.4576,  ...,  0.3286, -0.4156, -0.3475]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0298, -0.0882, -0.0162,  ..., -0.0503,  0.0499,  0.1117],\n",
            "        [-0.2255,  0.0348,  0.0107,  ...,  0.0889,  0.1007, -0.1210],\n",
            "        [-0.0623,  0.0234, -0.1322,  ...,  0.0601,  0.0702, -0.0650],\n",
            "        ...,\n",
            "        [ 0.1230, -0.1253, -0.1285,  ...,  0.1065, -0.2821, -0.2498],\n",
            "        [ 0.1230, -0.1253, -0.1285,  ...,  0.1065, -0.2821, -0.2498],\n",
            "        [ 0.0768,  0.2725, -0.2295,  ...,  0.0715, -0.1330,  0.0790]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0156,  0.1137,  0.1690,  ...,  0.1035, -0.2369,  0.0749],\n",
            "         [ 0.1532,  0.4995,  0.0400,  ..., -0.0833,  0.0977, -0.0288],\n",
            "         [ 0.1290, -0.2148, -0.3553,  ..., -0.0082, -0.0151,  0.1616],\n",
            "         ...,\n",
            "         [ 0.0159, -0.0444, -0.0648,  ...,  0.0441,  0.1845,  0.2201],\n",
            "         [ 0.0045,  0.1641,  0.3259,  ..., -0.0073,  0.0247,  0.1131],\n",
            "         [ 0.0579,  0.6051, -0.0614,  ...,  0.2084, -0.1956, -0.2083]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.4826,  0.3064, -0.3421,  ...,  0.3807, -0.5448, -0.4008],\n",
            "        [-0.1961,  0.6726,  0.1728,  ..., -0.1981,  0.2317,  0.3755],\n",
            "        [ 0.4995,  0.0960, -0.5443,  ...,  0.3386, -0.4300, -0.2402],\n",
            "        ...,\n",
            "        [-0.1497,  0.3698, -0.1562,  ...,  0.1764,  0.2091,  0.4075],\n",
            "        [-0.0203,  0.3391,  0.1078,  ...,  0.1362,  0.0913,  0.2008],\n",
            "        [-0.1472,  0.7156, -0.2862,  ...,  0.2990, -0.1366,  0.2368]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.1350,  0.1309, -0.0390,  ...,  0.0752,  0.0025, -0.0734],\n",
            "        [-0.0454, -0.0357,  0.0960,  ...,  0.0201, -0.0726, -0.1903],\n",
            "        [ 0.1350,  0.1309, -0.0390,  ...,  0.0752,  0.0025, -0.0734],\n",
            "        ...,\n",
            "        [ 0.1581, -0.1763, -0.1707,  ...,  0.1144, -0.2942, -0.1551],\n",
            "        [ 0.3563, -0.2397,  0.0416,  ...,  0.2800, -0.2820,  0.0052],\n",
            "        [ 0.1276, -0.4570, -0.1531,  ...,  0.0603, -0.2410, -0.2401]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 2.4221e-01,  3.6692e-01, -3.0747e-01,  ...,  3.2759e-01,\n",
            "          -2.9946e-01, -2.0652e-02],\n",
            "         [ 1.0519e-01,  5.7224e-01, -1.0400e-01,  ...,  1.3099e-01,\n",
            "          -2.0616e-01, -2.6015e-01],\n",
            "         [ 1.7485e-01, -1.9751e-01, -2.6429e-01,  ...,  3.4718e-05,\n",
            "          -3.2800e-01,  2.1846e-02],\n",
            "         ...,\n",
            "         [ 2.3753e-02,  2.5144e-02,  1.7070e-01,  ...,  2.6192e-02,\n",
            "           1.3811e-02,  1.4227e-01],\n",
            "         [ 9.7682e-02,  1.4562e-01, -7.4003e-02,  ...,  1.1059e-01,\n",
            "          -1.6906e-01, -1.6435e-01],\n",
            "         [ 1.4828e-01, -2.5830e-01, -7.6215e-02,  ...,  1.1271e-01,\n",
            "          -1.0556e-01, -1.9624e-01]]], grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5484,  0.4913, -0.5109,  ...,  0.3850, -0.4841, -0.3840],\n",
            "        [ 0.6401,  0.6640, -0.5673,  ...,  0.5273, -0.7027, -0.6430],\n",
            "        [ 0.6336,  0.1637, -0.5180,  ...,  0.3407, -0.6320, -0.4180],\n",
            "        ...,\n",
            "        [ 0.0128, -0.0716,  0.2281,  ..., -0.1193,  0.1100,  0.1548],\n",
            "        [ 0.5494,  0.2703, -0.4822,  ...,  0.4914, -0.5927, -0.5064],\n",
            "        [ 0.7543,  0.1174, -0.5603,  ...,  0.5414, -0.7006, -0.6906]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0600, -0.1055,  0.1323,  ...,  0.0169,  0.0400, -0.1060],\n",
            "        [ 0.0291, -0.0886, -0.0155,  ..., -0.0507,  0.0500,  0.1118],\n",
            "        [ 0.2531, -0.0820,  0.0224,  ...,  0.2337, -0.1657, -0.1828],\n",
            "        ...,\n",
            "        [ 0.1856,  0.5740,  0.0075,  ...,  0.0853, -0.0062,  0.2278],\n",
            "        [ 0.1856,  0.5740,  0.0075,  ...,  0.0853, -0.0062,  0.2278],\n",
            "        [ 0.3232,  0.0387, -0.1561,  ...,  0.0048,  0.0876,  0.0211]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.2850, -0.2075,  0.0593,  ...,  0.0730, -0.0710, -0.0767],\n",
            "         [ 0.4276,  0.2943, -0.1520,  ..., -0.0117, -0.2449, -0.2696],\n",
            "         [ 0.1856,  0.5740,  0.0075,  ...,  0.0853, -0.0062,  0.2278],\n",
            "         ...,\n",
            "         [ 0.1856,  0.5740,  0.0075,  ...,  0.0853, -0.0062,  0.2278],\n",
            "         [ 0.1856,  0.5740,  0.0075,  ...,  0.0853, -0.0062,  0.2278],\n",
            "         [ 0.3232,  0.0387, -0.1561,  ...,  0.0048,  0.0876,  0.0211]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6025,  0.1641, -0.3595,  ...,  0.3672, -0.4677, -0.4362],\n",
            "        [ 0.5279,  0.4734, -0.4676,  ...,  0.3397, -0.5681, -0.5324],\n",
            "        [-0.1877,  0.8491, -0.0715,  ...,  0.1203,  0.3056,  0.6314],\n",
            "        ...,\n",
            "        [-0.1877,  0.8491, -0.0715,  ...,  0.1203,  0.3056,  0.6314],\n",
            "        [-0.1877,  0.8491, -0.0715,  ...,  0.1203,  0.3056,  0.6314],\n",
            "        [ 0.4598,  0.2347, -0.3377,  ...,  0.2110, -0.1846, -0.2895]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0288, -0.0887, -0.0152,  ..., -0.0508,  0.0501,  0.1119],\n",
            "        [-0.1541,  0.0678,  0.0665,  ..., -0.0116, -0.0506,  0.2029],\n",
            "        [-0.2246,  0.0349,  0.0105,  ...,  0.0878,  0.1007, -0.1206],\n",
            "        ...,\n",
            "        [ 0.1194,  0.3103,  0.0563,  ...,  0.2971, -0.0093,  0.0325],\n",
            "        [ 0.0136, -0.0483, -0.0361,  ...,  0.0845,  0.1892, -0.0116],\n",
            "        [ 0.2502, -0.1207, -0.1352,  ...,  0.2366, -0.0287, -0.0336]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.0382,  0.3385, -0.2160,  ...,  0.2490, -0.1078,  0.0014],\n",
            "         [ 0.2395, -0.1394,  0.1516,  ...,  0.1817, -0.0741, -0.0609],\n",
            "         [ 0.3160, -0.0070,  0.1771,  ...,  0.4522, -0.1828, -0.1095],\n",
            "         ...,\n",
            "         [ 0.1194,  0.3103,  0.0563,  ...,  0.2971, -0.0093,  0.0325],\n",
            "         [ 0.0136, -0.0483, -0.0361,  ...,  0.0845,  0.1892, -0.0116],\n",
            "         [ 0.2502, -0.1207, -0.1352,  ...,  0.2366, -0.0287, -0.0336]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0732,  0.4769, -0.1725,  ...,  0.0438,  0.0564,  0.1450],\n",
            "        [ 0.6395,  0.1810, -0.3201,  ...,  0.4148, -0.4921, -0.4707],\n",
            "        [-0.0726,  0.4709, -0.0557,  ...,  0.3108,  0.0424,  0.2241],\n",
            "        ...,\n",
            "        [ 0.3505,  0.3485, -0.2931,  ...,  0.4383, -0.3313, -0.2212],\n",
            "        [ 0.0083, -0.1410,  0.1367,  ..., -0.1126,  0.1295,  0.0352],\n",
            "        [ 0.3989,  0.0556, -0.3185,  ...,  0.3278, -0.2432, -0.1527]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.2522, -0.0814,  0.0223,  ...,  0.2349, -0.1672, -0.1866],\n",
            "        [ 0.2522, -0.0814,  0.0223,  ...,  0.2349, -0.1672, -0.1866],\n",
            "        [ 0.1321,  0.1308, -0.0375,  ...,  0.0767,  0.0019, -0.0735],\n",
            "        ...,\n",
            "        [-0.1595,  0.0070, -0.0400,  ...,  0.1381, -0.0124,  0.0635],\n",
            "        [ 0.2098, -0.0385, -0.0857,  ..., -0.1069, -0.0569, -0.1279],\n",
            "        [ 0.1739,  0.2046, -0.1478,  ..., -0.0170, -0.1361, -0.1943]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1595,  0.0070, -0.0400,  ...,  0.1381, -0.0124,  0.0635],\n",
            "         [ 0.2098, -0.0385, -0.0857,  ..., -0.1069, -0.0569, -0.1279],\n",
            "         [ 0.1739,  0.2046, -0.1478,  ..., -0.0170, -0.1361, -0.1943],\n",
            "         ...,\n",
            "         [ 0.1711, -0.1217,  0.0357,  ..., -0.0235,  0.1445,  0.0291],\n",
            "         [ 0.2769, -0.1196,  0.0449,  ..., -0.1063, -0.0409,  0.0451],\n",
            "         [ 0.1157,  0.0167,  0.0676,  ...,  0.1025, -0.0330,  0.0703]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-0.0472,  0.1349, -0.2128,  ...,  0.1721, -0.1240,  0.0352],\n",
            "        [ 0.5968,  0.0488, -0.4135,  ...,  0.1556, -0.4485, -0.4412],\n",
            "        [ 0.3309,  0.3254, -0.3567,  ...,  0.1989, -0.3338, -0.2516],\n",
            "        ...,\n",
            "        [ 0.1335, -0.0038, -0.0658,  ...,  0.0611, -0.0344, -0.0574],\n",
            "        [ 0.2770, -0.0315, -0.0910,  ...,  0.0803, -0.1138, -0.0427],\n",
            "        [ 0.1383,  0.0498, -0.0617,  ...,  0.1727, -0.1217, -0.0090]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[ 0.0279, -0.0894, -0.0145,  ..., -0.0513,  0.0502,  0.1125],\n",
            "        [ 0.0012, -0.1955,  0.1517,  ..., -0.0086,  0.0181, -0.0908],\n",
            "        [ 0.2518, -0.0811,  0.0223,  ...,  0.2355, -0.1678, -0.1883],\n",
            "        ...,\n",
            "        [ 0.2709,  0.1669, -0.1541,  ...,  0.1600, -0.3132, -0.2820],\n",
            "        [ 0.3320, -0.5238,  0.0308,  ..., -0.0469, -0.1380, -0.1067],\n",
            "        [ 0.0507, -0.2080, -0.0196,  ...,  0.3527, -0.0219,  0.2583]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[ 0.3902, -0.2354, -0.1271,  ...,  0.1465, -0.0905,  0.0788],\n",
            "         [-0.0209, -0.1355, -0.0709,  ...,  0.1511, -0.0727, -0.0762],\n",
            "         [ 0.2943,  0.2512, -0.1921,  ...,  0.0612, -0.1346,  0.0220],\n",
            "         ...,\n",
            "         [ 0.1449, -0.5675,  0.1428,  ...,  0.0735, -0.1093, -0.1619],\n",
            "         [ 0.0228, -0.1553, -0.0449,  ...,  0.0658, -0.1535,  0.0800],\n",
            "         [ 0.3481, -0.1165, -0.1590,  ...,  0.1668, -0.0786,  0.0485]]],\n",
            "       grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6605,  0.1609, -0.4660,  ...,  0.3631, -0.5014, -0.2920],\n",
            "        [ 0.2804,  0.2795, -0.3739,  ...,  0.3515, -0.4306, -0.3160],\n",
            "        [ 0.5875,  0.3591, -0.4961,  ...,  0.3241, -0.5325, -0.2384],\n",
            "        ...,\n",
            "        [ 0.3371, -0.0951, -0.2688,  ...,  0.2663, -0.2917, -0.3517],\n",
            "        [ 0.2298,  0.1143, -0.3024,  ...,  0.2638, -0.3161, -0.0955],\n",
            "        [ 0.7779,  0.2032, -0.5511,  ...,  0.5231, -0.6627, -0.4978]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Output of encoder at every step:tensor([[-0.2239,  0.0352,  0.0105,  ...,  0.0876,  0.1007, -0.1203],\n",
            "        [ 0.2495, -0.0814,  0.0229,  ...,  0.2361, -0.1681, -0.1893],\n",
            "        [ 0.0276, -0.0897, -0.0143,  ..., -0.0515,  0.0503,  0.1128],\n",
            "        ...,\n",
            "        [ 0.0102, -0.0511, -0.3605,  ...,  0.2287, -0.1631, -0.0081],\n",
            "        [ 0.2822,  0.0077,  0.0241,  ...,  0.0331, -0.2134, -0.2475],\n",
            "        [-0.0913, -0.1764,  0.0071,  ...,  0.0287, -0.0581,  0.0847]])\n",
            "Output of encoder at last step:tensor([[[-0.0057,  0.0417, -0.0739,  ..., -0.0886,  0.0222, -0.0268],\n",
            "         [ 0.0102, -0.0511, -0.3605,  ...,  0.2287, -0.1631, -0.0081],\n",
            "         [ 0.2822,  0.0077,  0.0241,  ...,  0.0331, -0.2134, -0.2475],\n",
            "         ...,\n",
            "         [ 0.3514, -0.0688,  0.0894,  ...,  0.2518, -0.3096, -0.2981],\n",
            "         [ 0.2349,  0.0398,  0.0073,  ..., -0.0034, -0.1794, -0.1483],\n",
            "         [-0.0999,  0.0123, -0.2465,  ...,  0.0685, -0.0722,  0.0048]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.1466,  0.2024, -0.3183,  ...,  0.1692, -0.1716, -0.0942],\n",
            "        [ 0.2683,  0.2073, -0.4674,  ...,  0.3075, -0.3059, -0.2781],\n",
            "        [ 0.5991,  0.1788, -0.3231,  ...,  0.3016, -0.5346, -0.5180],\n",
            "        ...,\n",
            "        [ 0.3826,  0.1297, -0.2126,  ...,  0.2766, -0.4536, -0.3825],\n",
            "        [ 0.1686,  0.0634, -0.1108,  ...,  0.1032, -0.1797, -0.1361],\n",
            "        [-0.0427,  0.0478, -0.2384,  ...,  0.0797, -0.0795,  0.0152]])\n",
            "Output of encoder at every step:tensor([[-0.1136,  0.0146, -0.2112,  ...,  0.1080,  0.0118, -0.0368],\n",
            "        [ 0.2495, -0.0814,  0.0229,  ...,  0.2361, -0.1681, -0.1893],\n",
            "        [-0.0162,  0.0606,  0.1247,  ..., -0.0092, -0.0231, -0.1482],\n",
            "        ...,\n",
            "        [-0.0996,  0.1507, -0.3322,  ...,  0.2273, -0.1168, -0.1606],\n",
            "        [ 0.1075, -0.1072, -0.0709,  ...,  0.1300, -0.1583, -0.0815],\n",
            "        [ 0.0231, -0.1167, -0.3895,  ...,  0.2104, -0.1748, -0.1099]])\n",
            "Output of encoder at last step:tensor([[[ 0.0201,  0.2560, -0.0441,  ...,  0.0608, -0.0624, -0.0306],\n",
            "         [-0.0747, -0.1297, -0.3773,  ...,  0.1986, -0.0409, -0.0925],\n",
            "         [-0.0407,  0.1657, -0.2587,  ...,  0.2050, -0.0562, -0.2362],\n",
            "         ...,\n",
            "         [-0.0536, -0.0170, -0.2955,  ...,  0.2128, -0.1576, -0.1271],\n",
            "         [ 0.3019,  0.0286, -0.1026,  ...,  0.0735, -0.2319, -0.2734],\n",
            "         [-0.0223, -0.1500, -0.3160,  ...,  0.3446, -0.2494, -0.4132]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 3.1001e-02,  2.9058e-01, -4.5332e-02,  ...,  1.5514e-01,\n",
            "         -1.5635e-02, -3.8769e-04],\n",
            "        [ 1.8019e-01,  1.6580e-01, -4.8700e-01,  ...,  3.2727e-01,\n",
            "         -2.7758e-01, -3.2276e-01],\n",
            "        [ 1.5842e-02,  2.8597e-01, -3.2491e-01,  ...,  2.1891e-01,\n",
            "         -1.2171e-01, -1.6724e-01],\n",
            "        ...,\n",
            "        [ 2.8828e-01,  1.7967e-01, -4.7281e-01,  ...,  3.5487e-01,\n",
            "         -4.4790e-01, -3.6428e-01],\n",
            "        [ 5.3297e-01,  2.6279e-01, -3.8595e-01,  ...,  3.2165e-01,\n",
            "         -4.4307e-01, -5.0668e-01],\n",
            "        [ 3.7153e-01,  1.9311e-01, -5.1527e-01,  ...,  4.1865e-01,\n",
            "         -5.7487e-01, -5.6605e-01]])\n",
            "Output of encoder at every step:tensor([[ 0.0276, -0.0897, -0.0143,  ..., -0.0515,  0.0503,  0.1128],\n",
            "        [ 0.2495, -0.0814,  0.0229,  ...,  0.2361, -0.1681, -0.1893],\n",
            "        [-0.0860,  0.1818, -0.0856,  ..., -0.0987,  0.0265,  0.0691],\n",
            "        ...,\n",
            "        [-0.1782,  0.0110, -0.1477,  ...,  0.1042,  0.0402,  0.0934],\n",
            "        [-0.0239, -0.1342, -0.0724,  ...,  0.1497, -0.0737, -0.0771],\n",
            "        [ 0.1358,  0.0724,  0.2704,  ...,  0.4418, -0.2738,  0.0508]])\n",
            "Output of encoder at last step:tensor([[[-0.0480, -0.0997, -0.4288,  ...,  0.2225, -0.1715, -0.2419],\n",
            "         [ 0.0779, -0.1757, -0.2941,  ...,  0.2455, -0.1175, -0.1285],\n",
            "         [ 0.1685,  0.2154, -0.1219,  ...,  0.1478, -0.2703, -0.3310],\n",
            "         ...,\n",
            "         [ 0.0684, -0.0098, -0.0971,  ...,  0.0831, -0.1521, -0.1151],\n",
            "         [-0.0359, -0.1188, -0.2399,  ...,  0.1759,  0.0059,  0.0708],\n",
            "         [-0.0059,  0.2944,  0.1560,  ...,  0.0348, -0.0699,  0.0320]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.5685,  0.2190, -0.6714,  ...,  0.4749, -0.6842, -0.6920],\n",
            "        [ 0.4873,  0.0649, -0.5354,  ...,  0.3699, -0.4766, -0.4582],\n",
            "        [ 0.6893,  0.5345, -0.5726,  ...,  0.5531, -0.7188, -0.6724],\n",
            "        ...,\n",
            "        [ 0.5746,  0.1749, -0.4991,  ...,  0.4710, -0.6033, -0.5524],\n",
            "        [-0.0080,  0.1782, -0.3474,  ...,  0.2238, -0.0476,  0.0273],\n",
            "        [-0.0562,  0.3277, -0.0364,  ...,  0.1360, -0.0272,  0.0743]])\n",
            "Output of encoder at every step:tensor([[ 0.1299,  0.1303, -0.0362,  ...,  0.0775,  0.0014, -0.0735],\n",
            "        [-0.0856,  0.1106,  0.0602,  ..., -0.0785,  0.0930,  0.0491],\n",
            "        [ 0.0276, -0.0897, -0.0143,  ..., -0.0515,  0.0503,  0.1128],\n",
            "        ...,\n",
            "        [ 0.0620, -0.1385, -0.1167,  ...,  0.0889, -0.1891, -0.0799],\n",
            "        [ 0.1558, -0.1513,  0.1212,  ...,  0.0239, -0.0351, -0.1765],\n",
            "        [ 0.0135,  0.2656,  0.1439,  ...,  0.1009,  0.1017,  0.1781]])\n",
            "Output of encoder at last step:tensor([[[ 0.4919, -0.0142, -0.0121,  ...,  0.1165, -0.1636,  0.0336],\n",
            "         [ 0.0523,  0.3920, -0.1088,  ...,  0.0880, -0.1320, -0.1834],\n",
            "         [ 0.0688,  0.1997, -0.1913,  ...,  0.1014,  0.0036,  0.0509],\n",
            "         ...,\n",
            "         [ 0.3534, -0.1873, -0.2000,  ...,  0.3140, -0.3107, -0.0649],\n",
            "         [ 0.0322, -0.1254, -0.1393,  ...,  0.1033, -0.1945, -0.2676],\n",
            "         [ 0.0890,  0.2548, -0.0661,  ...,  0.0767, -0.1925, -0.0741]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6880,  0.0164, -0.3550,  ...,  0.3609, -0.5235, -0.4350],\n",
            "        [ 0.2344,  0.5242, -0.3820,  ...,  0.3599, -0.2517, -0.2052],\n",
            "        [-0.1480,  0.4711, -0.1479,  ..., -0.0101,  0.1682,  0.3309],\n",
            "        ...,\n",
            "        [ 0.5094,  0.1099, -0.3947,  ...,  0.3162, -0.4170, -0.3793],\n",
            "        [ 0.6783,  0.1992, -0.6189,  ...,  0.5814, -0.7709, -0.7344],\n",
            "        [ 0.3121,  0.5130, -0.3982,  ...,  0.3749, -0.3663, -0.1895]])\n",
            "Output of encoder at every step:tensor([[ 0.2495, -0.0814,  0.0229,  ...,  0.2361, -0.1681, -0.1893],\n",
            "        [ 0.0276, -0.0897, -0.0143,  ..., -0.0515,  0.0503,  0.1128],\n",
            "        [-0.1136,  0.0146, -0.2112,  ...,  0.1080,  0.0118, -0.0368],\n",
            "        ...,\n",
            "        [ 0.2097, -0.3512, -0.1908,  ..., -0.2306, -0.1404, -0.1632],\n",
            "        [-0.0668,  0.3687,  0.0714,  ...,  0.1987, -0.2386, -0.0511],\n",
            "        [ 0.1404, -0.0821,  0.0224,  ...,  0.3542, -0.4322, -0.1249]])\n",
            "Output of encoder at last step:tensor([[[ 0.0961,  0.2844,  0.0196,  ...,  0.3361, -0.1137, -0.0097],\n",
            "         [-0.0984,  0.1666,  0.3232,  ...,  0.1478,  0.0212,  0.0039],\n",
            "         [ 0.1275, -0.0692, -0.1868,  ...,  0.1216, -0.1675, -0.1502],\n",
            "         ...,\n",
            "         [ 0.0135,  0.2656,  0.1439,  ...,  0.1009,  0.1017,  0.1781],\n",
            "         [ 0.0983, -0.2685, -0.1180,  ...,  0.1348, -0.2863, -0.3143],\n",
            "         [ 0.0836, -0.4921, -0.2021,  ..., -0.2659, -0.1234, -0.0726]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.6191,  0.3310, -0.4409,  ...,  0.5226, -0.5925, -0.4926],\n",
            "        [-0.1803,  0.4643, -0.0469,  ...,  0.2795,  0.0957,  0.1960],\n",
            "        [ 0.5666,  0.2346, -0.5039,  ...,  0.3897, -0.5301, -0.5225],\n",
            "        ...,\n",
            "        [-0.2135,  0.5897, -0.0841,  ...,  0.2502,  0.2464,  0.5674],\n",
            "        [ 0.5986,  0.1018, -0.4468,  ...,  0.4323, -0.6550, -0.6296],\n",
            "        [ 0.5473, -0.2148, -0.5165,  ...,  0.2090, -0.5506, -0.4403]])\n",
            "Output of encoder at every step:tensor([[ 0.0276, -0.0897, -0.0143,  ..., -0.0515,  0.0503,  0.1128],\n",
            "        [ 0.0276, -0.0897, -0.0143,  ..., -0.0515,  0.0503,  0.1128],\n",
            "        [ 0.0276, -0.0897, -0.0143,  ..., -0.0515,  0.0503,  0.1128],\n",
            "        ...,\n",
            "        [ 0.3588, -0.3513, -0.3176,  ...,  0.3902, -0.3286,  0.0749],\n",
            "        [ 0.2559, -0.3227, -0.2254,  ...,  0.3907, -0.5205, -0.2646],\n",
            "        [ 0.2559, -0.3227, -0.2254,  ...,  0.3907, -0.5205, -0.2646]])\n",
            "Output of encoder at last step:tensor([[[ 0.2559, -0.3227, -0.2254,  ...,  0.3907, -0.5205, -0.2646],\n",
            "         [ 0.2559, -0.3227, -0.2254,  ...,  0.3907, -0.5205, -0.2646],\n",
            "         [ 0.3588, -0.3513, -0.3176,  ...,  0.3902, -0.3286,  0.0749],\n",
            "         ...,\n",
            "         [ 0.0602,  0.3274, -0.0400,  ...,  0.0788,  0.0281, -0.0101],\n",
            "         [ 0.1001,  0.1257, -0.1264,  ...,  0.0914, -0.1632, -0.0243],\n",
            "         [ 0.0073,  0.0258,  0.2800,  ..., -0.0227, -0.0019,  0.0477]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.8035,  0.0780, -0.6162,  ...,  0.5968, -0.8112, -0.7413],\n",
            "        [ 0.8035,  0.0780, -0.6162,  ...,  0.5968, -0.8112, -0.7413],\n",
            "        [ 0.8281,  0.0724, -0.6394,  ...,  0.6349, -0.7760, -0.5038],\n",
            "        ...,\n",
            "        [-0.1683,  0.6830, -0.0708,  ...,  0.1014,  0.3183,  0.4013],\n",
            "        [ 0.4535,  0.3387, -0.5094,  ...,  0.4417, -0.5472, -0.3973],\n",
            "        [ 0.1078,  0.1624, -0.0203,  ...,  0.1807, -0.0750, -0.0706]])\n",
            "Output of encoder at every step:tensor([[ 0.0276, -0.0897, -0.0143,  ..., -0.0515,  0.0503,  0.1128],\n",
            "        [ 0.0276, -0.0897, -0.0143,  ..., -0.0515,  0.0503,  0.1128],\n",
            "        [ 0.0276, -0.0897, -0.0143,  ..., -0.0515,  0.0503,  0.1128],\n",
            "        ...,\n",
            "        [ 0.2559, -0.3227, -0.2254,  ...,  0.3907, -0.5205, -0.2646],\n",
            "        [ 0.2559, -0.3227, -0.2254,  ...,  0.3907, -0.5205, -0.2646],\n",
            "        [ 0.2559, -0.3227, -0.2254,  ...,  0.3907, -0.5205, -0.2646]])\n",
            "Output of encoder at last step:tensor([[[ 0.2559, -0.3227, -0.2254,  ...,  0.3907, -0.5205, -0.2646],\n",
            "         [ 0.2559, -0.3227, -0.2254,  ...,  0.3907, -0.5205, -0.2646],\n",
            "         [ 0.2559, -0.3227, -0.2254,  ...,  0.3907, -0.5205, -0.2646],\n",
            "         ...,\n",
            "         [ 0.2559, -0.3227, -0.2254,  ...,  0.3907, -0.5205, -0.2646],\n",
            "         [ 0.2559, -0.3227, -0.2254,  ...,  0.3907, -0.5205, -0.2646],\n",
            "         [ 0.2559, -0.3227, -0.2254,  ...,  0.3907, -0.5205, -0.2646]]])\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.8035,  0.0780, -0.6162,  ...,  0.5968, -0.8112, -0.7413],\n",
            "        [ 0.8035,  0.0780, -0.6162,  ...,  0.5968, -0.8112, -0.7413],\n",
            "        [ 0.8035,  0.0780, -0.6162,  ...,  0.5968, -0.8112, -0.7413],\n",
            "        ...,\n",
            "        [ 0.8035,  0.0780, -0.6162,  ...,  0.5968, -0.8112, -0.7413],\n",
            "        [ 0.8035,  0.0780, -0.6162,  ...,  0.5968, -0.8112, -0.7413],\n",
            "        [ 0.8035,  0.0780, -0.6162,  ...,  0.5968, -0.8112, -0.7413]])\n",
            "\t Epoch: 9 | Train Loss: 0.043 | Train Acc: 99.07%\n",
            "\t Epoch: 9 | Val. Loss: 1.395 |  Val. Acc: 84.38% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW4TYgnR-XdY",
        "outputId": "854ec1a0-ae08-462a-9e7e-8992d3feefd9"
      },
      "source": [
        "\n",
        "N_EPOCHS = 10\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    \n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'drive/My Drive/END2/Session6-Assignment/encoder_decoder_classification_saved_weights.pt')\n",
        "    \n",
        "    print(f'\\t Epoch: {epoch} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Epoch: {epoch} | Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t Epoch: 0 | Train Loss: 0.879 | Train Acc: 67.01%\n",
            "\t Epoch: 0 | Val. Loss: 0.763 |  Val. Acc: 68.30% \n",
            "\n",
            "\t Epoch: 1 | Train Loss: 0.692 | Train Acc: 73.52%\n",
            "\t Epoch: 1 | Val. Loss: 0.684 |  Val. Acc: 74.55% \n",
            "\n",
            "\t Epoch: 2 | Train Loss: 0.591 | Train Acc: 77.57%\n",
            "\t Epoch: 2 | Val. Loss: 0.670 |  Val. Acc: 75.45% \n",
            "\n",
            "\t Epoch: 3 | Train Loss: 0.485 | Train Acc: 81.50%\n",
            "\t Epoch: 3 | Val. Loss: 0.670 |  Val. Acc: 77.23% \n",
            "\n",
            "\t Epoch: 4 | Train Loss: 0.371 | Train Acc: 86.82%\n",
            "\t Epoch: 4 | Val. Loss: 0.716 |  Val. Acc: 79.46% \n",
            "\n",
            "\t Epoch: 5 | Train Loss: 0.240 | Train Acc: 91.64%\n",
            "\t Epoch: 5 | Val. Loss: 0.683 |  Val. Acc: 78.57% \n",
            "\n",
            "\t Epoch: 6 | Train Loss: 0.207 | Train Acc: 93.07%\n",
            "\t Epoch: 6 | Val. Loss: 0.740 |  Val. Acc: 80.80% \n",
            "\n",
            "\t Epoch: 7 | Train Loss: 0.147 | Train Acc: 95.35%\n",
            "\t Epoch: 7 | Val. Loss: 0.749 |  Val. Acc: 78.57% \n",
            "\n",
            "\t Epoch: 8 | Train Loss: 0.072 | Train Acc: 98.65%\n",
            "\t Epoch: 8 | Val. Loss: 0.917 |  Val. Acc: 80.80% \n",
            "\n",
            "\t Epoch: 9 | Train Loss: 0.035 | Train Acc: 99.49%\n",
            "\t Epoch: 9 | Val. Loss: 1.074 |  Val. Acc: 79.02% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73XPku_1feEc"
      },
      "source": [
        "### Validation of the model by passing the tweets and observing it's outcome along with printing the output from encoder and decoder time steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3A3bf-t4-erR"
      },
      "source": [
        "path = 'drive/My Drive/END2/Session6-Assignment/encoder_decoder_classification_saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('drive/My Drive/END2/Session6-Assignment/tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_tweet(tweet):\n",
        "    \n",
        "    categories = {0: \"Negative\", 1:\"Positive\", 2:\"Neutral\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR8rcLfhu3ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b0a94d7-6dee-4afa-c7ff-5d151cad119a"
      },
      "source": [
        "twt=\"Today is a beautiful day\"\n",
        "print(f'Tweet : {twt}')\n",
        "print(f'Predicted Sentiment : {classify_tweet(twt)} \\n')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tweet : Today is a beautiful day\n",
            "Output of encoder at every step:tensor([[ 4.1017e-02,  3.8177e-02, -1.4185e-01,  ...,  7.6511e-02,\n",
            "         -6.1882e-02,  1.3359e-01],\n",
            "        [ 1.5422e-01, -4.6522e-02, -1.4529e-01,  ..., -1.1428e-02,\n",
            "         -1.1638e-01, -2.7448e-02],\n",
            "        [ 8.7313e-02,  6.1904e-02, -1.0125e-01,  ...,  1.0101e-02,\n",
            "          1.9596e-04,  5.5578e-02],\n",
            "        [-5.3976e-02,  3.0859e-02, -2.3801e-01,  ...,  1.2530e-01,\n",
            "         -2.4061e-03, -4.9863e-02],\n",
            "        [-1.3361e-02, -1.2220e-01, -1.5472e-01,  ...,  5.5615e-02,\n",
            "         -5.1296e-02, -1.1578e-01]], grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-1.3361e-02, -1.2220e-01, -1.5472e-01,  1.7765e-01, -2.7626e-02,\n",
            "          -1.1950e-01, -6.1540e-02, -1.6780e-01,  3.8703e-02, -6.7190e-02,\n",
            "           2.0765e-01,  1.2201e-01, -1.2193e-01,  1.3181e-01,  1.0310e-01,\n",
            "           6.4831e-02,  2.3413e-01,  1.5577e-01,  1.9202e-03,  3.6987e-02,\n",
            "          -1.1714e-01,  8.2315e-02, -4.1326e-02, -5.8618e-02,  2.4626e-02,\n",
            "          -2.4519e-01,  1.4568e-01,  3.0262e-02, -2.2569e-01, -1.5285e-01,\n",
            "          -3.9000e-02, -1.9272e-01,  1.0089e-02, -1.2645e-01, -2.3458e-01,\n",
            "           9.5419e-02,  1.7076e-01, -1.4099e-01, -2.9911e-02, -2.6527e-01,\n",
            "           9.7053e-02, -5.7139e-02,  3.2355e-02, -3.1044e-02, -4.4313e-03,\n",
            "           2.1389e-01,  8.8341e-02, -5.8415e-02,  1.4590e-01,  1.2956e-01,\n",
            "          -2.9226e-01, -3.0106e-02, -4.8573e-02,  8.6382e-04, -1.3598e-02,\n",
            "          -4.8396e-02, -1.6810e-02, -3.7997e-02,  1.0745e-01, -2.5880e-01,\n",
            "          -1.3008e-01, -1.0433e-01, -1.4324e-01,  9.1483e-02, -1.6592e-02,\n",
            "          -7.8848e-03,  6.0441e-02,  7.4219e-02, -2.6684e-01, -1.2057e-01,\n",
            "           2.8238e-01,  1.0112e-01, -1.1571e-01,  2.4651e-01, -2.0243e-03,\n",
            "          -6.3200e-02, -1.1444e-01, -9.6791e-02,  3.2926e-01, -1.6905e-02,\n",
            "           1.4745e-01,  3.5718e-02, -4.7626e-02, -8.3309e-02,  5.0885e-02,\n",
            "           8.7230e-02,  2.0994e-01, -2.4150e-02,  1.6710e-01,  1.3586e-01,\n",
            "          -3.4386e-02,  1.1992e-01,  6.1416e-02,  1.5784e-01,  2.2365e-02,\n",
            "           7.7891e-02,  3.4842e-02, -1.2367e-01,  1.9777e-01, -5.5230e-02,\n",
            "          -1.6487e-01,  3.7121e-02, -1.2074e-02,  7.8449e-04,  1.0949e-01,\n",
            "          -2.3283e-01, -5.7020e-02,  4.0596e-02,  2.7092e-01, -5.8277e-02,\n",
            "           3.0963e-02, -7.6933e-02, -5.6950e-03, -5.9637e-02, -1.9435e-01,\n",
            "          -3.2318e-02,  4.9497e-02, -7.3272e-02, -8.8019e-02,  2.5960e-02,\n",
            "           8.9884e-02,  1.6032e-01, -1.1255e-01, -3.4228e-01, -3.6909e-02,\n",
            "           5.9615e-03, -3.0795e-02,  7.4002e-02,  1.6825e-01,  2.6222e-02,\n",
            "           1.1986e-01,  1.4375e-02, -9.1091e-03,  1.0385e-04,  1.3652e-02,\n",
            "           5.6717e-02,  2.6149e-01, -3.4591e-02,  9.2039e-02, -1.8436e-01,\n",
            "          -1.1424e-01, -1.8572e-01, -3.2452e-01, -1.2933e-01,  6.2724e-02,\n",
            "           3.8860e-02, -5.7184e-02,  3.8018e-02,  2.1383e-01, -4.9968e-02,\n",
            "           1.4173e-01, -3.3955e-02,  6.2374e-02,  1.3713e-01,  3.3064e-02,\n",
            "           1.0661e-01,  6.4944e-03,  5.9588e-02, -1.0473e-01,  8.2943e-02,\n",
            "          -2.3922e-01,  1.4983e-01,  1.6096e-01, -4.3640e-03,  2.2161e-01,\n",
            "          -2.8601e-02,  7.8060e-02, -1.0904e-01, -5.0363e-02,  1.1823e-01,\n",
            "          -1.0704e-02,  4.7490e-02,  1.8749e-02,  1.2831e-01,  2.1964e-01,\n",
            "          -5.7102e-03,  2.1462e-01, -5.1897e-02,  6.4349e-02, -8.3237e-02,\n",
            "          -8.5802e-02, -1.6273e-01,  1.7668e-02, -2.1033e-01,  4.1039e-02,\n",
            "          -4.7575e-02, -1.3935e-01,  9.9473e-02,  2.4662e-01, -2.4659e-01,\n",
            "          -2.5862e-02,  1.8535e-01, -1.2756e-01, -1.2971e-01, -1.2921e-01,\n",
            "           3.1527e-02, -3.7234e-02,  3.8108e-02, -4.4050e-02,  1.0654e-01,\n",
            "          -2.5123e-01, -4.4381e-02,  3.7553e-02,  3.4857e-02, -5.8438e-02,\n",
            "           3.6780e-02, -1.7751e-01, -1.4278e-01, -2.8901e-01,  1.6776e-01,\n",
            "          -1.4116e-01,  3.2190e-01, -3.3942e-02, -1.3723e-01, -1.1578e-01,\n",
            "           8.4027e-03, -6.5246e-02,  2.5670e-01,  2.1272e-01,  5.8554e-02,\n",
            "          -9.3014e-02, -1.0772e-01,  8.1786e-03, -2.8015e-03,  8.9921e-02,\n",
            "           1.1520e-02, -1.2554e-01,  7.1944e-02, -9.7627e-02,  1.9771e-01,\n",
            "          -1.8939e-01,  5.8384e-02, -1.6441e-01, -1.1596e-01,  1.7329e-01,\n",
            "          -1.4238e-01,  6.2289e-02,  2.2093e-01,  7.7436e-02,  1.3276e-01,\n",
            "          -1.6111e-01, -3.0350e-01, -3.3293e-02,  1.9534e-01, -1.0750e-01,\n",
            "          -2.5793e-01,  8.0361e-02, -9.1541e-03, -1.7753e-01, -9.3831e-02,\n",
            "           2.3872e-02,  1.4178e-01, -1.2789e-01, -4.6672e-02,  2.4718e-01,\n",
            "          -4.1099e-02, -8.6895e-02, -1.4946e-01,  1.2740e-01, -1.9011e-02,\n",
            "           2.5675e-01,  8.4197e-02, -5.1470e-02,  9.1460e-02,  6.3196e-02,\n",
            "           4.8231e-02, -2.5074e-01, -6.3853e-02, -3.3017e-02,  1.3223e-01,\n",
            "          -7.7615e-03,  1.9606e-01, -1.1004e-01,  8.2947e-02,  1.6101e-01,\n",
            "           1.1906e-01,  5.9089e-02, -1.8810e-01,  1.0358e-01,  2.6228e-01,\n",
            "           9.2719e-02,  1.2155e-01, -1.0993e-02,  2.8958e-01,  1.4854e-01,\n",
            "          -5.2658e-02,  1.9608e-01,  7.6538e-02, -1.5566e-01, -1.0094e-01,\n",
            "          -1.1633e-01, -9.1423e-02, -8.5913e-03, -1.4746e-01, -9.7682e-02,\n",
            "           6.3461e-02,  1.7130e-01,  6.5822e-02,  9.9897e-02,  1.7080e-02,\n",
            "          -5.1556e-02,  1.4219e-01,  1.9652e-01,  1.2375e-01,  1.3223e-01,\n",
            "           6.0333e-02,  2.9381e-01, -1.8249e-01, -9.1516e-02, -1.0749e-03,\n",
            "           8.3770e-03, -3.3379e-02, -1.2275e-01,  1.7055e-01,  1.6218e-01,\n",
            "          -3.7504e-02, -9.6716e-02, -6.6538e-02,  1.1038e-01,  2.3131e-01,\n",
            "           8.3905e-02,  5.9095e-02,  1.1220e-01, -1.4599e-01,  2.2376e-02,\n",
            "          -1.5888e-01, -2.6581e-01, -2.0432e-01,  3.2224e-01, -7.1972e-02,\n",
            "          -1.0871e-01, -4.8042e-02,  1.2850e-01, -4.9815e-02, -1.1935e-01,\n",
            "           6.2632e-02,  3.0770e-02,  2.9987e-02, -4.1809e-02,  2.3434e-01,\n",
            "           7.1373e-02,  5.6349e-02,  2.1711e-03, -4.2459e-02,  1.9392e-02,\n",
            "           2.9795e-01,  2.5805e-02,  1.6770e-02, -3.2479e-01, -1.6572e-02,\n",
            "          -3.8816e-02, -1.3650e-01,  2.3658e-01,  5.4361e-02,  1.5783e-01,\n",
            "           9.8343e-02, -1.8093e-01, -2.2455e-01, -1.0973e-01,  1.4034e-01,\n",
            "          -2.2727e-02,  8.1484e-02,  6.1313e-02,  4.5719e-02,  5.6803e-02,\n",
            "          -3.0022e-01,  3.8221e-02,  8.4049e-02,  8.5317e-02,  9.4273e-02,\n",
            "           7.7812e-02,  2.2817e-02, -5.4079e-02,  1.7713e-01, -7.1340e-02,\n",
            "          -1.5955e-01,  2.5465e-02,  4.9594e-02,  5.5854e-04, -5.4393e-02,\n",
            "           5.9851e-02,  7.2795e-02, -1.4326e-01,  1.8131e-01,  3.6226e-02,\n",
            "          -2.7090e-02, -1.2614e-01,  3.4659e-02, -1.2959e-01, -1.8445e-02,\n",
            "          -1.4726e-01, -1.2045e-02,  8.4194e-02,  2.2986e-02, -1.1608e-01,\n",
            "          -1.1482e-01,  5.7086e-02,  2.0193e-01,  5.8803e-02, -2.0849e-02,\n",
            "          -1.9959e-01, -9.0184e-02, -7.2415e-02, -2.2318e-01, -1.1082e-01,\n",
            "          -5.5821e-02,  6.0170e-02,  6.4282e-02, -8.0556e-02,  1.5231e-01,\n",
            "           2.0346e-01,  4.1893e-03, -4.9060e-02, -1.1387e-01,  3.5531e-02,\n",
            "          -7.3265e-02,  1.8713e-01, -1.1701e-01, -1.5747e-01,  3.0277e-01,\n",
            "          -1.9547e-01,  5.8388e-02,  3.4712e-02, -1.9833e-02,  1.9756e-01,\n",
            "          -1.7336e-02,  1.4517e-01,  7.9421e-02,  2.0225e-01, -9.0793e-02,\n",
            "           9.2499e-03, -1.5080e-01, -8.3653e-03,  2.6183e-02, -4.6882e-02,\n",
            "           1.5711e-01,  6.0074e-02, -1.9753e-01, -3.0260e-01,  2.1827e-01,\n",
            "           8.9741e-02, -3.4154e-01,  2.6117e-02, -7.7735e-02, -8.4685e-02,\n",
            "          -1.0415e-01,  4.8454e-02, -9.4527e-03, -9.8600e-03, -3.3847e-02,\n",
            "           1.6426e-01, -4.5403e-02, -2.6502e-01, -1.3354e-01, -3.5271e-02,\n",
            "          -1.4911e-01,  1.7055e-02, -1.4297e-01,  2.1763e-02,  6.4573e-06,\n",
            "          -2.6673e-01,  1.1294e-01, -1.4326e-01, -1.9220e-01,  1.6650e-01,\n",
            "          -1.7967e-01, -1.3833e-01, -6.7722e-04,  3.0269e-02,  5.6923e-02,\n",
            "          -9.5825e-02, -1.4286e-01, -2.1361e-02, -2.9585e-01, -1.6725e-01,\n",
            "          -4.9864e-02,  2.7400e-01,  6.7199e-02, -2.1326e-01, -2.8032e-01,\n",
            "          -1.1487e-01,  4.2852e-03, -9.6480e-02, -4.2619e-02,  3.1577e-02,\n",
            "          -8.1232e-02, -2.8075e-01,  2.0152e-01, -9.7632e-02, -1.3937e-01,\n",
            "          -2.6193e-01,  1.2088e-01, -2.6044e-01, -2.6515e-02, -9.4238e-02,\n",
            "           1.2643e-02, -1.2770e-01,  1.4761e-01,  1.0288e-02, -5.0355e-03,\n",
            "          -5.0940e-02,  4.1184e-02,  1.2889e-01,  4.0094e-02, -2.3535e-02,\n",
            "          -7.1099e-03, -4.7462e-02,  1.8093e-01, -3.7951e-02,  5.5615e-02,\n",
            "          -5.1296e-02, -1.1578e-01]]], grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[ 0.0305,  0.0755, -0.1742,  0.1850,  0.0017, -0.0744,  0.0241, -0.1625,\n",
            "          0.1014, -0.1735,  0.1799,  0.1269, -0.0696,  0.1161,  0.1112,  0.1182,\n",
            "          0.1990,  0.0877,  0.0670,  0.1150, -0.0535,  0.1287, -0.0144, -0.1006,\n",
            "         -0.1220, -0.1869,  0.1193, -0.0561, -0.1954, -0.0494, -0.0216, -0.1047,\n",
            "         -0.0128, -0.0090, -0.2028,  0.1521,  0.1150, -0.1271,  0.0681, -0.2511,\n",
            "          0.1543, -0.0249, -0.0008, -0.0193, -0.0759,  0.0957, -0.0231,  0.1212,\n",
            "          0.1438,  0.0588,  0.0081, -0.0532, -0.1242,  0.1076,  0.0084, -0.1675,\n",
            "          0.1043,  0.0926,  0.1502, -0.2117, -0.1198, -0.2010, -0.1806,  0.0648,\n",
            "         -0.0822,  0.0830,  0.0553,  0.1193, -0.2692,  0.0815,  0.1986,  0.1456,\n",
            "         -0.2538,  0.0940, -0.0793, -0.1458, -0.2007, -0.0189,  0.3038,  0.0203,\n",
            "          0.0129,  0.0451, -0.0742, -0.0785,  0.1537,  0.1094,  0.0298,  0.0916,\n",
            "          0.2071,  0.1920, -0.1302,  0.1097, -0.0312,  0.0246,  0.0844,  0.2337,\n",
            "          0.1786, -0.1256,  0.1937,  0.0025, -0.0606,  0.1130, -0.1687, -0.0868,\n",
            "         -0.1156, -0.1227, -0.0372, -0.0252,  0.2775, -0.0026,  0.0448,  0.0146,\n",
            "          0.0772, -0.0384, -0.1920, -0.0377,  0.0279, -0.1890, -0.0866,  0.0189,\n",
            "          0.0167,  0.1522, -0.0253, -0.3246,  0.0072,  0.0925, -0.0415,  0.1310,\n",
            "          0.0663,  0.0124,  0.2121, -0.0368,  0.0283, -0.0451,  0.0887, -0.0371,\n",
            "          0.1911,  0.1399,  0.0487, -0.2064,  0.0478, -0.2264, -0.2231, -0.2475,\n",
            "          0.0070,  0.0318, -0.2185, -0.1098,  0.0885, -0.1464,  0.1276,  0.0344,\n",
            "          0.0033,  0.1314,  0.0427, -0.0276, -0.0041, -0.0503, -0.1120,  0.1521,\n",
            "         -0.1280,  0.1220,  0.1552, -0.1247,  0.1703, -0.1492,  0.1893, -0.0200,\n",
            "          0.0865,  0.1462,  0.0766,  0.1796,  0.1079,  0.2008,  0.2185,  0.0284,\n",
            "          0.1212,  0.0042, -0.0650, -0.0880, -0.1797, -0.0926,  0.0209, -0.1576,\n",
            "          0.0983, -0.1223, -0.0664,  0.0981,  0.1752, -0.1676, -0.0837,  0.0583,\n",
            "         -0.1744, -0.0127, -0.0308,  0.0959,  0.1038, -0.0150,  0.0050, -0.0480,\n",
            "         -0.1735, -0.1334, -0.0089, -0.0285, -0.1019, -0.0230, -0.1757, -0.0372,\n",
            "         -0.2791,  0.1120, -0.1313,  0.2432, -0.0008, -0.2080, -0.1227, -0.0016,\n",
            "         -0.1355,  0.1937,  0.2146,  0.0630, -0.0796,  0.0138,  0.0173,  0.0976,\n",
            "          0.1504,  0.1027,  0.0205, -0.0292, -0.0328,  0.1508, -0.2294,  0.0033,\n",
            "         -0.0087,  0.0702,  0.0156, -0.1429, -0.0511,  0.2453, -0.0060,  0.0011,\n",
            "         -0.2356, -0.1691, -0.0929,  0.1890,  0.0194, -0.2466,  0.1512, -0.0523,\n",
            "         -0.2669, -0.0326,  0.0836,  0.1724, -0.1784, -0.1417,  0.1410, -0.1043,\n",
            "          0.0704, -0.1058,  0.2582,  0.0902,  0.1411,  0.1818, -0.1448, -0.0584,\n",
            "          0.0029,  0.0588, -0.1969, -0.1533,  0.0232, -0.0885, -0.0192,  0.1702,\n",
            "         -0.2241,  0.1808,  0.1993,  0.0310, -0.0132, -0.0445,  0.1099,  0.2041,\n",
            "          0.0245,  0.0164,  0.1023,  0.0806, -0.0543, -0.0636,  0.2025, -0.0304,\n",
            "         -0.1552,  0.0483,  0.0130, -0.0823,  0.0751, -0.0511, -0.0698,  0.1484,\n",
            "          0.1491,  0.1078,  0.1228,  0.0344, -0.0640,  0.1664,  0.1773,  0.0115,\n",
            "          0.1777, -0.0077,  0.0133, -0.1703, -0.0779, -0.0624,  0.1196,  0.0061,\n",
            "         -0.0604,  0.0616,  0.2508,  0.1099,  0.0077, -0.0231,  0.2111,  0.1567,\n",
            "          0.0621,  0.0384, -0.0121, -0.0473, -0.0134, -0.0819, -0.2754, -0.2530,\n",
            "          0.2018,  0.0089, -0.1228,  0.0392,  0.1381, -0.1079, -0.1969, -0.0201,\n",
            "          0.0720,  0.1567,  0.0630,  0.2135,  0.0106, -0.0317,  0.0421,  0.0714,\n",
            "         -0.0725,  0.1874, -0.1097, -0.0643, -0.1583,  0.0730,  0.0679, -0.1846,\n",
            "          0.0654, -0.0519,  0.0354,  0.0985, -0.2054, -0.1123, -0.1373,  0.2176,\n",
            "          0.0996,  0.1325, -0.0261,  0.1182,  0.1153, -0.2160,  0.0076,  0.0251,\n",
            "         -0.0203, -0.0711,  0.1564,  0.1258, -0.0659,  0.2504, -0.0728, -0.1585,\n",
            "         -0.0612,  0.0678, -0.0152,  0.1454,  0.0604, -0.1155, -0.0621,  0.0053,\n",
            "          0.0308, -0.0865, -0.1096,  0.0694, -0.1121,  0.0942, -0.1387, -0.1362,\n",
            "         -0.0296, -0.0410, -0.1927, -0.0857, -0.0551,  0.1869,  0.0606, -0.0982,\n",
            "         -0.2307, -0.1333, -0.1551, -0.1093, -0.1486, -0.0110,  0.1055, -0.0365,\n",
            "         -0.1291,  0.1066,  0.0952,  0.1042, -0.1175, -0.0517,  0.0805,  0.0427,\n",
            "          0.0768, -0.1901, -0.1223,  0.2601, -0.1506,  0.1489,  0.0918, -0.1482,\n",
            "          0.1842,  0.0963,  0.0376,  0.0862,  0.1611, -0.1045, -0.1358, -0.0444,\n",
            "         -0.0776,  0.0007, -0.0887,  0.0721, -0.0624, -0.1348, -0.1978,  0.2265,\n",
            "          0.0403, -0.1261, -0.0859,  0.0829, -0.1819, -0.2142,  0.0308,  0.1359,\n",
            "          0.0784, -0.0574,  0.0988, -0.1157, -0.0734,  0.0754,  0.0484, -0.2519,\n",
            "          0.1459, -0.0580,  0.0332, -0.1225, -0.0885,  0.0853,  0.0428, -0.1313,\n",
            "         -0.0751, -0.1710, -0.1503, -0.0983,  0.0395, -0.0011,  0.0709, -0.2314,\n",
            "         -0.0581, -0.2562, -0.1962, -0.1042,  0.2206,  0.1166, -0.1710, -0.0983,\n",
            "         -0.1592,  0.0989, -0.0330, -0.0469,  0.0388, -0.0890, -0.2319,  0.1252,\n",
            "          0.1107, -0.1724, -0.2806,  0.1644, -0.1878, -0.0391, -0.1426, -0.0725,\n",
            "         -0.1483,  0.1484, -0.0746, -0.0727, -0.0665,  0.1022, -0.0270, -0.0983,\n",
            "          0.0429, -0.1438, -0.0625,  0.1307,  0.1528,  0.1331, -0.0786, -0.0448]],\n",
            "       grad_fn=<SelectBackward>)\n",
            "Predicted Sentiment : Negative \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9tYsw1wu_lt",
        "outputId": "76ef8c04-6797-45f0-d136-b505ae281098"
      },
      "source": [
        "twt=\"This is my first encoder decoder model\"\n",
        "print(f'Tweet : {twt}')\n",
        "print(f'Predicted Sentiment : {classify_tweet(twt)} \\n')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tweet : This is my first encoder decoder model\n",
            "Output of encoder at every step:tensor([[-0.0962,  0.0106, -0.0364,  ...,  0.0622,  0.0169, -0.0738],\n",
            "        [ 0.0962, -0.0580, -0.1003,  ..., -0.0934, -0.0778, -0.1424],\n",
            "        [-0.0245,  0.0443, -0.0313,  ...,  0.0421, -0.0003, -0.1922],\n",
            "        ...,\n",
            "        [-0.0727, -0.0507, -0.1769,  ...,  0.1477,  0.0570, -0.1120],\n",
            "        [-0.1469, -0.0145, -0.2458,  ...,  0.1483,  0.0508, -0.0986],\n",
            "        [-0.1820,  0.0041, -0.2727,  ...,  0.1500,  0.0334, -0.1067]],\n",
            "       grad_fn=<CatBackward>)\n",
            "Output of encoder at last step:tensor([[[-0.1820,  0.0041, -0.2727,  0.0875,  0.1219, -0.0830,  0.2838,\n",
            "          -0.2005, -0.1425,  0.0525,  0.0711,  0.2949, -0.3792,  0.2098,\n",
            "          -0.1306,  0.0744, -0.1069,  0.0665, -0.1161, -0.0232,  0.0521,\n",
            "          -0.1231,  0.2043,  0.1250,  0.3290, -0.2222,  0.2749, -0.0139,\n",
            "          -0.1411, -0.2938, -0.0789, -0.0240, -0.0107, -0.1770, -0.1599,\n",
            "          -0.0317,  0.1608, -0.3691, -0.2762, -0.0548, -0.0264, -0.2416,\n",
            "          -0.1552, -0.1597,  0.1556,  0.1688,  0.1007,  0.0331,  0.0539,\n",
            "           0.3271,  0.0503, -0.0977, -0.0653,  0.0754, -0.1910, -0.1259,\n",
            "          -0.2164, -0.0358, -0.0847, -0.4180,  0.1116, -0.0959,  0.0959,\n",
            "           0.0833, -0.1599, -0.1914,  0.0794,  0.0487,  0.0223, -0.1170,\n",
            "           0.2704,  0.0756,  0.1050,  0.1508, -0.2302,  0.0466, -0.2828,\n",
            "          -0.0425,  0.3387, -0.2007,  0.3527,  0.1020, -0.2005, -0.1817,\n",
            "           0.0817,  0.1645,  0.3655, -0.2624, -0.2200,  0.2972,  0.0930,\n",
            "          -0.1071,  0.0038,  0.1856,  0.2190, -0.0147, -0.0766, -0.1304,\n",
            "           0.2302, -0.0281,  0.0193,  0.1264,  0.0945,  0.0725,  0.1404,\n",
            "          -0.0585, -0.0151,  0.2261, -0.1805, -0.0611, -0.1494, -0.0896,\n",
            "           0.0444,  0.0594, -0.1597, -0.1642, -0.1016, -0.4109,  0.0174,\n",
            "          -0.0853,  0.0333, -0.0465, -0.2694, -0.5091, -0.1437,  0.1170,\n",
            "          -0.2815, -0.0686,  0.0517, -0.3802,  0.2399,  0.0207,  0.0403,\n",
            "           0.0908,  0.1393, -0.0900,  0.0350, -0.0363,  0.0988, -0.0752,\n",
            "          -0.0505, -0.2181, -0.1931, -0.4477,  0.0749, -0.0142, -0.0701,\n",
            "           0.0348,  0.0688, -0.0642, -0.1288, -0.0724,  0.1323,  0.1994,\n",
            "           0.0328,  0.1868, -0.0425,  0.0590, -0.0459,  0.1235, -0.2268,\n",
            "           0.1713, -0.1320,  0.0565,  0.1436, -0.1250,  0.1500,  0.1199,\n",
            "          -0.2891, -0.1282,  0.0747, -0.2034,  0.1185, -0.0124,  0.0262,\n",
            "          -0.0247,  0.0911, -0.1578,  0.2570, -0.0099,  0.2349, -0.0755,\n",
            "           0.1136,  0.1764,  0.2184, -0.1144, -0.0897, -0.0768,  0.2242,\n",
            "          -0.0725, -0.1682,  0.0415,  0.0133, -0.3178, -0.1940,  0.1796,\n",
            "          -0.0665,  0.0713,  0.2624, -0.0394, -0.4096, -0.0199,  0.0861,\n",
            "          -0.0216, -0.2831,  0.1960, -0.1711, -0.3075, -0.2359,  0.0902,\n",
            "          -0.4194,  0.2433, -0.1723,  0.0226,  0.2677,  0.1792, -0.1692,\n",
            "           0.2740,  0.1172,  0.0136, -0.2742, -0.1083,  0.1978,  0.2899,\n",
            "           0.3749, -0.1622, -0.1753,  0.0277, -0.3486, -0.1705, -0.1401,\n",
            "           0.2465, -0.0397, -0.2198,  0.0973, -0.1433, -0.2285,  0.3161,\n",
            "           0.0273,  0.2474, -0.3225,  0.3055, -0.1450,  0.1565, -0.0817,\n",
            "          -0.2096, -0.1053, -0.1771, -0.0922, -0.0074,  0.2228,  0.1220,\n",
            "           0.0885,  0.1125,  0.2607, -0.1014,  0.0733, -0.0058,  0.1988,\n",
            "          -0.0404,  0.1653,  0.0683, -0.2676,  0.0891,  0.0733,  0.1770,\n",
            "          -0.0990,  0.0043,  0.0530,  0.0542,  0.1071,  0.0933,  0.0073,\n",
            "          -0.0313, -0.0884, -0.0286, -0.0284, -0.3054,  0.0719,  0.0873,\n",
            "           0.0451,  0.2034,  0.0044,  0.3388,  0.0750,  0.1531, -0.1396,\n",
            "           0.2696, -0.0266, -0.1167,  0.0653, -0.0421,  0.2671, -0.2895,\n",
            "           0.1762,  0.0664,  0.1450,  0.2725, -0.0927, -0.2366, -0.3138,\n",
            "           0.0434, -0.0879,  0.0069,  0.1818,  0.0203,  0.1944, -0.1680,\n",
            "          -0.4122,  0.2464, -0.1357,  0.2604, -0.1709,  0.0865,  0.0374,\n",
            "           0.0414, -0.1250, -0.0829,  0.0517,  0.0952, -0.0547,  0.0550,\n",
            "          -0.1386, -0.3326, -0.0736, -0.0327, -0.0173, -0.0195,  0.3005,\n",
            "          -0.1480, -0.2430, -0.1827, -0.0216, -0.0593, -0.1069,  0.2364,\n",
            "           0.0682, -0.0610, -0.1592,  0.1584,  0.1372,  0.0591, -0.1618,\n",
            "           0.2051, -0.0348,  0.2053, -0.1058,  0.0318, -0.2557, -0.0755,\n",
            "           0.0072, -0.0581,  0.1380,  0.2679, -0.1997, -0.0639,  0.1918,\n",
            "          -0.2729, -0.2864,  0.2225,  0.0689,  0.2131,  0.0991, -0.0145,\n",
            "           0.0254, -0.3550,  0.1522,  0.0006, -0.0410, -0.2799,  0.2831,\n",
            "           0.2868, -0.1003,  0.3250, -0.2316, -0.2267, -0.0441, -0.1920,\n",
            "          -0.1687, -0.1412,  0.3920,  0.1049, -0.4564,  0.1581, -0.0579,\n",
            "          -0.1218,  0.0999, -0.0578,  0.1330, -0.0590, -0.0277,  0.1043,\n",
            "           0.0376,  0.0761,  0.0662, -0.4040,  0.2688,  0.1158,  0.1093,\n",
            "           0.1730, -0.1312,  0.2024, -0.1284,  0.2508, -0.0683,  0.1092,\n",
            "           0.1976,  0.1217, -0.1725,  0.1764,  0.1246,  0.0296, -0.2593,\n",
            "           0.0042,  0.2243,  0.0856,  0.1567, -0.0828, -0.2037,  0.1629,\n",
            "          -0.3733, -0.0734,  0.2563,  0.1321,  0.2596,  0.0863,  0.0660,\n",
            "           0.3283,  0.2542, -0.0781,  0.0416,  0.4799,  0.2338, -0.0706,\n",
            "          -0.1586,  0.0134, -0.0786, -0.1096, -0.1810, -0.0683,  0.0308,\n",
            "          -0.1790,  0.0467,  0.0254, -0.0817, -0.2284, -0.0715, -0.0218,\n",
            "          -0.0672, -0.2440, -0.0472, -0.1084, -0.0070, -0.0150,  0.1454,\n",
            "          -0.1934, -0.1277, -0.0602, -0.1147,  0.0380, -0.2961,  0.2289,\n",
            "          -0.1854,  0.0147,  0.1643,  0.0813, -0.2615, -0.0012, -0.0444,\n",
            "           0.0946,  0.0582, -0.1531,  0.0147, -0.1285, -0.0591,  0.1583,\n",
            "           0.2407, -0.0247, -0.3026, -0.2349,  0.0701, -0.0455,  0.0840,\n",
            "           0.1728, -0.1874, -0.3912, -0.3209,  0.2056, -0.0662,  0.0734,\n",
            "          -0.3728,  0.1429, -0.1442,  0.2786, -0.0866,  0.0923,  0.1747,\n",
            "           0.0372,  0.0335, -0.2010,  0.1581, -0.1034,  0.2334,  0.0621,\n",
            "          -0.1111,  0.4919, -0.2373, -0.0934, -0.0942,  0.1500,  0.0334,\n",
            "          -0.1067]]], grad_fn=<StackBackward>)\n",
            "Output of decoder at every step (Note that here it is single step):tensor([[-1.2066e-01,  7.7671e-02, -2.3179e-01,  1.4375e-01,  9.7331e-02,\n",
            "         -4.2643e-02,  2.3563e-01, -1.2304e-01, -5.9374e-02, -3.1898e-02,\n",
            "          5.6364e-02,  1.7877e-01, -1.5927e-01,  1.5977e-01, -5.9345e-02,\n",
            "          1.0131e-01,  2.4895e-02,  1.0570e-02, -1.1962e-02,  4.7914e-02,\n",
            "          4.4515e-02, -3.6491e-02,  1.1511e-01,  8.8573e-02,  1.1362e-01,\n",
            "         -1.4119e-01,  2.2548e-01, -6.1644e-02, -1.4188e-01, -1.7983e-01,\n",
            "          1.7372e-04,  3.6196e-02,  1.4463e-02, -6.1460e-02, -9.5649e-02,\n",
            "          5.8660e-03,  1.6197e-01, -1.9400e-01, -1.5269e-01, -1.5182e-01,\n",
            "          6.5409e-02, -1.2776e-01, -9.2744e-02, -6.6333e-02,  6.0113e-02,\n",
            "          8.7706e-03,  1.8188e-02,  1.8721e-01, -1.8941e-02,  2.0915e-01,\n",
            "          6.9569e-02, -9.2906e-02, -7.2737e-02,  1.7175e-01, -1.8765e-01,\n",
            "         -1.0041e-01, -6.5953e-02,  7.9420e-02,  1.7379e-02, -2.4868e-01,\n",
            "         -1.3973e-02, -1.7643e-01,  3.1263e-03,  9.4146e-02, -1.2207e-01,\n",
            "         -6.5191e-02,  9.1999e-02,  8.4523e-02,  2.2004e-03,  1.8982e-02,\n",
            "          1.3861e-01,  7.9637e-02, -3.8142e-02,  3.4088e-02, -1.4710e-01,\n",
            "          4.7680e-03, -2.2496e-01, -9.2380e-02,  2.7360e-01, -1.1842e-01,\n",
            "          1.4960e-01,  4.8421e-02, -1.8508e-01, -1.8641e-01,  7.7392e-02,\n",
            "          1.0494e-01,  2.0597e-01, -1.2908e-01, -1.5257e-01,  1.8180e-01,\n",
            "          2.0617e-02, -1.0115e-01, -5.1534e-02,  5.0156e-02,  1.6563e-01,\n",
            "          1.0534e-01,  7.8835e-02, -1.0114e-01,  1.5302e-01,  2.9484e-03,\n",
            "          1.2543e-02,  1.2227e-01,  2.5666e-02,  7.6324e-03, -4.0190e-02,\n",
            "          2.1141e-02, -8.5508e-02,  1.8020e-01,  6.4411e-03,  4.2903e-02,\n",
            "         -1.3630e-01,  8.4224e-02,  7.6246e-02,  2.5020e-02, -1.8961e-01,\n",
            "         -1.0529e-01, -5.0687e-02, -3.5550e-01, -4.6699e-02, -5.2137e-02,\n",
            "         -2.7159e-02,  1.0077e-01, -4.6762e-02, -3.2892e-01, -2.5506e-02,\n",
            "          9.8629e-02, -1.7152e-01,  3.8672e-02, -5.3312e-02, -1.7975e-01,\n",
            "          2.1846e-01, -4.1125e-02,  2.4413e-02,  5.3253e-02,  1.2067e-01,\n",
            "         -9.9259e-02,  2.3862e-02,  4.0491e-02,  1.0247e-01, -7.2928e-02,\n",
            "          4.6482e-02, -1.8390e-01, -1.5637e-01, -2.1608e-01, -3.7132e-02,\n",
            "         -3.8594e-02, -1.1266e-01, -3.8280e-02,  2.4652e-02, -7.7693e-02,\n",
            "         -5.6508e-02,  9.4678e-03,  1.0413e-01,  3.5772e-02, -1.3512e-02,\n",
            "          6.6805e-02, -1.3016e-01, -6.1613e-02, -5.9085e-02,  1.1429e-01,\n",
            "         -8.4691e-02,  1.0099e-01, -6.0654e-02, -7.8029e-02,  2.0425e-01,\n",
            "         -9.9384e-02,  1.1377e-01,  1.0545e-01, -6.4835e-02,  4.2554e-02,\n",
            "          9.1685e-02, -6.0583e-02,  1.1273e-01,  4.4705e-02,  7.5762e-02,\n",
            "          3.2212e-02, -9.7875e-04, -7.8355e-02,  9.7307e-02, -4.2653e-02,\n",
            "          6.5475e-02, -4.0850e-02,  5.6750e-02,  3.7189e-02,  1.8134e-01,\n",
            "         -1.1997e-01, -3.2777e-02, -1.3922e-01,  1.3502e-01, -2.0344e-02,\n",
            "         -1.2626e-01,  6.5200e-03,  1.0287e-02, -1.9509e-01, -1.9650e-02,\n",
            "          1.7868e-01,  3.1094e-02,  9.2414e-02,  1.3955e-01, -4.8278e-02,\n",
            "         -1.9290e-01, -4.8921e-02,  5.8072e-02, -1.9849e-02, -1.0048e-01,\n",
            "          5.0269e-02, -1.1720e-01, -1.8452e-01, -2.5063e-01,  2.1443e-03,\n",
            "         -2.0786e-01,  1.6693e-01, -1.4836e-01, -1.5303e-02,  7.5928e-02,\n",
            "          7.0309e-02, -2.2178e-01,  1.8682e-01,  1.3492e-01,  3.7593e-02,\n",
            "         -1.6618e-01, -2.0724e-02,  1.7096e-01,  1.4378e-01,  2.2556e-01,\n",
            "         -5.0912e-02, -5.3285e-02, -7.4800e-02, -1.7917e-01, -1.9656e-02,\n",
            "         -1.3871e-01,  9.9870e-02,  1.6207e-02, -3.0161e-02,  4.9935e-03,\n",
            "         -1.2393e-01, -1.6296e-01,  2.6255e-01, -3.0943e-02,  1.2077e-03,\n",
            "         -2.2155e-01,  9.0503e-02, -8.3956e-02,  1.2393e-01,  5.4880e-03,\n",
            "         -1.6139e-01, -9.2216e-02, -1.3053e-01, -1.3354e-01,  6.9306e-03,\n",
            "          1.2286e-01,  1.3400e-01,  7.1534e-02,  1.1923e-02,  1.2388e-01,\n",
            "         -9.8124e-02,  1.1021e-01, -3.5943e-02,  2.5443e-01,  2.6376e-02,\n",
            "          2.1254e-01,  1.5780e-01, -1.5471e-01, -4.8106e-02,  3.1452e-02,\n",
            "          1.1641e-01, -3.0316e-02, -1.2301e-01,  7.2582e-02, -4.1080e-02,\n",
            "          1.2817e-02,  1.0402e-01, -6.6585e-02,  4.4689e-02,  5.8937e-02,\n",
            "         -6.6936e-02, -2.1992e-02, -1.4788e-01,  2.1383e-02,  1.0248e-01,\n",
            "          5.3598e-02,  9.7469e-02,  1.1245e-01,  8.3706e-02,  2.3734e-02,\n",
            "          1.3872e-02, -5.3633e-02,  1.6226e-01, -1.0610e-01, -2.1902e-02,\n",
            "          3.9825e-02, -5.3975e-02,  1.8947e-01, -2.7188e-01,  9.6641e-03,\n",
            "          1.3091e-01,  1.0499e-01,  1.6619e-01, -2.6185e-02, -1.7414e-01,\n",
            "         -2.6750e-01,  8.2578e-02,  1.7590e-02, -3.1195e-02,  1.5116e-01,\n",
            "         -4.4262e-02,  5.9027e-02, -8.7610e-02, -1.6710e-01,  1.2258e-01,\n",
            "         -2.2641e-02,  1.7562e-01, -1.2415e-01,  1.1904e-01,  7.5226e-02,\n",
            "          1.3842e-01, -4.6921e-02,  2.2564e-02,  1.0065e-01,  6.3757e-02,\n",
            "         -1.0067e-01,  1.3708e-02, -1.0817e-01, -2.1227e-01, -9.4950e-02,\n",
            "         -1.8335e-02, -9.3249e-02, -6.5392e-02,  2.6102e-01, -5.3682e-02,\n",
            "         -1.1539e-01, -1.6876e-01,  7.1687e-02, -1.6961e-01, -6.0861e-02,\n",
            "          2.4135e-02,  8.8153e-02,  3.4940e-02, -6.5242e-02,  1.0091e-01,\n",
            "          8.7572e-02, -1.3348e-02, -1.0300e-01,  1.8295e-01, -6.4332e-02,\n",
            "          1.2941e-01, -1.8509e-01,  1.6539e-02, -2.2106e-01, -7.0304e-02,\n",
            "         -5.4937e-03, -3.7416e-02,  1.1877e-01,  8.9017e-02, -8.5153e-02,\n",
            "         -1.6218e-02,  1.3406e-02, -1.3655e-01, -2.0692e-01,  2.3522e-01,\n",
            "          1.5654e-01,  1.7923e-01,  1.1982e-02,  9.1910e-02,  9.6350e-02,\n",
            "         -2.2242e-01,  9.6799e-02, -5.2551e-02, -5.8984e-02, -2.5056e-01,\n",
            "          2.3526e-01,  1.7135e-01, -3.5340e-02,  1.9803e-01, -1.8717e-01,\n",
            "         -1.3651e-01, -8.8818e-02, -1.1164e-01, -7.3298e-02, -5.6571e-02,\n",
            "          1.1465e-01, -1.2239e-02, -1.6930e-01,  1.0594e-01, -1.3220e-02,\n",
            "         -1.3140e-01,  6.3833e-02, -1.7248e-02,  1.1378e-02,  3.2962e-02,\n",
            "         -5.1624e-02,  6.3017e-02, -3.3631e-02, -2.5487e-02, -9.3482e-02,\n",
            "         -1.5178e-01,  1.0329e-01,  1.1340e-01,  4.8150e-02,  9.4974e-04,\n",
            "         -1.6368e-01,  4.3394e-02, -1.3576e-01,  2.3501e-01, -4.2285e-02,\n",
            "          1.6863e-02,  8.5733e-02,  1.5095e-02, -1.1474e-01,  7.5245e-02,\n",
            "          1.2170e-01,  2.6977e-02, -1.5722e-01,  7.6715e-02,  1.7044e-01,\n",
            "          4.8246e-02,  4.8169e-02, -9.6314e-02, -1.0826e-01,  1.7994e-01,\n",
            "         -2.2409e-01, -1.1030e-02,  1.7859e-01, -2.3757e-02,  2.3040e-01,\n",
            "          7.8034e-02,  1.6239e-02,  2.0133e-01,  2.4564e-01, -1.2268e-01,\n",
            "         -6.7000e-02,  3.3751e-01,  9.7954e-02,  8.4613e-03, -9.8971e-02,\n",
            "         -5.9675e-02, -1.2967e-02, -9.9386e-02, -1.5370e-01,  2.3057e-02,\n",
            "         -6.2523e-02, -5.8424e-02,  1.1392e-02,  6.4754e-02, -9.0974e-02,\n",
            "         -2.3496e-01, -1.0509e-02,  7.1352e-02, -6.4183e-03, -2.1537e-01,\n",
            "         -6.3051e-02, -6.3968e-02,  5.0366e-02,  4.8721e-02,  3.5464e-02,\n",
            "         -2.0044e-01, -1.2672e-02, -3.6185e-02, -6.9501e-02, -6.9537e-02,\n",
            "         -2.0798e-01,  1.1946e-01, -1.0847e-02,  3.1464e-02,  2.7110e-02,\n",
            "          5.7796e-02, -2.0247e-01, -2.5344e-02, -4.9050e-02, -3.3723e-02,\n",
            "          1.0688e-01, -1.8436e-01,  2.3832e-02, -1.6098e-01, -1.1543e-01,\n",
            "          9.2690e-02,  1.9284e-01,  5.1996e-02, -1.6035e-01, -1.3120e-01,\n",
            "         -1.8242e-02,  3.9391e-02,  1.4322e-01,  6.0831e-02, -1.3300e-01,\n",
            "         -2.0077e-01, -3.1100e-01,  4.7000e-03,  2.4164e-02, -1.0796e-02,\n",
            "         -2.1305e-01,  1.7628e-01, -1.3219e-01,  1.9059e-01, -1.2309e-01,\n",
            "         -3.2666e-02,  5.8362e-02,  8.8684e-02,  5.3138e-02, -1.5385e-01,\n",
            "          8.7873e-02, -3.6832e-02,  1.7751e-01, -6.3538e-02, -7.0660e-02,\n",
            "          1.1040e-01, -5.2613e-02, -6.6905e-02,  1.9143e-02,  1.0706e-01,\n",
            "          5.6451e-02, -3.0441e-02]], grad_fn=<SelectBackward>)\n",
            "Predicted Sentiment : Negative \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHymV6GtXT5s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}